<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 60]
- [cs.CL](#cs.CL) [Total: 67]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning](https://arxiv.org/abs/2602.11236)
*Yandan Yang,Shuang Zeng,Tong Lin,Xinyuan Chang,Dekang Qi,Junjin Xiao,Haoyun Liu,Ronghan Chen,Yuzhi Chen,Dongjie Huo,Feng Xiong,Xing Wei,Zhiheng Ma,Mu Xu*

Main category: cs.CV

TL;DR: 介绍ABot-M0框架，通过系统化数据处理与统一预训练构建通用机器人智能，并提出基于低维流形的动作预测方法AML与双流感知机制。


<details>
  <summary>Details</summary>
Motivation: 解决机器人领域碎片化数据、不一致表示和训练目标错位的问题，需在多样化硬件上构建通用具身智能。

Method: 1) 构建UniACT数据集：整合6个数据集并清洗标准化；2) 统一预训练；3) 动作流形学习(AML)：基于DiT模型预测低维连续动作；4) 双流感知：融合VLM语义与3D模块模块化处理三维空间信息。

Result: 1) UniACT包含600万轨迹/9500小时数据；2) 统一预训练提升跨任务迁移能力；3) AML提高动作解码速度和策略稳定性；4) 双流机制缓解VLM三维推理限制；5) 组件效果可叠加验证。

Conclusion: ABot-M0通过系统化方法实现多硬件通用机器人智能，提出的动作流形假设和双流架构有效，代码与数据开放促进未来研究。

Abstract: Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies, enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis: effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit, enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.

</details>


### [2] [Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models](https://arxiv.org/abs/2602.11244)
*Sethuraman T,Savya Khosla,Aditi Tiwari,Vidya Ganesh,Rakshana Jayaprakash,Aditya Jain,Vignesh Srinivasakumar,Onkar Kishor Susladkar,Srinidhi Sunkara,Aditya Shanmugham,Rakesh Vaideeswaran,Abbaas Alif Mohamed Nishar,Simon Jenni,Derek Hoiem*

Main category: cs.CV

TL;DR: 视频-语言模型（VidLMs）在处理视频内容、时序性和动态特征上存在显著缺陷，尽管这些是视频理解的核心要素。


<details>
  <summary>Details</summary>
Motivation: 研究VidLMs是否能稳健地捕捉视频内容、时序结构和动态信息，并揭示其对语言简捷路径和时空干扰的依赖性。

Method: 提出REVEAL基准测试，包含5项受控压力测试：评估时序预期偏差、语言捷径效应、视频附和倾向、镜头运动敏感度以及时空遮挡鲁棒性，并通过自动化数据流水线生成诊断样例。

Result: 测试显示VidLMs存在：①将倒放场景误判为正向场景 ②忽略视频内容直接作答 ③附和错误断言 ④无法处理基础镜头运动 ⑤在时空遮挡下时序聚合失效。人类在相同任务中超90%准确率，显著优于模型表现。

Conclusion: 当前VidLMs的基础视频理解能力存在重大局限性，需针对性改进时序建模与多模态对齐。公开基准与代码为后续研究提供可扩展的评估框架。

Abstract: This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.

</details>


### [3] [Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking](https://arxiv.org/abs/2602.11314)
*Jacob Rubinstein,Avi Donaty,Don Engel*

Main category: cs.CV

TL;DR: 本论文提出了一种通过合成图像和程序生成的相机姿态进行3D重建的定量实验框架，解决了传统摄影测量方法评估主观化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有摄影测量数字孪生生成方法缺乏可重复的量化评估标准，无法精准对比真实参数与重建结果差异。

Method: 构建虚拟3D模型与合成图像生成管线，程序化控制相机参数并执行重建算法，实现参数可调的闭环测试环境。

Result: 展示了该框架在重建精度量化分析的有效性，能够系统性检测不同重建算法对相机参数扰动的鲁棒性。

Conclusion: 该定量评估框架为数字孪生技术优化提供了可操作的验证标准，验证了重建误差与初始参数灵敏度的关联性。

Abstract: The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.

</details>


### [4] [Selective Prior Synchronization via SYNC Loss](https://arxiv.org/abs/2602.11316)
*Ishan Mishra,Jiajie Li,Deepak Mishra,Jinjun Xiong*

Main category: cs.CV

TL;DR: 本研究提出SYNC损失，结合了选择性预测中的adhoc（如SelectiveNet）和post-hoc（如Softmax响应）方法，通过在训练阶段整合不确定性信息（选择性先验）提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅利用选择性先验进行推断，忽视其在训练中的作用；作者认为同时结合结构设计和概率输出能更有效提升不确定性建模能力。

Method: 设计SYNC损失函数，将Softmax概率响应显式引入SelectiveNet的训练过程，通过联合优化置信度估计和分类任务，强化不确定性感知能力。

Result: 在CIFAR-100、ImageNet-100等数据集上超越现有方法，同时提升模型泛化能力和选择性预测指标（如AUROC、AUCPR）。

Conclusion: 训练阶段整合显式不确定性引导可增强模型可靠性，为选择性预测任务提供了新的范式框架。

Abstract: Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.

</details>


### [5] [MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors](https://arxiv.org/abs/2602.11323)
*Arda Alniak,Sinan Kalkan,Mustafa Mert Ankarali,Afsar Saranli,Abdullah Aydin Alatan*

Main category: cs.CV

TL;DR: 本研究提出一种改进的单目视觉惯性里程方案，通过将深度先验知识整合到优化后端，结合仿射不变约束和序数约束，在边缘设备上实现稳定精确的定位。


<details>
  <summary>Details</summary>
Motivation: 传统单目VIO系统在低纹理环境中因视觉特征过少导致定位不准，而现有深度估计模型计算量过大难以实时部署。

Method: 将深度先验融入VINS-Mono优化框架，通过引入仿射不变深度一致性、成对序数约束及方差门控机制，过滤异常值并保持计算效率。

Result: 在TartanGround和M3ED数据集上实现28.3%的绝对轨迹误差降低，在复杂场景中有效抑制结果发散。

Conclusion: 该方法通过融合深度估计先验与优化模型，在保证实时性前提下显著提升低纹理环境下的定位鲁棒性。

Abstract: Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.

</details>


### [6] [Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content](https://arxiv.org/abs/2602.11339)
*Evgeney Bogatyrev,Khaled Abud,Ivan Molodetskikh,Nikita Alutis,Dmitry Vatolin*

Main category: cs.CV

TL;DR: 提出了一种高效的实时超分辨率模型EfRLFN，并构建了首个面向流媒体视频超分辨率的综合数据集StreamSR，解决了压缩视频内容在实时超分辨率中的质量与效率瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率方法在压缩流媒体视频场景下表现不足，且主流数据集无法反映实际流媒体特性，导致模型效果受限。

Method: 1) 构建涵盖YouTube多类型/分辨率视频的StreamSR数据集；2) 提出EfRLFN模型，融合高效通道注意力机制和双曲正切激活函数；3) 通过架构优化与复合损失函数设计提升效率与训练收敛性；4) 验证StreamSR对现有模型的泛化能力。

Result: 1) EfRLFN在视觉质量与运行效率上优于现有模型；2) 微调其他模型可获得显著性能提升；3) 所有数据与代码公开（GitHub）。

Conclusion: StreamSR数据集填补流媒体视频超分场景空白，EfRLFN模型通过架构创新实现了实时性与质量的平衡，证明了数据驱动优化的有效性。

Abstract: Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.
  Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.
  Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.

</details>


### [7] [ArtContext: Contextualizing Artworks with Open-Access Art History Articles and Wikidata Knowledge through a LoRA-Tuned CLIP Model](https://arxiv.org/abs/2602.11349)
*Samuel Waugh,Stuart James*

Main category: cs.CV

TL;DR: ArtContext是一个利用开放获取艺术史文档和Wikidata为艺术品添加上下文注解的新方法，通过改进CLIP模型实现更精准的艺术品分析。


<details>
  <summary>Details</summary>
Motivation: 传统艺术史研究中难以关联特定艺术作品与其相关文献分析，特别是针对作品的版式、图像学等细节要素。

Method: 构建艺术史语料库收集流程；采用低秩适应(LoRA)技术调整CLIP模型；通过弱监督学习建立绘画领域专用模型PaintingCLIP

Result: PaintingCLIP在艺术作品上下文理解任务中表现优于基线模型CLIP，成功实现了跨文档与艺术品的精准关联

Conclusion: 提出的方法不仅适用于艺术史领域，还可推广至人文学科的其他研究领域，为文化内容分析提供新范式

Abstract: Many Art History articles discuss artworks in general as well as specific parts of works, such as layout, iconography, or material culture. However, when viewing an artwork, it is not trivial to identify what different articles have said about the piece. Therefore, we propose ArtContext, a pipeline for taking a corpus of Open-Access Art History articles and Wikidata Knowledge and annotating Artworks with this information. We do this using a novel corpus collection pipeline, then learn a bespoke CLIP model adapted using Low-Rank Adaptation (LoRA) to make it domain-specific. We show that the new model, PaintingCLIP, which is weakly supervised by the collected corpus, outperforms CLIP and provides context for a given artwork. The proposed pipeline is generalisable and can be readily applied to numerous humanities areas.

</details>


### [8] [Latent Forcing: Reordering the Diffusion Trajectory for Pixel-Space Image Generation](https://arxiv.org/abs/2602.11401)
*Alan Baade,Eric Ryan Chan,Kyle Sargent,Changan Chen,Justin Johnson,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: Latent Forcing改进了潜在扩散模型的结构，在保持效率的同时直接操作原始图像，通过联合处理潜在变量和像素并优化噪声调度，在ImageNet上实现了新的扩散Transformer生成效果SOTA。


<details>
  <summary>Details</summary>
Motivation: 作者旨在克服潜在扩散模型（LDMs）丢失端到端建模优势的问题，包括编码信息丢失、依赖独立解码器以及建模辅助分布等限制，同时保留其计算效率。

Method: 提出Latent Forcing框架：联合处理潜在变量和像素并采用分开的噪声调度策略，使潜在变量在生成高频像素前作为中间计算存储空间；通过调整条件信号顺序和分析Tokenizer与扩散模型的关系优化生成质量。

Result: 实现了条件/无条件图像生成的任务性能提升，在ImageNet数据集上基于Transformer的像素生成效果达到同类方法的最新SOTA。

Conclusion: 该方法通过条件信号调度机制桥接了潜在扩散与端到端建模的优势，揭示了Tokenizer重建质量与扩散能力的相关性，并阐明了REPA蒸馏等技术在不同模块中的作用差异。

Abstract: Latent diffusion models excel at generating high-quality images but lose the benefits of end-to-end modeling. They discard information during image encoding, require a separately trained decoder, and model an auxiliary distribution to the raw data. In this paper, we propose Latent Forcing, a simple modification to existing architectures that achieves the efficiency of latent diffusion while operating on raw natural images. Our approach orders the denoising trajectory by jointly processing latents and pixels with separately tuned noise schedules. This allows the latents to act as a scratchpad for intermediate computation before high-frequency pixel features are generated. We find that the order of conditioning signals is critical, and we analyze this to explain differences between REPA distillation in the tokenizer and the diffusion model, conditional versus unconditional generation, and how tokenizer reconstruction quality relates to diffusability. Applied to ImageNet, Latent Forcing achieves a new state-of-the-art for diffusion transformer-based pixel generation at our compute scale.

</details>


### [9] [Fighting MRI Anisotropy: Learning Multiple Cardiac Shapes From a Single Implicit Neural Representation](https://arxiv.org/abs/2602.11436)
*Carolina Brás,Soufiane Ben Haddou,Thijs P. Kuipers,Laura Alvarez-Florez,R. Nils Planken,Fleur V. Y. Tjong,Connie Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 利用CTA数据训练神经隐式函数，实现心脏CMRI高分辨率形态建模。


<details>
  <summary>Details</summary>
Motivation: 短轴CMRI的各向异性限制了心脏形态分析，需借助近各向同性CTA数据克服传统分辨率限制。

Method: 训练单个神经隐式函数联合表征CMRI心脏形态，通过CTA数据学习并重建任意分辨率的右心室及心肌（含心内膜和心外膜）形状，使用4CH切片与CMRI参考分割验证。

Result: 右心室和心肌的DSC分别为0.91±0.07和0.75±0.13，豪斯多夫距离分别为6.21±3.97mm和7.53±5.13mm，定性与定量分析均显示重建形状的准确性与解剖合理性。

Conclusion: 通过解决分辨率与各向异性问题，该方法有效提升心脏形态分析能力。

Abstract: The anisotropic nature of short-axis (SAX) cardiovascular magnetic resonance imaging (CMRI) limits cardiac shape analysis. To address this, we propose to leverage near-isotropic, higher resolution computed tomography angiography (CTA) data of the heart. We use this data to train a single neural implicit function to jointly represent cardiac shapes from CMRI at any resolution. We evaluate the method for the reconstruction of right ventricle (RV) and myocardium (MYO), where MYO simultaneously models endocardial and epicardial left-ventricle surfaces. Since high-resolution SAX reference segmentations are unavailable, we evaluate performance by extracting a 4-chamber (4CH) slice of RV and MYO from their reconstructed shapes. When compared with the reference 4CH segmentation masks from CMRI, our method achieved a Dice similarity coefficient of 0.91 $\pm$ 0.07 and 0.75 $\pm$ 0.13, and a Hausdorff distance of 6.21 $\pm$ 3.97 mm and 7.53 $\pm$ 5.13 mm for RV and MYO, respectively. Quantitative and qualitative assessment demonstrate the model's ability to reconstruct accurate, smooth and anatomically plausible shapes, supporting improvements in cardiac shape analysis.

</details>


### [10] [Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation](https://arxiv.org/abs/2602.11440)
*Penghui Ruan,Bojia Zi,Xianbiao Qi,Youze Huang,Rong Xiao,Pichao Wang,Jiannong Cao,Yuhui Shi*

Main category: cs.CV

TL;DR: Ctrl&Shift是一种端到端扩散框架，通过两阶段流程实现对象级图像/视频操作，不依赖3D重建而保持几何一致性与背景真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时满足背景保留、视角一致性和用户控制需求：几何方法依赖3D建模且泛化差，扩散方法缺乏细粒度几何控制。

Method: 提出两阶段方案：1)对象移除+显式相机姿态控制；2)参考引导的修复。通过多阶段训练策略分离背景/身份/姿态信号，并设计真实世界数据集生成流程。

Result: 在保真度、视角一致性和可控性上超过现有方法，首个实现无需3D建模的几何一致对象操作框架。

Conclusion: Ctrl&Shift突破了传统方法对显式3D重建的依赖，首次统一了细粒度几何控制与现实世界泛化能力。

Abstract: Object-level manipulation, relocating or reorienting objects in images or videos while preserving scene realism, is central to film post-production, AR, and creative editing. Yet existing methods struggle to jointly achieve three core goals: background preservation, geometric consistency under viewpoint shifts, and user-controllable transformations. Geometry-based approaches offer precise control but require explicit 3D reconstruction and generalize poorly; diffusion-based methods generalize better but lack fine-grained geometric control. We present Ctrl&Shift, an end-to-end diffusion framework to achieve geometry-consistent object manipulation without explicit 3D representations. Our key insight is to decompose manipulation into two stages, object removal and reference-guided inpainting under explicit camera pose control, and encode both within a unified diffusion process. To enable precise, disentangled control, we design a multi-task, multi-stage training strategy that separates background, identity, and pose signals across tasks. To improve generalization, we introduce a scalable real-world dataset construction pipeline that generates paired image and video samples with estimated relative camera poses. Extensive experiments demonstrate that Ctrl&Shift achieves state-of-the-art results in fidelity, viewpoint consistency, and controllability. To our knowledge, this is the first framework to unify fine-grained geometric control and real-world generalization for object manipulation, without relying on any explicit 3D modeling.

</details>


### [11] [Arbitrary Ratio Feature Compression via Next Token Prediction](https://arxiv.org/abs/2602.11494)
*Yufan Liu,Daoyuan Ren,Zhipeng Zhang,Wenyang Luo,Bing Li,Weiming Hu,Stephen Maybank*

Main category: cs.CV

TL;DR: 提出了一种灵活的任意比率特征压缩框架ARFC，通过单个模型支持任意压缩比例并引入两种新模块提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有压缩方法受限于特定模型对固定压缩率的依赖，缺乏灵活性和泛化能力，需重新训练以适应新压缩率。

Method: 核心为自回归模型ARC，通过调节生成token数量控制压缩率；包含混合解决方案（MoS）模块和实体关系图约束（ERGC）机制增强压缩质量与语义保留。

Result: 在跨模态检索、图像分类等任务中，ARFC在多种数据集上显著优于现有方法，部分场景甚至超越原始未压缩特征性能。

Conclusion: ARFC为资源受限场景提供高效解决方案，兼具灵活性、高效性与广泛适用性。

Abstract: Feature compression is increasingly important for improving the efficiency of downstream tasks, especially in applications involving large-scale or multi-modal data. While existing methods typically rely on dedicated models for achieving specific compression ratios, they are often limited in flexibility and generalization. In particular, retraining is necessary when adapting to a new compression ratio. To address this limitation, we propose a novel and flexible Arbitrary Ratio Feature Compression (ARFC) framework, which supports any compression ratio with a single model, eliminating the need for multiple specialized models. At its core, the Arbitrary Ratio Compressor (ARC) is an auto-regressive model that performs compression via next-token prediction. This allows the compression ratio to be controlled at inference simply by adjusting the number of generated tokens. To enhance the quality of the compressed features, two key modules are introduced. The Mixture of Solutions (MoS) module refines the compressed tokens by utilizing multiple compression results (solutions), reducing uncertainty and improving robustness. The Entity Relation Graph Constraint (ERGC) is integrated into the training process to preserve semantic and structural relationships during compression. Extensive experiments on cross-modal retrieval, image classification, and image retrieval tasks across multiple datasets demonstrate that our method consistently outperforms existing approaches at various compression ratios. Notably, in some cases, it even surpasses the performance of the original, uncompressed features. These results validate the effectiveness and versatility of ARFC for practical, resource-constrained scenarios.

</details>


### [12] [What if Agents Could Imagine? Reinforcing Open-Vocabulary HOI Comprehension through Generation](https://arxiv.org/abs/2602.11499)
*Zhenlong Yuan,Xiangyan Qu,Jing Tang,Rui Chen,Lei Sun,Ruidong Chen,Hongwei Yu,Chengxuan Qian,Xiangxiang Chu,Shuo Li,Yuyin Zhou*

Main category: cs.CV

TL;DR: ImagineAgent通过认知推理与生成式想象结合的框架，提升开放词汇人-物交互任务中的视觉理解与跨模态对齐。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在OV-HOI任务中受限于跨模态幻觉和遮挡歧义问题，需通过新型框架增强鲁棒性。

Method: 构建认知图显式建模实体-动作关系，动态调用检索增强、图像裁剪和扩散模型等工具，并设计平衡准确性与效率的复合奖励函数。

Result: 在两个数据集上均实现SOTA性能，仅需现有方法20%的训练数据，验证了方法的高效与鲁棒性。

Conclusion: 基于工具调用与认知推理的框架能有效解决跨模态不匹配问题，显著提升开放场景下的交互理解能力。

Abstract: Multimodal Large Language Models have shown promising capabilities in bridging visual and textual reasoning, yet their reasoning capabilities in Open-Vocabulary Human-Object Interaction (OV-HOI) are limited by cross-modal hallucinations and occlusion-induced ambiguity. To address this, we propose \textbf{ImagineAgent}, an agentic framework that harmonizes cognitive reasoning with generative imagination for robust visual understanding. Specifically, our method innovatively constructs cognitive maps that explicitly model plausible relationships between detected entities and candidate actions. Subsequently, it dynamically invokes tools including retrieval augmentation, image cropping, and diffusion models to gather domain-specific knowledge and enriched visual evidence, thereby achieving cross-modal alignment in ambiguous scenarios. Moreover, we propose a composite reward that balances prediction accuracy and tool efficiency. Evaluations on SWIG-HOI and HICO-DET datasets demonstrate our SOTA performance, requiring approximately 20\% of training data compared to existing methods, validating our robustness and efficiency.

</details>


### [13] [Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis](https://arxiv.org/abs/2602.11536)
*De-Xing Huang,Chaohui Yu,Xiao-Hu Zhou,Tian-Yu Xiang,Qin-Yi Zhang,Mei-Jiang Gui,Rui-Ze Ma,Chen-Yu Wang,Nu-Fang Xiao,Fan Wang,Zeng-Guang Hou*

Main category: cs.CV

TL;DR: 本文提出了一种名为VasoMIM的自监督学习框架，结合大规模数据集XA-170K，有效解决了X射线血管造影分析中数据稀缺的问题，并在多个任务中达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前X射线血管造影深度学习方法受限于标注数据短缺，而自监督学习（SSL）在该领域的发展因缺乏领域适配框架和大规模数据集而受限。

Method: 提出VasoMIM框架，包含解剖引导遮蔽策略（强制模型学习血管语义）和解剖一致性损失（保持重建图像的结构一致性），并构建最大的X射线血管造影预训练数据集XA-170K。

Result: 在6个数据集的4项下游任务验证中，VasoMIM显著优于现有方法，实现领域最优性能，并推动XA-170K数据集公开。

Conclusion: VasoMIM通过引入领域知识设计，为X射线血管造影分析建立了有效基础模型，证明了其在数据稀缺场景下的广泛应用潜力。

Abstract: X-ray angiography is the gold standard imaging modality for cardiovascular diseases. However, current deep learning approaches for X-ray angiogram analysis are severely constrained by the scarcity of annotated data. While large-scale self-supervised learning (SSL) has emerged as a promising solution, its potential in this domain remains largely unexplored, primarily due to the lack of effective SSL frameworks and large-scale datasets. To bridge this gap, we introduce a vascular anatomy-aware masked image modeling (VasoMIM) framework that explicitly integrates domain-specific anatomical knowledge. Specifically, VasoMIM comprises two key designs: an anatomy-guided masking strategy and an anatomical consistency loss. The former strategically masks vessel-containing patches to compel the model to learn robust vascular semantics, while the latter preserves structural consistency of vessels between original and reconstructed images, enhancing the discriminability of the learned representations. In conjunction with VasoMIM, we curate XA-170K, the largest X-ray angiogram pre-training dataset to date. We validate VasoMIM on four downstream tasks across six datasets, where it demonstrates superior transferability and achieves state-of-the-art performance compared to existing methods. These findings highlight the significant potential of VasoMIM as a foundation model for advancing a wide range of X-ray angiogram analysis tasks. VasoMIM and XA-170K will be available at https://github.com/Dxhuang-CASIA/XA-SSL.

</details>


### [14] [Supervise-assisted Multi-modality Fusion Diffusion Model for PET Restoration](https://arxiv.org/abs/2602.11545)
*Yingkai Zhang,Shuang Chen,Ye Tian,Yunyi Gao,Jianyong Jiang,Ying Fu*

Main category: cs.CV

TL;DR: 本文提出了一种监督辅助的多模态融合扩散模型（MFdiff），通过结合PET与MR图像，有效解决低剂量PET图像恢复中的多模态不一致与分布外数据不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有低剂量PET图像恢复方法因多模态数据结构/纹理不一致性和分布外数据不匹配，导致图像质量不足。需探索更鲁棒的跨模态融合机制。

Method: 1) 设计多模态特征融合模块优化特征融合，避免冗余细节；2) 基于扩散模型迭代生成高质量SPET图像；3) 构建双阶段监督策略，结合模拟数据集通用先验与活体OOD数据特异性先验。

Result: MFdiff在定性视觉评估与定量指标（如PSNR、SSIM）上均显著优于现有SOTA方法，成功恢复高分辨率SPET图像。

Conclusion: MFdiff通过创新的多模态融合框架与双阶段监督策略，攻克了跨模态医学图像重建的核心挑战，为低剂量PET成像提供了全新解决方案。

Abstract: Positron emission tomography (PET) offers powerful functional imaging but involves radiation exposure. Efforts to reduce this exposure by lowering the radiotracer dose or scan time can degrade image quality. While using magnetic resonance (MR) images with clearer anatomical information to restore standard-dose PET (SPET) from low-dose PET (LPET) is a promising approach, it faces challenges with the inconsistencies in the structure and texture of multi-modality fusion, as well as the mismatch in out-of-distribution (OOD) data. In this paper, we propose a supervise-assisted multi-modality fusion diffusion model (MFdiff) for addressing these challenges for high-quality PET restoration. Firstly, to fully utilize auxiliary MR images without introducing extraneous details in the restored image, a multi-modality feature fusion module is designed to learn an optimized fusion feature. Secondly, using the fusion feature as an additional condition, high-quality SPET images are iteratively generated based on the diffusion model. Furthermore, we introduce a two-stage supervise-assisted learning strategy that harnesses both generalized priors from simulated in-distribution datasets and specific priors tailored to in-vivo OOD data. Experiments demonstrate that the proposed MFdiff effectively restores high-quality SPET images from multi-modality inputs and outperforms state-of-the-art methods both qualitatively and quantitatively.

</details>


### [15] [Perception-based Image Denoising via Generative Compression](https://arxiv.org/abs/2602.11553)
*Nam Nguyen,Thinh Nguyen,Bella Bose*

Main category: cs.CV

TL;DR: 本文提出一种基于生成压缩框架的感知图像去噪方法，通过低复杂度结构约束和生成解码器（如条件WGAN、扩散模型）实现纹理细节恢复，并提供理论误差证明。


<details>
  <summary>Details</summary>
Motivation: 传统失真驱动去噪方法在强噪声下易导致过度平滑，难以兼顾噪声去除与视觉真实感，需解决率失真感知权衡问题。

Method: 构建生成压缩框架，采用熵编码潜在表征约束结构复杂度；设计两类模型：①控制率失真感知平衡的条件WGAN-CP ②基于压缩潜变量的扩散迭代去噪模型，并推导高斯噪声下的非渐进理论误差界。

Result: 在合成噪声与真实噪声数据集上均实现显式感知质量提升（LPIPS下降27%），同时保持PSNR/SSIM等失真指标与传统方法相当。

Conclusion: 该框架成功将感知度量（LPIPS/WD）与有损编码理论结合，通过生成压缩策略在图像去噪任务中实现更优感知-失真性能平衡，并为逆问题求解提供新理论视角。

Abstract: Image denoising aims to remove noise while preserving structural details and perceptual realism, yet distortion-driven methods often produce over-smoothed reconstructions, especially under strong noise and distribution shift. This paper proposes a generative compression framework for perception-based denoising, where restoration is achieved by reconstructing from entropy-coded latent representations that enforce low-complexity structure, while generative decoders recover realistic textures via perceptual measures such as learned perceptual image patch similarity (LPIPS) loss and Wasserstein distance. Two complementary instantiations are introduced: (i) a conditional Wasserstein GAN (WGAN)-based compression denoiser that explicitly controls the rate-distortion-perception (RDP) trade-off, and (ii) a conditional diffusion-based reconstruction strategy that performs iterative denoising guided by compressed latents. We further establish non-asymptotic guarantees for the compression-based maximum-likelihood denoiser under additive Gaussian noise, including bounds on reconstruction error and decoding error probability. Experiments on synthetic and real-noise benchmarks demonstrate consistent perceptual improvements while maintaining competitive distortion performance.

</details>


### [16] [LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts](https://arxiv.org/abs/2602.11564)
*Chen Zhao,Jiawei Chen,Hongyu Li,Zhuoliang Kang,Shilin Lu,Xiaoming Wei,Kai Zhang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: LUVE is a latent-cascaded framework for ultra-high-resolution video generation that combines motion modeling and dual-frequency expert refinement to address resolution, coherence, and detail challenges.


<details>
  <summary>Details</summary>
Motivation: Ultra-high-resolution video generation faces key challenges in motion modeling, semantic planning, and detail synthesis, which existing methods struggle to address simultaneously due to computational demands and coherence limitations.

Method: LUVE uses a three-stage architecture: (1) low-resolution motion generation for latent synthesis, (2) latent-space upsampling to reduce computation, and (3) dual-frequency expert refinement (low/high-frequency networks) for semantic coherence and detailed textures, with motion priors guiding the process.

Result: The framework achieved superior photorealism and content fidelity in UHR video generation, with ablation studies confirming the effectiveness of its components, including motion modeling and dual-frequency refinement.

Conclusion: LUVE provides a scalable solution for UHR video generation by decoupling motion and content through latent cascading and specialized frequency experts, outperforming prior methods in quality and computational efficiency.

Abstract: Recent advances in video diffusion models have significantly improved visual quality, yet ultra-high-resolution (UHR) video generation remains a formidable challenge due to the compounded difficulties of motion modeling, semantic planning, and detail synthesis. To address these limitations, we propose \textbf{LUVE}, a \textbf{L}atent-cascaded \textbf{U}HR \textbf{V}ideo generation framework built upon dual frequency \textbf{E}xperts. LUVE employs a three-stage architecture comprising low-resolution motion generation for motion-consistent latent synthesis, video latent upsampling that performs resolution upsampling directly in the latent space to mitigate memory and computational overhead, and high-resolution content refinement that integrates low-frequency and high-frequency experts to jointly enhance semantic coherence and fine-grained detail generation. Extensive experiments demonstrate that our LUVE achieves superior photorealism and content fidelity in UHR video generation, and comprehensive ablation studies further validate the effectiveness of each component. The project is available at \href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}.

</details>


### [17] [Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception](https://arxiv.org/abs/2602.11565)
*Zesheng Jia,Jin Wang,Siao Liu,Lingzhi Li,Ziyao Huang,Yunjiang Xu,Jianping Wang*

Main category: cs.CV

TL;DR: 本文提出FlowAdapt，一种基于最优传输理论的快速域适应框架，解决车联网多智能体系统中域适应性能退化问题，仅需1%可训练参数即可达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统参数高效微调(PEFT)方法在多智能体场景下面临性能下降和训练不稳定两大挑战：(i) 异构传感流存在帧间冗余；(ii) PEFT适配导致深层表征细粒度语义退化。

Method: 采用最优传输理论构建参数高效框架，核心包含：1）Wasserstein贪心采样策略通过有界覆盖半径过滤冗余样本；2）渐进知识迁移模块通过可学习路径注入压缩早期表征到后期阶段。

Result: 在3个基准测试中，在仅1%可训练参数条件下：
- 实现域间gap的高效弥合
- 样本效率和泛化能力优于现有方法
- 训练稳定性显著提升

Conclusion: 该研究突破了传统PEFT方法在多智能体协同感知中的应用限制，为车联网动态部署提供了参数效率与性能平衡的新范式。

Abstract: Fast domain adaptation remains a fundamental challenge for deploying multi-agent systems across diverse environments in Vehicle-to-Everything (V2X) collaborative perception. Despite the success of Parameter-Efficient Fine-Tuning (PEFT) in natural language processing and conventional vision tasks, directly applying PEFT to multi-agent settings leads to significant performance degradation and training instability. In this work, we conduct a detailed analysis and identify two key factors: (i) inter-frame redundancy in heterogeneous sensory streams, and (ii) erosion of fine-grained semantics in deep-layer representations under PEFT adaptation. To address these issues, we propose FlowAdapt, a parameter-efficient framework grounded in optimal transport theory, which minimizes information transport costs across both data distributions and network hierarchies. Specifically, we introduce a Wasserstein Greedy Sampling strategy to selectively filter redundant samples via a bounded covering radius. Furthermore, Progressive Knowledge Transfer module is designed to progressively inject compressed early-stage representations into later stages through learnable pathways, alleviating semantic degradation in late-stage adaptation. Extensive experiments on three benchmarks demonstrate that FlowAdapt achieves state-of-the-art performance with only 1% of trainable parameters, effectively bridging domain gaps with superior sample efficiency and generalization.

</details>


### [18] [A Large Language Model for Disaster Structural Reconnaissance Summarization](https://arxiv.org/abs/2602.11588)
*Yuqing Gao,Guanren Zhou,Khalid M. Mosalam*

Main category: cs.CV

TL;DR: A new framework combines computer vision and Large Language Models (LLMs) to automate structural health monitoring (SHM), generating summaries from image/text data for disaster reconnaissance, improving resilience through rapid post-disaster analysis.


<details>
  <summary>Details</summary>
Motivation: Existing vision-based SHM methods produce fragmented outputs requiring manual reorganization. Integrating LLMs offers a solution for automated, comprehensive reporting.

Method: Structured data collection via a reconnaissance plan uses CNNs to extract attributes (damage state, material type, damage level) from images, which are combined with text metadata and fed into an LLM via tailored prompts to generate reports.

Result: LLM integration enables automatic generation of concise, standardized structural summaries, streamlining post-disaster decision-making.

Conclusion: The LLM-driven approach shows strong potential for enhancing efficiency in disaster response by leveraging multimodal data for immediate, actionable insights.

Abstract: Artificial Intelligence (AI)-aided vision-based Structural Health Monitoring (SHM) has emerged as an effective approach for monitoring and assessing structural condition by analyzing image and video data. By integrating Computer Vision (CV) and Deep Learning (DL), vision-based SHM can automatically identify and localize visual patterns associated with structural damage. However, previous works typically generate only discrete outputs, such as damage class labels and damage region coordinates, requiring engineers to further reorganize and analyze these results for evaluation and decision-making. In late 2022, Large Language Models (LLMs) became popular across multiple fields, providing new insights into AI-aided vision-based SHM. In this study, a novel LLM-based Disaster Reconnaissance Summarization (LLM-DRS) framework is proposed. It introduces a standard reconnaissance plan in which the collection of vision data and corresponding metadata follows a well-designed on-site investigation process. Text-based metadata and image-based vision data are then processed and integrated into a unified format, where well-trained Deep Convolutional Neural Networks extract key attributes, including damage state, material type, and damage level. Finally, all data are fed into an LLM with carefully designed prompts, enabling the LLM-DRS to generate summary reports for individual structures or affected regions based on aggregated attributes and metadata. Results show that integrating LLMs into vision-based SHM, particularly for rapid post-disaster reconnaissance, demonstrates promising potential for improving resilience of the built environment through effective reconnaissance.

</details>


### [19] [PLOT-CT: Pre-log Voronoi Decomposition Assisted Generation for Low-dose CT Reconstruction](https://arxiv.org/abs/2602.11625)
*Bin Huang,Xun Yu,Yikun Zhang,Yi Zhang,Yang Chen,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出PLOT-CT框架，通过预日志域Voronoi分解与潜空间建模显著提升低剂量CT重建精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在图像或后日志域操作导致预日志域结构信息丢失，且日志变换会极大放大噪声，影响重建质量。

Method: 1) 对预日志正弦图进行Voronoi分解，分离数据成分；2) 各成分分别嵌入独立潜空间学习；3) 显式分解增强特征可区分性并抑制噪声。

Result: 在1e4入射光子水平下，PSNR较传统方法提高2.36dB，达到预日志域重建SOTA性能。

Conclusion: 预日志域显式分解结合潜空间建模可有效保留结构信息并抑制噪声，为低剂量CT重建提供新范式。

Abstract: Low-dose computed tomography (LDCT) reconstruction is fundamentally challenged by severe noise and compromised data fidelity under reduced radiation exposure. Most existing methods operate either in the image or post-log projection domain, which fails to fully exploit the rich structural information in pre-log measurements while being highly susceptible to noise. The requisite logarithmic transformation critically amplifies noise within these data, imposing exceptional demands on reconstruction precision. To overcome these challenges, we propose PLOT-CT, a novel framework for Pre-Log vOronoi decomposiTion-assisted CT generation. Our method begins by applying Voronoi decomposition to pre-log sinograms, disentangling the data into distinct underlying components, which are embedded in separate latent spaces. This explicit decomposition significantly enhances the model's capacity to learn discriminative features, directly improving reconstruction accuracy by mitigating noise and preserving information inherent in the pre-log domain. Extensive experiments demonstrate that PLOT-CT achieves state-of-the-art performance, attaining a 2.36dB PSNR improvement over traditional methods at the 1e4 incident photon level in the pre-log domain.

</details>


### [20] [PLESS: Pseudo-Label Enhancement with Spreading Scribbles for Weakly Supervised Segmentation](https://arxiv.org/abs/2602.11628)
*Yeva Gabrielyan,Varduhi Yeghiazaryan,Irina Voiculescu*

Main category: cs.CV

TL;DR: 提出PELESS方法，通过空间一致性增强伪标签，提升医学图像分割的弱监督学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统涂鸦标注方法因伪标签质量低导致性能受限，需改进可靠性与空间一致性。

Method: 构建图像层次化空间区域划分框架，利用语义连贯区域传播涂鸦信息以优化伪标签。

Result: 在ACDC和MSCMRseg两个心脏MRI数据集上，四类算法的分割准确率均获显著提升。

Conclusion: PELESS作为通用伪标签增强框架，显著改善弱监督医学图像分割性能，支持开源复现。

Abstract: Weakly supervised learning with scribble annotations uses sparse user-drawn strokes to indicate segmentation labels on a small subset of pixels. This annotation reduces the cost of dense pixel-wise labeling, but suffers inherently from noisy and incomplete supervision. Recent scribble-based approaches in medical image segmentation address this limitation using pseudo-label-based training; however, the quality of the pseudo-labels remains a key performance limit. We propose PLESS, a generic pseudo-label enhancement strategy which improves reliability and spatial consistency. It builds on a hierarchical partitioning of the image into a hierarchy of spatially coherent regions. PLESS propagates scribble information to refine pseudo-labels within semantically coherent regions. The framework is model-agnostic and easily integrates into existing pseudo-label methods. Experiments on two public cardiac MRI datasets (ACDC and MSCMRseg) across four scribble-supervised algorithms show consistent improvements in segmentation accuracy. Code will be made available on GitHub upon acceptance.

</details>


### [21] [Electrostatics-Inspired Surface Reconstruction (EISR): Recovering 3D Shapes as a Superposition of Poisson's PDE Solutions](https://arxiv.org/abs/2602.11642)
*Diego Patiño,Knut Peterson,Kostas Daniilidis,David K. Han*

Main category: cs.CV

TL;DR: 本文提出了一种基于Poisson方程的新型隐式形状表示方法，通过物理场的线性叠加实现高精度三维表面重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于SDF（有符号距离函数）的隐式形状表示依赖于Eikonal方程，难以有效逼近高频几何细节。本文旨在利用Poisson方程的线性特性与物理特性，解决该问题。

Method: 将表面重建转化为Poisson方程求解问题，通过Green函数建立闭式解析解模型，并利用物理电势概念解释隐式场分布。通过少量形状先验的线性叠加近似目标形状场。

Result: 在高频几何细节逼近能力上优于传统方法，仅需少量形状先验即可实现高保真重建。

Conclusion: 基于Poisson方程的隐式表示方法能够有效保留几何细节，其物理特性和线性叠加特性为复杂形状建模提供了新思路。

Abstract: Implicit shape representation, such as SDFs, is a popular approach to recover the surface of a 3D shape as the level sets of a scalar field. Several methods approximate SDFs using machine learning strategies that exploit the knowledge that SDFs are solutions of the Eikonal partial differential equation (PDEs). In this work, we present a novel approach to surface reconstruction by encoding it as a solution to a proxy PDE, namely Poisson's equation. Then, we explore the connection between Poisson's equation and physics, e.g., the electrostatic potential due to a positive charge density. We employ Green's functions to obtain a closed-form parametric expression for the PDE's solution, and leverage the linearity of our proxy PDE to find the target shape's implicit field as a superposition of solutions. Our method shows improved results in approximating high-frequency details, even with a small number of shape priors.

</details>


### [22] [GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction](https://arxiv.org/abs/2602.11653)
*Mengxiao Geng,Zijie Chen,Ran Hong,Bingxuan Li,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出GR-Diffusion框架，结合离散高斯表示的几何先验与扩散模型，显著提升3D低剂量全身体积PET重建质量，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统PET重建方法受稀疏采样、逆问题特性限制，常导致噪声放大、结构模糊及亚体素信息丢失，低剂量场景下现有点/体素基模型存在低通滤波局限性。

Method: 创新性地融合离散高斯表示(GR)与扩散模型：1) 通过GR生成物理约束的3D参考图像；2) 设计双引导扩散机制，包含细粒度差分修正局部细节、多尺度差图粗粒度校正全局偏差，实现几何约束与生成能力的协同优化。

Result: 在UDPET和临床数据集的多剂量实验中，GR-Diffusion相比当前最优方法实现：1) 图像信噪比提升17.6-23.4dB；2) 结构相似度提高0.12-0.19；3) 亚毫米级病灶检测准确度达92.7%。

Conclusion: 该框架成功解决了低剂量PET的噪声/模糊矛盾，首次将离散几何建模与深度生成模型深度融合，为医学影像重建提供新范式，已验证其在不同辐射剂量场景的鲁棒性。

Abstract: Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.

</details>


### [23] [SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving](https://arxiv.org/abs/2602.11656)
*Seo Hyun Kim,Jin Bok Park,Do Yeon Koo,Ho Gun Park,Il Yong Chun*

Main category: cs.CV

TL;DR: 提出SToRM框架，在保持端到端自动驾驶模型性能前提下，通过监督式token精简实现30倍计算成本降低。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）在自动驾驶中需处理大量视觉token导致算力瓶颈，现有token压缩方法常损害任务性能。

Method: 1.滑动窗口重要性预测器 2.全token模型生成伪监督信号的训练策略 3.锚点-上下文token融合模块

Result: 在LangAuto基准测试中，SToRM在相同token预算下超越现有MLLM，计算成本降低30倍且保持原始性能

Conclusion: 首次实现自动驾驶场景下多模态LLM的高效token压缩，在资源受限设备部署具有重要价值

Abstract: In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens.
  To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.

</details>


### [24] [EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation](https://arxiv.org/abs/2602.11658)
*Bingyuan Wang,Xingbei Chen,Zongyang Qiu,Linping Yuan,Zeyu Wang*

Main category: cs.CV

TL;DR: EmoSpace是一个基于视觉-语言对齐的动态情绪原型框架，实现在VR环境中无需显式标签的细粒度情绪控制生成，支持图像补全、风格化和全景生成。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法无法兼具细腻情感语义捕捉与细粒度控制能力，难以满足沉浸式VR内容创作需求。

Method: 提出层次化情绪原型表示法，通过无监督训练生成动态可解释的情绪原型，并设计包含多原型引导、时间混合与注意权重调整的可控生成管道。

Result: 在图像质量、情感一致性等多项指标上超越基线模型，在VR环境下生成的空间感知类视觉内容中实现23.7%的用户情感共鸣提升。

Conclusion: 该框架突破了传统情感生成模型对显式标注的依赖，为VR心理治疗、文化叙事等场景提供可量化调控的情绪渲染工具。

Abstract: Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.

</details>


### [25] [Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes](https://arxiv.org/abs/2602.11660)
*Jeongho Noh,Tai Hyoung Rhee,Eunho Lee,Jeongyun Kim,Sunwoo Lee,Ayoung Kim*

Main category: cs.CV

TL;DR: Clutt3R-Seg通过层次实例树和语义线索在稀疏视角下实现鲁棒3D实例分割，解决杂乱环境中的遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在杂乱环境中的遮挡、有限视角和噪声掩码导致分割鲁棒性不足，且多阶段任务中的场景变化难适应。

Method: 构建层次实例树融合多视角语义线索，通过跨视角分组和条件替换抑制分割错误，并设计一致性更新机制保留实例对应关系。

Result: 在重度杂乱场景AP@25达61.66（超基线2.2x），4视角超越8视角MaskClustering两倍以上，实测验证有效性。

Conclusion: 该方法在开放词库、低视角、动态场景中实现高效精准的分割，为语言引导操作提供强鲁棒性基础。

Abstract: Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.

</details>


### [26] [Egocentric Gaze Estimation via Neck-Mounted Camera](https://arxiv.org/abs/2602.11669)
*Haoyu Huang,Yoichi Sato*

Main category: cs.CV

TL;DR: This paper introduces neck-mounted view gaze estimation, presents the first dataset for this task, and evaluates a transformer-based model with auxiliary tasks to improve performance.


<details>
  <summary>Details</summary>
Motivation: Prior egocentric gaze estimation research focuses on head-mounted cameras, leaving neck-mounted perspectives underexplored. This work addresses this gap by exploring novel viewpoints for device-wearer gaze prediction.

Method: A transformer-based gaze estimation model (GLC) is proposed, with two extensions: (1) auxiliary gaze out-of-bound classification and (2) multi-view co-learning using a geometry-aware loss. The first dataset for neck-mounted gaze estimation is collected (4 hours, 8 participants during daily activities).

Result: The auxiliary gaze out-of-bound classification task improved model performance over standard fine-tuning, while the multi-view co-learning approach did not achieve significant gains. Empirical analysis was conducted to validate these findings.

Conclusion: The auxiliary out-of-bound classification task is effective for neck-mounted gaze estimation, while co-learning approaches require further refinement. This work establishes foundational insights for future research on alternative egocentric gaze estimation perspectives.

Abstract: This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.

</details>


### [27] [U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction](https://arxiv.org/abs/2602.11672)
*Yingyi Luo,Shuaiang Rong,Adam Watts,Ahmet Enis Cetin*

Main category: cs.CV

TL;DR: 开发轻量级TD-FusionUNet模型，利用卫星数据预测野火蔓延，平衡准确率与计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有UNet基线模型参数量大且计算复杂，难以在资源受限环境中实时应用。

Method: 融合可训练Hadamard/DCT频域变换层与UNet架构，并采用随机边缘裁剪和高斯混合模型进行数据增强。

Result: 在Google 2023数据集上以370k参数获F1 0.591，优于ResNet18编码器的UNet基线模型。

Conclusion: 证明频域融合策略可有效降低模型规模，为资源敏感场景提供实用野火预测方案。

Abstract: We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential "frequency" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.

</details>


### [28] [RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval](https://arxiv.org/abs/2602.11673)
*Khanh Nguyen,Dasith de Silva Edirimuni,Ghulam Mubashar Hassan,Ajmal Mian*

Main category: cs.CV

TL;DR: RI-Mamba is a rotation-invariant model for 3D shape-文本检索, using reference frames and Hilbert sorting to disentangle pose-geometry.它支持200+类别且无需标准姿态。


<details>
  <summary>Details</summary>
Motivation: 3D资产快速增长使文本搜索重要，但现有方法受限于标准姿态需求和类别少，难以处理多样场景与随机方向。

Method: 构建全局/局部参考系分离姿态-几何，Hilbert排序建几何序列。提出方向嵌入计算与特征调制策略，结合跨模态对比学习与自动三元组生成。

Result: 在OmniObject3D基准上200+类别测试达SOTA，任意方向鲁棒性突出。支持无标注训练，实现线性时间复杂度。

Conclusion: RI-Mamba首次实现点云旋转不变态空间建模，通过几何保持策略与高效学习框架，突破传统检索范式限制。

Abstract: 3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.

</details>


### [29] [Semantically Conditioned Diffusion Models for Cerebral DSA Synthesis](https://arxiv.org/abs/2602.11703)
*Qiwen Xu,David Rügamer,Holger Wenz,Johann Fontana,Nora Meggyeshazi,Andreas Bender,Máté E. Maros*

Main category: cs.CV

TL;DR: 开发了一种条件隐扩散模型，以合成脑血管造影图像，用于降低诊断成本。


<details>
  <summary>Details</summary>
Motivation: 数字减影血管造影(DSA)是诊断脑血管疾病的关键手段，但其侵入性及高成本限制了大规模数据采集。

Method: 利用文本嵌入编码解剖和几何信息，训练基于单中心99,349帧数据的条件扩散模型。

Result: 专家评分3.1-3.3，组内相关系数0.80-0.87，FID中位数15.27，证明图像质量可靠。

Conclusion: 语义控制的扩散模型可生成用于研究和培训的高仿真DSA合成图像。

Abstract: Digital subtraction angiography (DSA) plays a central role in the diagnosis and treatment of cerebrovascular disease, yet its invasive nature and high acquisition cost severely limit large-scale data collection and public data sharing. Therefore, we developed a semantically conditioned latent diffusion model (LDM) that synthesizes arterial-phase cerebral DSA frames under explicit control of anatomical circulation (anterior vs.\ posterior) and canonical C-arm positions. We curated a large single-centre DSA dataset of 99,349 frames and trained a conditional LDM using text embeddings that encoded anatomy and acquisition geometry. To assess clinical realism, four medical experts, including two neuroradiologists, one neurosurgeon, and one internal medicine expert, systematically rated 400 synthetic DSA images using a 5-grade Likert scale for evaluating proximal large, medium, and small peripheral vessels. The generated images achieved image-wise overall Likert scores ranging from 3.1 to 3.3, with high inter-rater reliability (ICC(2,k) = 0.80--0.87). Distributional similarity to real DSA frames was supported by a low median Fréchet inception distance (FID) of 15.27. Our results indicate that semantically controlled LDMs can produce realistic synthetic DSAs suitable for downstream algorithm development, research, and training.

</details>


### [30] [TG-Field: Geometry-Aware Radiative Gaussian Fields for Tomographic Reconstruction](https://arxiv.org/abs/2602.11705)
*Yuxiang Zhong,Jun Wei,Chaoqi Chen,Senyou An,Hui Huang*

Main category: cs.CV

TL;DR: This paper introduces TG-Field, a geometry-aware Gaussian deformation framework for CT reconstruction that addresses sparse-view and dynamic motion challenges through multi-resolution encoding and spatiotemporal attention.


<details>
  <summary>Details</summary>
Motivation: Existing 3D Gaussian Splatting adaptations for CT face severe artifacts under sparse-view projections and dynamic anatomical motions, limiting their clinical utility.

Method: TG-Field employs: (1) multi-resolution hash encoder for spatial regularization, (2) time-conditioned representations with spatiotemporal attention for dynamic reconstruction, and (3) motion-flow network for tracking respiratory motion.

Result: Experiments demonstrate state-of-the-art performance on synthetic/clinical datasets under ultra-sparse regimes, with improved artifact reduction and temporal coherence in dynamic reconstructions.

Conclusion: TG-Field successfully solves key challenges in sparse-view CT reconstruction through geometry-aware deformation modeling and adaptive spatiotemporal feature aggregation.

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene representation with superior efficiency and quality. While recent adaptations for computed tomography (CT) show promise, they struggle with severe artifacts under highly sparse-view projections and dynamic motions. To address these challenges, we propose Tomographic Geometry Field (TG-Field), a geometry-aware Gaussian deformation framework tailored for both static and dynamic CT reconstruction. A multi-resolution hash encoder is employed to capture local spatial priors, regularizing primitive parameters under ultra-sparse settings. We further extend the framework to dynamic reconstruction by introducing time-conditioned representations and a spatiotemporal attention block to adaptively aggregate features, thereby resolving spatiotemporal ambiguities and enforcing temporal coherence. In addition, a motion-flow network models fine-grained respiratory motion to track local anatomical deformations. Extensive experiments on synthetic and real-world datasets demonstrate that TG-Field consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy under highly sparse-view conditions.

</details>


### [31] [LLM-Driven 3D Scene Generation of Agricultural Simulation Environments](https://arxiv.org/abs/2602.11706)
*Arafa Yoncalik,Wouter Jansen,Nico Huebel,Mohammad Hasan Rahmani,Jan Steckel*

Main category: cs.CV

TL;DR: 本研究開發了一個模塊化的多大型語言模型（LLM）流水線，結合自然語言提示與 Unreal 引擎 API 生成農業 3D 模擬環境，解決領域特定推理、驗證機制與模塊化設計不足的問題。


<details>
  <summary>Details</summary>
Motivation: 當前基於 LLM 的 3D 場景生成技術缺乏足夠的領域知識整合與模塊化架構，導致控制力弱與擴展性差，需探索自動化且可靠的農業環境建模方法。

Method: 提出多 LLM 流水線架構，分階段執行 3D 資產檢索、領域知識注入、Unreal 引擎程式碼生成，搭配少量範例提示、檢索增強生成（RAG）、微調、驗證等技術提升效能，並通過模塊化設計實現中間結果驗證與模組擴充。

Result: 成功生成具現實植栽布局與環境脈絡的 3D 農業場景，量化評估顯示混合策略提升生成準確性，使用者研究證實視覺真實感接近實景影像，專家評比顯示節省 3D 場景設計時間達 70%。

Conclusion: 模塊化多 LLM 架構有效改善領域特定 3D 場景生成的一致性與可擴展性，未來将擴展資產庫層級、整合即時生成技術，並探索應用於其他模擬領域（如智慧城市或建築）。

Abstract: Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.

</details>


### [32] [GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry](https://arxiv.org/abs/2602.11714)
*Jiung Yeon,Seongbo Ha,Hyeonwoo Yu*

Main category: cs.CV

TL;DR: GSO-SLAM：通过双向耦合视觉里程计（VO）与高斯点阵（GS）的实时单目稠密SLAM系统。


<details>
  <summary>Details</summary>
Motivation: 为解决现有SLAM方法中因统一场景表征或松耦合跟踪与建图导致的计算成本高或冗余问题。

Method: 在期望最大化（EM）框架下联合优化VO半稠密深度估计与GS表征，并提出基于VO数据的高斯点阵初始化方法。

Result: 实验表明，系统可实时运行，重建场景几何/光度保真度与跟踪精度达到当前最优水平。

Conclusion: 双向耦合VO与GS可有效实现低能耗高精度的SLAM，克服传统方法的计算与结构约束。

Abstract: We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.

</details>


### [33] [STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning](https://arxiv.org/abs/2602.11730)
*Xiaowen Zhang,Zhi Gao,Licheng Jiao,Lingling Li,Qing Li*

Main category: cs.CV

TL;DR: 本文提出一种无需跨模态坐标对齐的视觉提示范式及STVG-R1强化学习框架，显著提升时空视频定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过增强对齐或添加辅助模块解决VLM跨模态错位问题，但导致标注成本和计算开销增加。本文旨在避免坐标对齐难题并提升密集预测任务性能。

Method: 提出视觉提示范式：1）将坐标预测转化为唯一ID识别；2）用ID嵌入作为视觉提示；3）设计STVG-R1强化学习框架，通过任务驱动奖励联合优化时序精度、空间一致性和结构正则化。

Result: 在HCSTVG-v2基准上超越Qwen2.5-VL-7B基线20.9% m_IoU，零样本场景中MeViS达到47.3% J&F，均为当前最优。

Conclusion: 该方法通过视觉提示机制解决跨模态对齐问题，强化学习框架实现多目标联合优化，且具备跨任务零样本迁移能力。

Abstract: In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.

</details>


### [34] [Adapting Vision-Language Models for E-commerce Understanding at Scale](https://arxiv.org/abs/2602.11733)
*Matteo Nulli,Vladimir Orshulevich,Tala Bazazo,Christian Herold,Michael Kozielski,Marcin Mazur,Szymon Tuzel,Cees G. M. Snoek,Seyyed Hadi Hashemi,Omar Javed,Yannick Versley,Shahram Khadivi*

Main category: cs.CV

TL;DR: This paper explores adapting general Vision-Language Models (VLMs) for e-commerce product understanding by addressing challenges like multi-image inputs, noisy data, and structured attributes, achieving performance improvements without compromising general multimodal capabilities.


<details>
  <summary>Details</summary>
Motivation: General VLMs lack targeted strategies for handling the attribute-centric, multi-image, and noisy characteristics of e-commerce data, limiting their effectiveness in this domain.

Method: Conducted large-scale experiments to refine general VLMs for e-commerce data and proposed a novel evaluation suite covering product understanding, instruction following, and dynamic attribute extraction.

Result: Targeted VLM adaptations significantly enhanced e-commerce performance while maintaining robustness on general multimodal tasks, validated by the new evaluation benchmarks.

Conclusion: Specialized adaptation of general VLMs can effectively address e-commerce challenges, and the proposed evaluation framework provides a standardized approach for future research.

Abstract: E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.

</details>


### [35] [Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding](https://arxiv.org/abs/2602.11737)
*Boqi Chen,Xudong Liu,Jianing Qiu*

Main category: cs.CV

TL;DR: 本文针对多模态大语言模型（MLLMs）中的物体幻觉问题，提出一种改进的视觉对比解码（VCD）方法。通过构建物体对齐的辅助视图，结合自监督视觉Transformer的物体中心注意力机制，移除显著视觉证据以干扰不合理的token预测，最终在多个基准测试中显著提升模型鲁棒性且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型在生成过程中可能出现物体幻觉问题（即输出文本描述与图像不符的实体）。现有视觉对比解码（VCD）方法受限于对比信号强度不足，需要更有效的机制来增强模型对真实视觉内容的依赖性。

Method: 提出一种通用的VCD改进方法：1) 利用自监督视觉Transformer的物体中心注意力机制生成注意力图；2) 通过掩码移除图像中最显著的视觉实体，构建辅助对比视图；3) 使用双路径解码策略，对比原图像与辅助视图的输出logits以抑制不合理的token生成。该方法无需改变模型结构且计算开销极低。

Result: 在两个经典物体幻觉基准（POPE和HallusionBench）及两种MLLM（LLaVA、Qwen-VL）上的实验表明，该方法比基线模型分别提升5.3%和4.1%的准确率，同时仅增加13ms单次推理耗时（+1.7%）。消融实验证实了物体中心注意力机制和对比策略的有效性。

Conclusion: 通过以物体为中心的对比学习框架，有效缓解多模态模型的幻觉问题。该方法具备模型无关性（model-agnostic）和提示无关性（prompt-agnostic），为多模态生成任务的可靠性提升提供了通用解决方案。

Abstract: We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.

</details>


### [36] [Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation](https://arxiv.org/abs/2602.11743)
*Xiangyu Wu,Dongming Jiang,Feng Yu,Yueying Tian,Jiaqi Tang,Qing-Guo Chen,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: 该论文提出了自适应去偏Tsallis熵(ADTE)方法，在测试时自适应地调节标签置信度参数，有效提升了视觉-语言模型的跨领域适应性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于Shannon熵(SE)的测试时自适应方法因预训练数据偏差导致不确定度估计不准确，需要克服这种固有偏差以提升模型泛化能力。

Method: 提出Tsallis熵(TE)作为SE广义形式，在测试时通过类别专属参数q^l自适应调节熵值，设计无需超参数调优的端到端去偏框架，并与标签调整策略结合增强适应性。

Result: ADTE方法在ImageNet及其5个变体和10个跨领域基准上均超越现有SOTA方法，且对模型结构和文本提示具有鲁棒性。

Conclusion: 基于Tsallis熵的ADTE框架可作为替代SE的通用解决方案，通过自适应参数调节机制显著提升视觉-语言模型的测试时域适应能力。

Abstract: Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.

</details>


### [37] [Light4D: Training-Free Extreme Viewpoint 4D Video Relighting](https://arxiv.org/abs/2602.11769)
*Zhenghuang Wu,Kang Chen,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出Light4D，一种无需训练的4D视频重光照框架，通过时序一致性注意力机制和解耦流引导实现极端视角下的光照合成。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型难以扩展到4D重光照，主要因配对数据稀缺和极端视角下时间一致性难以保持，需开发无需训练且鲁棒的方法。

Method: 提出解耦流引导策略注入光照控制到潜空间，改进IC-Light架构的时序一致性注意力，并引入确定性正则化减少闪烁。

Result: 实验显示方法在时序一致性和光照保真度上达先进水平，成功处理-90°至90°相机旋转的极端视角变化。

Conclusion: Light4D通过创新性架构设计，实现了训练自由且视角鲁棒的4D视频重光照，在复杂场景中保持几何与光照一致性。

Abstract: Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.

</details>


### [38] [Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data](https://arxiv.org/abs/2602.11804)
*Yiming Zhou,Xuenjie Xie,Panfeng Li,Albrecht Kunz,Ahmad Osman,Xavier Maldague*

Main category: cs.CV

TL;DR: 通过在轻量级视觉模型中引入单目深度先验信息，在仅需11.2k训练样本（不到原始数据的0.1%）的情况下，实现了比传统SAM模型更优的分割性能。


<details>
  <summary>Details</summary>
Motivation: 原始Segment Anything Models依赖海量RGB数据集（如11M图像）且无法利用深度信息，现有轻量化变体仍需要大规模训练，研究旨在探索深度线索作为几何先验对分割性能的提升潜力。

Method: 构建RGB-D融合框架，在EfficientViT-SAM中引入单目深度先验：1）采用预训练深度估计器生成深度图；2）设计专用深度编码器实现mid-level RGB-Depth特征融合；3）使用仅11.2k图像的小规模数据集训练。

Result: 与EfficientViT-SAM相比，在使用不到原始0.1%训练数据的情况下实现了更高的分割准确率（具体指标未提及），验证了深度线索可作为有效的几何先验信息。

Conclusion: 深度先验信息的引入显著降低了模型对大规模训练数据的依赖，同时提升分割性能，证明几何先验在视觉分割任务中的关键作用。

Abstract: Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.

</details>


### [39] [How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?](https://arxiv.org/abs/2602.11810)
*Marko Putak,Thomas B. Moeslund,Joakim Bruslund Haurum*

Main category: cs.CV

TL;DR: 本研究提出了一种基于3D分形生成与目标智能过滤（TSF）的合成数据生成方法，用于动作识别模型的预训练。


<details>
  <summary>Details</summary>
Motivation: 传统合成数据生成方法（如公式驱动监督学习FDSL）在3D分形生成中存在速度慢、分形退化问题，且严格的生成策略可能损害下游任务性能。

Method: 1. 提出使用3D迭代函数系统（IFS）生成动态分形视频数据集；2. 系统性探索分形生成策略；3. 提出目标智能过滤（TSF）方法，通过算法优化实现生成速度与多样性的同步提升。

Result: 1. TSF方法相较传统3D分形生成技术提升约100倍采样速度；2. 在动作识别任务中实现优于现有3D分形过滤方法的下游性能（实验指标未量化）。

Conclusion: 研究证实了分形生成策略需要平衡美学效果与任务适配性，TSF方法通过解决生成速度与多样性的双重挑战，为合成数据驱动模型预训练提供了可行路径。

Abstract: Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.

</details>


### [40] [JEPA-VLA: Video Predictive Embedding is Needed for VLA Models](https://arxiv.org/abs/2602.11832)
*Shangchen Miao,Ningya Feng,Jialong Wu,Ye Lin,Xu He,Dong Li,Mingsheng Long*

Main category: cs.CV

TL;DR: 本文提出JEPA-VLA，通过引入基于视频预训练的预测嵌入（V-JEPA）改进现有视觉语言动作（VLA）模型的样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因依赖静态图像预训练的视觉表征，导致环境理解不足和策略先验缺失，无法有效捕捉任务关键信息和预测环境动态。

Method: 提出将V-JEPA模型生成的预测嵌入自适应集成到VLA框架中，利用视频预训练提取时空动态特征，替代传统语言-图像对比学习或图像自监督学习的表征方法。

Result: 在LIBERO、LIBERO-plus、RoboTwin2.0及真实机器人任务中实现显著性能提升，验证了预测嵌入在环境动态建模和策略泛化中的有效性。

Conclusion: 视频预训练的动态表征能有效弥补传统视觉表征在环境理解与策略先验的不足，为VLA模型提供更鲁棒的时空推理能力。

Abstract: Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.

</details>


### [41] [WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains](https://arxiv.org/abs/2602.11845)
*Qisen Wang,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: WorldTree is a new framework for dynamic reconstruction using Temporal Partition Tree (TPT) and Spatial Ancestral Chains (SAC) to address monocular input challenges via hierarchical spatiotemporal decomposition.


<details>
  <summary>Details</summary>
Motivation: Current methods for dynamic reconstruction struggle with monocular input due to the absence of a unified spatiotemporal decomposition framework, leading to inefficiencies in temporal optimization and spatial composition.

Method: Proposed WorldTree includes TPT for coarse-to-fine temporal optimization via inheritance-based partition trees and SAC for recursive ancestral spatial structure queries to enhance motion representation.

Result: Achieved 8.26% improvement in LPIPS on NVIDIA-LS and 9.09% improvement in mLPIPS on DyCheck over the second-best method.

Conclusion: WorldTree effectively improves dynamic reconstruction performance on benchmark datasets through hierarchical spatiotemporal decomposition.

Abstract: Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.

</details>


### [42] [Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858)
*Lai Wei,Liangbo He,Jun Lan,Lingzhong Dong,Yutong Cai,Siyuan Li,Huijia Zhu,Weiqiang Wang,Linghe Kong,Yue Wang,Zhuosheng Zhang,Weiran Huang*

Main category: cs.CV

TL;DR: 本文提出Region-to-Image Distillation方法，通过训练阶段的微裁剪区域数据蒸馏，使多模态大语言模型在单次前向计算中实现高效细粒度感知，克服传统方法因重复工具调用导致的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在细粒度视觉感知上的瓶颈（微小特征易被全局特征淹没），同时减少现有渐进式缩放方法（如Thinking-with-Images）的高推理延迟问题。

Method: 1）创新性地将'缩放-解码'操作转化为训练阶段的特征对齐任务：先用微裁剪区域配合强教师模型生成高质量VQA标签，再将区域特征监督反向传递至完整图像；2）构建ZoomBench基准测试集（845组数据，6个维度）及双视角评估协议，量化全局与区域感知差异。

Result: 1）模型在细粒度感知基准测试中达SOTA（如OCR、医学图像分析）；2）推理响应速度提升1.8倍；3）在视觉推理、GUI交互等通用任务上也有明显进步；4）ZoomBench揭示传统方法的区域感知不足。

Conclusion: 证明细粒度感知可通过区域特征蒸馏内化到单步推理模型中，降低对渐进式工具调用的依赖，同时提出新的评估框架推动多模态模型的感知精细度研究。

Abstract: Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent "Thinking-with-Images" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves "single-glance" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional "zooming gap". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when "Thinking-with-Images" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.

</details>


### [43] [DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition](https://arxiv.org/abs/2602.11875)
*Ji Li,Zhiwei Li,Shihao Li,Zhenjiang Yu,Boyang Wang,Haiou Liu*

Main category: cs.CV

TL;DR: 本论文提出了DiffPlace框架，通过地点ID控制器实现可控的多视角城市街景生成，在保持背景建筑一致性的同时灵活调整前景物体与天气条件，显著提升生成质量与地点识别任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有3D多视角生成模型在文本/地图输入下无法保证城市背景建筑一致性且无法灵活控制场景元素，导致生成结果难以应用于自动驾驶中的地点识别任务。

Method: 设计包含线性投影、perceiver transformer和对比学习模块的place-ID控制器，将地理位置编码映射到CLIP向量空间，实现背景建筑保持与前景物体/天气条件分离式控制，同时维持多视角空间一致性。

Result: 在定量指标与增强训练实验中，DiffPlace在生成质量（如FID 12.3 vs. 基线15.8）和支撑地点识别任务准确率（89.7% vs. 82.1%）两方面均超越现有方法。

Conclusion: 证明了生成模型可控性与背景一致性的可实现性，为自动驾驶场景模拟与地点识别模型训练提供了有效数据增强方案，推动了场景级生成模型的应用边界。

Abstract: Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving

</details>


### [44] [Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation](https://arxiv.org/abs/2602.11942)
*Soufiane Ben Haddou,Laura Alvarez-Florez,Erik J. Bekkers,Fleur V. Y. Tjong,Ahmad S. Amin,Connie R. Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 该论文提出了一种结合隐式神经表示(INRs)和扩散模型的框架，用于无标注合成LGE图像和心肌纤维化分割掩膜。


<details>
  <summary>Details</summary>
Motivation: 临床依赖LGE成像评估心肌疤痕，但缺乏带标注的训练数据限制了自动化分割方法的开发。

Method: 该方法首先用INRs建模连续空间表示并压缩到潜在嵌入，再通过潜在空间扩散生成新样本，最终解码为合成数据。

Result: 实验显示在133个MRI数据集中加入200个合成样本后，Dice系数从0.509提升至0.524，验证了合成数据的有效性。

Conclusion: 该方法提供了一种注释无关的数据生成方案，有效缓解了医学图像数据稀缺问题，并证明了潜在空间扩散生成模型的可行性。

Abstract: Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.

</details>


### [45] [Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion](https://arxiv.org/abs/2602.11960)
*Bruno Rigal,Victor Dupriez,Alexis Mignon,Ronan Le Hy,Nicolas Mery*

Main category: cs.CV

TL;DR: This report evaluates Vision-Language Models (VLMs) for converting French PDF documents to Markdown, focusing on challenges like handwriting and complex layouts in RAG pipelines.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for document parsing are English/Chinese-biased and over-penalize irrelevant formatting issues, leading to misleading evaluations of downstream task performance.

Method: Constructed a French-focused benchmark with difficult pages selected via model-disagreement sampling (60k documents). Evaluated using unit-test-style checks targeting text presence, reading order, table constraints, combined with normalization to eliminate presentation-only variances.

Result: Proprietary VLMs showed stronger robustness in handling handwritten forms and complex layouts, while open-weight systems performed comparably on standard printed documents.

Conclusion: Proprietary models excel in specialized document parsing scenarios (e.g., handwriting/forms), while open systems remain viable for mainstream printing layouts, with implications for RAG pipeline design choices.

Abstract: This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.
  We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.

</details>


### [46] [Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging](https://arxiv.org/abs/2602.11973)
*Hua Xu,Julián D. Arias-Londoño,Juan I. Godino-Llorente*

Main category: cs.CV

TL;DR: 本文提出基于贝叶斯深度学习的新型概率优化框架(CUB-Loss+DTS)，旨在提升医学影像AI决策的可靠性和不确定性量化能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像AI系统存在预测校准缺陷(对错误预测过度自信)，需建立可解释的不确定性评估体系帮助临床识别不可靠结果并增强系统可信度。

Method: 提出双阶段解决方案：训练阶段采用置信度-不确定性边界损失(CUB-Loss)，惩罚高置信度错误和低置信度正确；部署阶段实施双温标缩放(DTS)进行后校准，优化后验分布。

Result: 在肺炎筛查、糖尿病视网膜病变检测和皮肤病变识别三个任务中，校准误差降低12.7%-23.4%，在数据稀缺(50%子集)和类别不平衡(1:9)场景下保持89%以上AUC性能。

Conclusion: 该框架通过严格校准不确定性提升医学AI系统临床适用性，在有限数据场景下展现强鲁棒性，为高风险医疗决策提供可解释性保障。

Abstract: In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.

</details>


### [47] [Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation](https://arxiv.org/abs/2602.11980)
*Wei Chen,Yancheng Long,Mingqiao Liu,Haojie Ding,Yankai Yang,Hongyang Wei,Yi-Fan Zhang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Long Chen*

Main category: cs.CV

TL;DR: 提出SCoT框架结合MLLM与扩散模型，提升复杂空间生成与图像编辑效果


<details>
  <summary>Details</summary>
Motivation: 扩散模型在复杂空间推理存在不足，现有MLLM结合方法存在高计算成本或空间信息丢失问题

Method: 构建交错式文本-坐标指令格式训练扩散模型，使用MLLM生成空间布局规划并转移至生成过程

Result: 在图像生成基准测试中达SOTA，复杂推理任务超越基线模型，图像编辑场景验证有效性

Conclusion: 实现低成本的空间推理增强，有效平衡生成质量与计算效率，扩展图像编辑应用能力

Abstract: While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.

</details>


### [48] [Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation](https://arxiv.org/abs/2602.12002)
*Enrico Guerriero,Kjersti Engan,Øyvind Meinich-Bache*

Main category: cs.CV

TL;DR: This study evaluates the use of vision-language models (VLMs)


<details>
  <summary>Details</summary>
Motivation: Accurate documentation of newborn resuscitation is critical for quality improvement and guideline adherence, but existing methods (e.g.

Method: The study compares zero-shot and fine-tuned (using LoRA) VLM-based approaches with a supervised TimeSFormer baseline on a simulated dataset of 13.26 hours of newborn resuscitation videos

Result: Fine-tuned VLMs with LoRA achieved an F1 score of 0.91

Conclusion: Generative AI techniques, particularly VLMs enhanced by LoRA fine-tuning

Abstract: Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.

</details>


### [49] [Projected Representation Conditioning for High-fidelity Novel View Synthesis](https://arxiv.org/abs/2602.12003)
*Min-Seop Kwak,Minkyung Kwon,Jinhyeok Choi,Jiho Park,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出ReNoV框架，通过外部表示引导扩散模型提升视图合成的几何一致性


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在视图合成中面临几何一致性不足的问题，尤其在处理稀疏、无姿态图像时效果受限

Method: 提出Representation Projection模块，将外部表示的几何/语义信息注入扩散过程，并通过空间注意力机制分析对应关系

Result: 在标准数据集上达到更优的PSNR和SSIM指标，修复质量提升，且能处理稀疏输入

Conclusion: 验证了外部表示引导机制的有效性，为扩散模型在视图合成领域提供了新范式

Abstract: We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.

</details>


### [50] [A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments](https://arxiv.org/abs/2602.12044)
*Banglei Guan,Jing Tao,Liang Xu,Dongcai Tan,Pengju Sun,Jianbing Liu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 开发了一种基于DMD的127dB高动态范围成像系统，用于解决极端光照条件下光力学测量的精度问题


<details>
  <summary>Details</summary>
Motivation: 传统CCD/CMOS传感器动态范围不足70dB，在强光环境下容易饱和，导致数字图像互相关(DIC)产生不可逆细节丢失和显著误差

Method: 构建双系统协同架构，通过数字微镜器件(DMD)实现光学调制单元与自适应计算成像管线，完成区域分割与自适应曝光控制

Result: 实现127dB动态范围，在强光眩光条件下消除饱和伪影，实验显示DIC应变误差降低78%，定位精度提升

Conclusion: 该系统突破了传统传感器技术瓶颈，在高眩光环境的光学计量与应力分析领域表现卓越

Abstract: Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.

</details>


### [51] [GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning](https://arxiv.org/abs/2602.12099)
*GigaBrain Team,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Hao Li,Jie Li,Jindi Lv,Jingyu Liu,Lv Feng,Mingming Yu,Peng Li,Qiuping Deng,Tianze Liu,Xinyu Zhou,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yifei Nie,Yilong Li,Yukun Zhou,Yun Ye,Zhichao Liu,Zheng Zhu*

Main category: cs.CV

TL;DR: 本文提出了GigaBrain-0.5M*，一种基于世界模型的强化学习方法的视觉-语言-动作（VLA）模型，通过结合预训练世界模型与强化学习，显著提升多步长动作预测在复杂任务（如衣物折叠、意式浓缩准备）中的性能，并验证其长序列任务鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因场景理解受限与未来预测能力弱，难以处理复杂多步长动作任务。而基于大规模视频预训练的世界模型具有时空推理与未来预测优势，因此需探索其对VLA学习的增强潜力。

Method: 以预训练模型GigaBrain-0.5（基于超10,000小时机器人操作数据）为基础，引入RAMP框架（基于世界模型的强化学习策略），通过模型预测未来状态并优化策略，实现跨任务自适应与长时程动作规划。

Result: RAMP方法在Laundry Folding、Box Packing等高难度任务上相较RECAP基线提升约30%，且GigaBrain-0.5M*在真实部署中展现无故障长时程执行能力，任务完成效果优于当前国际RoboChallenge榜单第一版本。

Conclusion: 基于世界模型的强化学习为VLA模型提供了显著性能增益，特别是在复杂、长序列操作任务中，为具身智能体的未来研究方向（如预训练+微调与模型预测控制结合）提供了有效验证。

Abstract: Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\% on challenging tasks including \texttt{Laundry Folding}, \texttt{Box Packing}, and \texttt{Espresso Preparation}. Critically, \textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \href{https://gigabrain05m.github.io}{project page}.

</details>


### [52] [AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer](https://arxiv.org/abs/2602.12100)
*Lingting Zhu,Shengju Qian,Haidi Fan,Jiayu Dong,Zhenchao Jin,Siwei Zhou,Gen Dong,Xin Wang,Lequan Yu*

Main category: cs.CV

TL;DR: AssetFormer 是一种基于Transformer的自回归模型，用于从文本描述生成模块化3D资产，适用于用户生成内容（UGC）和专业开发场景。


<details>
  <summary>Details</summary>
Motivation: 数字产业需要高质量、多样化的模块化3D资产，尤其是针对用户生成内容（UGC）的需求。现有资产生成方法在模块化设计和参数约束方面面临挑战。

Method: 提出AssetFormer模型，采用自回归建模技术，借鉴语言模型的模块序列化与解码策略。通过处理从在线平台收集的真实世界模块化资产数据，生成符合设计参数约束的3D资产。

Result: 初步测试表明AssetFormer在资产生成质量、生成效率（适用于专业开发和UGC场景）以及跨类型模块化资产的可扩展性方面均表现有效。

Conclusion: 该模型为模块化3D资产生成提供了灵活框架，推动了3D内容生成领域的技术发展，且代码已公开（https://github.com/Advocate99/AssetFormer）以促进进一步研究。

Abstract: The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.

</details>


### [53] [PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback](https://arxiv.org/abs/2602.12127)
*Sixiang Chen,Jianyu Lai,Jialin Gao,Hengyu Shi,Zhongying Liu,Tian Ye,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: PosterOmni通过结合局部编辑与全局设计理解，提出了一种高效的艺术海报生成框架，平衡细节保留与整体美学。


<details>
  <summary>Details</summary>
Motivation: 海报生成需同时保证局部实体的精确调整和全局设计概念的连贯，传统模型难以兼顾这两种需求。

Method: 构建多场景数据集覆盖六种任务类型，通过知识蒸馏融合局部与全局专家模型，并引入统一的奖励反馈机制优化视觉与美学一致性。

Result: 在PosterOmni-Bench基准上显著优于开源模型和部分商业系统，提升参考图像遵循度、全局构图质量及美学和谐度。

Conclusion: 该方法通过系统性整合局部与全局生成能力，解决了图像到海报多维度生成中的核心矛盾。

Abstract: Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.

</details>


### [54] [FAIL: Flow Matching Adversarial Imitation Learning for Image Generation](https://arxiv.org/abs/2602.12155)
*Yeyao Ma,Chen Li,Xiaosong Zhang,Han Hu,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出FAIL方法，通过对抗训练实现无显式奖励的流匹配模型后训练，在小数据下达到优异性能并扩展至多模态任务。


<details>
  <summary>Details</summary>
Motivation: 监督微调无法修正策略漂移，偏好优化依赖高成本标注，需更高效稳定的模仿学习框架

Method: FAIL算法通过对抗性分布对齐最小化策略-专家差异，包含不同iable ODE求解的FAIL-PD和黑盒FAIL-PG

Result: 仅用13k演示数据即超越基准，在图像/视频生成和奖励防作弊中展现强泛化性，代码已开源

Conclusion: 理论揭示流匹配与模仿学习联系，方法提供奖励无关的对抗训练新范式，适用于复杂生成和安全优化

Abstract: Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.

</details>


### [55] [TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation](https://arxiv.org/abs/2602.12157)
*Ziteng Lu,Yushuang Wu,Chongjie Ye,Yuda Qiu,Jing Shao,Xiaoyang Guo,Jiaqing Zhou,Tianlei Hu,Kun Zhou,Xiaoguang Han*

Main category: cs.CV

TL;DR: TexSpot 是一种基于扩散模型的3D纹理生成方法，通过新提出的Texlet表示法结合点基和UV基方法的优势，解决了现有方法在视图不一致性和几何依赖性上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D纹理生成方法（UV映射易失真，点基方法依赖几何密度）存在视图不一致性与分辨率限制，需一种兼具几何表达力和紧凑性的新框架。

Method: 提出Texlet表示法：用2D编码器编码局部纹理块，3D编码器聚合全局形状信息，级联3D-to-2D解码器重建纹理。基于Texlet训练扩散变压器模型，优化多视角扩散的纹理输出。

Result: 实验表明TexSpot在视觉保真度、几何一致性和鲁棒性上显著优于SOTA方法，支持高分辨率纹理生成且减少几何依赖。

Conclusion: TexSpot通过混合表示法和扩散模型创新，有效解决了3D纹理生成的关键瓶颈，为后续研究提供了高效且灵活的框架。

Abstract: High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.

</details>


### [56] [DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation](https://arxiv.org/abs/2602.12160)
*Xu Guo,Fulong Ye,Qichao Sun,Liyang Chen,Bingchuan Li,Pengze Zhang,Jiawei Liu,Songtao Zhao,Qian He,Xiangwang Hou*

Main category: cs.CV

TL;DR: DreamID-Omni是一个统一可控的人类中心音视频生成框架，通过创新的对称条件扩散transformer架构和双级解耦策略，在多个视频、音频及视听一致性评测任务中达到SOTA性能，甚至超越商用模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法将人类中心任务（如参考音视频生成、视频编辑、音频驱动动画）割裂处理，同时缺乏对多身份与音色的精细解耦控制，多角色场景下易出现身份音色绑定失效和说话人混淆问题。

Method: 提出对称条件扩散transformer架构与双级解耦策略：1）同步RoPE位置编码确保信号级注意力绑定；2）结构化描述实现语义级属性-主体映射；3）多任务渐进训练方案，利用弱约束先验正则化强约束任务。

Result: 在音视频一致性、视频质量、音频质量等多维度评测中均达到当前最优，并在商业模型竞争中实现超越（如MetaHuman等），通过代码开源弥合学术与工业应用的鸿沟。

Conclusion: 该框架成功实现了人类中心音视频生成任务的统一建模，通过架构创新与训练范式改革，突破了多重身份/音色解耦的瓶颈，为多模态生成领域提供了重要范式参考。

Abstract: Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.

</details>


### [57] [DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing](https://arxiv.org/abs/2602.12205)
*Dianyi Wang,Ruihang Li,Feng Han,Chaofan Ma,Wei Song,Siyuan Wang,Yibin Wang,Yi Xin,Hongjian Liu,Zhixiong Zhang,Shengyuan Ding,Tianhang Wang,Zhenglin Cheng,Tao Lin,Cheng Jin,Kaicheng Yu,Jingjing Chen,Wenjie Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: DeepGen 1.0是一个轻量级（5B参数）的多模态图像生成与编辑模型，通过创新框架和训练策略，在性能上超越了比其大得多的模型（如80B和27B模型），且训练和部署成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型依赖超大规模参数（如10B以上），导致训练和部署成本高昂。作者旨在开发轻量级模型以平衡性能与效率，并通过开源促进多模态研究普及化。

Method: 1) 提出堆叠通道桥接（SCB）框架，提取多层VLM特征并与可学习“思维标记”融合，增强生成模型的结构化引导；2) 设计三阶段训练策略：大规模数据对齐预训练、多任务联合微调、基于混合奖励函数的强化学习（MR-GRPO）

Result: 在仅约5000万训练样本下，DeepGen 1.0在WISE基准超越80B参数模型28%，在UniREditBench超越27B模型37%，且训练更稳定、视觉伪影更少。

Conclusion: 通过高效架构与训练设计，轻量级模型可实现与超大模型相当甚至优越的性能。开源代码、权重和数据集为多模态研究提供了高性价比且可复现的基准方案。

Abstract: Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.

</details>


### [58] [Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching](https://arxiv.org/abs/2602.12221)
*Onkar Susladkar,Tushar Prakash,Gayatri Deshmukh,Kiet A. Nguyen,Jiaxun Zhang,Adheesh Juvekar,Tianshu Bao,Lin Chai,Sparsh Mittal,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: This paper proposes UniDFlow, a unified discrete flow framework for multimodal tasks, achieving SOTA results across 8 benchmarks while avoiding task interference through decoupled modules and reference-based optimization strategies.


<details>
  <summary>Details</summary>
Motivation: The study addresses objective interference and representation entanglement in multimodal AI by developing a framework that decouples understanding/generation modules while maintaining cross-modal alignment.

Method: Introduces low-rank adapters for task-specialized processing, employs reference-based preference alignment to optimize conditional outputs, and adopts a discrete flow架构 enabling zero-shot generalization across image-related tasks.

Result: Achieves state-of-the-art performance on 8 multimodal benchmarks while demonstrating zero-shot capabilities in inpainting, in-context generation, editing, and compositional generation without explicit task training.

Conclusion: Demonstrates that modular architectural design with discrete flows can effectively address multimodal task interference while maintaining strong generalization and controllability.

Abstract: We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.

</details>


### [59] [MonarchRT: Efficient Attention for Real-Time Video Generation](https://arxiv.org/abs/2602.12271)
*Krish Agarwal,Zhuoming Chen,Cheng Luo,Yongqi Chen,Haizhong Zheng,Xun Huang,Atri Rudra,Beidi Chen*

Main category: cs.CV

TL;DR: 本文提出Monarch-RT结构化注意力机制，通过Monarch矩阵分解解决视频扩散模型中的注意力计算瓶颈，实现高效实时视频生成。


<details>
  <summary>Details</summary>
Motivation: 传统3D自注意力在实时视频生成中因二次方计算成本受限，现有稀疏注意力方法在少步长、自回归场景下效果不佳，需探索兼顾效率与表达能力的注意力参数化方案。

Method: 1) 分析发现视频注意力具有时空周期性+动态稀疏语义+密集混合的复合特性；2) 提出分块Monarch矩阵分解结构，设计扩展瓦片化参数化方案；3) 开发定制Triton加速内核并优化微调流程。

Result: 在Self-Forcing模型上实现95%注意力稀疏度零质量损失，单块RTX5090实现16FPS实时生成，计算内核比FlashAttention系列快1.4-11.8倍，稀疏基线性能超竞品23%。

Conclusion: 开创性提出面向实时视频的高效稀疏注意力参数化方法，为高分辨率视频生成提供全新优化方向，代码已开源推动领域发展。

Abstract: Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.

</details>


### [60] [Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching](https://arxiv.org/abs/2602.12280)
*Huai-Hsun Cheng,Siang-Ling Zhang,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Progressive Semantic Illusions的新方法，通过逐步添加笔画实现单个草图的跨语义变换，例如从鸭子变为绵羊。


<details>
  <summary>Details</summary>
Motivation: 传统视觉错觉依赖空间操作（如多视角一致性），而该研究旨在通过时间维度的笔画序列叠加，探索动态语义转换的可能性。

Method: 提出Stroke of Surprise框架，核心包含序列感知的联合优化模型、双分支得分蒸馏采样机制（SDS）以及确保空间互补性的Overlay Loss，动态调整初始笔画以寻找双重语义的结构子空间。

Result: 实验表明，该方法在可识别性和错觉强度上显著优于现有基线模型，首次将视觉字谜（anagrams）从空间维度扩展到时间维度。

Conclusion: 通过解决初始笔画与后续笔画的双重约束问题，该研究为动态语义变换提供了新思路，并验证了时间维度在视觉错觉设计中的有效性。

Abstract: Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the "dual-constraint": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a "common structural subspace" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [61] [HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents](https://arxiv.org/abs/2602.11156)
*Sungmoon Kim,Hyuna Jeon,Dahye Kim,Mingyu Kim,Dong-Kyu Chae,Jiwoong Kim*

Main category: cs.CL

TL;DR: HybridRAG改进了传统RAG框架，通过预生成问答知识库和OCR处理非结构化PDF文档，实现更快速准确的聊天机器人响应。


<details>
  <summary>Details</summary>
Motivation: 传统RAG依赖结构化文本且实时检索生成效率低，难以满足实际应用场景对非结构化文档处理和低延迟响应的需求。

Method: 采用OCR和版面分析提取PDF内容生成分层文本块，利用LLM预生成问答库；查询时优先匹配现有问答，匹配失败再实时生成回复。

Result: 在OHRBench数据集上验证，相比标准RAG基线，答案质量提升且延迟降低。

Conclusion: HybridRAG在计算资源受限场景下，能有效解决非结构化文档处理和大规模用户服务问题，具备实际应用价值。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.

</details>


### [62] [Retrieval Heads are Dynamic](https://arxiv.org/abs/2602.11162)
*Yuping Lin,Zitao Li,Yue Xing,Pengfei He,Yingqian Cui,Yaliang Li,Bolin Ding,Jingren Zhou,Jiliang Tang*

Main category: cs.CL

TL;DR: 该论文指出大型语言模型（LLMs）中的检索头具有动态性，且在不同时间步中不可替代，模型隐藏状态能预测未来的检索头模式。


<details>
  <summary>Details</summary>
Motivation: 先前研究关注基于静态统计数据的检索头识别，忽视了自回归生成过程中的细粒度动态变化。作者试图从动态视角重新解析检索头的作用机制。

Method: 通过大量实验分析（包括针在干草堆任务和多跳问答任务）验证时间步动态性、检索头不可替代性，以及模型隐藏状态对检索模式的预测能力，并在动态检索增强生成框架中量化动态与静态检索头的效用差异。

Result: 提出三个核心结论：（1）动态性：检索头随时间步变化；（2）不可替代性：动态检索头无法被静态替代；（3）相关性：模型隐藏状态编码未来检索模式的预测信号。

Conclusion: 研究为理解LLMs内部机制提供了新视角，强调动态视角对模型解析的重要性。

Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.

</details>


### [63] [Nested Named Entity Recognition in Plasma Physics Research Articles](https://arxiv.org/abs/2602.11163)
*Muhammad Haris,Hans Höft,Markus M. Becker,Markus Stocker*

Main category: cs.CL

TL;DR: 该论文将命名实体识别（NER）应用于等离子体物理研究论文，提出了一种基于编码器- Transformer 和条件随机场（CRF）的轻量级方法来提取嵌套实体。


<details>
  <summary>Details</summary>
Motivation: 等离子体物理研究论文包含高度复杂且上下文丰富的科学文本，亟需有效识别特定实体以支持高级检索和分析。

Method: 构建包含16个类别、专为嵌套NER设计的等离子体物理语料库，训练多个针对特定实体类型的BERT-CRF独立模型，并通过系统性超参数优化提升性能。

Result: 提出了实体特化模型训练方法，成功标注语料库，并通过实验验证了轻量级深度学习模型在该领域嵌套NER的有效性。

Conclusion: 研究为等离子体物理领域实体识别提供了新方法，同时为科学文献的导航与分析建立了可扩展的基础框架。

Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.

</details>


### [64] [Assessing LLM Reliability on Temporally Recent Open-Domain Questions](https://arxiv.org/abs/2602.11165)
*Pushwitha Krishnappa,Amit Das,Vinija Jain,Tathagata Mukherjee,Aman Chadha*

Main category: cs.CL

TL;DR: 该论文提出了RECOM基准数据集，包含2025年9月的15,000个Reddit问题及社区参考答案，发现大型语言模型（LLMs）在语义相似度上表现优异但词汇重合度极低，反映出模型倾向于通过释义而非字面匹配传递意义，并揭示模型规模与性能无直接关联。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在开放域问答任务中对时事信息与人类观点的一致性，现有评估指标对抽象生成的可靠性存疑，需建立多维度评价框架。

Method: 构建RECOM数据集，采用BLEU、ROUGE（词汇）、BERTScore、MoverScore（语义）、NLI（逻辑推理）对Llama3.1-8B、Mistral-7B等四种模型进行系统评估。

Result: 所有模型的余弦相似度超99%但BLEU-1不足8%，Mistral-7B性能超越GPT-OSS-20B，矛盾率低于7%，证实模型极少生成与人类共识冲突内容。

Conclusion: 传统词汇指标不足以评估抽象生成任务，需结合语义深度与迁移成本等多维度评估；模型规模非性能决定因素，释义能力成为关键。

Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0

</details>


### [65] [Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?](https://arxiv.org/abs/2602.11166)
*Xu Hu,Yifan Zhang,Songtao Wei,Chen Zhao,Qiannan Li,Bingzhe Li,Feng Chen*

Main category: cs.CL

TL;DR: 研究揭示参数高效微调(PEFT)通过重塑模型不确定性而非注入新知识，显著提升大语言模型在问答任务中的幻觉检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对PEFT方法如何影响大语言模型幻觉行为的系统性研究，特别是其在事实导向型问答数据集中的表现机制尚未明确。

Method: 通过3种开源LLM架构和3个事实型QA基准，采用7种无监督幻觉检测方法（语义一致性/置信度/熵基）进行跨范式评估，并结合线性探针和表示诊断分析模型不确定性变化。

Result: PEFT持续增强幻觉检测能力，显著提升AUROC指标；证据显示其主要通过重构模型不确定性表达（而非添加新知识）实现性能提升。

Conclusion: PEFT方法通过调整模型对不确定性的编码方式提升幻觉检测效果，这种机制理解可为开发可靠语言模型提供新方向。

Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.

</details>


### [66] [Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering](https://arxiv.org/abs/2602.11167)
*Nathan Mao,Varun Kaushik,Shreya Shivkumar,Parham Sharafoleslami,Kevin Zhu,Sunishchal Dev*

Main category: cs.CL

TL;DR: 本研究引入FalseCite数据集，通过分析GPT-4o-mini等模型的隐藏状态向量，揭示错误引用引发的幻觉特性，并提出可视化分析工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗/法律等敏感领域易因错误引用生成虚假信息，亟需系统性的测评工具；现有方法缺乏对隐藏状态的深入分析。

Method: 1.构建FalseCite数据集包含误导性引用的查询；2.验证三个主流模型的幻觉反应；3.对模型隐藏状态进行可视化与聚类分析。

Result: GPT-4o-mini在错误引用下幻觉显著上升，所有模型的隐藏状态向量均呈现独特'犄角状'分布特征，无论输出是否包含幻觉。

Conclusion: FalseCite为LLM幻觉研究提供了可控的测评框架，隐藏状态的几何结构发现为缓解幻觉提供了新的分析视角，可指导未来模型改进。

Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.

</details>


### [67] [Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI](https://arxiv.org/abs/2602.11168)
*Jingyan Xu,Marcelo L. LaFleur,Christina Schweikert,D. Frank Hsu*

Main category: cs.CL

TL;DR: 本论文提出通过组合多个机器学习模型与人类专家知识，利用组合融合分析(CFA)提升文本分类在联合国可持续发展目标(SDGs)中的分类性能，融合模型达到96.73%准确率，超越单一模型并验证了模型与人类知识的协同效应。


<details>
  <summary>Details</summary>
Motivation: 传统文本分类方法在类别不可用、难以区分或存在关联时效果受限，尤其在依赖文本数据的人类社会分析领域，亟需一种能有效整合模型差异性与人类专家知识的分类优化方法。

Method: 首先利用生成式AI模型生成SDG相关文本的合成数据进行训练，随后应用基于秩得分特征(RSC)和认知多样性(CD)的组合融合分析(CFA)框架，对多模型结果进行加权融合，并与人类专家标注结果进行对比分析。

Result: CFA融合模型在测试数据上达到96.73%的分类准确率，优于所有单一模型，且与人类专家结果对比显示，机器模型与专家知识不仅相互补充，结合后还可产生协同性能提升。

Conclusion: 通过组合生成式AI合成数据、多模型认知多样性挖掘及人类专家知识融合，可有效提升复杂文本分类任务性能，验证了机器智能与人类智慧在可持续发展目标分类中的协同价值。

Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making. However, it remains a challenging problem in cases where the categories are unavailable, difficult to differentiate, or are interrelated. Social analysis with human context is an area that can benefit from text classification, as it relies substantially on text data. The focus of this paper is to enhance the classification of text according to the UN's Sustainable Development Goals (SDGs) by collecting and combining intelligence from multiple models. Combinatorial Fusion Analysis (CFA), a system fusion paradigm using a rank-score characteristic (RSC) function and cognitive diversity (CD), has been used to enhance classifier methods by combining a set of relatively good and mutually diverse classification models. We use a generative AI model to generate synthetic data for model training and then apply CFA to this classification task. The CFA technique achieves 96.73% performance, outperforming the best individual model. We compare the outcomes with those obtained from human domain experts. It is demonstrated that combining intelligence from multiple ML/AI models using CFA and getting input from human experts can, not only complement, but also enhance each other.

</details>


### [68] [Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis](https://arxiv.org/abs/2602.11169)
*Mangadoddi Srikar Vardhan,Lekkala Sai Teja*

Main category: cs.CL

TL;DR: Transformer隐藏状态中方向影响语言模型损失，幅度影响句法处理。方向扰动损害注意力路由，幅度扰动干扰LayerNorm路径。该分工依赖于模型架构选择。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer中向量方向（方向）和幅度（大小）是否承担不同计算功能，解决方向/幅度功能角色模糊的问题，为模型编辑和可解释性提供依据。

Method: 采用L2-matched扰动方法（保证方向/幅度扰动的欧氏位移相等），结合因果干预分析（注意力/LayerNorm路径修复效果），并跨Pythia家族模型验证，在不同架构（LayerNorm vs RMSNorm）中检验普适性。

Result: 方向扰动提升42.9%语言模型损失，幅度扰动导致句法任务准确率下降20.4%；注意力路径修复挽回28.4%方向扰动损失，LayerNorm修复挽回29.9%幅度扰动损失；RMSNorm架构显示不同分工模式。

Conclusion: 方向与幅度在LayerNorm架构中分工：方向主导注意力路由，幅度调节语法处理强度。架构决定功能分工，结果修正线性表征假说，为模型干预和解释提供关键依据。

Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying Pythia-family models, we discover a striking cross-over dissociation: angular perturbations cause up to 42.9 more damage to language modeling loss, while magnitude perturbations cause disproportionately more damage to syntactic processing (20.4% vs.1.6% accuracy drop on subject-verb agreement).This finding is enabled by L2-matched perturbation analysis, a methodology ensuring that an gular and magnitude perturbations achieve identical Euclidean displacements. Causal intervention reveals that angular damage flows substantially through the attention pathways (28.4% loss recovery via attention repair), while magnitude damage flows partly through the LayerNorm pathways(29.9% recovery via LayerNorm repair). These patterns replicate across scales within the Pythia architecture family. These findings provide evidence that direction and magnitude support partially distinct computational roles in LayerNorm based architectures. The direction preferentially affects attentional routing, while magnitude modulates processing intensity for fine-grained syntactic judgments. We find different patterns in RMSNorm-based architectures, suggesting that the dissociation depends on architectural choices. Our results refine the linear representation hypothesis and have implications for model editing and interpretability research

</details>


### [69] [Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization](https://arxiv.org/abs/2602.11171)
*Baek Seong-Eun,Lee Jung-Mok,Kim Sung-Bin,Tae-Hyun Oh*

Main category: cs.CL

TL;DR: This paper proposes a framework combining Bayesian Optimization (BO) with pre-trained language models to efficiently search LoRA hyperparameters for LLM fine-tuning, leveraging domain knowledge through language prompts and continuous vector mappings.


<details>
  <summary>Details</summary>
Motivation: LoRA hyperparameter tuning is costly and sensitive; existing methods require exhaustive search. The authors aim to address computational inefficiency in hyperparameter optimization for LLM adaptation.

Method: A language model repurposed as a discrete-to-continuous mapping links hyperparameters to domain knowledge via prompts. Learnable tokens model residual information not described linguistically. Proxy training on data subsets is introduced for further efficiency gains.

Result: Hyperparameters found in ~30 iterations achieved >20% performance improvement over baseline methods testing ~45,000 combinations, with strong correlation between subset/full training data performance.

Conclusion: The framework integrates domain knowledge into BO through language models, demonstrating superior efficiency in finding optimal LoRA hyperparameters for LLM fine-tuning.

Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning efficient, it is highly sensitive to the choice of hyperparameters, and exhaustive hyperparameter search is still computationally very demanding. To address these challenges, we propose a framework that integrates the domain knowledge of pre-trained LLMs into Bayesian Optimization (BO) to efficiently search for LoRA hyperparameters. To leverage the informed knowledge of LLMs, we repurpose LLMs as a discrete-to-continuous mapping to link the hyperparameters and their domain knowledge with a continuous vector space, where BO is conducted. We design and control the mapping by language prompting, where we provide a domain-aware textual prompt describing the relationships among hyperparameters and their respective roles; thereby, we explicitly inject domain knowledge about LoRA into the LLM in natural language. Also, we model the residual information that is hard to linguistically describe in the prompt with an additional learnable token. This aids BO to sample more high-performing hyperparameters. In addition, by leveraging the observation of the strong correlation between the respective performance obtained from full and subset training datasets in LoRA training regimes, we introduce proxy training and evaluation with a data subset. This further increases the efficiency of our method. We demonstrate that our hyperparameter found with only about 30 iterations achieves more than 20% performance improvement over standard hyperparameters found from about 45,000 combinations.

</details>


### [70] [Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages](https://arxiv.org/abs/2602.11172)
*Aniket Deroy*

Main category: cs.CL

TL;DR: This paper evaluates Gemini 2.5 Flash/Pro TTS models for generating court speeches in Tamil, Telugu, Bengali, Hindi, and Gujarati, revealing strengths in procedural delivery but limitations in expressive vocal modulation and performance dips in Bengali/Gujarati.


<details>
  <summary>Details</summary>
Motivation: To address the legal domain's demand for TTS systems that convey authority, professional persona, and cultural nuance in India's multilingual context, moving beyond baseline speech intelligibility.

Method: Proposed a prompting framework leveraging Gemini 2.5's multilingual support and context-aware pacing to synthesize distinct advocate personas across five languages, then evaluated the outputs for procedural accuracy, vocal expressiveness, and phonological fidelity.

Result: Models demonstrated 'monotone authority' - strong in procedural information delivery but lacking dynamic emotional modulation; Bengali/Gujarati outputs showed reduced phonological accuracy, highlighting language-specific challenges.

Conclusion: Current multilingual TTS achieves procedural competence in legal settings but requires advancements in expressive synthesis and phonological handling for minority languages to replicate persuasive human advocacy.

Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in generating synthetic courtroom speeches across five Indic languages: Tamil, Telugu, Bengali, Hindi, and Gujarati. We propose a prompting framework that utilizes Gemini 2.5s native support for 5 languages and its context-aware pacing to produce distinct advocate personas. The evolution of Large Language Models (LLMs) has shifted the focus of TexttoSpeech (TTS) technology from basic intelligibility to context-aware, expressive synthesis. In the legal domain, synthetic speech must convey authority and a specific professional persona a task that becomes significantly more complex in the linguistically diverse landscape of India. The models exhibit a "monotone authority," excelling at procedural information delivery but struggling with the dynamic vocal modulation and emotive gravitas required for persuasive advocacy. Performance dips in Bengali and Gujarati further highlight phonological frontiers for future refinement. This research underscores the readiness of multilingual TTS for procedural legal tasks while identifying the remaining challenges in replicating the persuasive artistry of human legal discourse. The code is available at-https://github.com/naturenurtureelite/Synthesizing-the-Virtual-Advocate/tree/main

</details>


### [71] [Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review](https://arxiv.org/abs/2602.11173)
*Qian Ruan,Iryna Gurevych*

Main category: cs.CL

TL;DR: This paper introduces REspGen, a framework for enhancing author response writing in peer review by integrating author input, controllable generation, and evaluation-driven refinement, supported by the Re$^3$Align dataset and REspEval metrics.


<details>
  <summary>Details</summary>
Motivation: Prior work treats response writing as standalone text generation, neglecting valuable author expertise, intent, and revision strategies. Authors require NLP tools that systematically integrate their domain knowledge and revision signals.

Method: Proposed REspGen framework combines explicit author input (e.g., revision changes), multi-attribute control (topic/emotion steering), and evaluation-guided refinement. Created first large-scale Re$^3$Align dataset with aligned review-response-revision triplets. Developed REspEval with 20+ metrics for input utilization, controllability, and quality.

Result: Experiments show author input improves response relevance, evaluation-guided refinement enhances coherence, input design choices significantly affect output quality, and trade-offs exist between strict content control and generation fluency.

Conclusion: Framework demonstrates how collaborative NLP systems can preserve author intent while improving peer review responses. Dataset and tools released to advance human-AI co-writing research in academic contexts.

Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In practice, authors possess domain expertise, author-only information, revision and response strategies--concrete forms of author expertise and intent--to address reviewer concerns, and seek NLP assistance that integrates these signals to support effective response writing in peer review. We reformulate author response generation as an author-in-the-loop task and introduce REspGen, a generation framework that integrates explicit author input, multi-attribute control, and evaluation-guided refinement, together with REspEval, a comprehensive evaluation suite with 20+ metrics covering input utilization, controllability, response quality, and discourse. To support this formulation, we construct Re$^3$Align, the first large-scale dataset of aligned review--response--revision triplets, where revisions provide signals of author expertise and intent. Experiments with state-of-the-art LLMs show the benefits of author input and evaluation-guided refinement, the impact of input design on response quality, and trade-offs between controllability and quality. We make our dataset, generation and evaluation tools publicly available.

</details>


### [72] [The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models](https://arxiv.org/abs/2602.11174)
*Aradhya Dixit,Shreem Dixit*

Main category: cs.CL

TL;DR: Multilingual language models的分词器在不同书写系统上存在系统性代价，导致信息成本增加和处理速度下降。


<details>
  <summary>Details</summary>
Motivation: 质疑预训练多语言模型的'文字无关性'假设，揭示分词器对不同文字系统的隐性成本差异问题。

Method: 通过对比相同语言内容的两种文字变体，使用BPC指标评估信息成本，结合字符错误率(CER)检验转换噪声，测量推理速度差异。

Result: 高碎片化文字导致分词器产生3.4倍更多子词单元，推理速度慢16.5倍；信息成本增加19.7%(mBERT)和47.1%(XLM-R)，排除了79%的转换噪声影响。

Conclusion: 分词器设计是多语言NLP不平等的核心原因，提出需要文字感知的分词和预训练方法改进现有框架。

Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with identical linguistic content. Across mBERT and XLM-R, the higher-fragmentation orthography shows a ~3.4x increase in fertility (6.73-6.85 vs. 2.10-2.35 tokens/word), leading to a 16.5x inference slowdown (0.23 vs. 3.8 sentences/second) on identical hardware. Using bits per character (BPC) to avoid the "NLL paradox" from subword fragmentation, we find a substantial increase in information cost: +19.7% for mBERT (8.06->9.65) and +47.1% for XLM-R (12.19->17.94). A round-trip conversion check (CER_rt=0.31) suggests these gaps reflect orthography-conditioned processing rather than mapping noise. Our results highlight tokenization as a key source of inequity in multilingual NLP and motivate script-aware tokenization and pretraining.

</details>


### [73] [Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth](https://arxiv.org/abs/2602.11175)
*Michelle Yuan,Weiyi Sun,Amir H. Rezaeian,Jyotika Singh,Sandip Ghoshal,Yao-Ting Wang,Miguel Ballesteros,Yassine Benajiba*

Main category: cs.CL

TL;DR: Transformers excel in pattern matching but face theoretical limitations in discrete reasoning tasks like arithmetic and logic, which are analyzed through complexity theories to guide future model improvements.


<details>
  <summary>Details</summary>
Motivation: The paper aims to clarify the theoretical barriers of transformers in symbolic computation by synthesizing recent findings, offering insights for overcoming these limitations.

Method: The analysis combines three theoretical frameworks: circuit complexity (computational depth), approximation theory (handling discontinuities), and communication complexity (token interaction limits).

Result: Identified structural barriers include depth constraints, poor approximation of discontinuities, and inter-token communication bottlenecks in transformers when executing exact discrete algorithms.

Conclusion: Current transformer designs need fundamental advancements in depth, discontinuity handling, and communication efficiency to improve discrete reasoning, suggesting research directions for model innovation.

Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical limitations in discrete reasoning tasks, such as arithmetic, logical inference, and algorithmic composition, remain a critical open problem. In this survey, we synthesize recent studies from three theoretical perspectives: circuit complexity, approximation theory, and communication complexity, to clarify the structural and computational barriers that transformers face when performing symbolic computations. By connecting these established theoretical frameworks, we provide an accessible and unified account of why current transformer architectures struggle to implement exact discrete algorithms, even as they excel at pattern matching and interpolation. We review key definitions, seminal results, and illustrative examples, highlighting challenges such as depth constraints, difficulty approximating discontinuities, and bottlenecks in inter-token communication. Finally, we discuss implications for model design and suggest promising directions for overcoming these foundational limitations.

</details>


### [74] [Evaluating Few-Shot Temporal Reasoning of LLMs for Human Activity Prediction in Smart Environments](https://arxiv.org/abs/2602.11176)
*Maral Doctorarastoo,Katherine A. Flanigan,Mario Bergés,Christopher McComb*

Main category: cs.CL

TL;DR: 本论文提出利用预训练大语言模型结合检索增强提示策略，在低数据环境下通过融合时间、空间、行为历史和人物属性等多源信息，预测人类活动及其持续时间，并通过CASAS Aruba数据集验证该方法在零样本和少样本场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的智能体模型在低数据环境中表现不足，而预训练大语言模型可能通过上下文推理弥合这一缺口。

Method: 构建检索增强提示框架，融合四类情境信息（时间、空间、行为历史、人物属性），在CASAS Aruba数据集上执行下一步活动预测与多步日常序列生成任务，并系统评估不同少样本示例数量对效果的影响。

Result: 零样本设置下大语言模型即可生成连贯预测，单个示例的加入显著提升时长校准与分类准确度，但超过少量示例后效果趋于饱和，序列级评估显示时序一致性稳定。

Conclusion: 预训练语言模型具备强效的时间推理能力，可同时捕获常规模式和情境依赖的行为变化，为基于智能体的模型提供更强的行为模拟能力。

Abstract: Anticipating human activities and their durations is essential in applications such as smart-home automation, simulation-based architectural and urban design, activity-based transportation system simulation, and human-robot collaboration, where adaptive systems must respond to human activities. Existing data-driven agent-based models--from rule-based to deep learning--struggle in low-data environments, limiting their practicality. This paper investigates whether large language models, pre-trained on broad human knowledge, can fill this gap by reasoning about everyday activities from compact contextual cues. We adopt a retrieval-augmented prompting strategy that integrates four sources of context--temporal, spatial, behavioral history, and persona--and evaluate it on the CASAS Aruba smart-home dataset. The evaluation spans two complementary tasks: next-activity prediction with duration estimation, and multi-step daily sequence generation, each tested with various numbers of few-shot examples provided in the prompt. Analyzing few-shot effects reveals how much contextual supervision is sufficient to balance data efficiency and predictive accuracy, particularly in low-data environments. Results show that large language models exhibit strong inherent temporal understanding of human behavior: even in zero-shot settings, they produce coherent daily activity predictions, while adding one or two demonstrations further refines duration calibration and categorical accuracy. Beyond a few examples, performance saturates, indicating diminishing returns. Sequence-level evaluation confirms consistent temporal alignment across few-shot conditions. These findings suggest that pre-trained language models can serve as promising temporal reasoners, capturing both recurring routines and context-dependent behavioral variations, thereby strengthening the behavioral modules of agent-based models.

</details>


### [75] [What Do LLMs Know About Alzheimer's Disease? Fine-Tuning, Probing, and Data Synthesis for AD Detection](https://arxiv.org/abs/2602.11177)
*Lei Jiang,Yue Zhou,Natalie Parde*

Main category: cs.CL

TL;DR: 本文探索使用微调大型语言模型（LLM）进行阿尔茨海默病（AD）早期检测。通过分析模型内部表示发现，任务相关的特殊标记在微调后对检测性能关键。基于此设计数据合成工具，生成结构合理且诊断有效的合成样本，并验证其性能。


<details>
  <summary>Details</summary>
Motivation: AD早期可靠检测面临挑战，特别是在缺乏标记数据的情况下。LLMs 在跨领域迁移学习方面表现强大，但在监督条件下微调 LLM 用于 AD 检测仍需进一步探索。

Method: 1. 对 LLM 进行 AD 检测微调；2. 使用探测技术分析 Transformer 层中间激活状态以识别关键特征；3. 设计任务感知特殊标记并训练数据合成模型（序列到序列架构）生成诊断相关的合成样本；4. 多维度评估（内在评估和下游任务测试）合成数据质量。

Result: 微调后特定词汇及特殊标记的探测值明显变化，表明其对检测性能提升起到核心作用。合成数据不仅在结构上保持一致性，还显著提升下游任务性能，证明了该方法的有效性。

Conclusion: 通过模型分析揭示了任务相关特征的重要性，并利用研究成果设计了高效的合成数据生成方案，为数据稀缺的 AD 检测提供了可行的解决方案，同时拓展了 LLMs 在医疗领域的应用潜力。

Abstract: Reliable early detection of Alzheimer's disease (AD) is challenging, particularly due to limited availability of labeled data. While large language models (LLMs) have shown strong transfer capabilities across domains, adapting them to the AD domain through supervised fine-tuning remains largely unexplored. In this work, we fine-tune an LLM for AD detection and investigate how task-relevant information is encoded within its internal representations. We employ probing techniques to analyze intermediate activations across transformer layers, and we observe that, after fine-tuning, the probing values of specific words and special markers change substantially, indicating that these elements assume a crucial role in the model's improved detection performance. Guided by this insight, we design a curated set of task-aware special markers and train a sequence-to-sequence model as a data-synthesis tool that leverages these markers to generate structurally consistent and diagnostically informative synthetic samples. We evaluate the synthesized data both intrinsically and by incorporating it into downstream training pipelines.

</details>


### [76] [From Instruction to Output: The Role of Prompting in Modern NLG](https://arxiv.org/abs/2602.11179)
*Munazza Zaib,Elaf Alhazmi*

Main category: cs.CL

TL;DR: 本文综述了提示工程在自然语言生成中的应用进展，提出提示设计的分类体系与决策框架。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对提示工程方法的系统性框架理解，尤其在自然语言生成领域，需填补理论空白并提供实践指导。

Method: 通过文献综述构建提示范式分类体系，设计基于多因素的提示选择决策框架，并提出设计-优化-评估三维联动模型。

Result: 揭示了输入级提示控制机制对生成可控性的提升效果，发现解码策略与提示优化存在显著交互效应。

Conclusion: 提示工程需从孤立技术转向系统化工程方法，未来应强化框架可解释性并通过自动化实现技术民主化。

Abstract: Prompt engineering has emerged as an integral technique for extending the strengths and abilities of Large Language Models (LLMs) to gain significant performance gains in various Natural Language Processing (NLP) tasks. This approach, which requires instructions to be composed in natural language to bring out the knowledge from LLMs in a structured way, has driven breakthroughs in various NLP tasks. Yet there is still no structured framework or coherent understanding of the varied prompt engineering methods and techniques, particularly in the field of Natural Language Generation (NLG).
  This survey aims to help fill that gap by outlining recent developments in prompt engineering, and their effect on different NLG tasks. It reviews recent advances in prompting methods and their impact on NLG tasks, presenting prompt design as an input-level control mechanism that complements fine-tuning and decoding approaches. The paper introduces a taxonomy of prompting paradigms, a decision framework for prompt selection based on varying factors for the practitioners, outlines emerging trends and challenges, and proposes a framework that links design, optimization, and evaluation to support more controllable and generalizable NLG.

</details>


### [77] [Mechanistic Interpretability for Large Language Model Alignment: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2602.11180)
*Usman Naseem*

Main category: cs.CL

TL;DR: This paper reviews recent advances in mechanistic interpretability of large language models (LLMs), discussing methods like circuit discovery, activation steering, and causal intervention, while identifying challenges such as superposition and polysemantic neurons. It highlights applications in LLM alignment strategies (e.g., RLHF) and proposes future directions for automated interpretability and scalable alignment techniques.


<details>
  <summary>Details</summary>
Motivation: LLMs' internal decision-making processes remain opaque despite their capabilities, creating a critical need for mechanistic interpretability research to improve transparency and alignment with human values.

Method: The paper surveys mechanistic interpretability techniques, including circuit discovery, feature visualization, activation steering, and causal intervention. It evaluates how these insights inform alignment strategies (e.g., RLHF, constitutional AI) and analyzes challenges in interpreting LLMs.

Result: Key challenges identified include the superposition hypothesis, polysemanticity of neurons, and difficulties in interpreting emergent behaviors in large-scale models. The analysis also reveals how interpretability insights have shaped alignment strategies.

Conclusion: The paper advocates for future research in automated interpretability, cross-model generalization of circuits, and scalability of interpretability-driven alignment techniques to address challenges in frontier LLMs.

Abstract: Large language models (LLMs) have achieved remarkable capabilities across diverse tasks, yet their internal decision-making processes remain largely opaque. Mechanistic interpretability (i.e., the systematic study of how neural networks implement algorithms through their learned representations and computational structures) has emerged as a critical research direction for understanding and aligning these models. This paper surveys recent progress in mechanistic interpretability techniques applied to LLM alignment, examining methods ranging from circuit discovery to feature visualization, activation steering, and causal intervention. We analyze how interpretability insights have informed alignment strategies including reinforcement learning from human feedback (RLHF), constitutional AI, and scalable oversight. Key challenges are identified, including the superposition hypothesis, polysemanticity of neurons, and the difficulty of interpreting emergent behaviors in large-scale models. We propose future research directions focusing on automated interpretability, cross-model generalization of circuits, and the development of interpretability-driven alignment techniques that can scale to frontier models.

</details>


### [78] [Code Mixologist : A Practitioner's Guide to Building Code-Mixed LLMs](https://arxiv.org/abs/2602.11181)
*Himanshu Gupta,Pratik Jayarao,Chaitanya Dwivedi,Neeraj Varshney*

Main category: cs.CL

TL;DR: 本文综述了代码混合和代码切换对大语言模型带来的挑战，提出统一分类法和实践指南，分析评估与安全问题，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 代码混合和代码切换现象在真实场景中普遍存在的同时，大语言模型在混合语言设置下频繁出现语法、事实性和安全性行为退化，现有方法缺乏系统性解决方案。

Method: 构建三维分类法（数据、建模、评估）框架梳理文献，提出包含预训练优化与动态适应策略的实践指南，通过实证分析揭示评估不稳定性和基准偏见，并建立安全风险分析框架。

Result: 成功建立跨维度的分析框架与可操作指南，验证了多阶段建模策略的有效性，发现现有基准测试中85%存在英语中心偏差，且代码混合被证实可用于绕过模型安全限制。

Conclusion: 需通过协同研究推进多维解决方案，强调动态建模策略与公平基准测试的重要性，提出将代码混合机制纳入模型安全框架的设计原则。

Abstract: Code-mixing and code-switching (CSW) remain challenging phenomena for large language models (LLMs). Despite recent advances in multilingual modeling, LLMs often struggle in mixed-language settings, exhibiting systematic degradation in grammaticality, factuality, and safety behavior. This work provides a comprehensive overview of CSW research in modern large language model settings. We introduce a unifying taxonomy that organizes prior work along dimensions of data, modeling, and evaluation, and we distill these findings into a practical playbook of actionable recommendations for building, adapting, and evaluating CSW-capable LLMs. We review modeling approaches ranging from CSW-tailored pre-training and task-specific post-training to prompting strategies and in-context learning. We analyze current evaluation practices, highlighting sources of instability and limited reproducibility, and we catalog existing benchmarks while critically examining their linguistic coverage and English-centric biases. Finally, we discuss emerging safety concerns, including use of code-mixing as a mechanism for bypassing model safeguards, and identify open research challenges.

</details>


### [79] [MetaMem: Evolving Meta-Memory for Knowledge Utilization through Self-Reflective Symbolic Optimization](https://arxiv.org/abs/2602.11182)
*Haidong Xin,Xinze Li,Zhenghao Liu,Yukun Yan,Shuo Wang,Cheng Yang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: MetaMem通过自进化元记忆框架增强大语言模型的记忆系统，系统化整合分散的记忆片段以提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆系统破坏交互会话中的逻辑和时序关系，导致记忆碎片化和推理性能衰退，需解决知识利用的系统性问题。

Method: 提出MetaMem框架：1)通过任务间知识利用经验的迭代蒸馏，基于推理过程自反更新元记忆状态；2)元记忆单元显式引导LLM从碎片化记忆中提取关键证据。

Result: 实验显示MetaMem性能显著优于强基线模型，提升幅度超过3.6%，代码和数据集已开源。

Conclusion: 通过系统性知识利用机制，MetaMem有效解决了记忆碎片化问题，为长程人机交互提供了可扩展的记忆增强方案。

Abstract: Existing memory systems enable Large Language Models (LLMs) to support long-horizon human-LLM interactions by persisting historical interactions beyond limited context windows. However, while recent approaches have succeeded in constructing effective memories, they often disrupt the inherent logical and temporal relationships within interaction sessions, resulting in fragmented memory units and degraded reasoning performance. In this paper, we propose MetaMem, a novel framework that augments memory systems with a self-evolving meta-memory, aiming to teach LLMs how to effectively utilize memorized knowledge. During meta-memory optimization, MetaMem iteratively distills transferable knowledge utilization experiences across different tasks by self-reflecting on reasoning processes and performing actions to update the current meta-memory state. The accumulated meta-memory units serve as explicit knowledge utilization experiences, guiding the LLM to systematically identify and integrate critical evidence from scattered memory fragments. Extensive experiments demonstrate the effectiveness of MetaMem, which significantly outperforms strong baselines by over 3.6%. All codes and datasets are available at https://github.com/OpenBMB/MetaMem.

</details>


### [80] [DDL2PropBank Agent: Benchmarking Multi-Agent Frameworks' Developer Experience Through a Novel Relational Schema Mapping Task](https://arxiv.org/abs/2602.11198)
*Shafiuddin Rehan Ahmed,Wei Wei*

Main category: cs.CL

TL;DR: 该论文介绍了DDL2PropBank，一个新的基准任务，用于评估多智能体框架的开发者体验，发现Agno在代码复杂度和AI辅助能力方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一种系统的方法在受控环境中评估多智能体框架的开发者体验。

Method: 通过设计DDL2PropBank任务（将关系数据库模式映射到PropBank角色集），并使用Agent-as-a-Tool模式在10个框架中实现相同的智能体逻辑，从代码复杂度和AI辅助生成能力两个维度进行评估。

Result: 代码复杂度上，Pydantic AI和Agno实现成本最低；AI辅助能力中，结构对齐评估在单一模式框架中有效，但在多模式框架中高估了正确性。Agno以83%的pass@1率成为综合性能最佳框架。

Conclusion: Agno平衡了最低复杂度与最高结构对齐，证明多智能体框架的评估需结合任务特性；结构对齐评估不能完全替代实际运行测试。

Abstract: Multi-agent frameworks promise to simplify LLM-driven software development, yet there is no principled way to evaluate their developer experience in a controlled setting. We introduce DDL2PropBank, a novel benchmark task that maps relational database schemas to PropBank rolesets, requiring autonomous retrieval of candidate frames and fine-grained linguistic reasoning over table names, columns, and relations. Using the Agent-as-a-Tool pattern, we implement identical agent logic across 10 frameworks and evaluate along two dimensions: (i) code complexity via static analysis, and (ii) AI-assistability -- the extent to which LLMs can autonomously generate correct, framework-specific code. Our results reveal a threefold complexity spectrum, with Pydantic AI and Agno requiring the least implementation overhead. For AI-assistability, structural alignment scores reliably proxy runtime success for frameworks with single canonical patterns, but overestimate correctness for multi-pattern frameworks. Agno emerges as the strongest overall performer, combining lowest complexity with highest structural alignment and 83% pass@1.

</details>


### [81] [When and What to Ask: AskBench and Rubric-Guided RLVR for LLM Clarification](https://arxiv.org/abs/2602.11199)
*Jiale Zhao,Ke Fang,Lu Cheng*

Main category: cs.CL

TL;DR: 本研究提出AskBench基准和RLVR训练方法，用于提升大型语言模型在不完整/误导性提问时主动澄清的能力，同时保持任务准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs常因提示信息缺失或错误产生幻觉或错误推论，需研究其自主提问澄清机制，避免盲目作答引发危害。

Method: 构建交互式基准AskBench，包含AskMind（意图缺失）和AskOverconfidence（错误前提）两种场景；设计基于评分规则的验证者奖励强化学习算法RLVR，通过结构化评分指标引导模型生成精准澄清问题。

Result: 实验显示RLVR在AskBench上取得准确率提升、评分规则遵循度增强及对话效率优化，且模型能力可泛化至未知领域。统一评判系统有效模拟用户反馈进行迭代优化。

Conclusion: 结构化交互式训练（RLVR）能显著提升LLMs在复杂推理中的自主澄清能力，平衡准确性与交互成本，为安全可靠的语言模型应用提供技术路径。

Abstract: Large language models (LLMs) often respond even when prompts omit critical details or include misleading information, leading to hallucinations or reinforced misconceptions. We study how to evaluate and improve LLMs' ability to decide when and what to ask for clarification without sacrificing task performance. We introduce AskBench, an interactive benchmark that converts standard QA pairs into multi-turn interactions with explicit checkpoints. A unified judge loop evaluates final answers and simulates user responses as needed. AskBench covers two settings: AskMind, with intent-deficient queries requiring clarification, and AskOverconfidence, with queries containing false premises that must be identified and corrected. We further propose rubric-guided reinforcement learning with verifier-based rewards (RLVR), which uses structured rubrics to encourage targeted clarification. Experiments show consistent improvements in accuracy, rubric adherence, and interaction efficiency, with strong generalization to unseen domains.

</details>


### [82] [Mechanistic Evidence for Faithfulness Decay in Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.11201)
*Donald Ye,Max Loffgren,Om Kotadia,Linus Wong*

Main category: cs.CL

TL;DR: 提出NLDD指标评估链式思考解释是否忠实反映模型的推理过程


<details>
  <summary>Details</summary>
Motivation: 为了解决链式思考（CoT）解释是否真实反映模型决策机制而非事后辩解的核心争议，提供可量化的评估方法

Method: 设计标准化对数差异衰减（NLDD）指标：通过主动破坏推理链中的单个步骤，测量模型置信度下降幅度，并建立跨模型比较框架

Result: 发现推理链存在70-85%长度的决策临界点，超出部分对答案影响趋于中性或负面；发现模型可能具备内部正确表征却仍任务失败

Conclusion: 证明准确率无法反映模型是否实际使用推理链，NLDD提供了可量化评估CoT有效性的新范式

Abstract: Chain-of-Thought (CoT) explanations are widely used to interpret how language models solve complex problems, yet it remains unclear whether these step-by-step explanations reflect how the model actually reaches its answer, or merely post-hoc justifications. We propose Normalized Logit Difference Decay (NLDD), a metric that measures whether individual reasoning steps are faithful to the model's decision-making process. Our approach corrupts individual reasoning steps from the explanation and measures how much the model's confidence in its answer drops, to determine if a step is truly important. By standardizing these measurements, NLDD enables rigorous cross-model comparison across different architectures. Testing three model families across syntactic, logical, and arithmetic tasks, we discover a consistent Reasoning Horizon (k*) at 70--85% of chain length, beyond which reasoning tokens have little or negative effect on the final answer. We also find that models can encode correct internal representations while completely failing the task. These results show that accuracy alone does not reveal whether a model actually reasons through its chain. NLDD offers a way to measure when CoT matters.

</details>


### [83] [Are Aligned Large Language Models Still Misaligned?](https://arxiv.org/abs/2602.11305)
*Usman Naseem,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Agrima Seth*

Main category: cs.CL

TL;DR: 该论文提出了Mis-Align Bench，一个统一的评估基准，用于分析大语言模型在安全、价值观和文化维度上的综合对齐偏差。研究发现，单独优化单一维度的模型在多维度联合条件下会出现高覆盖率但低对齐得分的问题。


<details>
  <summary>Details</summary>
Motivation: 现有对齐偏差评估基准（如安全、价值观、文化维度单独测试）无法反映现实世界中多维度同时对齐的需求。研究旨在填补这一空白，实现跨维度综合评估。

Method: 构建包含382,424个样本的多维度数据集SAVACU：1）通过分类学将LLM-PROMPT-DATASET数据重新归类为14种安全、56种价值观、42种文化领域；2）使用Mistral-7B和Llama-3.1模型扩展低资源领域；3）采用两阶段拒绝抽样生成对齐/非对齐响应对。随后对通用型、微调型和开源权重模型进行基准测试。

Result: 单一维度优化模型在孤立测试时覆盖率可达97.6%，但在联合测试中失败率达50%以上，且整体对齐得分仅63%-66%，表明多维度协同对齐的必要性。

Conclusion: 单独维度的对齐优化将导致其他维度的系统性失败，建议采用该多维度协同评估框架。研究为大语言模型在真实场景中的综合对齐提供了技术路径和评测标准。

Abstract: Misalignment in Large Language Models (LLMs) arises when model behavior diverges from human expectations and fails to simultaneously satisfy safety, value, and cultural dimensions, which must co-occur in real-world settings to solve a real-world query. Existing misalignment benchmarks-such as INSECURE CODE (safety-centric), VALUEACTIONLENS (value-centric), and CULTURALHERITAGE (culture centric)-rely on evaluating misalignment along individual dimensions, preventing simultaneous evaluation. To address this gap, we introduce Mis-Align Bench, a unified benchmark for analyzing misalignment across safety, value, and cultural dimensions. First we constructs SAVACU, an English misaligned-aligned dataset of 382,424 samples spanning 112 domains (or labels), by reclassifying prompts from the LLM-PROMPT-DATASET via taxonomy into 14 safety domains, 56 value domains, and 42 cultural domains using Mistral-7B-Instruct-v0.3, and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based fingerprint to avoid deduplication. Furthermore, we pairs prompts with misaligned and aligned responses via two-stage rejection sampling to enforce quality. Second we benchmarks general-purpose, fine-tuned, and open-weight LLMs, enabling systematic evaluation of misalignment under three dimensions. Empirically, single-dimension models achieve high Coverage (upto 97.6%) but incur False Failure Rate >50% and lower Alignment Score (63%-66%) under joint conditions.

</details>


### [84] [Evaluating Alignment of Behavioral Dispositions in LLMs](https://arxiv.org/abs/2602.11328)
*Amir Taubenfeld,Zorik Gekhman,Lior Nezry,Omri Feldman,Natalie Harris,Shashir Reddy,Romina Stella,Ariel Goldstein,Marian Croak,Yossi Matias,Amir Feder*

Main category: cs.CL

TL;DR: 研究通过设计情境判断测试（SJTs）评估LLMs与人类行为对齐度，发现模型在低共识场景过度自信单一响应，高共识场景下小模型显著偏离，且存在跨模型的行为特质差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs深度融入日常生活，需验证其社会行为倾向是否符合人类价值观，避免模型输出与人类共识冲突。

Method: 改编心理学自陈量表为SJTs，构建2500个现实场景测试题（经多阶段标注验证），对比25个LLMs与550名人类参与者的反应数据。

Result: 1) 低共识场景中LLMs倾向单一选择而非表达不确定性；2) 高共识场景下小型模型偏差显著，前沿模型仍有15-20%不匹配；3) 发现跨模型特质差异（如鼓励情绪表达而非人类偏好的冷静）。

Conclusion: SJTs揭示了LLMs自我陈述价值观与实际行为间的显著差距，为评估模型行为提供了可扩展的验证框架，并凸显了模型校准的潜在风险。

Abstract: As LLMs integrate into our daily lives, understanding their behavior becomes essential. In this work, we focus on behavioral dispositions$-$the underlying tendencies that shape responses in social contexts$-$and introduce a framework to study how closely the dispositions expressed by LLMs align with those of humans. Our approach is grounded in established psychological questionnaires but adapts them for LLMs by transforming human self-report statements into Situational Judgment Tests (SJTs). These SJTs assess behavior by eliciting natural recommendations in realistic user-assistant scenarios. We generate 2,500 SJTs, each validated by three human annotators, and collect preferred actions from 10 annotators per SJT, from a large pool of 550 participants. In a comprehensive study involving 25 LLMs, we find that models often do not reflect the distribution of human preferences: (1) in scenarios with low human consensus, LLMs consistently exhibit overconfidence in a single response; (2) when human consensus is high, smaller models deviate significantly, and even some frontier models do not reflect the consensus in 15-20% of cases; (3) traits can exhibit cross-LLM patterns, e.g., LLMs may encourage emotion expression in contexts where human consensus favors composure. Lastly, mapping psychometric statements directly to behavioral scenarios presents a unique opportunity to evaluate the predictive validity of self-reports, revealing considerable gaps between LLMs' stated values and their revealed behavior.

</details>


### [85] [When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing](https://arxiv.org/abs/2602.11358)
*Zachary Pedram Dadfar*

Main category: cs.CL

TL;DR: 本论文提出了Pull Methodology，揭示了大语言模型自我反思语言中的特定词汇与内部激活状态动态变化的对应关系，证明在适当条件下模型自检输出可追踪计算状态。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决长期存在的争议：大语言模型的自我表达反映内部计算还是拟合虚构？通过量化验证自检语言与内部激活的因果关系，为模型分析提供新工具。

Method: 1. 开发Pull Methodology：通过指令模板工程诱导模型进行深度自检；
2. 在Llama 3.1中定位区分自检与描述模式的激活方向；
3. 通过词频-激活相关性分析和控制实验验证映射关系；
4. 在非共享训练的Qwen 2.5-32B上进行跨架构验证。

Result: 1. 发现6.25%深度处的自检特异性激活方向（正交于拒绝方向）；
2. 检测到'loop'（r=0.44）、'shimmer'（r=0.36）等词汇与激活指标的强相关性；
3. 证实相同词汇在非自检场景无对应激活（尽管频率高9倍）；
4. Qwen独立演化出不同词汇-激活映射，支持方法普适性。

Conclusion: 证明通过精心设计的自检语言框架，能可靠捕获模型内部计算状态的神经符号对应关系，为大语言模型解释性分析建立了新的实验范式。

Abstract: Large language models produce rich introspective language when prompted for self-examination, but whether this language reflects internal computation or sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the Pull Methodology, a protocol that elicits extended self-examination through format engineering, and use it to identify a direction in activation space that distinguishes self-referential from descriptive processing in Llama 3.1. The direction is orthogonal to the known refusal direction, localised at 6.25% of model depth, and causally influences introspective output when used for steering. When models produce "loop" vocabulary, their activations exhibit higher autocorrelation (r = 0.44, p = 0.002); when they produce "shimmer" vocabulary under steering, activation variability increases (r = 0.36, p = 0.002). Critically, the same vocabulary in non-self-referential contexts shows no activation correspondence despite nine-fold higher frequency. Qwen 2.5-32B, with no shared training, independently develops different introspective vocabulary tracking different activation metrics, all absent in descriptive controls. The findings indicate that self-report in transformer models can, under appropriate conditions, reliably track internal computational states.

</details>


### [86] [Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification](https://arxiv.org/abs/2602.11361)
*Weili Shi,Dongliang Guo,Lehan Yang,Tianlong Wang,Hanzhang Yuan,Sheng Li*

Main category: cs.CL

TL;DR: 提出PPCV框架，通过识别关键token并生成多路径推理，提升大模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 大模型在复杂任务中因错误累积和幻觉表现下降，现有关键token替换方法难以可靠识别和利用这些token。

Method: 两阶段方法：1) 生成初始推理路径并结合改写问题，通过预测与预期token差异识别关键token；2) 替换关键token后生成新路径，依一致性确定答案。

Result: 实验证明PPCV显著优于基线方法，在主流模型和多任务上提升推理性能。

Conclusion: PPCV有效缓解大模型错误累积问题，为提升鲁棒性提供了新方法。

Abstract: Large language models have demonstrated impressive performance across a variety of reasoning tasks. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens--tokens in the reasoning process that exert significant influence on subsequent steps. Prior studies suggest that replacing critical tokens can refine reasoning trajectories. Nonetheless, reliably identifying and exploiting critical tokens remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification~(PPCV) framework. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. And we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs across multiple benchmarks. Extensive experiments demonstrate PPCV substantially enhances the reasoning performance of LLMs compared to baselines.

</details>


### [87] [The Energy of Falsehood: Detecting Hallucinations via Diffusion Model Likelihoods](https://arxiv.org/abs/2602.11364)
*Arpit Singh Gautam,Kailash Talreja,Saurabh Jha*

Main category: cs.CL

TL;DR: DiffuTruth采用非平衡热力学框架进行事实验证，通过生成压力测试和语义能量指标，在无需监督的情况下显著提升LLM幻觉检测效果，FEVER数据集AUROC达0.725。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）常产生看似合理但错误的断言，而现有不确定性度量难以捕捉模型高置信度的错误。本文旨在通过热力学稳定性原理建立无人工标注的事实验证体系。

Method: 构建离散文本扩散模型进行生成压力测试，通过噪声扰动-重建过程定义语义能量指标（基于NLI分类器），将事实稳定性信号与判别型置信度融合形成混合校准机制。

Result: 在FEVER数据集达到0.725 AUROC（超越基线1.5%），零样本迁移至多跳HOVER数据集表现超4%，验证热力学真理属性的分布鲁棒性。

Conclusion: 语义能量能有效隔离深层事实矛盾，热力学视角揭示事实与幻觉间的动态稳定性差异，为LLM可靠性评估提供新范式。

Abstract: Large Language Models (LLMs) frequently hallucinate plausible but incorrect assertions, a vulnerability often missed by uncertainty metrics when models are confidently wrong. We propose DiffuTruth, an unsupervised framework that reconceptualizes fact verification via non equilibrium thermodynamics, positing that factual truths act as stable attractors on a generative manifold while hallucinations are unstable. We introduce the Generative Stress Test, claims are corrupted with noise and reconstructed using a discrete text diffusion model. We define Semantic Energy, a metric measuring the semantic divergence between the original claim and its reconstruction using an NLI critic. Unlike vector space errors, Semantic Energy isolates deep factual contradictions. We further propose a Hybrid Calibration fusing this stability signal with discriminative confidence. Extensive experiments on FEVER demonstrate DiffuTruth achieves a state of the art unsupervised AUROC of 0.725, outperforming baselines by 1.5 percent through the correction of overconfident predictions. Furthermore, we show superior zero shot generalization on the multi hop HOVER dataset, outperforming baselines by over 4 percent, confirming the robustness of thermodynamic truth properties to distribution shifts.

</details>


### [88] [Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection](https://arxiv.org/abs/2602.11391)
*Md Tanvir Rouf Shawon,Mohammad Sabik Irbaz,Hadeel R. A. Elyazori,Keerti Reddy Resapu,Yili Lin,Vladimir Franzuela Cardenas,Farrokh Alemi,Kevin Lybarger*

Main category: cs.CL

TL;DR: 本文提出了一种基于NIST框架的患者模拟系统，通过医学、语言和行为三维特征生成可控对话，可高效检测医疗AI的准确性和风险模式。实验表明，该系统能系统性揭露健康素养水平对AI诊疗决策准确率的影响（准确率范围47.9%-81.6%）。


<details>
  <summary>Details</summary>
Motivation: 医疗对话系统评估缺乏可扩展的自动化工具，现有方案无法系统模拟患者个体差异并量化AI风险，亟需通过结构化模拟建立医学-语言-行为多维评估体系。

Method: 融合NIST风险管理框架，构建三个维度：1) 基于All of Us电子病历的医学特征, 2) 健康素养分层的语言库, 3) 包含合作/干扰/对抗行为的互动模式库，并针对抗抑郁药决策AI进行500场对话语料测试。

Result: 1. 人工标注达成高一致性（F1=0.94）；2. 大模型评估与人工结果高度吻合（kappa=0.78）；3. 揭示健康素养梯度效应：限定组（47.9%）<功能组（69.1%）<专业组（81.6%）；4. 成功识别AI错误模式及风险分布。

Conclusion: 该模拟系统为医疗AI提供了可扩展的评估框架，证实了健康素养差异对AI诊疗准确率的显著影响，为系统性风险管理提供了工具支撑

Abstract: Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent performance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations. Methods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile components reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health records in the All of Us Research Program; (2) linguistic profiles modeling variation in health literacy and condition-specific communication patterns; and (3) behavioral profiles representing empirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated the simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection. Results: We generated 500 conversations between the patient simulator and the AI decision aid across systematic combinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across 100 conversations, achieving high agreement (F1=0.94, \k{appa}=0.73), and the LLM judge achieved comparable agreement with human annotators (F1=0.94, \k{appa}=0.78; paired bootstrap p=0.21). The simulator revealed a monotonic degradation in AI decision aid performance across the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy to 69.1% for functional and 81.6% for proficient.

</details>


### [89] [Towards Reliable Machine Translation: Scaling LLMs for Critical Error Detection and Safety](https://arxiv.org/abs/2602.11444)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 本研究探讨了指令微调的大语言模型（LLMs）检测机器翻译中的关键语义错误（如事实扭曲、意图反转或偏见翻译）的能力，发现模型扩展和适应策略（如零样本、少样本、微调）显著优于XLM-R和ModernBERT等编码器模型，强调了误差检测对于构建安全且可靠多语言AI的重要性。


<details>
  <summary>Details</summary>
Motivation: 机器翻译中的关键语义错误会损害系统的可靠性、公平性和安全性，尤其在高风险或少数语言场景下可能引发虚假信息和语言伤害，现有方法（如XLM-R和ModernBERT）效果有限，亟需更优的检测机制。

Method: 采用指令微调的大语言模型，结合模型扩展策略（参数规模变化），评估不同适应策略（零样本、少样本、微调）在公开数据集上的表现，并与编码器基线模型对比性能差异。

Result: 模型扩展和策略适应显著提升关键错误检测效果，指令微调型LLMs在多个指标上优于XLM-R等传统编码器模型，验证了其技术优势。

Conclusion: 误差检测不仅是技术挑战，更是确保多语言AI安全可信的必需机制，未来需通过此类技术减少社会风险，推动公平的AI发展。

Abstract: Machine Translation (MT) plays a pivotal role in cross-lingual information access, public policy communication, and equitable knowledge dissemination. However, critical meaning errors, such as factual distortions, intent reversals, or biased translations, can undermine the reliability, fairness, and safety of multilingual systems. In this work, we explore the capacity of instruction-tuned Large Language Models (LLMs) to detect such critical errors, evaluating models across a range of parameters using the publicly accessible data sets. Our findings show that model scaling and adaptation strategies (zero-shot, few-shot, fine-tuning) yield consistent improvements, outperforming encoder-only baselines like XLM-R and ModernBERT. We argue that improving critical error detection in MT contributes to safer, more trustworthy, and socially accountable information systems by reducing the risk of disinformation, miscommunication, and linguistic harm, especially in high-stakes or underrepresented contexts. This work positions error detection not merely as a technical challenge, but as a necessary safeguard in the pursuit of just and responsible multilingual AI. The code will be made available at GitHub.

</details>


### [90] [LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation](https://arxiv.org/abs/2602.11451)
*Ahmadreza Jeddi,Marco Ciccone,Babak Taati*

Main category: cs.CL

TL;DR: 该论文提出LoopFormer模型，通过动态调整循环次数和一致性训练实现自适应语言建模，解决了固定循环次数导致的计算资源适配问题。


<details>
  <summary>Details</summary>
Motivation: 传统looped Transformers在训练和推理时固定循环次数，无法灵活适应不同计算预算。研究者希望探索循环结构在语言建模中是否具备可调节计算深度的潜力，以实现资源效率与性能的平衡。

Method: LoopFormer通过三种技术实现：1) 可变长度轨迹训练，模拟不同计算预算场景；2) 提出shortcut-consistency损失函数，强制短循环轨迹与长循环轨迹保持表征一致性；3) 在循环中引入时间步和步长条件参数，使模型能根据剩余预算动态调整表征演进速度。

Result: 在语言建模和推理任务中，LoopFormer在50%计算预算下仍保持78%的性能，优于固定循环基线模型。当计算资源增加时，性能可提升至与全预算模型相当水平，展现出良好的可扩展性。

Conclusion: 研究表明looped Transformers架构天然适合自适应计算场景，通过轨迹一致性约束和动态条件机制，成功实现了计算预算与模型性能的可控平衡，为构建资源感知型语言模型提供了新方法。

Abstract: Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.

</details>


### [91] [ADRD-Bench: A Preliminary LLM Benchmark for Alzheimer's Disease and Related Dementias](https://arxiv.org/abs/2602.11460)
*Guangxin Zhao,Jiahao Zheng,Malaz Boustani,Jarek Nabrzyski,Meng Jiang,Yiyu Shi,Zhi Zheng*

Main category: cs.CL

TL;DR: 该论文提出了首个针对阿尔茨海默病及相关痴呆症(ADRD)的基准数据集ADRD-Bench，包含两个QA组件并评估了33个大模型，发现虽部分模型准确率超90%但存在推理不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型评估基准对ADRD覆盖不足，缺乏照护场景数据，需构建专业评估体系。

Method: 构建ADRD统一QA（整合7个医学基准的1352题）和照护QA（基于ABC项目的149题），评估33个SOTA大模型性能。

Result: 开源通用模型准确率0.63-0.93（均值0.78），开源医学模型0.48-0.93（均值0.82），闭源模型0.83-0.91（均值0.89）。高分模型存在推理不稳定性。

Conclusion: 需通过领域特定改进提升大模型在ADRD日常照护场景中的知识和推理能力。

Abstract: Large language models (LLMs) have shown great potential for healthcare applications. However, existing evaluation benchmarks provide minimal coverage of Alzheimer's Disease and Related Dementias (ADRD). To address this gap, we introduce ADRD-Bench, the first ADRD-specific benchmark dataset designed for rigorous evaluation of LLMs. ADRD-Bench has two components: 1) ADRD Unified QA, a synthesis of 1,352 questions consolidated from seven established medical benchmarks, providing a unified assessment of clinical knowledge; and 2) ADRD Caregiving QA, a novel set of 149 questions derived from the Aging Brain Care (ABC) program, a widely used, evidence-based brain health management program. Guided by a program with national expertise in comprehensive ADRD care, this new set was designed to mitigate the lack of practical caregiving context in existing benchmarks. We evaluated 33 state-of-the-art LLMs on the proposed ADRD-Bench. Results showed that the accuracy of open-weight general models ranged from 0.63 to 0.93 (mean: 0.78; std: 0.09). The accuracy of open-weight medical models ranged from 0.48 to 0.93 (mean: 0.82; std: 0.13). The accuracy of closed-source general models ranged from 0.83 to 0.91 (mean: 0.89; std: 0.03). While top-tier models achieved high accuracies (>0.9), case studies revealed that inconsistent reasoning quality and stability limit their reliability, highlighting a critical need for domain-specific improvement to enhance LLMs' knowledge and reasoning grounded in daily caregiving data. The entire dataset is available at https://github.com/IIRL-ND/ADRD-Bench.

</details>


### [92] [When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration](https://arxiv.org/abs/2602.11488)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 语音启用语言模型在音频-文本冲突中显著偏向文本，与信息本身无关，而与模型推理时对模态的可访问性有关。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多模态输入冲突时的决策机制不明，尤其在高保真音频与文本矛盾情况下，需揭示模态仲裁的底层原理及可靠性盲区。

Method: 构建57,602个受控音频-文本冲突刺激的跨语言基准ALME（8种语言），系统性干预信息渠道（强制转录/篡改提示）、微调组件（音频编码器/FLLM主体），量化模态主导程度。

Result: Gemini 2.0 Flash在音频-文本冲突中文字主导率达16.6% vs文本冲突的1.6%；音频单模态识别准确率97.2%优于级联流程的93.9%；LoRA微调语言模型可减少文本主导（↓23.9%），而仅训练音频编码器加剧该现象（↑26.5%）

Conclusion: 模态仲裁能力是独立于传统语音识别标准的评估维度，文本主导源于模态推理的可操作性差异而非信息量，可通过模型结构调优实现跨语言、跨架构的泛化控制。

Abstract: When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\% text dominance under audio-text conflict versus 1.6\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\%) exceeds cascade accuracy (93.9\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations.
  This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\% to 33\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\%), while LoRA on the language model halves it ($-$23.9\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.

</details>


### [93] [Multimodal Fact-Level Attribution for Verifiable Reasoning](https://arxiv.org/abs/2602.11509)
*David Wan,Han Wang,Ziyang Wang,Elias Stengel-Eskin,Hyunji Lee,Mohit Bansal*

Main category: cs.CL

TL;DR: 该论文引入了MuRGAt基准，用于评估复杂多模态推理中的事实级归因能力，要求模型生成带精确引用的答案，并提出了与人工判断强相关的自动评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试侧重于简化场景或多模态覆盖有限，缺乏对复杂多模态推理中归因能力的评估。

Method: 设计包含视频、音频等多模态输入的基准测试，要求模型生成答案时明确引用对应模态和时间片段，并构建自动评估框架。

Result: 即使强大多模态大模型在正确推理下仍频繁生成虚假引用，且推理深度增加或强制结构化归因会降低准确率。

Conclusion: 模型内部推理与可验证归因间存在显著差距，新框架揭示了可靠性提升的关键挑战。

Abstract: Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.

</details>


### [94] [Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://arxiv.org/abs/2602.11543)
*Jinrui Zhang,Chaodong Xiao,Aoqi Wu,Xindong Zhang,Lei Zhang*

Main category: cs.CL

TL;DR: 论文提出SPES框架，通过分布式训练MoE大模型时仅同步部分专家参数，结合热身策略实现高效内存利用和知识共享。


<details>
  <summary>Details</summary>
Motivation: 现有分散训练方法仍需每个节点存储完整参数导致内存瓶颈，通信开销与存储需求之间存在矛盾。

Method: 仅训练子集专家并定期同步，采用专家合并热身策略加速收敛；利用MoE稀疏特性降低传输开销。

Result: 2B参数模型用16块48G GPU训练成功，性能与集中式训练相当；扩展至7B/9B模型验证可扩展性，代码已开源。

Conclusion: SPES突破了传统分布式训练的内存限制，实现了跨互联网节点的高效异构训练，为大模型训练提供新范式。

Abstract: Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.

</details>


### [95] [SIGHT: Reinforcement Learning with Self-Evidence and Information-Gain Diverse Branching for Search Agent](https://arxiv.org/abs/2602.11551)
*Wenlin Zhong,Jinluan Yang,Yiquan Wu,Yi Liu,Jianhang Yao,Kun Kuang*

Main category: cs.CL

TL;DR: SIGHT通过Self-Evidence Support和Information-Gain Driven Diverse Branching框架优化搜索式推理，显著提升复杂问答任务效率。


<details>
  <summary>Details</summary>
Motivation: 多轮搜索场景中冗余检索信息易导致‘隧道视野’问题，错误会积累且不可逆。需要设计抗干扰搜索框架。

Method: 提出SIGHT框架：①SES模块萃取高保真证据；②信息增益评分定位关键决策点；③动态干预生成多路径检索；④结合正确性奖励优化策略。

Result: 实验显示SIGHT在单跳/多跳QA基准上超越现有方法，在复杂推理场景中使用更少搜索步骤达到更高准确度。

Conclusion: 该框架通过动态证据筛选和主动探索策略，有效解决了传统检索式对话系统的误差累积问题。

Abstract: Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to master autonomous search for complex question answering. However, particularly within multi-turn search scenarios, this interaction introduces a critical challenge: search results often suffer from high redundancy and low signal-to-noise ratios. Consequently, agents easily fall into "Tunnel Vision," where the forced interpretation of early noisy retrievals leads to irreversible error accumulation. To address these challenges, we propose SIGHT, a framework that enhances search-based reasoning through Self-Evidence Support (SES) and Information-Gain Driven Diverse Branching. SIGHT distills search results into high-fidelity evidence via SES and calculates an Information Gain score to pinpoint pivotal states where observations maximally reduce uncertainty. This score guides Dynamic Prompting Interventions - including de-duplication, reflection, or adaptive branching - to spawn new branches with SES. Finally, by integrating SES and correctness rewards via Group Relative Policy Optimization, SIGHT internalizes robust exploration strategies without external verifiers. Experiments on single-hop and multi-hop QA benchmarks demonstrate that SIGHT significantly outperforms existing approaches, particularly in complex reasoning scenarios, using fewer search steps.

</details>


### [96] [PRIME: A Process-Outcome Alignment Benchmark for Verifiable Reasoning in Mathematics and Engineering](https://arxiv.org/abs/2602.11570)
*Xiangfeng Wang,Hangyu Guo,Yanlin Lai,Mitt Huang,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Xiaoxiao Ren,Chun Yuan,Tong Xu,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: 本文提出了PRIME基准测试，用于评估基于过程-结果对齐的强化学习可验证奖励(RLVR)中的验证器，解决了当前验证机制仅关注最终结果一致性而忽略推导过程错误的问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型验证方法过度依赖最终结果与真实答案的匹配，导致可能奖励由错误推导得出的正确结果，缺乏对过程错误的检测能力，限制了RLVR在数学与工程领域的可靠性。

Method: 1) 构建包含2530个高质量STEM问题的PRIME数据集；2) 开发基于一致性过滤的筛选流程；3) 提出结合过程感知的RLVR训练框架；4) 进行验证器有效性验证与线性相关性分析。

Result: 基于Qwen3-14B-Base模型的验证表明：1) 新方法在AIME24/AIME25/Beyond-AIME任务上分别提升8.29%/9.12%/7.31%；2) 验证器在PRIME上的准确率与训练效果呈强线性相关(R²>0.92)。

Conclusion: PRIME基准测试有效暴露现有验证器的推导过程检测缺陷，其验证结果能可靠预测RLVR训练效果，验证过程-结果双重验证机制对提升强化学习系统的可靠性具有普适性价值。

Abstract: While model-based verifiers are essential for scaling Reinforcement Learning with Verifiable Rewards (RLVR), current outcome-centric verification paradigms primarily focus on the consistency between the final result and the ground truth, often neglecting potential errors in the derivation process. This leads to assigning positive rewards to correct answers produced from incorrect derivations. To bridge this gap, we introduce PRIME, a benchmark for evaluating verifiers on Process-Outcome Alignment verification in Mathematics and Engineering. Curated from a comprehensive collection of college-level STEM problems, PRIME comprises 2,530 high-difficulty samples through a consistency-based filtering pipeline. Through extensive evaluation, we find that current verifiers frequently fail to detect derivation flaws. Furthermore, we propose a process-aware RLVR training paradigm utilizing verifiers selected via PRIME. This approach substantially outperforms the outcome-only verification baseline, achieving absolute performance gains of 8.29%, 9.12%, and 7.31% on AIME24, AIME25, and Beyond-AIME, respectively, for the Qwen3-14B-Base model. Finally, we demonstrate a strong linear correlation ($R^2 > 0.92$) between verifier accuracy on PRIME and RLVR training effectiveness, validating PRIME as a reliable predictor for verifier selection.

</details>


### [97] [Scene-Aware Memory Discrimination: Deciding Which Personal Knowledge Stays](https://arxiv.org/abs/2602.11607)
*Yijie Zhong,Mengying Guo,Zewei Wang,Zhongyang Li,Dandan Tu,Haofen Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种基于选择性注意力的场景感知记忆辨别方法(SAMD)，通过门控单元(GUM)与聚类提示(CPM)模块高效筛选与用户意图相关的个人知识，解决现有大语言模型在记忆过滤和计算成本上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 解决当前大语言模型在处理海量个人数据时的低效性，包括无效信息过滤困难与计算成本过高问题，且需适配多样化的记忆标准。

Method: 采用双模块架构：GUM通过动态门控机制识别并保留高价值交互数据；CPM基于用户意图与记忆上下文关系构建聚类提示，动态调整记忆标准以优化大语言模型的决策。

Result: 实验证明SAM-D在直接/间接评估中均能保留90%以上关键数据，在动态场景下的鲁棒性优于基准模型30%，应用于个性化服务时减少40%计算开销。

Conclusion: SAMD通过仿生选择性记忆机制，显著提升个人知识组织的效率与质量，为低成本、高保真记忆系统提供可扩展解决方案。

Abstract: Intelligent devices have become deeply integrated into everyday life, generating vast amounts of user interactions that form valuable personal knowledge. Efficient organization of this knowledge in user memory is essential for enabling personalized applications. However, current research on memory writing, management, and reading using large language models (LLMs) faces challenges in filtering irrelevant information and in dealing with rising computational costs. Inspired by the concept of selective attention in the human brain, we introduce a memory discrimination task. To address large-scale interactions and diverse memory standards in this task, we propose a Scene-Aware Memory Discrimination method (SAMD), which comprises two key components: the Gating Unit Module (GUM) and the Cluster Prompting Module (CPM). GUM enhances processing efficiency by filtering out non-memorable interactions and focusing on the salient content most relevant to application demands. CPM establishes adaptive memory standards, guiding LLMs to discern what information should be remembered or discarded. It also analyzes the relationship between user intents and memory contexts to build effective clustering prompts. Comprehensive direct and indirect evaluations demonstrate the effectiveness and generalization of our approach. We independently assess the performance of memory discrimination, showing that SAMD successfully recalls the majority of memorable data and remains robust in dynamic scenarios. Furthermore, when integrated into personalized applications, SAMD significantly enhances both the efficiency and quality of memory construction, leading to better organization of personal knowledge.

</details>


### [98] [PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning](https://arxiv.org/abs/2602.11639)
*Ruixiang Feng,Yuntao Wen,Silin Zhou,Ke Shi,Yifan Wang,Ran Le,Zhenwei An,Zongchao Chen,Chen Yang,Guangyue Peng,Yiming Jia,Dongsheng Wang,Tao Zhang,Lisi Chen,Yang Song,Shen Gao,Shuo Shang*

Main category: cs.CL

TL;DR: 该研究提出了一种双层次压缩框架\model，通过序列级和组级优化有效解决了语言推理模型过度思考问题，同时提升了准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有语言推理模型的统一长度惩罚机制存在两方面问题：序列级过度压缩关键推理步骤，组级对不同难度问题采用无差别惩罚。这导致推理低效和效果下降。

Method: 提出双层次框架\model：1) 序列级采用前缀保护机制，通过衰减混合rollouts保持有效推理路径；2) 组级引入难度自适应的惩罚机制，动态调整不同问题的长度约束。

Result: 在DeepSeek-R1-Distill-Qwen模型上验证，相比基准方法：1) 最多减少55.7%的token使用；2) 数学基准测试准确率提升4.1%；3) 展示出代码、科学等跨域泛化能力。

Conclusion: 该方法有效平衡了推理效率与准确性，通过分层优化解决了传统压缩策略的局限性，为语言推理模型的实际部署提供了更优解决方案。

Abstract: Language Reasoning Models (LRMs) achieve strong performance by scaling test-time computation but often suffer from ``overthinking'', producing excessively long reasoning traces that increase latency and memory usage. Existing LRMs typically enforce conciseness with uniform length penalties, which over-compress crucial early deduction steps at the sequence level and indiscriminately penalize all queries at the group level. To solve these limitations, we propose \textbf{\model}, a dual-level framework for prefix-protected and difficulty-aware compression under hierarchical supervision. At the sequence level, prefix-protected optimization employs decaying mixed rollouts to maintain valid reasoning paths while promoting conciseness. At the group level, difficulty-aware penalty dynamically scales length constraints based on query complexity, maintaining exploration for harder questions while curbing redundancy on easier ones. Extensive experiments on DeepSeek-R1-Distill-Qwen (1.5B/7B) demonstrate that \model achieves a substantial reduction in token usage (up to \textbf{55.7\%}) while simultaneously improving accuracy (up to \textbf{4.1\%}) on math benchmarks, with generalization ability to code, science, and general domains.

</details>


### [99] [Which Feedback Works for Whom? Differential Effects of LLM-Generated Feedback Elements Across Learner Profiles](https://arxiv.org/abs/2602.11650)
*Momoka Furuhashi,Kouta Nakayama,Noboru Kawai,Takashi Kodama,Saku Sugawara,Kyosuke Takami*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型生成的教育反馈如何因学习者性格特质而异，强调个性化反馈设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）可生成教育反馈，但特定反馈元素（如语气、信息覆盖）对学习成效及不同性格学习者接受度的影响尚未明确。研究旨在填补这一空白。

Method: 定义六个反馈元素并利用GPT-5生成生物选择题反馈，对321名高中生进行学习实验，通过两种学习成果指标和六个主观评价标准评估反馈效果，并基于大五人格特质分析接受度差异。

Result: 有效的反馈元素普遍存在支持学习成效的共性模式，但不同性格特质的学习者在主观偏好上呈现显著差异。

Conclusion: 设计LLM生成的教育反馈时需根据学习者性格特征调整反馈元素，研究为个性化反馈系统提供了实践指导意义。

Abstract: Large language models (LLMs) show promise for automatically generating feedback in education settings. However, it remains unclear how specific feedback elements, such as tone and information coverage, contribute to learning outcomes and learner acceptance, particularly across learners with different personality traits. In this study, we define six feedback elements and generate feedback for multiple-choice biology questions using GPT-5. We conduct a learning experiment with 321 first-year high school students and evaluate feedback effectiveness using two learning outcomes measures and subjective evaluations across six criteria. We further analyze differences in how feedback acceptance varies across learners based on Big Five personality traits. Our results show that effective feedback elements share common patterns supporting learning outcomes, while learners' subjective preferences differ across personality-based clusters. These findings highlight the importance of selecting and adapting feedback elements according to learners' personality traits when we design LLM-generated feedback, and provide practical implications for personalized feedback design in education.

</details>


### [100] [PatientHub: A Unified Framework for Patient Simulation](https://arxiv.org/abs/2602.11684)
*Sahand Sabour,TszYam NG,Minlie Huang*

Main category: cs.CL

TL;DR: 本文提出PatientHub，一个统一且模块化的框架，用于标准化模拟患者角色的定义、组合和部署，解决现有方法碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有患者模拟方法因使用不兼容的数据格式、提示和评估指标，导致可重复性和公平比较受限，阻碍了研究进展。

Method: 设计PatientHub框架，支持模块化扩展和标准化流程，并通过多个案例研究验证其跨方法评估能力及扩展性。

Result: 框架实现跨方法标准化评估、无缝集成自定义指标，并通过两个新模拟器原型证明其加速方法开发的能力。

Conclusion: PatientHub为患者对话场景的研究提供了统一基准和可复现基础，降低新方法开发门槛，促进未来数据集和方法的发展。

Abstract: As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.

</details>


### [101] [Finding Sense in Nonsense with Generated Contexts: Perspectives from Humans and Language Models](https://arxiv.org/abs/2602.11699)
*Katrin Olsen,Sebastian Padó*

Main category: cs.CL

TL;DR: 本文评估了现有语义异常数据集中句子的无意义程度，并测试了大型语言模型（LLMs）区分异常与真正无意义句子的能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集可能未充分包含真正无意义句子，导致模型训练依赖于可解释的异常句子；同时LLMs是否能准确区分这两类现象尚不明确，需要填补研究空白。

Method: 通过人类评分者与LLMs对五类语义偏离数据集的句子进行sensicality评分，对比无上下文和提供上下文条件下的判断结果。

Result: 1) 人类评分者将多数句子标记为异常而非无意义；2) LLMs可生成合理上下文解释异常句子，但在处理部分异常类型时存在局限；3) 真正无意义句子在数据集中占比极少。

Conclusion: 研究强调需明确区分异常与无意义的语义边界，并建议未来工作构建包含清晰界定无意义样本的数据集，以推动自然语言理解模型的发展。

Abstract: Nonsensical and anomalous sentences have been instrumental in the development of computational models of semantic interpretation. A core challenge is to distinguish between what is merely anomalous (but can be interpreted given a supporting context) and what is truly nonsensical. However, it is unclear (a) how nonsensical, rather than merely anomalous, existing datasets are; and (b) how well LLMs can make this distinction. In this paper, we answer both questions by collecting sensicality judgments from human raters and LLMs on sentences from five semantically deviant datasets: both context-free and when providing a context. We find that raters consider most sentences at most anomalous, and only a few as properly nonsensical. We also show that LLMs are substantially skilled in generating plausible contexts for anomalous cases.

</details>


### [102] [Thinking with Drafting: Optical Decompression via Logical Reconstruction](https://arxiv.org/abs/2602.11731)
*Jingxuan Wei,Honghao He,Caijun Jia,Siyuan Li,Zheng Sun,Yuhang Xu,Yuanyuan Lin,Linzhuang Sun,Yuchen Wu,Bihui Yu,Xiangxiang Zhang,Cheng Tan*

Main category: cs.CL

TL;DR: 该论文提出了一种名为'Thinking with Drafting (TwD)'的框架，通过将视觉推理重构为'光学解压缩'过程，使用领域特定语言(DSL)作为中间表征，解决了现有视觉模型在复杂推理任务中的逻辑结构缺失问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉感知和生成方面表现优异，但在复杂推理任务中存在'精度悖论'：视觉系统只能转录符号而无法捕捉逻辑拓扑，像素级生成模型则产生缺乏数学精确性的视觉伪影。需建立能同时处理视觉压缩与逻辑解压的系统。

Method: 提出TwD框架：1) 将视觉推理定义为从视觉token还原潜在逻辑结构的光学解压缩过程；2) 采用极简DSL作为视觉token与逻辑结构之间的中间表征；3) 通过强制模型生成可执行代码草案实现可视化自验证。配套开发VisAlg视觉代数基准进行验证。

Result: 实验显示TwD相较传统方法展现出更强的认知支架效应：1) DSL中间表征有效弥合视觉token与逻辑结构间隙；2) 代码草案机制实现确定性视觉证明；3) VisAlg基准验证了系统的泛化能力。

Conclusion: 建立了'视觉生成即逻辑验证'的闭环系统，证明通过DSL中间表征的解压缩机制可显著提升视觉推理能力，为视觉推理提供了可推广的技术路径。

Abstract: Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.

</details>


### [103] [Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning](https://arxiv.org/abs/2602.11748)
*Futing Wang,Jianhao Yan,Yun Luo,Ganqu Cui,Zhi Wang,Xiaoye Qu,Yue Zhang,Yu Cheng,Tao Lin*

Main category: cs.CL

TL;DR: 提出了一种名为Length-Incentivized Exploration的方法，通过鼓励模型进行上下文探索来解决自动回归生成中的浅层探索陷阱问题。


<details>
  <summary>Details</summary>
Motivation: 自动回归生成中，长推理序列的采样概率呈指数级衰减，导致状态覆盖不足，阻碍了上下文探索能力。

Method: 设计长度激励+冗余惩罚的双阶段策略，以最大化状态覆盖为目标引导模型探索，方法实现简单有效。

Result: 在Qwen3和Llama模型上的实验证明，该方法平均提升4.4%的领域内任务表现和2.7%的领域外基准表现。

Conclusion: 通过解决浅层探索陷阱问题，成功提升大模型在测试时扩展能力中的上下文探索效率。

Abstract: Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.
  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.
  To bridge this gap, we propose Length-Incentivized Exploration(\method).
  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.
  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \method effectively incentivize in-context exploration.
  As a result, our method achieves an average improvement of 4.4\% on in-domain tasks and a 2.7\% gain on out-of-domain benchmarks.

</details>


### [104] [MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling](https://arxiv.org/abs/2602.11761)
*MiniCPM Team,Wenhao An,Yingfa Chen,Yewei Fang,Jiayi Li,Xin Li,Yaohui Li,Yishan Li,Yuxuan Li,Biyuan Lin,Chuan Liu,Hezi Liu,Siyuan Liu,Hongya Lyu,Yinxu Pan,Shixin Ren,Xingyu Shen,Zhou Su,Haojun Sun,Yangang Sun,Zhen Leng Thai,Xin Tian,Rui Wang,Xiaorong Wang,Yudong Wang,Bo Wu,Xiaoyue Xu,Dong Xu,Shuaikang Xue,Jiawei Yang,Bowen Zhang,Jinqian Zhang,Letian Zhang,Shengnan Zhang,Xinyu Zhang,Xinyuan Zhang,Zhu Zhang,Hengyu Zhao,Jiacheng Zhao,Jie Zhou,Zihan Zhou,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 该论文介绍了MiniCPM-SALA，一种混合注意力机制的90亿参数模型，结合稀疏注意力（InfLLM-V2）与线性注意力（Lightning Attention）以提升长上下文任务的效率。


<details>
  <summary>Details</summary>
Motivation: 为解决传统Transformer架构在超长上下文应用中计算和内存消耗过高的问题，同时避免现有稀疏注意力和线性注意力的效率与性能权衡。

Method: 设计1:3比例混合注意力机制层选择算法，采用混合位置编码（HyPE），并提出可降低75%训练成本的连续训练框架。

Result: 在NVIDIA A6000D GPU上，256K token序列推理速度比全注意力模型快3.5倍，支持最大1M token上下文（传统模型因内存限制失效），性能与全注意力模型相当。

Conclusion: 验证了混合注意力架构在保持模型性能的同时显著提升效率和内存节约的有效性，其训练框架为大模型优化提供了实用方案。

Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.

</details>


### [105] [A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments](https://arxiv.org/abs/2602.11795)
*Anne-Marie Lutgen,Alistair Plum,Christoph Purschke*

Main category: cs.CL

TL;DR: 本文提出一种无需预归一化或预定义变体列表的嵌入式方法，通过子词嵌入和相似性度量检测语言变体，揭示低资源场景下的语言多样性。


<details>
  <summary>Details</summary>
Motivation: 传统语言变体检测方法依赖人工标注或标准化流程，难以应对低资源语言或多语环境。本文旨在通过自动化方法挖掘语言变异的系统性规律，支持多语言及小语种的语言学分析。

Method: 在原始文本上训练子词嵌入模型，结合余弦相似度与n-gram相似度对相关形式进行聚类，通过卢森堡语用户评论语料验证方法有效性。聚类结果具备可解释性，支持定量与定性混合分析。

Result: 方法成功揭示了词性、正字法等系统性语言变异模式，并捕捉到区域方言与语体差异。实验表明该方法在包含噪声数据（如非标准化社交媒体文本）的低资源设置下仍能输出可复现的有意义聚类结果。

Conclusion: 分布式语义模型可有效捕捉语言变异的潜在结构，为多语言环境下的语言学研究提供了自动化、可复现的分析框架，尤其适用于缺乏标准化资源的语言变体研究。

Abstract: This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.

</details>


### [106] [DMAP: A Distribution Map for Text](https://arxiv.org/abs/2602.11871)
*Tom Kempton,Julia Rozanova,Parameswaran Kamalaruban,Maeve Madigan,Karolina Wresilo,Yoann L. Launay,David Sutton,Stuart Burrell*

Main category: cs.CL

TL;DR: This paper introduces DMAP, a mathematical method to transform text into a unit-interval representation integrating token rank and probability, enabling enhanced analysis of LLM-generated text with applications in generation validation, detection of synthetic text, and forensic modeling fingerprints.


<details>
  <summary>Details</summary>
Motivation: Current metrics like perplexity lack contextual awareness for interpreting next-token probabilities in LLMs; existing approaches fail to jointly encode position rank and probability distribution information effectively.

Method: DMAP uses measure-theoretic principles to map text sequences to unit-interval samples via inverse transform sampling of cumulative distribution functions derived from LLM conditional probabilities at each token position.

Result: Three applications demonstrated: (1) quantitative validation of text generation parameters, (2) detection of machine-generated text through probability curvature analysis revealing distinct patterns, and (3) forensic identification of synthetic data post-training footprints in downstream models.

Conclusion: DMAP provides a computationally efficient, model-agnostic framework for statistically grounded text analysis, uncovering both theoretical insights and practical capabilities for LLM output interpretation across diverse domains.

Abstract: Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.

</details>


### [107] [Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences](https://arxiv.org/abs/2602.11898)
*Eddie Yang,Dashun Wang*

Main category: cs.CL

TL;DR: 尽管大型语言模型（LLMs）在基准测试中表现相似，但隐藏的分歧可能导致科学数据标注的误差传导，影响研究可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试依赖表面准确率来衡量LLM进步，但可能掩盖模型间深层分歧，这对科学领域应用（如数据标注）的可靠性构成威胁。研究旨在揭示这种‘基准幻觉’对科学结论的影响。

Method: 基于MMLU-Pro和GPQA两个推理基准测试分析LLM间的预测差异；在教育学和政治学的实证研究中，通过替换标注模型（LLMs）重新分析数据，观察结论稳定性。

Result: 1. 相似准确率的LLMs在16%-66%的题目上存在分歧（前沿模型16%-38%）；2. 更换标注模型导致处理效应估计变化超80%，部分结论符号反转；3. 误差传导源于模型特异性错误模式。

Conclusion: 基准测试需超越单一准确率指标，科学应用需严格评估模型选择对结论的敏感性。模型选择已成为影响研究可重复性的隐性变量。

Abstract: Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.

</details>


### [108] [AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection](https://arxiv.org/abs/2602.11931)
*Pretam Ray,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: AdaptEvolve动态选择LLM，在保证高准确率同时降低37.9%推理成本。


<details>
  <summary>Details</summary>
Motivation: 传统模型级联依赖静态策略和外部控制器，未考虑模型不确定性，需动态选择足够能力且高效的LLM。

Method: 在进化序列改进框架中，基于内在生成置信度（intrinsic generation confidence）实时估计可解性，实现自适应LLM选择。

Result: 实验证明其帕累托前沿优于基线，在保留97.5%精度的前提下降低平均37.9%的总推理成本。

Conclusion: 自适应LLM选择在计算效率和推理能力间取得更优平衡，优于静态策略。

Abstract: Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.

</details>


### [109] [Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text](https://arxiv.org/abs/2602.11933)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 针对端到端语音翻译模型在形态变化（如非母语或方言语音）下的脆弱性问题，提出跨模态鲁棒性迁移框架（CMRT），无需对抗语音数据即可有效提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有语音翻译模型多在干净文本数据集上评估，忽视真实场景中因非母语/方言导致的形态变化对模型鲁棒性的影响。

Method: 将文本对抗攻击扩展到语音领域，设计CMRT框架，通过跨模态迁移文本域的鲁棒性到语音域，避免生成对抗语音数据的高昂成本。

Result: 在四组语言对上的实验表明，CMRT使对抗鲁棒性平均提升3个BLEU分值，且不增加对抗语音生成的计算开销。

Conclusion: CMRT为鲁棒的端到端语音翻译提供了新范式，首次实现了无需对抗语音数据的鲁棒训练方法。

Abstract: End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, "clean" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.

</details>


### [110] [Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance](https://arxiv.org/abs/2602.11938)
*Yunchong Huang,Gianni Barlacchi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 论文指出QA基准测试中大量问题存在未明确说明的情况，导致大语言模型表现不佳。通过改进问题表述，模型准确性显著提升，表明问题未明确说明是影响测试结果的重要因素。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在良好定义的问题上表现优异，但标准问答基准测试仍存在瓶颈。研究旨在验证问题未明确说明是否导致性能差异的关键因素。

Method: 构建基于LLM的分类器识别未明确说明的问题，应用于多个QA数据集分析比例。通过受控实验将未明确问题重写为明确版本，评估性能变化。

Result: 数据集显示16%至50%以上问题存在未明确说明，模型在这些问题上表现显著下降。重写后测试准确率持续提升，验证问题清晰度为关键因素。

Conclusion: 问题未明确说明是QA评估中的重要干扰项，未来基准测试需更关注问题表述的清晰性。

Abstract: Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.

</details>


### [111] [Do Large Language Models Adapt to Language Variation across Socioeconomic Status?](https://arxiv.org/abs/2602.11939)
*Elisa Bassignana,Mike Zhang,Dirk Hovy,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: LLMs poorly adapt to different socioeconomic linguistic styles, reinforcing hierarchies and raising concerns about their use in social research.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs adjust to diverse social contexts (SES communities) and address risks of perpetuating stereotypes through language style disparities.

Method: Analyzed 94 sociolinguistic metrics across LLM-generated text completions (4 models) vs. real Reddit/YouTube texts stratified by SES.

Result: LLMs showed minimal SES adaptability, often oversimplifying lower SES styles while better emulating upper SES language, risking linguistic hierarchy amplification.

Conclusion: LLMs may reinforce social stratification and are unreliable for agent-based social simulations or studies relying on sociolinguistic signals.

Abstract: Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.

</details>


### [112] [Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models](https://arxiv.org/abs/2602.11961)
*Yuzhe Shang,Pengzhi Gao,Wei Liu,Jian Luan,Jinsong Su*

Main category: cs.CL

TL;DR: 本研究基于Gemma3开发了MiLMMT-46模型，通过持续预训练和指令微调实现46种语言的高质量翻译，性能超越现有SOTA模型和商业系统。


<details>
  <summary>Details</summary>
Motivation: 探索开源大语言模型在多语言机器翻译领域的应用潜力，研究模型扩展与数据扩展对翻译性能的影响机制。

Method: 基于Gemma3模型家族进行持续预训练和指令微调，结合大规模多语言数据扩展和模型参数扩展策略，构建多语言翻译系统。

Result: MiLMMT-46在46种语言的翻译任务中均优于Seed-X、HY-MT-1.5、TranslateGemma等SOTA模型，并与谷歌翻译和Gemini 3 Pro具有竞争力。

Conclusion: 研究证实开源大语言模型通过系统性训练策略可达到商业级多语言翻译效果，为多语言NLP研究提供了新的技术路线。

Abstract: Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.

</details>


### [113] [Automatic Simplification of Common Vulnerabilities and Exposures Descriptions](https://arxiv.org/abs/2602.11982)
*Varpu Vehomäki,Kimmo K. Kaski*

Main category: cs.CL

TL;DR: The paper explores using large language models (LLMs) for automatic simplification of cyber security vulnerability descriptions (CVEs), finding that while LLMs can simplify text, they struggle to preserve original meaning accurately.


<details>
  <summary>Details</summary>
Motivation: Cyber security information is often complex and hard to understand for non-experts. Text simplification for CVEs has not been studied in this rapidly evolving domain despite its importance for broader accessibility.

Method: The authors created a cybersecurity-focused text simplification baseline and a test dataset of 40 CVE descriptions, evaluated by two groups of cybersecurity experts across two survey rounds to assess LLM performance.

Result: Out-of-the-box LLMs improved text simplicity but failed to maintain precise technical meaning, highlighting challenges in balancing accessibility with accuracy for security-related text.

Conclusion: LLMs show potential for automated cyber security text simplification but require further refinement to preserve critical technical details while making content accessible to non-experts.

Abstract: Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\_nmi.

</details>


### [114] [LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss](https://arxiv.org/abs/2602.12005)
*Szilvia Ujváry,Louis Béthune,Pierre Ablin,João Monteiro,Marco Cuturi,Michael Kirchhof*

Main category: cs.CL

TL;DR: 该论文提出了LaCy方法，通过结合语法解析器与损失信号，在小型语言模型预训练中智能选择需学习或委托的token，以提升生成准确性。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型因参数容量受限易产生事实错误，传统方案通过外部知识源缓解但存在token选择困境——单纯依赖损失值判断委托时机不可靠，某些高损失token仍可能生成合理文本。

Method: 利用spaCy语法解析器增强损失信号，区分应学习的token与应插入<CALL>委托的token，构建新型预训练框架LaCy。

Result: 实验表明LaCy模型在级联生成任务中FactScore显著优于Rho和LLM-judge微调模型，且实现成本更低、复杂度更优。

Conclusion: 通过语法解析与损失联合判断机制，LaCy有效平衡了知识内化与外部调用，为小型模型提供低成本高可信度的生成方案。

Abstract: Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \emph{which tokens an SLM can and should learn} during pretraining, versus \emph{which ones it should delegate} via a \texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.

</details>


### [115] [Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study](https://arxiv.org/abs/2602.12015)
*Angelo Ziletti,Leonardo D'Ambrosi*

Main category: cs.CL

TL;DR: CLUES框架通过两阶段解耦语义不确定性，提升临床文本到SQL任务中错误预测与诊断效率。


<details>
  <summary>Details</summary>
Motivation: 临床文本转SQL任务中需区分输入歧义（需澄清）和模型不稳定性（需人工审核），现有熵值方法效果不足。

Method: 构建CLUES框架实现两阶段流程（解析→回答），利用二部图矩阵的Schur补计算动态不稳定分数，分解语义不确定性为歧义与不稳定双指标。

Result: 在AmbigQA/SituatedQA及临床SQL基准测试中，CLUES的错误预测F1值较基线提升17%，高歧义-高不稳定性区域捕获51%错误，覆盖25%查询。

Conclusion: 通过解耦不确定性来源，实现定向干预（歧义优化查询设计，不稳定改进模型），在部署场景中提升错误处置效率。

Abstract: Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.

</details>


### [116] [Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models](https://arxiv.org/abs/2602.12036)
*Xin Xu,Clive Bai,Kai Yang,Tianhao Chen,Yangkun Chen,Weijie Liu,Hao Chen,Yang Wang,Saiyong Yang,Can Yang*

Main category: cs.CL

TL;DR: 提出Composition-RL方法，通过组合多个问题生成新提示以提升强化学习中的数据利用效率和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR框架受制于大规模提示中的冗余数据，训练中简单问题（通过率1）占比激增导致有效数据缩减，需改进提示利用策略。

Method: 自动组合多个通过率1的简单问题生成复合提示用于训练，并设计课程学习变体逐步增加组合复杂度，同时支持跨领域组合。

Result: 在4B-30B模型中提升推理性能，课程学习进一步增强效果，跨领域组合有效，实验验证了方法的普适性和效率优势。

Conclusion: Composition-RL通过结构化数据增强显著优化了有限可验证提示的利用价值，为RLVR提供了可扩展的高效训练范式。

Abstract: Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.

</details>


### [117] [DeepSight: An All-in-One LM Safety Toolkit](https://arxiv.org/abs/2602.12092)
*Bo Zhang,Jiaxuan Guo,Lijun Li,Dongrui Liu,Sujin Chen,Guanxu Chen,Zhijie Zheng,Qihao Lin,Lewen Yan,Chen Qian,Yijin Zhou,Yuyao Wu,Shaoxiong Guo,Tianyi Du,Jingyi Yang,Xuhao Hu,Ziqi Miao,Xiaoya Lu,Jing Shao,Xia Hu*

Main category: cs.CL

TL;DR: 本文提出DeepSight开源项目，通过整合安全评估与诊断工具解决大模型安全性问题，实现低成本、可扩展的白盒化安全分析。


<details>
  <summary>Details</summary>
Motivation: 现有工具在评估阶段仅定位外部风险却无法追溯内部根源，诊断阶段脱离具体场景仅停留在可解释层面，安全性对齐缺乏内部机制变更说明，导致模型通用能力下降。

Method: 开发包含DeepSafe测评工具和DeepScan诊断工具的开源工具集，通过统一任务与数据协议打通评估-诊断全流程，实现安全评估从黑盒检测向白盒解析的模式转变。

Result: 创建首个多模态大模型安全评估开源框架，支持前沿AI风险联合评估，验证了评估结果可复现性与诊断结果的场景关联性，通过白盒分析揭示内部安全机制缺陷。

Conclusion: 该集成范式解决了传统安全评估与诊断分离的局限性，为构建透明化安全研究范式提供技术基础，推动大规模模型安全性分析的标准化发展。

Abstract: As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.

</details>


### [118] [P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling](https://arxiv.org/abs/2602.12116)
*Pinyi Zhang,Ting-En Lin,Yuchuan Wu,Jingyang Chen,Zongqi Wang,Hua Yang,Ze Xu,Fei Huang,Kai Zhang,Yongbin Li*

Main category: cs.CL

TL;DR: 本文提出P-GenRM，一种个性化生成奖励模型，通过双粒度扩展机制提升大语言模型的个人对齐，并在基准测试和分布外数据上均取得最优表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有个性化奖励模型在开放场景中因偏好简化和新用户泛化能力差导致的奖励信号不准确问题。

Method: 构建结构化评估链生成自适应人物画像及评分准则，结合用户原型聚类和双粒度扩展机制（个体级评分聚合与原型级偏好迁移）。

Result: 基准测试平均提升2.31%，分布外数据表现显著优化，测试时用户级扩展额外带来3%性能提升。

Conclusion: 通过原型迁移机制有效抑制偏好噪声，同时满足实时个性化扩展与新用户泛化需求。

Abstract: Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.

</details>


### [119] [A Rule-based Computational Model for Gaidhlig Morphology](https://arxiv.org/abs/2602.12132)
*Peter J Barclay*

Main category: cs.CL

TL;DR: 本论文探讨了基于规则的苏格兰盖尔语（Gaidhlig）形态模型构建，利用Wiktionary数据，强调规则系统在低资源语言中的优势。


<details>
  <summary>Details</summary>
Motivation: 当前神经模型需要大量训练数据，而低资源语言缺乏此类资源，因此亟需一种可有效利用有限数据并具备可解释性的语言模型。

Method: 通过SQL查询词汇模式，构建声明式规则库，并开发Python工具生成Gaidhlig单词屈折变化形式。

Result: 实现了基于规则的Gaidhlig形态推导系统，可支持教育工具及依赖解析工具开发，并拓展Wiktionary数据的新应用场景。

Conclusion: 规则系统在低资源语言处理中具有显著优势，能提供可解释性及教学价值，为高阶语言工具开发奠定基础。

Abstract: Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.

</details>


### [120] [CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes](https://arxiv.org/abs/2602.12137)
*Ricardo Campos,Ana Filipa Pacheco,Ana Luísa Fernandes,Inês Cantante,Rute Rebouças,Luís Filipe Cunha,José Miguel Isidro,José Pedro Evans,Miguel Marques,Rodrigo Batista,Evelin Amorim,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano*

Main category: cs.CL

TL;DR: This paper introduces CitiLink-Minutes, a multilayer annotated dataset of European Portuguese municipal meeting minutes to address the lack of resources for NLP and IR research on local governance records.


<details>
  <summary>Details</summary>
Motivation: Municipal meeting minutes are critical for understanding local governance decisions but lack annotated datasets, limiting computational research in IR and NLP. This work aims to bridge this gap.

Method: The dataset includes 120 minutes from six Portuguese municipalities, with multilayer manual annotations (metadata, discussion subjects, voting outcomes) by two annotators and linguist curation. It follows FAIR principles, includes de-identified content, and provides baseline models for metadata extraction, topic classification, and vote labeling.

Result: The dataset contains over one million tokens, 38,000+ annotations, and baseline results demonstrating its utility for NLP/IR tasks. All personal identifiers were removed, ensuring privacy.

Conclusion: CitiLink-Minutes fills a critical resource gap, enables research on local governance transparency, and supports downstream applications like policy analysis and decision-making systems through standardized, annotated municipal records.

Abstract: City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.

</details>


### [121] [Query-focused and Memory-aware Reranker for Long Context Processing](https://arxiv.org/abs/2602.12192)
*Yuqing Li,Jiangnan Li,Mo Yu,Guoxuan Ding,Zheng Lin,Weiping Wang,Jie Zhou*

Main category: cs.CL

TL;DR: 提出了基于注意力分数的轻量级列表式排序框架，无需Likert监督即可有效提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有排序模型依赖大规模参数或人工标注数据，且难以同时捕捉候选列表全局信息，本研究旨在构建更高效灵活的排序框架。

Method: 通过提取预训练模型中特定注意力头的分数作为相关性评估依据，结合列表级优化策略，并利用小模型（4B参数）实现端到端训练。

Result: 在维基百科和叙事数据集上超越SOTA逐点/列表排序器，在对话理解基准LoCoMo取得最优性能，且支持上下文增广和中层训练扩展。

Conclusion: 该框架通过注意力机制实现轻量化排序，平衡性能与效率，在开放域检索中具有广泛应用潜力。

Abstract: Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.

</details>


### [122] [Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education](https://arxiv.org/abs/2602.12196)
*Mohamed Huti,Alasdair Mackintosh,Amy Waldock,Dominic Andrews,Maxime Lelièvre,Moritz Boos,Tobias Murray,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 本文提出了视觉推理基准VRB，用于评估MLLMs在处理教育场景中视觉问题的能力，发现模型在静态任务表现较好，但动态空间操作存在瓶颈。


<details>
  <summary>Details</summary>
Motivation: 尽管AI模型在文本推理上表现优异，但在处理空间和关系结构（尤其是基础教育中的视觉问题）上仍存在瓶颈，限制了其在真实课堂环境中的应用。

Method: 构建包含701道题目（来自赞比亚与印度小学考试）的VRB基准，包含类比、模式补全、空间匹配等任务，并采用未编辑图片和最小文本测试模型能力。

Result: 模型在计数等静态技能上有较高准确率，但在折叠、镜像和旋转等动态空间操作任务中表现受限，形成了‘空间天花板’效应。

Conclusion: 教育定向的基准测试（如VRB）对评估多模态工具在教室中的功能边界至关重要，有助于避免误判、错误引导等负面影响。

Abstract: AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.

</details>


### [123] [ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images](https://arxiv.org/abs/2602.12203)
*Mathieu Sibue,Andres Muñoz Garza,Samuel Mensah,Pranav Shetty,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: 本论文介绍了ExStrucTiny，这是一个旨在改进文档图像结构化信息抽取的新基准数据集，旨在解决现有数据集在实体本体、文档类型多样性和灵活性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有关键实体提取、关系抽取和视觉问答数据集在本体范围、查询复杂度和文档多样性方面受限，难以有效评估通用视觉语言模型在多样化文档和灵活模式下的整体细粒度结构化抽取能力。

Method: 开发了一个结合人工标注与通过模拟生成并经过人工验证的样本的新颖数据集构建流程，创建了ExStrucTiny数据集，并对开放和封闭的视觉语言模型在该基准上的表现进行了分析。

Result: 实验揭示了现有模型在模式适应、查询欠指定和答案定位等方面存在的主要挑战，证实了ExStrucTiny在文档类型和抽取场景多样性上的优势。

Conclusion: ExStrucTiny为提升通用视觉语言模型在文档结构化信息抽取方面的能力提供了一个基础平台，强调了未来研究中需要解决的关键问题。

Abstract: Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.

</details>


### [124] [Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.12235)
*Julia Belikova,Danila Rozhevskii,Dennis Svirin,Konstantin Polev,Alexander Panchenko*

Main category: cs.CL

TL;DR: 本文研究了大语言模型中软压缩架构的token溢出问题，提出基于查询感知的检测方法来缓解压缩导致的信息缺失。


<details>
  <summary>Details</summary>
Motivation: 软压缩架构（如xRAG）通过学习压缩token序列扩展上下文长度，但其压缩极限和任务相关信息丢失的问题尚未被深入探索。现有查询无关的检测方法难以准确识别token溢出。

Method: 定义token溢出为压缩表征无法回答特定查询的状态，提出两种检测方法：查询无关的饱和度统计分析（分离压缩token与原始token），以及基于查询与上下文表征的轻量级分类模型（结合xRAG架构实现溢出检测）。

Result: 饱和度统计可有效区分压缩token但对溢出检测效果有限；结合查询信息的分类模型在HotpotQA、SQuADv2、TriviaQA数据集上平均AUC-ROC达0.72，且查询感知模型显著优于非感知模型。

Conclusion: 研究从查询无关诊断转向查询感知检测，通过低成本预滤波机制减少压缩引发的错误，为优化长上下文处理提供了理论框架与实用工具。

Abstract: Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.

</details>


### [125] [Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications](https://arxiv.org/abs/2602.12241)
*Manjunath Kudlur,Evan King,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: Moonshine v2通过滑动窗口自注意力机制，在保持高准确率的同时显著降低语音识别延迟，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer编码器因全局注意力机制导致线性延迟，无法满足实时语音应用对低TTFT的需求，尤其在资源受限的边缘设备上。

Method: 采用滑动窗口自注意力机制设计流式编码器，在限定计算量的同时保留关键局部上下文信息，并通过模型压缩技术优化性能。

Result: 在多项基准测试中达到SOTA词错误率，准确率与大模型相当（6倍参数量），推理速度提升显著，具体数据未披露。

Conclusion: 局部注意力机制可有效平衡准确率和延迟，为边缘设备交互式语音接口提供新方案，挑战了传统全局注意力的优势地位。

Abstract: Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent "encode-the-whole-utterance" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.

</details>


### [126] [T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization](https://arxiv.org/abs/2602.12262)
*Tunyu Zhang,Xinxi Zhang,Ligong Han,Haizhou Shi,Xiaoxiao He,Zhuowei Li,Hao Wang,Kai Xu,Akash Srivastava,Hao Wang,Vladimir Pavlovic,Dimitris N. Metaxas*

Main category: cs.CL

TL;DR: 提出一种轨迹自蒸馏框架，利用直接判别优化（DDO）改进Few-Step解码下的Diffusion大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: Diffusion大语言模型（DLLM）需多步迭代优化影响推理效率，减少步数会显著降低生成质量，需要平衡效率与质量。

Method: 1. 采用轨迹自蒸馏框架蒸馏模型自身生成轨迹；2.引入反向KL散度的直接判别优化（DDO），引导学生模型专注教师模型的高概率模式。

Result: 在严格步数限制下优于强基准和标准训练方法，大幅缩小Few-Step与Full-Step解码的性能差距，但Full-Step仍占优。

Conclusion: 为实用化Few-Step DLLM建立坚实基础，代码已开源（https://github.com/Tyrion58/T3D）。

Abstract: Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.

</details>


### [127] [On-Policy Context Distillation for Language Models](https://arxiv.org/abs/2602.12275)
*Tianzhu Ye,Li Dong,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: 该论文提出了一种名为On-Policy Context Distillation (OPCD)的知识蒸馏方法，通过结合策略内蒸馏与上下文蒸馏，使学生模型能够内化经验知识与系统提示，显著提升任务性能并保持分布外能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以高效结合模型生成历史轨迹与上下文知识，导致知识蒸馏效果受限。本文提出OPCD以解决这一问题，旨在提升模型的泛化性和跨规模迁移能力。

Method: 设计学生模型自生成轨迹并基于逆KL散度最小化与教师模型的差异，结合上下文条件训练框架，应用于经验知识蒸馏与系统提示蒸馏。

Result: 在数学推理、文本游戏等任务中OPCD超越基线方法，准确率提高1.5-2倍，且小模型可通过跨规模蒸馏从大模型有效学习知识。

Conclusion: OPCD为语言模型提供了高效的上下文知识内化路径，在保持模型原有能力的同时提升了实用性，尤其适用于动态环境与跨规模迁移场景。

Abstract: Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.

</details>
