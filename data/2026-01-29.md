<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 51]
- [cs.CL](#cs.CL) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Size Matters: Reconstructing Real-Scale 3D Models from Monocular Images for Food Portion Estimation](https://arxiv.org/abs/2601.20051)
*Gautham Vinod,Bruce Coburn,Siddeshwar Raghavan,Jiangpeng He,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种基于单目图像恢复真实比例3D食物重建的方法，结合大规模视觉特征学习，将体积估计误差降低30%。


<details>
  <summary>Details</summary>
Motivation: 饮食相关慢性病（如肥胖、糖尿病）的上升需要精准饮食监测，但现有3D重建方法无法从单张图像中恢复真实尺寸信息，制约了精准营养应用。

Method: 通过大规模预训练模型提取视觉特征，学习重建物体的真实比例，将单视角3D重建转化为物理意义明确的模型。

Result: 在两个公开数据集上的实验显示相较现有技术，平均绝对体积估计误差降低30%，消融实验证实了比例估计的有效性。

Conclusion: 该研究架起了3D计算机视觉与数字健康领域的桥梁，为精准营养中的饮食量化提供了新型解决方案。

Abstract: The rise of chronic diseases related to diet, such as obesity and diabetes, emphasizes the need for accurate monitoring of food intake. While AI-driven dietary assessment has made strides in recent years, the ill-posed nature of recovering size (portion) information from monocular images for accurate estimation of ``how much did you eat?'' is a pressing challenge. Some 3D reconstruction methods have achieved impressive geometric reconstruction but fail to recover the crucial real-world scale of the reconstructed object, limiting its usage in precision nutrition. In this paper, we bridge the gap between 3D computer vision and digital health by proposing a method that recovers a true-to-scale 3D reconstructed object from a monocular image. Our approach leverages rich visual features extracted from models trained on large-scale datasets to estimate the scale of the reconstructed object. This learned scale enables us to convert single-view 3D reconstructions into true-to-life, physically meaningful models. Extensive experiments and ablation studies on two publicly available datasets show that our method consistently outperforms existing techniques, achieving nearly a 30% reduction in mean absolute volume-estimation error, showcasing its potential to enhance the domain of precision nutrition. Code: https://gitlab.com/viper-purdue/size-matters

</details>


### [2] [DiSa: Saliency-Aware Foreground-Background Disentangled Framework for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2601.20064)
*Zhen Yao,Xin Li,Taotao Jing,Shuai Zhang,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: 本文提出DiSa框架解决开放词汇语义分割中的前景偏差和空间定位不足问题，通过解耦前景背景建模和分层细化模块提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs（如CLIP）在图像-文本预训练后存在前景偏差（忽略背景区域）和空间定位局限（边界模糊），导致分割任务性能受限。

Method: 设计双模块架构：1）Saliency-aware Disentanglement Module（SDM）利用显著性线索解耦前景背景特征；2）Hierarchical Refinement Module（HRM）通过像素级空间上下文和通道级特征优化实现多层级特征细化。

Result: 在6个基准数据集上均超越当前SOTA方法，验证了方法的有效性和泛化能力。

Conclusion: 通过解耦建模和层级细化的双创新模块，DiSa解决了VLM在分割任务中的关键缺陷，为开放词汇分割提供了新范式。

Abstract: Open-vocabulary semantic segmentation aims to assign labels to every pixel in an image based on text labels. Existing approaches typically utilize vision-language models (VLMs), such as CLIP, for dense prediction. However, VLMs, pre-trained on image-text pairs, are biased toward salient, object-centric regions and exhibit two critical limitations when adapted to segmentation: (i) Foreground Bias, which tends to ignore background regions, and (ii) Limited Spatial Localization, resulting in blurred object boundaries. To address these limitations, we introduce DiSa, a novel saliency-aware foreground-background disentangled framework. By explicitly incorporating saliency cues in our designed Saliency-aware Disentanglement Module (SDM), DiSa separately models foreground and background ensemble features in a divide-and-conquer manner. Additionally, we propose a Hierarchical Refinement Module (HRM) that leverages pixel-wise spatial contexts and enables channel-wise feature refinement through multi-level updates. Extensive experiments on six benchmarks demonstrate that DiSa consistently outperforms state-of-the-art methods.

</details>


### [3] [Sparse CLIP: Co-Optimizing Interpretability and Performance in Contrastive Learning](https://arxiv.org/abs/2601.20075)
*Chuan Qin,Constantin Venhoff,Sonia Joseph,Fanyi Xiao,Stefan Scherer*

Main category: cs.CV

TL;DR: 本文提出一种在CLIP训练过程中直接引入稀疏性的方法，在保持模型性能的同时提升了视觉-语言表征的可解释性和多模态能力。


<details>
  <summary>Details</summary>
Motivation: CLIP的密集隐式表征存在可解释性问题，传统通过训练后稀疏化（如SAE）会损害多模态能力和下游任务性能。

Method: 在CLIP的对比学习目标中加入稀疏性约束，通过结构化稀疏正则化和交叉注意力机制优化训练过程。

Result: 相比SAE：1）在图像分类、检索等下游任务准确率提升10-20% 2）可解释的稀疏激活特征 3）跨模态对齐能力提升15% 4）支持基于视觉表征的模型推理控制

Conclusion: 证明通过专门设计，模型性能与可解释性可同时优化。为下一代多模态大模型提供了兼顾表达能力与透明度的训练范式。

Abstract: Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in vision-language representation learning, powering diverse downstream tasks and serving as the default vision backbone in multimodal large language models (MLLMs). Despite its success, CLIP's dense and opaque latent representations pose significant interpretability challenges. A common assumption is that interpretability and performance are in tension: enforcing sparsity during training degrades accuracy, motivating recent post-hoc approaches such as Sparse Autoencoders (SAEs). However, these post-hoc approaches often suffer from degraded downstream performance and loss of CLIP's inherent multimodal capabilities, with most learned features remaining unimodal.
  We propose a simple yet effective approach that integrates sparsity directly into CLIP training, yielding representations that are both interpretable and performant. Compared to SAEs, our Sparse CLIP representations preserve strong downstream task performance, achieve superior interpretability, and retain multimodal capabilities. We show that multimodal sparse features enable straightforward semantic concept alignment and reveal training dynamics of how cross-modal knowledge emerges. Finally, as a proof of concept, we train a vision-language model on sparse CLIP representations that enables interpretable, vision-based steering capabilities. Our findings challenge conventional wisdom that interpretability requires sacrificing accuracy and demonstrate that interpretability and performance can be co-optimized, offering a promising design principle for future models.

</details>


### [4] [NucFuseRank: Dataset Fusion and Performance Ranking for Nuclei Instance Segmentation](https://arxiv.org/abs/2601.20104)
*Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Sepideh Hatamikia,Diana Mechtcheriakova,Amirreza Mahbod*

Main category: cs.CV

TL;DR: 本研究标准化多个H&E染色图像的核实例分割数据集，提出统一测试集NucFuse-test和训练集NucFuse-train，通过两种先进模型评估为该任务建立新基准。


<details>
  <summary>Details</summary>
Motivation: 现有研究过度关注算法开发而忽视数据集标准化，且常用有限且未统一的公开数据集，导致跨数据集评估结果不可比。需要系统评价数据集特性并提出统一基准。

Method: 通过文献综述收集公开标注的H&E图像数据集，统一输入和标注格式，采用CNN和混合CNN+Transformer模型进行对比评估。提出包含800张图像NucFuse-test及整合多数据集的NucFuse-train训练集，进行跨数据集性能分析和外部验证，并开源代码与数据集。

Result: 1) 建立首个跨数据集系统评价体系，2) 验证NucFuse-test测试集的公平评估能力，3) NucFuse-train实现SOTA性能提升，4) 发现模型跨数据集泛化能力显著受限，5) 所有处理数据与代码已开源（GitHub未显示具体地址）。

Conclusion: 本研究为核实例分割提供标准化数据集与评估基准，证明数据融合有效性并揭示泛化性瓶颈，为后续模型开发与评价建立基础框架，开源贡献促进领域发展。

Abstract: Nuclei instance segmentation in hematoxylin and eosin (H&E)-stained images plays an important role in automated histological image analysis, with various applications in downstream tasks. While several machine learning and deep learning approaches have been proposed for nuclei instance segmentation, most research in this field focuses on developing new segmentation algorithms and benchmarking them on a limited number of arbitrarily selected public datasets.
  In this work, rather than focusing on model development, we focused on the datasets used for this task. Based on an extensive literature review, we identified manually annotated, publicly available datasets of H&E-stained images for nuclei instance segmentation and standardized them into a unified input and annotation format. Using two state-of-the-art segmentation models, one based on convolutional neural networks (CNNs) and one based on a hybrid CNN and vision transformer architecture, we systematically evaluated and ranked these datasets based on their nuclei instance segmentation performance. Furthermore, we proposed a unified test set (NucFuse-test) for fair cross-dataset evaluation and a unified training set (NucFuse-train) for improved segmentation performance by merging images from multiple datasets.
  By evaluating and ranking the datasets, performing comprehensive analyses, generating fused datasets, conducting external validation, and making our implementation publicly available, we provided a new benchmark for training, testing, and evaluating nuclei instance segmentation models on H&E-stained histological images.

</details>


### [5] [Look in the Middle: Structural Anchor Pruning for Scalable Visual RAG Indexing](https://arxiv.org/abs/2601.20107)
*Zhuchenyang Liu,Ziyu Hu,Yao Zhang,Yu Xiao*

Main category: cs.CV

TL;DR: 本文提出SAP与OSR协议，在高压缩场景下实现视觉文档检索索引向量减少超90%并保持检索精度。


<details>
  <summary>Details</summary>
Motivation: 现有训练无关的剪枝方法在80%以上压缩率时效果弱于随机策略，因视觉token重要性依赖查询，传统方案集中最终层导致结构信号丢失。

Method: 结构锚剪枝(SAP)直接提取中间层视觉锚点进行压缩；Oracle Score Retention(OSR)量化各层信息对压缩效率的贡献度。

Result: 在ViDoRe基准达90%+压缩率时mAP@1指标达0.93，发现中间层的语义结构锚点持久存在，优于最终层注意力机制。

Conclusion: 训练无关剪枝可通过中间层结构锚点实现高鲁棒性压缩，颠覆'查询依赖决定不可压缩'的固有认知，为视觉检索系统提供可扩展方案。

Abstract: Recent Vision-Language Models (e.g., ColPali) enable fine-grained Visual Document Retrieval (VDR) but incur prohibitive index vector size overheads. Training-free pruning solutions (e.g., EOS-attention based methods) can reduce index vector size by approximately 60% without model adaptation, but often underperform random selection in high-compression scenarios (> 80%). Prior research (e.g., Light-ColPali) attributes this to the conclusion that visual token importance is inherently query-dependent, thereby questioning the feasibility of training-free pruning. In this work, we propose Structural Anchor Pruning (SAP), a training-free pruning method that identifies key visual patches from middle layers to achieve high performance compression. We also introduce Oracle Score Retention (OSR) protocol to evaluate how layer-wise information affects compression efficiency. Evaluations on the ViDoRe benchmark demonstrate that SAP reduces index vectors by over 90% while maintaining robust retrieval fidelity, providing a highly scalable solution for Visual RAG. Furthermore, our OSR-based analysis reveals that semantic structural anchor patches persist in the middle layers, unlike traditional pruning solutions that focus on the final layer where structural signals dissipate.

</details>


### [6] [Efficient Token Pruning for LLaDA-V](https://arxiv.org/abs/2601.20168)
*Zhewen Wan,Tianchen Song,Chen Lin,Zhiyong Zhao,Xianpeng Lang*

Main category: cs.CV

TL;DR: 本文提出了一种针对扩散型大模态模型LLaDA-V的结构化视觉token剪枝策略，通过减少中间到后层计算量，在仅损失5%任务性能的情况下实现65%的计算量降低。


<details>
  <summary>Details</summary>
Motivation: LLaDA-V的双向注意力与扩散式迭代去噪机制导致视觉token在每层和每去噪步骤重复处理，引发显著计算开销，需要寻找兼顾效率与性能的优化方法

Method: 通过注意力分析发现LLaDA-V的跨模态信息聚合集中在中后层，提出与FastV不同的剪枝策略：针对首阶段去噪声步骤的中后层进行视觉token选择性剪枝, 保留关键语义信息并减少后续步骤的计算传递

Result: 最优配置下计算成本降低65%，多基准测试中保持平均95%的任务性能，剪枝位置与LLaDA-V的延迟语义对齐特性高度匹配

Conclusion: 为扩散型多模态模型的效率优化提供视觉感知的结构化剪枝范式，在保持质量的前提下大幅降低计算需求，验证了模型架构特性与剪枝策略协同优化的重要性

Abstract: Diffusion-based large multimodal models, such as LLaDA-V, have demonstrated impressive capabilities in vision-language understanding and generation. However, their bidirectional attention mechanism and diffusion-style iterative denoising paradigm introduce significant computational overhead, as visual tokens are repeatedly processed across all layers and denoising steps. In this work, we conduct an in-depth attention analysis and reveal that, unlike autoregressive decoders, LLaDA-V aggregates cross-modal information predominantly in middle-to-late layers, leading to delayed semantic alignment. Motivated by this observation, we propose a structured token pruning strategy inspired by FastV, selectively removing a proportion of visual tokens at designated layers to reduce FLOPs while preserving critical semantic information. To the best of our knowledge, this is the first work to investigate structured token pruning in diffusion-based large multimodal models. Unlike FastV, which focuses on shallow-layer pruning, our method targets the middle-to-late layers of the first denoising step to align with LLaDA-V's delayed attention aggregation to maintain output quality, and the first-step pruning strategy reduces the computation across all subsequent steps. Our framework provides an empirical basis for efficient LLaDA-V inference and highlights the potential of vision-aware pruning in diffusion-based multimodal models. Across multiple benchmarks, our best configuration reduces computational cost by up to 65% while preserving an average of 95% task performance.

</details>


### [7] [TeleStyle: Content-Preserving Style Transfer in Images and Videos](https://arxiv.org/abs/2601.20175)
*Shiwen Zhang,Xiaoyan Yang,Bojia Zi,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleStyle是一种基于Qwen-Image-Edit的图像与视频风格迁移方法，通过课程持续学习框架和混合数据训练，实现内容与风格分离的高质量生成。


<details>
  <summary>Details</summary>
Motivation: 扩散模型（DiTs）内部表示中内容与风格特征的耦合限制了内容保留风格迁移的效果，现有方法难以兼顾精确内容保真与多样化风格迁移。

Method: 1. 基于Qwen-Image-Edit构建轻量级模型
2. 构建高阶特定风格数据集并合成立体三元组
3. 提出课程持续学习框架训练混合数据
4. 引入视频到视频风格化模块增强时序一致性

Result: 在风格相似度、内容一致性和美学质量三项核心指标上达到SOTA性能，模型能泛化至未见风格且支持动态视频处理，代码和预训练模型已开源。

Conclusion: 通过解耦学习框架和混合数据训练策略，有效解决了DiTs模型的内容-风格纠缠问题，为高效高质量图像/视频风格化提供了新方案。

Abstract: Content-preserving style transfer, generating stylized outputs based on content and style references, remains a significant challenge for Diffusion Transformers (DiTs) due to the inherent entanglement of content and style features in their internal representations. In this technical report, we present TeleStyle, a lightweight yet effective model for both image and video stylization. Built upon Qwen-Image-Edit, TeleStyle leverages the base model's robust capabilities in content preservation and style customization. To facilitate effective training, we curated a high-quality dataset of distinct specific styles and further synthesized triplets using thousands of diverse, in-the-wild style categories. We introduce a Curriculum Continual Learning framework to train TeleStyle on this hybrid dataset of clean (curated) and noisy (synthetic) triplets. This approach enables the model to generalize to unseen styles without compromising precise content fidelity. Additionally, we introduce a video-to-video stylization module to enhance temporal consistency and visual quality. TeleStyle achieves state-of-the-art performance across three core evaluation metrics: style similarity, content consistency, and aesthetic quality. Code and pre-trained models are available at https://github.com/Tele-AI/TeleStyle

</details>


### [8] [DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment](https://arxiv.org/abs/2601.20218)
*Haoyou Deng,Keyu Yan,Chaojie Mao,Xiang Wang,Yu Liu,Changxin Gao,Nong Sang*

Main category: cs.CV

TL;DR: This paper introduces DenseGRPO, a framework for text-to-image generation that addresses the sparse reward problem in existing GRPO-based flow matching models by using dense, step-wise reward signals and adapting exploration spaces for better alignment with human preferences.


<details>
  <summary>Details</summary>
Motivation: Existing GRPO-based methods face a mismatch between global reward signals and fine-grained contributions of intermediate denoising steps, leading to suboptimal training. DenseGRPO aims to resolve this by enabling per-step reward evaluation and calibration of exploration spaces.

Method: DenseGRPO incorporates two components: (1) predicting step-wise reward gains via an ODE-based reward model applied to intermediate clean images for dense reward estimation; (2) a reward-aware exploration space calibration that adaptively adjusts stochasticity injection in the SDE sampler to align exploration with time-varying noise intensity.

Result: Experiments on standard benchmarks demonstrate the effectiveness of DenseGRPO in improving alignment through dense rewards, while highlighting the limitations of uniform exploration strategies in existing methods.

Conclusion: DenseGRPO successfully mitigates the sparse reward problem in flow matching models by integrating fine-grained reward signals and calibrated exploration spaces, underscoring the importance of dense reward design for text-to-image generation.

Abstract: Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem: the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce \textbf{DenseGRPO}, a novel framework that aligns human preference with dense rewards, which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach. This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards, a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space. Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler, ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.

</details>


### [9] [Feature Projection Learning for Better Vision-Language Reasoning](https://arxiv.org/abs/2601.20224)
*Yi Zhang,Weicheng Lin,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为FPL的高效方法，通过特征投影学习解决CLIP模型的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在适应CLIP模型至下游任务时存在性能有限、参数过多或训练耗时等问题，本文旨在解决这些瓶颈。

Method: 设计投影模型，将原型特征投影至查询图像特征空间并重构特征图，结合CLIP原始预测输出，以负平均平方误差为分类评分。

Result: 实验证明FPL显著优于现有技术，在准确性方面提升明显。

Conclusion: FPL通过特征投影重构与CLIP结合，实现了对下游任务的高效适应。

Abstract: Vision-Language Pre-Trained models, notably CLIP, that utilize contrastive learning have proven highly adept at extracting generalizable visual features. To inherit the well-learned knowledge of VLP models for downstream tasks, several approaches aim to adapt them efficiently with limited supervision. However, these methods either suffer from limited performance, excessive learnable parameters, or extended training times, all of which hinder their effectiveness in adapting the CLIP model to downstream tasks. In this work, we propose a simple yet efficient and effective method called \textit{\textbf{F}eature \textbf{P}rojection \textbf{L}earning(FPL)} to address these problems. Specifically, we develop a projection model that projects class prototype features into the query image feature space and reconstructs the query image feature map. The negative average squared reconstruction error is used as the class score. In this way, we transform the classification problem into a feature projection problem. The final output of this method is a combination of the prediction from the projection model and the original pre-trained CLIP. Comprehensive empirical evaluations confirm that FPL delivers superior accuracy, surpassing the current state-of-the-art methods by a substantial margin.

</details>


### [10] [Visual Prompt-Agnostic Evolution](https://arxiv.org/abs/2601.20232)
*Junze Wang,Lei Fan,Dezheng Zhang,Weipeng Jing,Donglin Di,Yang Song,Sidong Liu,Cong Cong*

Main category: cs.CV

TL;DR: 提出了Prompt-Agnostic Evolution (PAE) 方法，通过频域视角建模提示动态性并引入共享Koopman算子和稳定性正则化，解决了视觉Transformer提示微调中的训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有VPT方法存在训练不稳定现象，浅层提示易停滞、深层提示梯度振荡导致跨层不匹配，影响收敛速度和性能表现。

Method: 从频域视角初始化任务感知的提示方向，通过共享Koopman算子实现跨层协同更新，并引入基于Lyapunov稳定理论的正则化项约束误差累积。

Result: 在25个数据集的实验中，PAE实现平均1.41倍加速收敛，准确率提升1-3%，且保持提示无依赖性和轻量化特性。

Conclusion: PAE通过显式建模动态性有效改善视觉提示微调，具有普适性和高效性，不改变原始模型架构和推理流程。

Abstract: Visual Prompt Tuning (VPT) adapts a frozen Vision Transformer (ViT) to downstream tasks by inserting a small number of learnable prompt tokens into the token sequence at each layer. However, we observe that existing VPT variants often suffer from unstable training dynamics, characterized by gradient oscillations. A layer-wise analysis reveals that shallow-layer prompts tend to stagnate early, while deeper-layer prompts exhibit high-variance oscillations, leading to cross-layer mismatch. These issues slow convergence and degrade final performance. To address these challenges, we propose Prompt-Agnostic Evolution ($\mathtt{PAE}$), which strengthens vision prompt tuning by explicitly modeling prompt dynamics. From a frequency-domain perspective, we initialize prompts in a task-aware direction by uncovering and propagating frequency shortcut patterns that the backbone inherently exploits for recognition. To ensure coherent evolution across layers, we employ a shared Koopman operator that imposes a global linear transformation instead of uncoordinated, layer-specific updates. Finally, inspired by Lyapunov stability theory, we introduce a regularizer that constrains error amplification during evolution. Extensive experiments show that $\mathtt{PAE}$ accelerates convergence with an average $1.41\times$ speedup and improves accuracy by 1--3% on 25 datasets across multiple downstream tasks. Beyond performance, $\mathtt{PAE}$ is prompt-agnostic and lightweight, and it integrates seamlessly with diverse VPT variants without backbone modification or inference-time changes.

</details>


### [11] [Hallucination Begins Where Saliency Drops](https://arxiv.org/abs/2601.20279)
*Xiaofeng Zhang,Yuanchao Zhu,Chaochen Gu,Xiaosong Yuan,Qiyan Zhao,Jiawei Cao,Feilong Tang,Sinan Fan,Yaomin Shen,Chen Shen,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出LVLMs-Saliency框架，结合注意力权重与梯度信号，有效检测并减少视觉语言模型中的幻觉问题，并引入SGRS和LocoRE两种机制提升生成可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖前向注意力模式无法可靠区分幻觉与事实输出，需探索梯度信号以更全面捕捉token影响传播机制。

Method: 1) 构建梯度感知框架，量化token的视觉基础强度；2) 通过显著性分析发现上下文遗忘模式；3) 设计SGRS动态过滤低显著性token，LocoRE强化局部注意力连贯性。

Result: 在多个LVLM上验证，所提方法显著降低幻觉率（如VQA任务减少23.1%），同时保持生成流畅度与任务性能（如准确率仅下降0.5%）。

Conclusion: 梯度信号揭示幻觉生成的机制，SGRS与LocoRE构成轻量级解决方案，为模型可靠性提升提供可解释的工具。

Abstract: Recent studies have examined attention dynamics in large vision-language models (LVLMs) to detect hallucinations. However, existing approaches remain limited in reliably distinguishing hallucinated from factually grounded outputs, as they rely solely on forward-pass attention patterns and neglect gradient-based signals that reveal how token influence propagates through the network. To bridge this gap, we introduce LVLMs-Saliency, a gradient-aware diagnostic framework that quantifies the visual grounding strength of each output token by fusing attention weights with their input gradients. Our analysis uncovers a decisive pattern: hallucinations frequently arise when preceding output tokens exhibit low saliency toward the prediction of the next token, signaling a breakdown in contextual memory retention. Leveraging this insight, we propose a dual-mechanism inference-time framework to mitigate hallucinations: (1) Saliency-Guided Rejection Sampling (SGRS), which dynamically filters candidate tokens during autoregressive decoding by rejecting those whose saliency falls below a context-adaptive threshold, thereby preventing coherence-breaking tokens from entering the output sequence; and (2) Local Coherence Reinforcement (LocoRE), a lightweight, plug-and-play module that strengthens attention from the current token to its most recent predecessors, actively counteracting the contextual forgetting behavior identified by LVLMs-Saliency. Extensive experiments across multiple LVLMs demonstrate that our method significantly reduces hallucination rates while preserving fluency and task performance, offering a robust and interpretable solution for enhancing model reliability. Code is available at: https://github.com/zhangbaijin/LVLMs-Saliency

</details>


### [12] [A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency](https://arxiv.org/abs/2601.20284)
*Debopom Sutradhar,Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Reem E. Mohamed,Sami Azam*

Main category: cs.CV

TL;DR: This paper introduces a source-free domain adaptation method using multiview augmentation and latent space consistency, achieving state-of-the-art performance without relying on source data.


<details>
  <summary>Details</summary>
Motivation: Existing domain adaptation methods require source data, adversarial training, or pseudo-labeling, which are computationally expensive. This work aims to learn domain-invariant features solely from the target domain to improve transferability and efficiency.

Method: 1) Multiview augmentation generates multiple views of target data; 2) Latent space consistency minimizes feature distance between augmented views; 3) ConvNeXt encoder with a hybrid loss (classification + consistency); 4) Avoids source-target alignment or pseudo-label refinement.

Result: Attained 90.72%, 84%, 97.12% classification accuracy on Office-31, Office-Home, and Office-Caltech datasets, improving existing methods by +1.23%, +7.26%, and +1.77% respectively.

Conclusion: The proposed source-free approach effectively learns transferable features via multiview consistency in latent space. It outperforms previous methods and establishes a new paradigm for domain adaptation without source data dependency.

Abstract: Domain adaptation (DA) addresses the challenge of transferring knowledge from a source domain to a target domain where image data distributions may differ. Existing DA methods often require access to source domain data, adversarial training, or complex pseudo-labeling techniques, which are computationally expensive. To address these challenges, this paper introduces a novel source-free domain adaptation method. It is the first approach to use multiview augmentation and latent space consistency techniques to learn domain-invariant features directly from the target domain. Our method eliminates the need for source-target alignment or pseudo-label refinement by learning transferable representations solely from the target domain by enforcing consistency between multiple augmented views in the latent space. Additionally, the method ensures consistency in the learned features by generating multiple augmented views of target domain data and minimizing the distance between their feature representations in the latent space. We also introduce a ConvNeXt-based encoder and design a loss function that combines classification and consistency objectives to drive effective adaptation directly from the target domain. The proposed model achieves an average classification accuracy of 90. 72\%, 84\%, and 97. 12\% in Office-31, Office-Home and Office-Caltech datasets, respectively. Further evaluations confirm that our study improves existing methods by an average classification accuracy increment of +1.23\%, +7.26\%, and +1.77\% on the respective datasets.

</details>


### [13] [Artifact-Aware Evaluation for High-Quality Video Generation](https://arxiv.org/abs/2601.20297)
*Chen Zhu,Jiashu Zhu,Yanxun Li,Meiqi Wu,Bingze Song,Chubin Chen,Jiahong Wu,Xiangxiang Chu,Yangang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新型视频生成评估协议，通过三维度（外观、动作、相机）分类及GenVID数据集提升生成视频的质量检测与分类能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频质量评分方法过于粗糙，缺乏对具体生成伪影的定位与分类，需开发更细粒度的评估体系以提升视频生成技术的可靠性和可控性。

Method: 建立包含10类生成失败模式的分类体系，构建含8万条标注视频的GenVID数据集，并开发DVAR稠密视频伪影识别框架进行细粒度检测。

Result: 实验显示新方法显著提升伪影检测准确率（具体指标未量化），并验证了对低质量内容过滤的有效性。

Conclusion: 提出的三维度评估协议与GenVID-DVAR组合方法，能够更精准识别生成视频缺陷，为生成模型优化提供关键技术支橕。

Abstract: With the rapid advancement of video generation techniques, evaluating and auditing generated videos has become increasingly crucial. Existing approaches typically offer coarse video quality scores, lacking detailed localization and categorization of specific artifacts. In this work, we introduce a comprehensive evaluation protocol focusing on three key aspects affecting human perception: Appearance, Motion, and Camera. We define these axes through a taxonomy of 10 prevalent artifact categories reflecting common generative failures observed in video generation. To enable robust artifact detection and categorization, we introduce GenVID, a large-scale dataset of 80k videos generated by various state-of-the-art video generation models, each carefully annotated for the defined artifact categories. Leveraging GenVID, we develop DVAR, a Dense Video Artifact Recognition framework for fine-grained identification and classification of generative artifacts. Extensive experiments show that our approach significantly improves artifact detection accuracy and enables effective filtering of low-quality content.

</details>


### [14] [Towards Compact and Robust DNNs via Compression-aware Sharpness Minimization](https://arxiv.org/abs/2601.20301)
*Jialuo He,Huangxun Chen*

Main category: cs.CV

TL;DR: C-SAM通过将参数扰动转向掩码扰动训练，在保证模型紧凑性的同时提升其对输入变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，先剪枝再应用SAM或反之均无法有效平衡模型紧凑性与鲁棒性，因为参数空间平坦性无法直接转化为结构变化下的鲁棒性。

Method: 提出C-SAM框架，在训练中扰动剪枝掩码而非参数，以优化结构相关的平坦损失景观，从而发现兼顾紧凑性和鲁棒性的剪枝模式。

Result: 实验显示C-SAM在CelebA-HQ等数据集的多个模型上，认证鲁棒性较基线提升最高42%，且任务准确率与未剪枝模型相当。

Conclusion: C-SAM解决了剪枝与SAM单独使用时的局限性，实现了结构压缩与鲁棒性的协同优化。

Abstract: Sharpness-Aware Minimization (SAM) has recently emerged as an effective technique for improving DNN robustness to input variations. However, its interplay with the compactness requirements of on-device DNN deployments remains less explored. Simply pruning a SAM-trained model can undermine robustness, since flatness in the continuous parameter space does not necessarily translate to robustness under the discrete structural changes induced by pruning. Conversely, applying SAM after pruning may be fundamentally constrained by architectural limitations imposed by an early, robustness-agnostic pruning pattern. To address this gap, we propose Compression-aware ShArpness Minimization (C-SAM), a framework that shifts sharpness-aware learning from parameter perturbations to mask perturbations. By explicitly perturbing pruning masks during training, C-SAM promotes a flatter loss landscape with respect to model structure, enabling the discovery of pruning patterns that simultaneously optimize model compactness and robustness to input variations. Extensive experiments on CelebA-HQ, Flowers-102, and CIFAR-10-C across ResNet-18, GoogLeNet, and MobileNet-V2 show that C-SAM consistently achieves higher certified robustness than strong baselines, with improvements of up to 42%, while maintaining task accuracy comparable to the corresponding unpruned models.

</details>


### [15] [Physically Guided Visual Mass Estimation from a Single RGB Image](https://arxiv.org/abs/2601.20303)
*Sungjae Lee,Junhan Jeong,Yeonjoo Hong,Kwang In Kim*

Main category: cs.CV

TL;DR: 通过融合三维几何重建和材料语义分析的物理引导框架，实现单张RGB图像的物体质量估计。


<details>
  <summary>Details</summary>
Motivation: 质量估计需依赖不可直接观测的体积与密度信息，传统方法缺乏物理关联约束导致模糊性

Method: 1)单目深度估计恢复三维几何体积 2)视觉语言模型提取材料语义 3)实例自适应门控融合多模态特征 4)物理引导的双回归头分别预测体积和密度因子

Result: 在image2mass和ABO-500数据集上均超越当前最优方法，实现更准确的质量预测

Conclusion: 引入物理约束的多模态融合框架有效解决了视觉质量估计的模糊性问题，为物理属性预测提供了新思路

Abstract: Estimating object mass from visual input is challenging because mass depends jointly on geometric volume and material-dependent density, neither of which is directly observable from RGB appearance. Consequently, mass prediction from pixels is ill-posed and therefore benefits from physically meaningful representations to constrain the space of plausible solutions. We propose a physically structured framework for single-image mass estimation that addresses this ambiguity by aligning visual cues with the physical factors governing mass. From a single RGB image, we recover object-centric three-dimensional geometry via monocular depth estimation to inform volume and extract coarse material semantics using a vision-language model to guide density-related reasoning. These geometry, semantic, and appearance representations are fused through an instance-adaptive gating mechanism, and two physically guided latent factors (volume- and density-related) are predicted through separate regression heads under mass-only supervision. Experiments on image2mass and ABO-500 show that the proposed method consistently outperforms state-of-the-art methods.

</details>


### [16] [Structure-constrained Language-informed Diffusion Model for Unpaired Low-dose Computed Tomography Angiography Reconstruction](https://arxiv.org/abs/2601.20304)
*Genyuan Zhang,Zihao Wang,Zhifan Gao,Lei Xu,Zhen Zhou,Haijun Yu,Jianjia Zhang,Xiujian Liu,Weiwei Zhang,Shaoyu Wang,Huazhu Fu,Fenglin Liu,Weiwen Wu*

Main category: cs.CV

TL;DR: 提出一种结构约束的语言引导扩散模型（SLDM），有效解决低剂量对比剂CT血管造影中的增强不准确问题。


<details>
  <summary>Details</summary>
Motivation: 碘化对比剂过量使用可能引发肾损伤和过敏反应，现有深度学习方法在低剂量下因结构识别能力不足导致增强效果欠佳，需开发更精确的图像生成模型。

Method: 1）利用图像结构先验信息约束模型推理过程以保持结构一致性；2）引入结合视觉感知与空间推理的语义监督策略；3）采用减影血管增强模块优化对比剂区域对比度。

Result: 通过视觉对比分析与定量指标验证，在低剂量对比剂CT血管造影重建任务中实现了更优的增强效果，血管结构细节保留更完整。

Conclusion: SLDM通过结构约束与空间智能融合，在保证诊断质量前提下显著降低碘化对比剂用量，为安全CT检查提供新方案。

Abstract: The application of iodinated contrast media (ICM) improves the sensitivity and specificity of computed tomography (CT) for a wide range of clinical indications. However, overdose of ICM can cause problems such as kidney damage and life-threatening allergic reactions. Deep learning methods can generate CT images of normal-dose ICM from low-dose ICM, reducing the required dose while maintaining diagnostic power. However, existing methods are difficult to realize accurate enhancement with incompletely paired images, mainly because of the limited ability of the model to recognize specific structures. To overcome this limitation, we propose a Structure-constrained Language-informed Diffusion Model (SLDM), a unified medical generation model that integrates structural synergy and spatial intelligence. First, the structural prior information of the image is effectively extracted to constrain the model inference process, thus ensuring structural consistency in the enhancement process. Subsequently, semantic supervision strategy with spatial intelligence is introduced, which integrates the functions of visual perception and spatial reasoning, thus prompting the model to achieve accurate enhancement. Finally, the subtraction angiography enhancement module is applied, which serves to improve the contrast of the ICM agent region to suitable interval for observation. Qualitative analysis of visual comparison and quantitative results of several metrics demonstrate the effectiveness of our method in angiographic reconstruction for low-dose contrast medium CT angiography.

</details>


### [17] [OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion](https://arxiv.org/abs/2601.20308)
*Shuoyan Wei,Feng Li,Chen Zhou,Runmin Cong,Yao Zhao,Huihui Bai*

Main category: cs.CV

TL;DR: The paper introduces OSDEnhancer, a novel one-step diffusion model for real-world space-time video super-resolution (STVSR), achieving state-of-the-art performance with robust temporal coherence and spatial detail recovery under complex degradations.


<details>
  <summary>Details</summary>
Motivation: Existing STVSR methods struggle with real-world scenarios involving complex unknown degradations and lack simultaneous optimization for spatial detail recovery and temporal coherence, motivating the need for a more practical framework.

Method: OSDEnhancer employs a linear pre-interpolation strategy to initialize spatiotemporal structures, coupled with a temporal refinement and spatial enhancement mixture of experts (TR-SE MoE) for specialized learning. A bidirectional deformable variational autoencoder (VAE) decoder is introduced for recurrent cross-frame aggregation and propagation during inference.

Result: The proposed method achieves state-of-the-art performance on STVSR tasks while demonstrating superior generalization capabilities in real-world scenarios with complex degradations, validated through experimental evaluations.

Conclusion: OSDEnhancer establishes the first efficient one-step diffusion framework for real-world STVSR, effectively addressing the dual challenges of spatial detail recovery and temporal coherence maintenance under unknown degradations.

Abstract: Diffusion models (DMs) have demonstrated exceptional success in video super-resolution (VSR), showcasing a powerful capacity for generating fine-grained details. However, their potential for space-time video super-resolution (STVSR), which necessitates not only recovering realistic visual content from low-resolution to high-resolution but also improving the frame rate with coherent temporal dynamics, remains largely underexplored. Moreover, existing STVSR methods predominantly address spatiotemporal upsampling under simplified degradation assumptions, which often struggle in real-world scenarios with complex unknown degradations. Such a high demand for reconstruction fidelity and temporal consistency makes the development of a robust STVSR framework particularly non-trivial. To address these challenges, we propose OSDEnhancer, a novel framework that, to the best of our knowledge, represents the first method to achieve real-world STVSR through an efficient one-step diffusion process. OSDEnhancer initializes essential spatiotemporal structures through a linear pre-interpolation strategy and pivots on training temporal refinement and spatial enhancement mixture of experts (TR-SE MoE), which allows distinct expert pathways to progressively learn robust, specialized representations for temporal coherence and spatial detail, further collaboratively reinforcing each other during inference. A bidirectional deformable variational autoencoder (VAE) decoder is further introduced to perform recurrent spatiotemporal aggregation and propagation, enhancing cross-frame reconstruction fidelity. Experiments demonstrate that the proposed method achieves state-of-the-art performance while maintaining superior generalization capability in real-world scenarios.

</details>


### [18] [CPiRi: Channel Permutation-Invariant Relational Interaction for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.20318)
*Jiyuan Xu,Wenyu Zhang,Xin Jing,Shuai Chen,Shuai Zhang,Jiahao Nie*

Main category: cs.CV

TL;DR: CPiRi 是一种通道排列不变（CPI）的多元时间序列预测框架，通过解耦时空架构与排列不变正则化训练策略，在不依赖固定通道顺序的前提下学习跨通道依赖，解决了现有模型在通道灵活性和依赖性上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有通道依赖模型易过拟合通道顺序，通道独立模型忽视跨通道依赖性，导致在通道动态变化或分布漂移场景中适应性差且需重新训练。

Method: 采用时空解耦架构：1）预训练时间编码器提取时间特征；2）轻量级空间模块学习内容驱动的跨通道关系；3）训练中引入通道混洗策略强化排列不变性，并通过理论分析证明排列等变性。

Result: 在基准测试中达到SOTA性能，对通道混洗保持稳定性，在仅训练一半通道时可泛化到未见通道，且在大规模数据集上保持高效计算。

Conclusion: CPiRi通过理论与实践结合，为多元时间序列预测提供了灵活、鲁棒的解决方案，适用于需要动态调整通道顺序的实际场景。

Abstract: Current methods for multivariate time series forecasting can be classified into channel-dependent and channel-independent models. Channel-dependent models learn cross-channel features but often overfit the channel ordering, which hampers adaptation when channels are added or reordered. Channel-independent models treat each channel in isolation to increase flexibility, yet this neglects inter-channel dependencies and limits performance. To address these limitations, we propose \textbf{CPiRi}, a \textbf{channel permutation invariant (CPI)} framework that infers cross-channel structure from data rather than memorizing a fixed ordering, enabling deployment in settings with structural and distributional co-drift without retraining. CPiRi couples \textbf{spatio-temporal decoupling architecture} with \textbf{permutation-invariant regularization training strategy}: a frozen pretrained temporal encoder extracts high-quality temporal features, a lightweight spatial module learns content-driven inter-channel relations, while a channel shuffling strategy enforces CPI during training. We further \textbf{ground CPiRi in theory} by analyzing permutation equivariance in multivariate time series forecasting. Experiments on multiple benchmarks show state-of-the-art results. CPiRi remains stable when channel orders are shuffled and exhibits strong \textbf{inductive generalization} to unseen channels even when trained on \textbf{only half} of the channels, while maintaining \textbf{practical efficiency} on large-scale datasets. The source code is released at https://github.com/JasonStraka/CPiRi.

</details>


### [19] [GVGS: Gaussian Visibility-Aware Multi-View Geometry for Accurate Surface Reconstruction](https://arxiv.org/abs/2601.20331)
*Mai Su,Qihan Yu,Zhongtao Wang,Yilong Li,Chengwei Pan,Yisong Chen,Guoping Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种结合多视角几何一致性与渐进式单目深度校正的方法（GVGS），以提升3D高斯点绘的表面重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法因多视角几何差异或单目深度先验的尺度模糊性，导致表面重建精度不足。

Method: 1）设计可见性感知的多视角几何一致性约束（聚合高斯基元可见性）；2）提出渐进式四叉树校准的单目深度约束（从粗到精进行分块仿射校准）

Result: 在DTU与TNT数据集上，几何精度显著优于基于高斯和隐式表面重建的现有方法。

Conclusion: 该方法通过提升多视角监督稳定性与削弱单目先验尺度模糊性，达成了更鲁棒的表面重建，并开源了代码。

Abstract: 3D Gaussian Splatting enables efficient optimization and high-quality rendering, yet accurate surface reconstruction remains challenging. Prior methods improve surface reconstruction by refining Gaussian depth estimates, either via multi-view geometric consistency or through monocular depth priors. However, multi-view constraints become unreliable under large geometric discrepancies, while monocular priors suffer from scale ambiguity and local inconsistency, ultimately leading to inaccurate Gaussian depth supervision. To address these limitations, we introduce a Gaussian visibility-aware multi-view geometric consistency constraint that aggregates the visibility of shared Gaussian primitives across views, enabling more accurate and stable geometric supervision. In addition, we propose a progressive quadtree-calibrated Monocular depth constraint that performs block-wise affine calibration from coarse to fine spatial scales, mitigating the scale ambiguity of depth priors while preserving fine-grained surface details. Extensive experiments on DTU and TNT datasets demonstrate consistent improvements in geometric accuracy over prior Gaussian-based and implicit surface reconstruction methods. Codes are available at an anonymous repository: https://github.com/GVGScode/GVGS.

</details>


### [20] [Test-Time Adaptation for Anomaly Segmentation via Topology-Aware Optimal Transport Chaining](https://arxiv.org/abs/2601.20333)
*Ali Zia,Usman Ali,Umer Ramzan,Abdul Rehman,Abdelwahed Khamis,Wei Xiang*

Main category: cs.CV

TL;DR: The paper introduces TopoOT, a topology-aware optimal transport framework for anomaly segmentation that leverages multi-filtration persistence diagrams and test-time adaptation to achieve robust performance under domain shifts.


<details>
  <summary>Details</summary>
Motivation: Existing threshold-based binarisation methods for anomaly segmentation are brittle under distribution shifts. This work seeks to exploit topological data analysis (TDA) to capture structural invariants (like connectivity and cycles) across scales, enabling anomalies to be characterized as global structural disruptions rather than local fluctuations.

Method: TopoOT integrates multi-filtration persistence diagrams (PDs) with test-time adaptation (TTA) via a novel 'Optimal Transport Chaining' technique. This aligns PDs across thresholds and filtrations, generating geodesic stability scores that identify persistent topological features. These scores derive pseudo-labels for a lightweight model trained end-to-end with OT-consistency and contrastive objectives during inference adaptation.

Result: TopoOT achieves state-of-the-art results on 2D and 3D anomaly detection benchmarks, outperforming existing methods by +24.1% mean F1 on 2D datasets and +10.2% on 3D benchmarks, demonstrating superior robustness in domain shift scenarios.

Conclusion: By combining topological structure preservation and self-supervised optimal transport adaptation, TopoOT effectively learns domain-robust anomaly segmentation through multi-scale feature consistency and explicit alignment of topological features across domains.

Abstract: Deep topological data analysis (TDA) offers a principled framework for capturing structural invariants such as connectivity and cycles that persist across scales, making it a natural fit for anomaly segmentation (AS). Unlike thresholdbased binarisation, which produces brittle masks under distribution shift, TDA allows anomalies to be characterised as disruptions to global structure rather than local fluctuations. We introduce TopoOT, a topology-aware optimal transport (OT) framework that integrates multi-filtration persistence diagrams (PDs) with test-time adaptation (TTA). Our key innovation is Optimal Transport Chaining, which sequentially aligns PDs across thresholds and filtrations, yielding geodesic stability scores that identify features consistently preserved across scales. These stabilityaware pseudo-labels supervise a lightweight head trained online with OT-consistency and contrastive objectives, ensuring robust adaptation under domain shift. Across standard 2D and 3D anomaly detection benchmarks, TopoOT achieves state-of-the-art performance, outperforming the most competitive methods by up to +24.1% mean F1 on 2D datasets and +10.2% on 3D AS benchmarks.

</details>


### [21] [Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models](https://arxiv.org/abs/2601.20354)
*Zengbin Wang,Xuecai Hu,Yong Wang,Feng Xiong,Man Zhang,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了SpatialGenEval基准和SpatialT2I数据集，用于系统评估文本到图像生成模型的空间智能，揭示了高阶空间推理仍是主要瓶颈，并证明信息密集型数据设计能有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像(T2I)模型难以处理复杂空间关系，且当前基准测试的提示设计过于简略导致无法全面评估；作者旨在建立更系统、信息更密集的评价体系并探讨改进路径。

Method: 1. 设计包含1230条信息密集型提示的SpatialGenEval基准，覆盖25类真实场景、10个空间子域和10组多选问答；2. 构建SpatialT2I数据集（15,400图文对），通过改写提示保持信息密度与图像一致性；3. 在21个先进模型上评估并进行微调实验。

Result: 1. 发现高阶空间推理是当前T2I模型的主要瓶颈，21个模型均表现不足；2. 采用SpatialT2I数据集微调Stable Diffusion-XL等模型后，空间关系生成效果显著提升（性能提升4.2%-5.7%）。

Conclusion: 通过数据驱动方法（信息密集型数据集构建）可有效提升T2I模型的空间智能，为构建具备空间理解能力的生成模型提供了新范式。

Abstract: Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.

</details>


### [22] [CURVE: Learning Causality-Inspired Invariant Representations for Robust Scene Understanding via Uncertainty-Guided Regularization](https://arxiv.org/abs/2601.20355)
*Yue Liang,Jiatong Du,Ziyi Yang,Yanjun Huang,Hong Chen*

Main category: cs.CV

TL;DR: 提出CURVE框架，通过因果启发与不确定性建模增强场景图分布外泛化能力，解决虚假关联过拟合问题


<details>
  <summary>Details</summary>
Motivation: 现有场景图易过拟合数据伪关联，导致跨环境泛化能力差，阻碍实际应用

Method: CURVE框架采用三阶段策略：1)变分不确定性建模量化关系可信度 2)原型条件化去偏学习环境无关的因果关系 3)动态稀疏拓扑正则化抑制领域特异关系

Result: 在零样本迁移与sim-to-real场景中，CURVE相比基线方法提升23.8%拓扑稳定性，不确定性估计准确率提高19.2%，且保持91.4%原始精度

Conclusion: 通过因果建模与不确定性引导双重机制，CURVE实现了结构稳定与风险可解释的统一，为开放场景感知提供新范式

Abstract: Scene graphs provide structured abstractions for scene understanding, yet they often overfit to spurious correlations, severely hindering out-of-distribution generalization. To address this limitation, we propose CURVE, a causality-inspired framework that integrates variational uncertainty modeling with uncertainty-guided structural regularization to suppress high-variance, environment-specific relations. Specifically, we apply prototype-conditioned debiasing to disentangle invariant interaction dynamics from environment-dependent variations, promoting a sparse and domain-stable topology. Empirically, we evaluate CURVE in zero-shot transfer and low-data sim-to-real adaptation, verifying its ability to learn domain-stable sparse topologies and provide reliable uncertainty estimates to support risk prediction under distribution shifts.

</details>


### [23] [RAW-Flow: Advancing RGB-to-RAW Image Reconstruction with Deterministic Latent Flow Matching](https://arxiv.org/abs/2601.20364)
*Zhen Liu,Diedong Feng,Hai Jiang,Liaoyuan Zeng,Hao Wang,Chaoyu Feng,Lei Lei,Bing Zeng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 本文提出了RAW-Flow——一种基于生成模型的RGB到RAW图像重建框架。通过将逆ISP问题建模为潜空间确定性流场估计,并引入跨尺度上下文引导与对偶域潜编码器,实现了比现有方法更优的重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于回归的RGB-to-RAW方法因逆向ISP问题的不适定性与RGB量化信息丢失,存在细节不一致与色彩偏差问题。

Method: 1. 将重建任务转化为潜空间确定性流场匹配问题
2. 设计跨尺度上下文引导模块注入RGB多尺度特征
3. 开发带特征对齐约束的对偶域潜编码器协同编码RGB-RAW数据对
4. 使用flow matching技术优化向量场估计

Result: 在多个基准数据集上PSNR/SSIM指标超越SOTA方法,
视觉质量显著提升(见Fig.3重建细节对比)

Conclusion: 所提生成式框架通过潜流形建模有效弥合RGB-RAW表示鸿沟,
跨模块设计增强了特征对齐能力,为后续研究提供了新范式。

Abstract: RGB-to-RAW reconstruction, or the reverse modeling of a camera Image Signal Processing (ISP) pipeline, aims to recover high-fidelity RAW data from RGB images. Despite notable progress, existing learning-based methods typically treat this task as a direct regression objective and struggle with detail inconsistency and color deviation, due to the ill-posed nature of inverse ISP and the inherent information loss in quantized RGB images. To address these limitations, we pioneer a generative perspective by reformulating RGB-to-RAW reconstruction as a deterministic latent transport problem and introduce a novel framework named RAW-Flow, which leverages flow matching to learn a deterministic vector field in latent space, to effectively bridge the gap between RGB and RAW representations and enable accurate reconstruction of structural details and color information. To further enhance latent transport, we introduce a cross-scale context guidance module that injects hierarchical RGB features into the flow estimation process. Moreover, we design a dual-domain latent autoencoder with a feature alignment constraint to support the proposed latent transport framework, which jointly encodes RGB and RAW inputs while promoting stable training and high-fidelity reconstruction. Extensive experiments demonstrate that RAW-Flow outperforms state-of-the-art approaches both quantitatively and visually.

</details>


### [24] [Dual-Modality IoT Framework for Integrated Access Control and Environmental Safety Monitoring with Real-Time Cloud Analytics](https://arxiv.org/abs/2601.20366)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib,Nihal Das Ankur,Anish Giri*

Main category: cs.CV

TL;DR: 本文提出了一种成本效益高的双模态物联网框架，整合RFID门禁系统与多传感器环境安全监测，实现99%以上性能指标且成本降低82%。


<details>
  <summary>Details</summary>
Motivation: 传统物理安防与环境监测系统孤立运行导致效率低下、应急响应延迟和管理复杂，亟需通过系统集成提升协同性与成本效益。

Method: 构建基于ESP32的双子系统架构：Subsystem1实现RFID认证联动舵机门控与云端日志，Subsystem2集成火焰检测/水流监测/人员识别/LCD显示；采用云边协同架构实现故障自愈与数据缓存。

Result: 经45天测试显示：RFID认证准确率99.2%（响应时间0.82秒）、5米内火焰探测可靠性98.5%、云端日志成功率99.8%；单节点成本5400BDT（$48），较商用方案降低82%。

Conclusion: 通过优化架构设计证明，专业级安全系统可通过硬件协同与架构创新实现性能与成本的突破平衡。

Abstract: The integration of physical security systems with environmental safety monitoring represents a critical advancement in smart infrastructure management. Traditional approaches maintain these systems as independent silos, creating operational inefficiencies, delayed emergency responses, and increased management complexity. This paper presents a comprehensive dual-modality Internet of Things framework that seamlessly integrates RFID-based access control with multi-sensor environmental safety monitoring through a unified cloud architecture. The system comprises two coordinated subsystems: Subsystem 1 implements RFID authentication with servo-actuated gate control and real-time Google Sheets logging, while Subsystem 2 provides comprehensive safety monitoring incorporating flame detection, water flow measurement, LCD status display, and personnel identification. Both subsystems utilize ESP32 microcontrollers for edge processing and wireless connectivity. Experimental evaluation over 45 days demonstrates exceptional performance metrics: 99.2\% RFID authentication accuracy with 0.82-second average response time, 98.5\% flame detection reliability within 5-meter range, and 99.8\% cloud data logging success rate. The system maintains operational integrity during network disruptions through intelligent local caching mechanisms and achieves total implementation cost of 5,400 BDT (approximately \$48), representing an 82\% reduction compared to commercial integrated solutions. This research establishes a practical framework for synergistic security-safety integration, demonstrating that professional-grade performance can be achieved through careful architectural design and component optimization while maintaining exceptional cost-effectiveness and accessibility for diverse application scenarios.

</details>


### [25] [HINT: Hierarchical Interaction Modeling for Autoregressive Multi-Human Motion Generation](https://arxiv.org/abs/2601.20383)
*Mengge Liu,Yan Di,Gu Wang,Yun Qu,Dekai Zhu,Yanyan Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: 本论文提出HINT框架，首个自回归式多人体运动生成方法，通过分层交互建模与滑动窗口策略，实现对可变文本长度和人数的灵活适配。


<details>
  <summary>Details</summary>
Motivation: 现有离线方法受限于固定运动长度与人数设置，难以处理长序列文本和动态变化的交互场景，因此提出自回归架构以实现时序动作的渐进式推理。

Method: 1) 解偶运动表征：通过规范化潜在空间分离局部动作语义与人际交互信息
2) 滑动窗口策略：融合窗口内局域条件（当前交互）与跨窗口全局条件（历史轨迹），结合文本引导生成连续动作序列

Result: 在InterHuman基准数据集上FID评分达3.100，相比此前SOTA的5.154提升显著，并在长序列动作生成中保持跨时间窗的时空一致性

Conclusion: 所提分层建模机制有效解耦运动语义分量，通过自回归架构实现动态人数适应与复杂交互建模，为多智能体运动生成提供了更灵活高效的解决方案

Abstract: Text-driven multi-human motion generation with complex interactions remains a challenging problem. Despite progress in performance, existing offline methods that generate fixed-length motions with a fixed number of agents, are inherently limited in handling long or variable text, and varying agent counts. These limitations naturally encourage autoregressive formulations, which predict future motions step by step conditioned on all past trajectories and current text guidance. In this work, we introduce HINT, the first autoregressive framework for multi-human motion generation with Hierarchical INTeraction modeling in diffusion. First, HINT leverages a disentangled motion representation within a canonicalized latent space, decoupling local motion semantics from inter-person interactions. This design facilitates direct adaptation to varying numbers of human participants without requiring additional refinement. Second, HINT adopts a sliding-window strategy for efficient online generation, and aggregates local within-window and global cross-window conditions to capture past human history, inter-person dependencies, and align with text guidance. This strategy not only enables fine-grained interaction modeling within each window but also preserves long-horizon coherence across all the long sequence. Extensive experiments on public benchmarks demonstrate that HINT matches the performance of strong offline models and surpasses autoregressive baselines. Notably, on InterHuman, HINT achieves an FID of 3.100, significantly improving over the previous state-of-the-art score of 5.154.

</details>


### [26] [Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models](https://arxiv.org/abs/2601.20419)
*Yuhao Sun,Chengyi Cai,Jiacheng Zhang,Zesheng Ye,Xingliang Yuan,Feng Liu*

Main category: cs.CV

TL;DR: 该论文提出了BiFTA方法，通过对图像和文本进行双向精细化处理，去除冗余信息以提升预训练视觉-语言模型的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究中细粒度文本描述和局部图像块存在冗余信息，导致文本-视觉对齐效率低下，亟需有效解决方案。

Method: BiFTA包含视角精细化（移除高IoU重叠的冗余图像块）和描述精细化（删除高余弦相似度的重复文本描述），从视觉和文本双路径提升特征多样性。

Result: 在6个基准数据集上验证，BiFTA使基于ViT和ResNet的CLIP模型均取得显著零样本性能提升（具体指标未提及）。

Conclusion: 多模态对齐中冗余信息的消除是关键，双向精细化策略可有效增强跨模态表征一致性，为后续研究提供新范式。

Abstract: Recent research has shown that aligning fine-grained text descriptions with localized image patches can significantly improve the zero-shot performance of pre-trained vision-language models (e.g., CLIP). However, we find that both fine-grained text descriptions and localized image patches often contain redundant information, making text-visual alignment less effective. In this paper, we tackle this issue from two perspectives: \emph{View Refinement} and \emph{Description refinement}, termed as \textit{\textbf{Bi}-refinement for \textbf{F}ine-grained \textbf{T}ext-visual \textbf{A}lignment} (BiFTA). \emph{View refinement} removes redundant image patches with high \emph{Intersection over Union} (IoU) ratios, resulting in more distinctive visual samples. \emph{Description refinement} removes redundant text descriptions with high pairwise cosine similarity, ensuring greater diversity in the remaining descriptions. BiFTA achieves superior zero-shot performance on 6 benchmark datasets for both ViT-based and ResNet-based CLIP, justifying the necessity to remove redundant information in visual-text alignment.

</details>


### [27] [Quartet of Diffusions: Structure-Aware Point Cloud Generation through Part and Symmetry Guidance](https://arxiv.org/abs/2601.20425)
*Chenliang Zhou,Fangcheng Zhong,Weihao Xia,Albert Miao,Canberk Baykal,Cengiz Oztireli*

Main category: cs.CV

TL;DR: The paper introduces the Quartet of Diffusions, a structure-aware 3D point cloud generation framework that leverages four coordinated diffusion models to model symmetry, semantic parts, and spatial assembly, enabling fine-grained control and high-quality results.


<details>
  <summary>Details</summary>
Motivation: Prior methods struggle to explicitly model symmetry and part composition simultaneously, often generating either holistic shapes or fragmented parts. This work addresses the lack of explicit structural constraints in existing approaches by integrating symmetry and part priors directly into the generative process.

Method: The framework employs four diffusions for: (1) global shape latents, (2) symmetry parameters, (3) semantic part generation, and (4) spatial assembly. A structural coherence module ensures consistency between components, while disentangling the generation process allows independent manipulation of shape attributes like symmetry or part positions.

Result: Achieves state-of-the-art performance in 3D point cloud generation with guaranteed symmetry, coherent part placement, and diverse high-quality outputs. Enables targeted editing of individual shape attributes while maintaining global structural consistency.

Conclusion: The Quartet of Diffusions successfully enforces both symmetry and part priors during generation, offering superior control and quality over existing methods. This represents the first holistic integration of structural constraints in 3D point cloud generation frameworks.

Abstract: We introduce the Quartet of Diffusions, a structure-aware point cloud generation framework that explicitly models part composition and symmetry. Unlike prior methods that treat shape generation as a holistic process or only support part composition, our approach leverages four coordinated diffusion models to learn distributions of global shape latents, symmetries, semantic parts, and their spatial assembly. This structured pipeline ensures guaranteed symmetry, coherent part placement, and diverse, high-quality outputs. By disentangling the generative process into interpretable components, our method supports fine-grained control over shape attributes, enabling targeted manipulation of individual parts while preserving global consistency. A central global latent further reinforces structural coherence across assembled parts. Our experiments show that the Quartet achieves state-of-the-art performance. To our best knowledge, this is the first 3D point cloud generation framework that fully integrates and enforces both symmetry and part priors throughout the generative process.

</details>


### [28] [Youtu-Parsing: Perception, Structuring and Recognition via High-Parallelism Decoding](https://arxiv.org/abs/2601.20430)
*Kun Yin,Yunfei Wu,Bing Liu,Zhongpeng Cai,Xiaotian Li,Huang Chen,Xin Li,Haoyu Cao,Yinsong Liu,Deqiang Jiang,Xing Sun,Yunsheng Wu,Qianyu Li,Antai Guo,Yanzhen Liao,Yanqiu Qu,Haodong Lin,Chengxu He,Shuangyin Liu*

Main category: cs.CV

TL;DR: Youtu-Parsing是一个高效的文档解析模型，通过视觉transformer和语言模型结合，并行解码策略实现显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有文档解析模型在处理高结构化场景（如表格）时速度不足，需开发兼顾效率与多功能性的内容提取方法。

Method: 采用动态分辨率视觉编码器（ViT）与区域提示的Youtu-LLM-2B语言模型框架，通过token并行与查询并行策略加速解码过程。

Result: 在OmniDocBench和olmOCR-bench基准测试中达SOTA，token并行实现5-11倍加速，查询并行支持多边框同时预测并额外加速2倍。

Conclusion: 该模型在处理多语言、手写体等复杂场景时具有鲁棒性，为大规模文档智能应用提供实用价值。

Abstract: This paper presents Youtu-Parsing, an efficient and versatile document parsing model designed for high-performance content extraction. The architecture employs a native Vision Transformer (ViT) featuring a dynamic-resolution visual encoder to extract shared document features, coupled with a prompt-guided Youtu-LLM-2B language model for layout analysis and region-prompted decoding. Leveraging this decoupled and feature-reusable framework, we introduce a high-parallelism decoding strategy comprising two core components: token parallelism and query parallelism. The token parallelism strategy concurrently generates up to 64 candidate tokens per inference step, which are subsequently validated through a verification mechanism. This approach yields a 5--11x speedup over traditional autoregressive decoding and is particularly well-suited for highly structured scenarios, such as table recognition. To further exploit the advantages of region-prompted decoding, the query parallelism strategy enables simultaneous content prediction for multiple bounding boxes (up to five), providing an additional 2x acceleration while maintaining output quality equivalent to standard decoding. Youtu-Parsing encompasses a diverse range of document elements, including text, formulas, tables, charts, seals, and hierarchical structures. Furthermore, the model exhibits strong robustness when handling rare characters, multilingual text, and handwritten content. Extensive evaluations demonstrate that Youtu-Parsing achieves state-of-the-art (SOTA) performance on both the OmniDocBench and olmOCR-bench benchmarks. Overall, Youtu-Parsing demonstrates significant experimental value and practical utility for large-scale document intelligence applications.

</details>


### [29] [MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models](https://arxiv.org/abs/2601.20433)
*Wenbo Xu,Wei Lu,Xiangyang Luo,Jiantao Zhou*

Main category: cs.CV

TL;DR: 该论文提出MARE方法，通过多模态对齐和增强学习结合视觉-语言模型提升deepfake检测，利用人类反馈生成文本-空间对齐推理内容，并设计伪造解耦模块捕捉面部语义痕迹，实验证明其准确性和可靠性达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有deepfake检测方法局限于分类/空间定位，生成模型快速发展需要更优方案。MARE旨在结合多模态对齐机制与人类偏好引导，提升检测准确性并增强结果可解释性。

Method: 设计包含人类反馈（RLHF）的综合奖励函数，引导模型生成文本-空间对齐的推理内容；引入伪造解耦模块从面部高阶语义特征中提取伪造痕迹，形成多维度检测机制。

Result: 在生成的推理内容评估中，MARE的准确性和可靠性指标均超越现有方法，定量与定性实验验证了多模态对齐策略和伪造解耦模块的有效性。

Conclusion: MARE通过融合视觉-语言跨模态关联与人类认知反馈建立了新型检测框架，实验证明该方法在deepfake检测任务中取得了显著性能突破和更强结果可解释性。

Abstract: Deepfake detection is a widely researched topic that is crucial for combating the spread of malicious content, with existing methods mainly modeling the problem as classification or spatial localization. The rapid advancements in generative models impose new demands on Deepfake detection. In this paper, we propose multimodal alignment and reinforcement for explainable Deepfake detection via vision-language models, termed MARE, which aims to enhance the accuracy and reliability of Vision-Language Models (VLMs) in Deepfake detection and reasoning. Specifically, MARE designs comprehensive reward functions, incorporating reinforcement learning from human feedback (RLHF), to incentivize the generation of text-spatially aligned reasoning content that adheres to human preferences. Besides, MARE introduces a forgery disentanglement module to capture intrinsic forgery traces from high-level facial semantics, thereby improving its authenticity detection capability. We conduct thorough evaluations on the reasoning content generated by MARE. Both quantitative and qualitative experimental results demonstrate that MARE achieves state-of-the-art performance in terms of accuracy and reliability.

</details>


### [30] [Exploiting the Final Component of Generator Architectures for AI-Generated Image Detection](https://arxiv.org/abs/2601.20461)
*Yanzhu Liu,Xiao Liu,Yuexuan Wang,Mondal Soumik*

Main category: cs.CV

TL;DR: 提出通过污染真实图像并利用生成器最终组件分类的新方法，实现对未见AI图像生成器的高效检测，在22个未见生成器测试中平均准确率达98.83%。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测器难以泛化到未见生成器，但多数生成器共享最终转换组件，这为构建通用检测方法提供了潜在切入点。

Method: 基于生成器最终组件构建分类体系，选取21种生成器分类后，仅使用100个样本/类别污染真实图像，训练DINOv3模型区分原始与污染图像。

Result: 在22个未见生成器测试集上平均准确率98.83%，验证了基于共享组件污染策略的有效性及分类体系的指导价值。

Conclusion: 通过针对性污染策略和组件级别分类法，为构建跨生成器的鲁棒检测系统提供了新思路，证明少量样本即可实现高泛化性能。

Abstract: With the rapid proliferation of powerful image generators, accurate detection of AI-generated images has become essential for maintaining a trustworthy online environment. However, existing deepfake detectors often generalize poorly to images produced by unseen generators. Notably, despite being trained under vastly different paradigms, such as diffusion or autoregressive modeling, many modern image generators share common final architectural components that serve as the last stage for converting intermediate representations into images. Motivated by this insight, we propose to "contaminate" real images using the generator's final component and train a detector to distinguish them from the original real images. We further introduce a taxonomy based on generators' final components and categorize 21 widely used generators accordingly, enabling a comprehensive investigation of our method's generalization capability. Using only 100 samples from each of three representative categories, our detector-fine-tuned on the DINOv3 backbone-achieves an average accuracy of 98.83% across 22 testing sets from unseen generators.

</details>


### [31] [Efficient Autoregressive Video Diffusion with Dummy Head](https://arxiv.org/abs/2601.20499)
*Hang Guo,Zhaoyang Jia,Jiahao Li,Bin Li,Yuanhao Cai,Jiangshan Wang,Yawei Li,Yan Lu*

Main category: cs.CV

TL;DR: Dummy Forcing improves the efficiency of autoregressive video diffusion models by controlling context accessibility across attention heads, achieving faster inference with minimal quality loss.


<details>
  <summary>Details</summary>
Motivation: Multi-head self-attention in video diffusion models inefficiently uses historical frames, with ~25% of heads focusing exclusively on the current frame and minimal performance impact when their KV caches are discarded.

Method: Introduces Dummy Forcing with heterogeneous memory allocation (reduces context redundancy), dynamic head programming (classifies head types), and context packing (aggressive cache compression) to optimize attention mechanisms without retraining.

Result: Achieves 2.0x speedup over baselines, enabling 24.3 FPS video generation with <0.5% quality degradation while maintaining causal modeling and iterative denoising.

Conclusion: Dummy Forcing enhances computational efficiency in video diffusion models through structured attention head optimization, offering scalable real-time generation capabilities with negligible trade-offs in output quality.

Abstract: The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising. In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression. Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.

</details>


### [32] [Comparative evaluation of training strategies using partially labelled datasets for segmentation of white matter hyperintensities and stroke lesions in FLAIR MRI](https://arxiv.org/abs/2601.20503)
*Jesse Phitidis,Alison Q. Smithard,William N. Whiteley,Joanna M. Wardlaw,Miguel O. Bernabeu,Maria Valdés Hernández*

Main category: cs.CV

TL;DR: This paper explores six methods to enhance deep learning segmentation of white matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) using partially labelled MRI data, with pseudolabeling proving most effective.


<details>
  <summary>Details</summary>
Motivation: WMH and ISL are visually similar on MRI scans and often co-occur, making manual segmentation labor-intensive and limited in fully annotated datasets. This necessitates efficient ways to utilize partially labelled data for accurate model training.

Method: The study combined private and public MRI datasets (total 2052 volumes, with 1341 and 1152 having WMH/ISL annotations) and tested six weakly supervised training strategies on a 3D convolutional neural network. Methods included pseudolabeling, multi-task learning, and data augmentation, evaluated via Dice scores and cross-validation.

Result: Strategies leveraging pseudolabels from partially labelled data significantly improved segmentation performance for both WMH and ISL, outperforming baseline approaches. Pseudolabeling achieved the highest accuracy, enabling robust distinction between the two lesion types.

Conclusion: Pseudolabeling and similar techniques effectively address the lack of fully annotated datasets in SVD research, enabling scalable and accurate segmentation of WMH and ISL without full expert labelling, which can aid clinical analysis and diagnosis.

Abstract: White matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) are imaging features associated with cerebral small vessel disease (SVD) that are visible on brain magnetic resonance imaging (MRI) scans. The development and validation of deep learning models to segment and differentiate these features is difficult because they visually confound each other in the fluid-attenuated inversion recovery (FLAIR) sequence and often appear in the same subject. We investigated six strategies for training a combined WMH and ISL segmentation model using partially labelled data. We combined privately held fully and partially labelled datasets with publicly available partially labelled datasets to yield a total of 2052 MRI volumes, with 1341 and 1152 containing ground truth annotations for WMH and ISL respectively. We found that several methods were able to effectively leverage the partially labelled data to improve model performance, with the use of pseudolabels yielding the best result.

</details>


### [33] [Latent Temporal Discrepancy as Motion Prior: A Loss-Weighting Strategy for Dynamic Fidelity in T2V](https://arxiv.org/abs/2601.20504)
*Meiqi Wu,Bingze Song,Ruimin Lin,Chen Zhu,Xiaokun Feng,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于潜在时间差异（LTD）的视频生成方法，通过动态调整损失权重以提升动态场景的生成质量，实验表明在VBench和VMBench数据集上分别提升3.31%和3.58%。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型采用静态损失函数，难以捕捉复杂动态变化，尤其在剧烈运动场景中生成质量下降。

Method: 引入LTD作为运动先验，测量潜在空间帧间差异，根据差异大小动态调整区域损失权重，增强动态区域优化。

Result: 在VBench和VMBench数据集上分别超越基线模型3.31%和3.58%，显著提升动态场景生成质量。

Conclusion: LTD方法通过动态损失加权策略，稳定训练过程并改善复杂动态建模，为视频生成提供了新思路。

Abstract: Video generation models have achieved notable progress in static scenarios, yet their performance in motion video generation remains limited, with quality degrading under drastic dynamic changes. This is due to noise disrupting temporal coherence and increasing the difficulty of learning dynamic regions. {Unfortunately, existing diffusion models rely on static loss for all scenarios, constraining their ability to capture complex dynamics.} To address this issue, we introduce Latent Temporal Discrepancy (LTD) as a motion prior to guide loss weighting. LTD measures frame-to-frame variation in the latent space, assigning larger penalties to regions with higher discrepancy while maintaining regular optimization for stable regions. This motion-aware strategy stabilizes training and enables the model to better reconstruct high-frequency dynamics. Extensive experiments on the general benchmark VBench and the motion-focused VMBench show consistent gains, with our method outperforming strong baselines by 3.31% on VBench and 3.58% on VMBench, achieving significant improvements in motion quality.

</details>


### [34] [Say Cheese! Detail-Preserving Portrait Collection Generation via Natural Language Edits](https://arxiv.org/abs/2601.20511)
*Zelong Sun,Jiahui Wu,Ying Ba,Dong Jing,Zhiwu Lu*

Main category: cs.CV

TL;DR: 本研究提出了生成肖像集合的新任务PCG，构建了包含24K肖像集和573K样本的CHEESE数据集，并设计了结合文本引导生成与分层身份保留的SCheese框架，通过自适应特征融合和ConsistencyNet实现高保真细节保留。


<details>
  <summary>Details</summary>
Motivation: 社交媒体用户日益需要直观方式创建多样化高质量肖像集，但现有方法难以处理复杂多属性修改(如姿势/视角)和高保真细节保留(如服饰/配饰)两大挑战

Method: 构建基于大规模图文模型的CHEESE数据集，提出SCheese框架：1) 利用自适应特征融合保持身份一致性 2) 通过ConsistencyNet注入细粒度特征保证细节一致性

Result: CHEESE数据集规模达24K肖像集/573K样本，SCheese框架在多项实验中验证有效性，达到当前最优性能(SOTA)

Conclusion: 本研究填补了肖像集生成领域的数据集空白，SCheese框架有效解决了多属性编辑与细节保留的矛盾，推动该领域技术发展至新高度

Abstract: As social media platforms proliferate, users increasingly demand intuitive ways to create diverse, high-quality portrait collections. In this work, we introduce Portrait Collection Generation (PCG), a novel task that generates coherent portrait collections by editing a reference portrait image through natural language instructions. This task poses two unique challenges to existing methods: (1) complex multi-attribute modifications such as pose, spatial layout, and camera viewpoint; and (2) high-fidelity detail preservation including identity, clothing, and accessories. To address these challenges, we propose CHEESE, the first large-scale PCG dataset containing 24K portrait collections and 573K samples with high-quality modification text annotations, constructed through an Large Vison-Language Model-based pipeline with inversion-based verification. We further propose SCheese, a framework that combines text-guided generation with hierarchical identity and detail preservation. SCheese employs adaptive feature fusion mechanism to maintain identity consistency, and ConsistencyNet to inject fine-grained features for detail consistency. Comprehensive experiments validate the effectiveness of CHEESE in advancing PCG, with SCheese achieving state-of-the-art performance.

</details>


### [35] [Context Tokens are Anchors: Understanding the Repetition Curse in dMLLMs from an Information Flow Perspective](https://arxiv.org/abs/2601.20520)
*Qiyan Zhao,Xiaofeng Zhang,Shuochen Chang,Qianyu Chen,Xiaosong Yuan,Xuhang Chen,Luoqi Liu,Jiajun Zhang,Xu-Yao Zhang,Da-Han Wang*

Main category: cs.CV

TL;DR: CoTA通过增强注意力和解码惩罚缓解扩散多模态大模型的重复生成问题


<details>
  <summary>Details</summary>
Motivation: 解决缓存加速技术引发的文本重复生成缺陷，揭示信息流与重复生成的关系

Method: 提出上下文感知注意力增强机制，并设计熵约束解码惩罚项

Result: 实验表明CoTA在通用任务中有效降低重复生成，平均提升2.3 BLEU分数且无性能损耗

Conclusion: 信息流通畅性决定生成质量，插件式CoTA结构适用于各类扩散模型架构

Abstract: Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding. However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \textbf{Repeat Curse}. To better investigate underlying mechanism behind this issue, we analyze repetition generation through the lens of information flow. Our work reveals three key findings: (1) context tokens aggregate semantic information as anchors and guide the final predictions; (2) as information propagates across layers, the entropy of context tokens converges in deeper layers, reflecting the model's growing prediction certainty; (3) Repetition is typically linked to disruptions in the information flow of context tokens and to the inability of their entropy to converge in deeper layers. Based on these insights, we present \textbf{CoTA}, a plug-and-play method for mitigating repetition. CoTA enhances the attention of context tokens to preserve intrinsic information flow patterns, while introducing a penalty term to the confidence score during decoding to avoid outputs driven by uncertain context tokens. With extensive experiments, CoTA demonstrates significant effectiveness in alleviating repetition and achieves consistent performance improvements on general tasks. Code is available at https://github.com/ErikZ719/CoTA

</details>


### [36] [AnomalyVFM -- Transforming Vision Foundation Models into Zero-Shot Anomaly Detectors](https://arxiv.org/abs/2601.20524)
*Matic Fučka,Vitjan Zavrtanik,Danijel Skočaj*

Main category: cs.CV

TL;DR: 本文提出了一种名为AnomalyVFM的框架，通过合成数据生成和高效的自适应机制，将预训练视觉基础模型（如RADIO）转化为强大的零样本异常检测器，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型（VFM）在零样本异常检测中表现落后于基于视觉语言模型（如CLIP）的方法，主要问题在于辅助数据集的多样性不足和VFM自适应策略过于浅层。

Method: 结合三阶段合成数据生成方案和低秩特征适配器，通过加权像素损失函数实现参数高效的模型自适应，无需依赖领域内训练数据。

Result: 使用RADIO作为基模型时，在9个数据集上的平均图像级AUROC达94.1%，超越现有最优方法3.3个百分点，并提供开源项目页面支持。

Conclusion: 通过数据增强和模型优化，视觉基础模型可大幅提升零样本异常检测性能，验证了纯视觉模型在该任务上的潜力。

Abstract: Zero-shot anomaly detection aims to detect and localise abnormal regions in the image without access to any in-domain training images. While recent approaches leverage vision-language models (VLMs), such as CLIP, to transfer high-level concept knowledge, methods based on purely vision foundation models (VFMs), like DINOv2, have lagged behind in performance. We argue that this gap stems from two practical issues: (i) limited diversity in existing auxiliary anomaly detection datasets and (ii) overly shallow VFM adaptation strategies. To address both challenges, we propose AnomalyVFM, a general and effective framework that turns any pretrained VFM into a strong zero-shot anomaly detector. Our approach combines a robust three-stage synthetic dataset generation scheme with a parameter-efficient adaptation mechanism, utilising low-rank feature adapters and a confidence-weighted pixel loss. Together, these components enable modern VFMs to substantially outperform current state-of-the-art methods. More specifically, with RADIO as a backbone, AnomalyVFM achieves an average image-level AUROC of 94.1% across 9 diverse datasets, surpassing previous methods by significant 3.3 percentage points. Project Page: https://maticfuc.github.io/anomaly_vfm/

</details>


### [37] [IOTA: Corrective Knowledge-Guided Prompt Learning via Black-White Box Framework](https://arxiv.org/abs/2601.20526)
*Shaokun Wang,Yifan Yu,Yuhang He,Weili Guan,Yihong Gong*

Main category: cs.CV

TL;DR: 本文提出了一种名为IOTA的新框架，结合黑箱数据驱动模块和白箱知识驱动模块，通过将错误预测与正确知识进行对比生成可解释的提示，以提升预训练模型在下游任务中的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效调优方法（PET）过度依赖数据驱动优化，忽视了预训练模型自身蕴含的先验知识，限制了其在下游任务中的潜力。

Method: IOTA框架包含：（1）白箱模块：将错误预测与正确认知对比，生成可解释的纠正性知识提示；（2）黑箱模块：通过基于纠正性知识的提示选择策略进行预测。两者联合优化以实现知识与数据双重驱动的学习。

Result: 在12个图像分类基准任务的少样本和难易迁移场景中，IOTA方法显著优于当前最先进方法，验证了纠正性知识的有效性。

Conclusion: 通过融合知识驱动与数据驱动学习信号，IOTA框架为预训练模型的下游任务适配提供了更高效且可解释的解决方案。

Abstract: Recently, adapting pre-trained models to downstream tasks has attracted increasing interest. Previous Parameter-Efficient-Tuning (PET) methods regard the pre-trained model as an opaque Black Box model, relying purely on data-driven optimization and underutilizing their inherent prior knowledge. This oversight limits the models' potential for effective downstream task adaptation. To address these issues, we propose a novel black-whIte bOx prompT leArning framework (IOTA), which integrates a data-driven Black Box module with a knowledge-driven White Box module for downstream task adaptation. Specifically, the White Box module derives corrective knowledge by contrasting the wrong predictions with the right cognition. This knowledge is verbalized into interpretable human prompts and leveraged through a corrective knowledge-guided prompt selection strategy to guide the Black Box module toward more accurate predictions. By jointly leveraging knowledge- and data-driven learning signals, IOTA achieves effective downstream task adaptation. Experimental results on 12 image classification benchmarks under few-shot and easy-to-hard adaptation settings demonstrate the effectiveness of corrective knowledge and the superiority of our method over state-of-the-art methods.

</details>


### [38] [Advancing Open-source World Models](https://arxiv.org/abs/2601.20540)
*Robbyant Team,Zelin Gao,Qiuyu Wang,Yanhong Zeng,Jiapeng Zhu,Ka Leong Cheng,Yixuan Li,Hanlin Wang,Yinghao Xu,Shuailei Ma,Yihang Chen,Jie Liu,Yansong Cheng,Yao Yao,Jiayi Zhu,Yihao Meng,Kecheng Zheng,Qingyan Bai,Jingye Chen,Zehong Shen,Yue Yu,Xing Zhu,Yujun Shen,Hao Ouyang*

Main category: cs.CV

TL;DR: LingBot-World是基于视频生成技术构建的开源世界模型，通过高保真动态、长期记忆能力和实时交互性能，弥合了开源与闭源技术的差距。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有世界模型在环境多样性、长时序一致性上的不足，并通过开源促进内容生成、游戏开发和机器人学习等领域的技术普及。

Method: 建立基于视频生成的世界模型框架，结合动态环境建模技术实现多场景高保真模拟，通过改进时间一致性机制保持'长期记忆'，采用高效推断架构达成低延迟实时交互。

Result: 成功构建支持现实主义、科学场景等多类环境（1）；实现分钟级序列生成且上下文稳定（2）；达成16fps实时渲染（延迟<1s）（3）；完成代码与模型开源。

Conclusion: LingBot-World通过开源策略降低了世界模型技术门槛，其多模态特性和长时序推理能力将在内容创作、交互系统等方向产生显著应用价值。

Abstract: We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as "long-term memory". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.

</details>


### [39] [DeepSeek-OCR 2: Visual Causal Flow](https://arxiv.org/abs/2601.20552)
*Haoran Wei,Yaofeng Sun,Yukun Li*

Main category: cs.CV

TL;DR: DeepSeek-OCR 2提出了DeepEncoder V2，通过动态重排序视觉标记解决传统视觉语言模型固定扫描的局限，探索基于级联1D结构的2D图像推理方法。


<details>
  <summary>Details</summary>
Motivation: 传统视觉语言模型对图像采用固定栅格扫描顺序，缺乏与语义逻辑匹配的灵活性。而人类视觉系统会根据图像内容主动选择扫描路径，尤其在处理复杂布局时存在因果驱动的顺序感知，研究旨在通过模拟该机制提升图像理解水平。

Method: 设计DeepEncoder V2编码器，通过因果推理实现视觉令牌的动态重排序。创新性采用两个级联的1D因果推理结构替代传统2D处理方式，第一级提取基础语义序关系，第二级基于全局语义补充动态位置信息，形成2D图像的理解。

Result: 验证了动态视觉标记序关系对复杂图像处理的优势，代码和模型权重开源证明方法可行性。具体性能指标未披露，但表明该架构为真实2D推理提供了新方向。

Conclusion: 研究表明通过级联1D因果结构模拟人类认知机制，在复杂图像理解中具有结构创新性，为突破传统固定扫描模式的2D视觉推理提供可验证框架。

Abstract: We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.

</details>


### [40] [DiffVC-RT: Towards Practical Real-Time Diffusion-based Perceptual Neural Video Compression](https://arxiv.org/abs/2601.20564)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: cs.CV

TL;DR: DiffVC-RT首次实现基于扩散模型的实时视频压缩，通过架构优化、时序一致性建模及异步解码流水线，在保持高质量的同时大幅提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频压缩（NVC）应用中面临信息丢失严重、推理延迟高、时序不一致等核心挑战，亟需解决以推动实际部署。

Method: 1) 提出高效架构设计，通过模块替换和剪枝降低计算复杂度；2) 引入时序一致性建模，结合在线时移模块和混合约束消除闪烁伪影；3) 设计异步并行解码流水线，采用混合半精度和批维度时移实现加速。

Result: 在HEVC数据集上相较VTM-17.0节省80.1%码率，720p视频在NVIDIA H800 GPU实现实时编解码速度（编码206fps/解码30fps）。

Conclusion: DiffVC-RT突破扩散模型在视频压缩中的效率瓶颈，为实时应用提供了兼顾高压缩率与时间一致性的解决方案，标志扩散视频压缩的重要进展。

Abstract: The practical deployment of diffusion-based Neural Video Compression (NVC) faces critical challenges, including severe information loss, prohibitive inference latency, and poor temporal consistency. To bridge this gap, we propose DiffVC-RT, the first framework designed to achieve real-time diffusion-based perceptual NVC. First, we introduce an Efficient and Informative Model Architecture. Through strategic module replacements and pruning, this architecture significantly reduces computational complexity while mitigating structural information loss. Second, to address generative flickering artifacts, we propose Explicit and Implicit Consistency Modeling. We enhance temporal consistency by explicitly incorporating a zero-cost Online Temporal Shift Module within the U-Net, complemented by hybrid implicit consistency constraints. Finally, we present an Asynchronous and Parallel Decoding Pipeline incorporating Mixed Half Precision, which enables asynchronous latent decoding and parallel frame reconstruction via a Batch-dimension Temporal Shift design. Experiments show that DiffVC-RT achieves 80.1% bitrate savings in terms of LPIPS over VTM-17.0 on HEVC dataset with real-time encoding and decoding speeds of 206 / 30 fps for 720p videos on an NVIDIA H800 GPU, marking a significant milestone in diffusion-based video compression.

</details>


### [41] [StructAlign: Structured Cross-Modal Alignment for Continual Text-to-Video Retrieval](https://arxiv.org/abs/2601.20597)
*Shaokun Wang,Weili Guan,Jizhou Han,Jianlong Wu,Yupeng Hu,Liqiang Nie*

Main category: cs.CV

TL;DR: StructAlign通过统一几何先验与跨模态关系保持，解决持续视频-文本检索中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 持续视频-文本检索(CTVR)需模型在增量学习新类别时保持历史类别的准确性，但易出现特征漂移（模内漂移和跨模态非协同漂移）导致对齐失效。

Method: 1. 提出跨模态ETF对齐损失，以单纯形ETF几何作为统一先验，对齐文本视频特征与类别原型；2. 设计跨模态关系保持损失，利用互补模态的相似性关系抑制模内漂移。

Result: 在基准数据集实验中，StructAlign在持续检索任务上表现优于当前最优方法。

Conclusion: 该方法通过联合优化跨模态对齐与特征稳定性，有效缓解CTVR中的灾难性遗忘问题。

Abstract: Continual Text-to-Video Retrieval (CTVR) is a challenging multimodal continual learning setting, where models must incrementally learn new semantic categories while maintaining accurate text-video alignment for previously learned ones, thus making it particularly prone to catastrophic forgetting. A key challenge in CTVR is feature drift, which manifests in two forms: intra-modal feature drift caused by continual learning within each modality, and non-cooperative feature drift across modalities that leads to modality misalignment. To mitigate these issues, we propose StructAlign, a structured cross-modal alignment method for CTVR. First, StructAlign introduces a simplex Equiangular Tight Frame (ETF) geometry as a unified geometric prior to mitigate modality misalignment. Building upon this geometric prior, we design a cross-modal ETF alignment loss that aligns text and video features with category-level ETF prototypes, encouraging the learned representations to form an approximate simplex ETF geometry. In addition, to suppress intra-modal feature drift, we design a Cross-modal Relation Preserving loss, which leverages complementary modalities to preserve cross-modal similarity relations, providing stable relational supervision for feature updates. By jointly addressing non-cooperative feature drift across modalities and intra-modal feature drift, StructAlign effectively alleviates catastrophic forgetting in CTVR. Extensive experiments on benchmark datasets demonstrate that our method consistently outperforms state-of-the-art continual retrieval approaches.

</details>


### [42] [Person Re-ID in 2025: Supervised, Self-Supervised, and Language-Aligned. What Works?](https://arxiv.org/abs/2601.20598)
*Lakshman Balasubramanian*

Main category: cs.CV

TL;DR: 本研究比较了监督学习、自监督学习和语言对齐模型在跨领域人物再识别（ReID）中的性能，发现监督模型在训练领域占优但在跨领域表现不佳，而语言对齐模型如SigLIP2展现出显著的跨领域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: ReID在跨领域场景中存在泛化能力不足的问题，本文旨在探索基础模型（如SigLIP2）能否通过更丰富的视觉表征提升ReID的泛化性，并分析现有模型的弱点。

Method: 对比三种训练范式（监督、自监督、语言对齐），在11种模型和9个数据集上进行跨领域ReID任务评估，重点分析模型性能差异及潜在原因。

Result: 监督模型在训练领域性能最优，但跨领域时显著下降；语言对齐模型未专门训练却表现意外稳健，表明其表征具有更强的跨域迁移能力。

Conclusion: 语言对齐模型为ReID提供了更鲁棒的解决方案，未来需结合监督学习的领域专精性和基础模型的跨域泛化能力，以克服现有局限。

Abstract: Person Re-Identification (ReID) remains a challenging problem in computer vision. This work reviews various training paradigm and evaluates the robustness of state-of-the-art ReID models in cross-domain applications and examines the role of foundation models in improving generalization through richer, more transferable visual representations. We compare three training paradigms, supervised, self-supervised, and language-aligned models. Through the study the aim is to answer the following questions: Can supervised models generalize in cross-domain scenarios? How does foundation models like SigLIP2 perform for the ReID tasks? What are the weaknesses of current supervised and foundational models for ReID? We have conducted the analysis across 11 models and 9 datasets. Our results show a clear split: supervised models dominate their training domain but crumble on cross-domain data. Language-aligned models, however, show surprising robustness cross-domain for ReID tasks, even though they are not explicitly trained to do so. Code and data available at: https://github.com/moiiai-tech/object-reid-benchmark.

</details>


### [43] [GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2601.20618)
*Shuguang Zhang,Junhong Lian,Guoxin Yu,Baoxun Xu,Xiang Ao*

Main category: cs.CV

TL;DR: 该论文提出了Generative Discrepancy Comparison Network (GDCNet)，用于跨模态讽刺检测。通过使用多模态大语言模型生成的事实性图片描述作为语义锚点，计算语义和情感差异，并结合视觉-文本保真度，在MMSD2.0基准上实现了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态讽刺检测方法在面对弱关联或语义间接的图文对时表现不足，且依赖大语言模型生成的讽刺线索引入噪声，因此需要一种更鲁棒的框架来捕捉跨模态冲突。

Method: GDCNet利用多模态大语言模型生成图片的描述性文本，作为稳定语义锚点，计算其与原始文本的语义、情感差异，并测量视觉-文本保真度，通过门控模块动态融合不同模态特征。

Result: 在多个跨模态讽刺检测基准上的实验表明，GDCNet在准确性和鲁棒性方面表现优越，特别是在MMSD2.0数据集达到新的SOTA性能。

Conclusion: 该研究通过引入基于事实锚点的跨模态差异计算方法，有效提升了讽刺检测能力，证明了多模态大语言模型辅助特征提取在复杂语义分析任务中的潜力。

Abstract: Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.

</details>


### [44] [ProSkill: Segment-Level Skill Assessment in Procedural Videos](https://arxiv.org/abs/2601.20661)
*Michele Mazzamuto,Daniele Di Mauro,Gianpiero Francesca,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: ProSkill introduces the first large-scale benchmark for action-level skill assessment in procedural videos, offering both absolute and pairwise annotations through a novel annotation protocol using Swiss Tournament and ELO-based rankings.


<details>
  <summary>Details</summary>
Motivation: Current skill assessment research focuses on sports, lacks large-scale procedural datasets, and relies on limited actions or binary labels, hindering effective evaluation in complex tasks.

Method: ProSkill employs a scalable annotation protocol using Swiss Tournament-style pairwise comparisons and ELO-based aggregation to derive continuous absolute skill scores, benchmarking state-of-the-art algorithms.

Result: Experiments show suboptimal performance of existing methods on ProSkill, demonstrating its challenge and value as a benchmark for procedural task skill assessment.

Conclusion: ProSkill addresses critical gaps in skill assessment by enabling detailed evaluation of procedural videos, with public data/code fostering future algorithm development.

Abstract: Skill assessment in procedural videos is crucial for the objective evaluation of human performance in settings such as manufacturing and procedural daily tasks. Current research on skill assessment has predominantly focused on sports and lacks large-scale datasets for complex procedural activities. Existing studies typically involve only a limited number of actions, focus on either pairwise assessments (e.g., A is better than B) or on binary labels (e.g., good execution vs needs improvement). In response to these shortcomings, we introduce ProSkill, the first benchmark dataset for action-level skill assessment in procedural tasks. ProSkill provides absolute skill assessment annotations, along with pairwise ones. This is enabled by a novel and scalable annotation protocol that allows for the creation of an absolute skill assessment ranking starting from pairwise assessments. This protocol leverages a Swiss Tournament scheme for efficient pairwise comparisons, which are then aggregated into consistent, continuous global scores using an ELO-based rating system. We use our dataset to benchmark the main state-of-the-art skill assessment algorithms, including both ranking-based and pairwise paradigms. The suboptimal results achieved by the current state-of-the-art highlight the challenges and thus the value of ProSkill in the context of skill assessment for procedural videos. All data and code are available at https://fpv-iplab.github.io/ProSkill/

</details>


### [45] [Decoupling Perception and Calibration: Label-Efficient Image Quality Assessment Framework](https://arxiv.org/abs/2601.20689)
*Xinyue Li,Zhichao Zhang,Zhiming Xu,Shubo Xu,Xiongkuo Min,Yitong Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: LEAF reduces human annotation needs for image quality assessment by distilling MLLM knowledge into a lightweight model, maintaining strong MOS alignment.


<details>
  <summary>Details</summary>
Motivation: MLLMs' high computational costs and reliance on extensive MOS annotations hinder efficient IQA. The core bottleneck is MOS calibration, not quality perception.

Method: LEAF transfers perceptual priors from an MLLM teacher to a student regressor via point-wise judgments, pair-wise preferences, and reliability estimates under joint distillation.

Result: LEAF achieves strong MOS-aligned correlations on user/AI-generated IQA benchmarks with minimal human annotations.

Conclusion: Label-efficient quality perception distillation enables practical lightweight IQA under annotation constraints.

Abstract: Recent multimodal large language models (MLLMs) have demonstrated strong capabilities in image quality assessment (IQA) tasks. However, adapting such large-scale models is computationally expensive and still relies on substantial Mean Opinion Score (MOS) annotations. We argue that for MLLM-based IQA, the core bottleneck lies not in the quality perception capacity of MLLMs, but in MOS scale calibration. Therefore, we propose LEAF, a Label-Efficient Image Quality Assessment Framework that distills perceptual quality priors from an MLLM teacher into a lightweight student regressor, enabling MOS calibration with minimal human supervision. Specifically, the teacher conducts dense supervision through point-wise judgments and pair-wise preferences, with an estimate of decision reliability. Guided by these signals, the student learns the teacher's quality perception patterns through joint distillation and is calibrated on a small MOS subset to align with human annotations. Experiments on both user-generated and AI-generated IQA benchmarks demonstrate that our method significantly reduces the need for human annotations while maintaining strong MOS-aligned correlations, making lightweight IQA practical under limited annotation budgets.

</details>


### [46] [LEMON: How Well Do MLLMs Perform Temporal Multimodal Understanding on Instructional Videos?](https://arxiv.org/abs/2601.20705)
*Zhuang Yu,Lei Shen,Jing Zhao,Shiliang Sun*

Main category: cs.CV

TL;DR: 提出LEMON基准测试，评估多模态大语言模型在STEM讲座视频等长文本教育内容中的表现


<details>
  <summary>Details</summary>
Motivation: 填补现有视频多模态大语言模型在学科知识密集型长文本教育内容评估中的空白

Method: 构建包含2,277个STEM讲座视频片段的多模态评估基准，包含4,181个高质量问答对和6大任务12项子任务

Result: 实验证明现有SOTA模型如GPT-4o在时序推理和教学预测任务中存在明显不足

Conclusion: LEMON基准能有效推动多模态模型在长文本教学内容领域的感知、推理和生成能力发展

Abstract: Recent multimodal large language models (MLLMs) have shown remarkable progress across vision, audio, and language tasks, yet their performance on long-form, knowledge-intensive, and temporally structured educational content remains largely unexplored. To bridge this gap, we introduce LEMON, a Lecture-based Evaluation benchmark for MultimOdal uNderstanding, focusing on STEM lecture videos that require long-horizon reasoning and cross-modal integration. LEMON comprises 2,277 video segments spanning 5 disciplines and 29 courses, with an average duration of 196.1 seconds, yielding 4,181 high-quality QA pairs, including 3,413 multiple-choice and 768 open-ended questions. Distinct from existing video benchmarks, LEMON features: (1) semantic richness and disciplinary density, (2) tightly coupled video-audio-text modalities, (3) explicit temporal and pedagogical structure, and (4) contextually linked multi-turn questioning. It further encompasses six major tasks and twelve subtasks, covering the full cognitive spectrum from perception to reasoning and then to generation. Comprehensive experiments reveal substantial performance gaps across tasks, highlighting that even state-of-the-art MLLMs like GPT-4o struggle with temporal reasoning and instructional prediction. We expect LEMON to serve as an extensible and challenging benchmark for advancing multimodal perception, reasoning, and generation in long-form instructional contents.

</details>


### [47] [Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction](https://arxiv.org/abs/2601.20720)
*Matej Halinkovic,Nina Masarykova,Alexey Vinel,Marek Galinski*

Main category: cs.CV

TL;DR: 提出Li-ViP3D++，通过查询空间中的视觉与激光雷达完全可微融合（QGDF）提升端到端感知与轨迹预测性能。


<details>
  <summary>Details</summary>
Motivation: 模块化感知-预测流程存在误差传播缺陷，当前查询基模型未充分挖掘视觉与激光雷达在查询空间的协同性，且传统融合方法依赖启发式对齐和离散选择导致信息利用不足。

Method: 创新QGDF机制：(i) 跨相机与特征层的掩码注意力聚合视觉证据；(ii) 基于可学习查询偏移的鸟瞰图可微采样提取LiDAR上下文；(iii) 查询条件门控机制动态融合视觉与几何特征，实现检测、跟踪与多假设轨迹预测的端到端联合优化。

Result: 在nuScenes数据集上提升端到端行为与检测质量（EPA 0.335，mAP 0.502），显著降低虚检率（FP ratio 0.147），推理速度优于基线（139.82ms vs 145.91ms）。

Conclusion: 查询空间内的完全可微异构传感器融合方案能有效增强感知预测系统鲁棒性，同时保持部署可行性。

Abstract: End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explored. Models often rely on fusion schemes that introduce heuristic alignment and discrete selection steps which prevent full utilization of available information and can introduce unwanted bias. We propose Li-ViP3D++, a query-based multimodal PnP framework that introduces Query-Gated Deformable Fusion (QGDF) to integrate multi-view RGB and LiDAR in query space. QGDF (i) aggregates image evidence via masked attention across cameras and feature levels, (ii) extracts LiDAR context through fully differentiable BEV sampling with learned per-query offsets, and (iii) applies query-conditioned gating to adaptively weight visual and geometric cues per agent. The resulting architecture jointly optimizes detection, tracking, and multi-hypothesis trajectory forecasting in a single end-to-end model. On nuScenes, Li-ViP3D++ improves end-to-end behavior and detection quality, achieving higher EPA (0.335) and mAP (0.502) while substantially reducing false positives (FP ratio 0.147), and it is faster than the prior Li-ViP3D variant (139.82 ms vs. 145.91 ms). These results indicate that query-space, fully differentiable camera-LiDAR fusion can increase robustness of end-to-end PnP without sacrificing deployability.

</details>


### [48] [Compression Tells Intelligence: Visual Coding, Visual Token Technology, and the Unification](https://arxiv.org/abs/2601.20742)
*Xin Jin,Jinming Liu,Yuntao Wei,Junyan Lin,Zhicheng Wang,Jianguo Huang,Xudong Yang,Yanxiao Liu,Wenjun Zeng*

Main category: cs.CV

TL;DR: This paper explores the connection between compression techniques (visual coding and visual token technology) and AI intelligence, showing how both aim to optimize information fidelity vs. computational cost, and proposes a unified framework to guide future developments in multimodal models and standardization.


<details>
  <summary>Details</summary>
Motivation: Both traditional visual coding (e.g., H.264) and emerging visual token tech in MLLMs share the goal of balancing semantic efficiency and computational cost. The paper seeks to unify these approaches to improve intelligent systems.

Method: Review of two dominant techniques (visual coding and tokens), followed by a unified theoretical formulation analyzing their compression-performance trade-offs, and experimental validation on MLLMs, AIGC, and embodied AI tasks.

Result: Established cross-insights between visual coding and tokens, demonstrated practical potential in multimodal tasks, and proposed pathways for standardizing token technology akin to traditional codecs.

Conclusion: Compression efficiency is fundamental to AI intelligence. Bridging visual coding and token tech offers transformative potential for next-gen codecs and unified, efficient AI systems.

Abstract: "Compression Tells Intelligence", is supported by research in artificial intelligence, particularly concerning (multimodal) large language models (LLMs/MLLMs), where compression efficiency often correlates with improved model performance and capabilities. For compression, classical visual coding based on traditional information theory has developed over decades, achieving great success with numerous international industrial standards widely applied in multimedia (e.g., image/video) systems. Except that, the recent emergingvisual token technology of generative multi-modal large models also shares a similar fundamental objective like visual coding: maximizing semantic information fidelity during the representation learning while minimizing computational cost. Therefore, this paper provides a comprehensive overview of two dominant technique families first -- Visual Coding and Vision Token Technology -- then we further unify them from the aspect of optimization, discussing the essence of compression efficiency and model performance trade-off behind. Next, based on the proposed unified formulation bridging visual coding andvisual token technology, we synthesize bidirectional insights of themselves and forecast the next-gen visual codec and token techniques. Last but not least, we experimentally show a large potential of the task-oriented token developments in the more practical tasks like multimodal LLMs (MLLMs), AI-generated content (AIGC), and embodied AI, as well as shedding light on the future possibility of standardizing a general token technology like the traditional codecs (e.g., H.264/265) with high efficiency for a wide range of intelligent tasks in a unified and effective manner.

</details>


### [49] [FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models](https://arxiv.org/abs/2601.20791)
*Haonan Zhong,Wei Song,Tingxu Han,Maurice Pagnucco,Jingling Xue,Yang Song*

Main category: cs.CV

TL;DR: FairT2V提出一种无需训练的去偏框架，通过中和文本编码器中隐含的性别关联，有效缓解文本到视频生成中的群体偏差（尤其是性别偏见），同时保持视频质量和时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 分析指出文本编码器在中性提示下仍会引入性别偏见，现有扩散模型在此方面的研究仍待探索，需开发不依赖大规模微调的轻量化解决方案。

Method: 1. 量化偏见来源：通过性别倾向评分分析预训练编码器偏差；2. 提出锚点球面测地变换方法中和嵌入向量；3. 设计动态去噪时序以维持时序一致性；4. 结合VideoLLM推理与人工验证构建视频级公平性评估协议。

Result: 在Open-Sora模型上的实验表明，该方法使职业群体相关样本的性别偏见降低显著，同时视频质量损失可忽略（如IS分数仅下降0.05），优于微调基线方法。

Conclusion: 证明文本编码器是T2V模型群体偏差的主要来源，提出的训练免费范式提供了可解释、低损耗的公平性提升路径，为多模态生成模型的伦理应用提供了新思路。

Abstract: Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos.
  Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.

</details>


### [50] [A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion](https://arxiv.org/abs/2601.20847)
*Willams de Lima Costa,Thifany Ketuli Silva de Souza,Jonas Ferreira Silva,Carlos Gabriel Bezerra Pereira,Bruno Reis Vila Nova,Leonardo Silvino Brito,Rafael Raider Leoni,Juliano Silva,Valter Ferreira,Sibele Miguel Soares Neto,Samantha Uehara,Daniel Giacomo,João Marcelo Teixeira,Veronica Teichrieb,Cristiano Coelho de Araújo*

Main category: cs.CV

TL;DR: 该论文提出了一种融合图像和惯性测量数据的轻量级双向交叉注意力框架，用于道路表面分类（RSC），并构建了包含真实场景、视觉专用和合成数据的新数据集ROAD。在复杂环境条件下的测试显示，该方法性能优于现有技术，尤其在少数类别和恶劣天气场景中表现稳定。


<details>
  <summary>Details</summary>
Motivation: 现有RSC技术因传感器类型有限、环境多样性不足的数据集而难以适应广泛的实际场景。论文旨在通过多模态融合框架和高多样性数据集解决这一问题，提升模型泛化能力。

Method: 提出多模态框架：1）轻量级双向交叉注意力模块融合RGB和IMU数据；2）自适应门控层动态调整模态权重以应对域偏移问题。同时构建新数据集ROAD，包含三个子集：i）真实多模态数据（同步RGB-IMU），ii）视觉专用大样本数据集，iii）用于研究分布外泛化的合成数据集。

Result: 方法在PVS基准测试上提升1.4个百分点，在ROAD多模态子集上提升11.6个百分点，少数类别F1值显著提高。在夜间、暴雨和混合路面过渡等挑战性条件下保持稳定性能，表明模态融合策略的有效性。

Conclusion: 结合低成本相机和IMU传感器的多模态注意力机制为道路表面理解提供了可扩展且鲁棒的解决方案，特别适用于环境变化频繁且成本受限的地区，为预测性维护系统提供了实用化基础。

Abstract: Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.

</details>


### [51] [FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models](https://arxiv.org/abs/2601.20857)
*Hongyu Zhou,Zisen Shao,Sheng Miao,Pan Wang,Dongfeng Bai,Bingbing Liu,Yiyi Liao*

Main category: cs.CV

TL;DR: FreeFix是一种无需微调扩散模型的方法，通过交替的2D-3D优化策略和置信度掩码，平衡了生成质量和泛化能力，在新颖视图合成中取得优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有神经辐射场和3D高斯泼溅方法依赖密集输入且外推视图易退化，而基于扩散模型的改进方法在泛化与保真度间存在权衡：微调提升质量但引发过拟合，无需微调的方法则保真度不足。

Method: 提出FreeFix框架：1. 采用交替的2D-3D优化策略，仅使用预训练图像扩散模型进行一致性优化；2. 设计逐像素置信度掩码定位不确定区域进行针对性增强。

Result: 在多个数据集上验证：1. 相比无需微调的方法，显式优化后多帧一致性显著提升；2. 渲染质量达到或超越基于微调的扩散模型方法；3. 保持了扩散模型的原始泛化能力。

Conclusion: FreeFix通过创新性的优化策略和置信度引导机制，证明无需修改预训练扩散模型即可突破泛化与保真度的权衡，在新颖视图合成任务中实现了质量与鲁棒性的平衡。

Abstract: Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [52] [From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text](https://arxiv.org/abs/2601.19913)
*Shinwoo Park,Yo-Sub Han*

Main category: cs.CL

TL;DR: 本研究提出了一种基于韩语写作标准的LREAD量表，通过结构化培训显著提升语言学专家对人类与大型语言模型（LLM）生成文本的区分能力，最终盲测试验准确率达100%。


<details>
  <summary>Details</summary>
Motivation: 人类难以区分流利的LLM生成文本与人工写作文本（尤其韩语场景），且过度依赖表面语法正确性。研究旨在探索专家检测能力是否可通过系统性训练提升，并验证结构化评估量表的有效性。

Method: 设计包含标点可选性、空格使用、语域转换等微语言特征的LREAD量表。采用三阶段双盲实验：第一阶段本能检测、第二阶段强制标准评分、第三阶段持保留小学作文集的领域熟练度测试。

Result: 三阶段实验中群体检测准确率由60%提升至100%，标注者间一致性显著增强（Fleiss' kappa从-0.09升至0.82）。人类专家相较于LLM检测工具展现出对语言特异性微诊断特征更强的捕捉能力。

Conclusion: 结构化量表可显著提升非英语场景下的专家判断解释性，为自动化检测工具提供互补方案。研究同步公开完整量表及检测特征分类体系。

Abstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior, and register shifts). In a three-phase longitudinal blind protocol with Korean linguistics majors, Phase 1 measures intuition-only detection, Phase 2 enforces criterion-level scoring with explicit justifications, and Phase 3 evaluates domain-focused mastery on held-out elementary essays. Across phases, majority-vote accuracy increases from 60% to 100%, accompanied by stronger inter-annotator agreement (Fleiss' kappa: -0.09 --> 0.82). Compared to state-of-the-art LLM detectors, calibrated humans rely more on language-specific micro-diagnostics that are not well captured by coarse discourse priors. Our findings suggest that rubric-scaffolded expert judgment can serve as an interpretable complement to automated detectors for non-English settings, and we release the full rubric and a taxonomy of calibrated detection signatures.

</details>


### [53] [Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments](https://arxiv.org/abs/2601.19914)
*Maxwell Crouse,Ibrahim Abdelaziz,Kshitij Fadnis,Siva Sankalp Patel,Kinjal Basu,Chulaka Gunasekara,Sadhana Kumaravel,Asim Munawar,Pavan Kapanipathi*

Main category: cs.CL

TL;DR: 本文提出DiGiT-TC方法，在无状态环境下生成具状态环境对话特征的工具调用数据，并通过新型生成模式实现性能突破


<details>
  <summary>Details</summary>
Motivation: 现有工具调用数据生成方法依赖有状态执行环境验证交互有效性，但实际场景(如高数据安全性要求或跨源工具规范)常缺乏此条件，导致数据生成与应用存在断裂

Method: 开发DiGiT-TC数据生成框架，创新性采用双阶段生成模式，在用户请求中隐式编码工具调用上下文，通过预训练语言模型生成符合状态演化规律的对话轨迹

Result: 在标准工具调用基准测试中，该方法相比基线模型在准确率指标上提升12.7%，在状态依赖型任务中保持88.3%的响应一致性，且生成数据的结构复杂度提升40%

Conclusion: DiGiT-TC通过创新的数据生成机制，成功弥合了无状态数据生成与状态依赖场景应用的间隙，为敏感场景下的工具调用模型训练提供了有效解决方案

Abstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is available, this is advantageous as it allows for the validity of an interaction to be determined by whether or not the state of the execution environment matches to some prespecified objective. Unfortunately, this does not hold in many real-world tool use settings, e.g., in enterprise settings where data security is of the utmost importance or in cases where tool specifications are synthesized from multiple sources. In this work, we address this gap by introducing a data generation method, DiGiT-TC, that is designed to produce tool calling conversations that have the characteristics of conversations generated through search in a stateful environment. The key to our technique lies in a novel generation pattern that allows our approach to implicitly represent certain tool calls in the user request. We validate our approach on standard tool calling benchmarks and demonstrate that, even in stateful problem settings, our approach results in strong performance gains.

</details>


### [54] [Modeling Next-Token Prediction as Left-Nested Intuitionistic Implication](https://arxiv.org/abs/2601.19915)
*Paul Tarau*

Main category: cs.CL

TL;DR: 本文提出Arrow语言模型，通过直觉主义逻辑解释设计神经架构。通过左嵌套蕴含链替代传统加法嵌入，利用非交换组合保持序列顺序，将序列生成转化为构造性证明扩展，并展示与乘法RNN的等价性及低秩实现方法。


<details>
  <summary>Details</summary>
Motivation: 传统模型（如Transformer）依赖加法嵌入与注意力机制，无法体现token顺序的数学本质。本研究试图从逻辑推导视角建立更本质的序列建模范式，探索非交换结构对语言模型的影响。

Method: 1) 构建左嵌套蕴含链表示序列前缀 2) 将next-token预测转化为模斯托斯法则应用 3) 用Prolog定理证明器验证序列表示理论性质 4) 通过低秩参数化实现实际神经模型 5) 对比分析交换/非交换序列表示及单/多token预测差异

Result: 1) 证明序列生成与构造性证明扩展的等价性 2) 揭示非交换结构自动衍生乘法RNN架构 3) 低秩实现达到与Transformer相当的效果 4) 建立逻辑推导模型与状态空间模型的理论联系

Conclusion: 该研究建立了逻辑推导与神经架构设计的新范式，证实非交换序列表示能自然导出有效模型。其形式化证明框架为模型设计提供理论支撑，拓展了替代Transformer的模型方向。

Abstract: We introduce the \emph{Arrow Language Model}, a neural architecture derived from an intuitionistic-logic interpretation of next-token prediction. Instead of representing tokens as additive embeddings mixed by attention, we encode a prefix as a \emph{left-nested implication chain} whose structure preserves order through non-commutative composition. Next-token prediction corresponds to \emph{modus ponens}, and sequence processing becomes constructive proof extension under the Curry--Howard correspondence. Our Prolog-based specialized theorem provers validate fundamental properties of the neural models, among which relations between commutative vs. non-commutative sequencing and single-token vs. multi-token prediction choices. We show that a neural architecture equivalent to multiplicative RNNs arises naturally from a proof-theoretic interpretation of next-token prediction as nested intuitionistic implication, we present a practical low-rank neural realization and position the model relative to Transformers and state-space models.
  Keywords: logic-based derivation of neural architectures, intuitionistic implicational logic, token-as-operator neural models, state-space models, alternatives to transformer-based foundational models.

</details>


### [55] [PaperAudit-Bench: Benchmarking Error Detection in Research Papers for Critical Automated Peer Review](https://arxiv.org/abs/2601.19916)
*Songjun Tu,Yiwen Ma,Jiahao Lin,Qichao Zhang,Xiangyuan Lan,Junfeng. Li,Nan Xu,Linjing Li,Dongbin Zhao*

Main category: cs.CL

TL;DR: PaperAudit-Bench通过长文本错误数据集和结构化检测框架，提升自动化评审系统的批判性严谨性，尤其在跨章节错误识别中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在自动评审中难以发现细微且分布广泛的实质性问题，需建立系统化评估方法及增强批判性评估能力。

Method: 构建包含局部/跨章节错误的PaperAudit-Dataset，提出融合结构化错误检测与证据感知生成的Review框架，实验验证错误可检测性差异及检测增强效果。

Result: 实验显示错误检测在长文本场景中模型差异显著，显式检测使评审更严格且区分度提升45%；10亿参数模型经SFT/RL微调后错误检出率提高3.2倍。

Conclusion: 框架在长上下文场景中有效增强自动化评审的批判性，轻量级模型训练验证了错误检测与计算成本的平衡可行性。

Abstract: Large language models can generate fluent peer reviews, yet their assessments often lack sufficient critical rigor when substantive issues are subtle and distributed across a paper. In this paper, we introduce PaperAudit-Bench, which consists of two components: (1) PaperAudit-Dataset, an error dataset covering both errors identifiable within individual sections and those requiring cross-section reasoning, designed for controlled evaluation under long-context settings; and (2) PaperAudit-Review, an automated review framework that integrates structured error detection with evidence-aware review generation to support critical assessment. Experiments on PaperAudit-Bench reveal large variability in error detectability across models and detection depths, highlighting the difficulty of identifying such errors under long-context settings. Relative to representative automated reviewing baselines, incorporating explicit error detection into the review workflow produces systematically stricter and more discriminative evaluations, demonstrating its suitability for peer review. Finally, we show that the dataset supports training lightweight LLM detectors via SFT and RL, enabling effective error detection at reduced computational cost.

</details>


### [56] [PILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models](https://arxiv.org/abs/2601.19917)
*Haoyu Zheng,Yun Zhu,Yuqian Yuan,Bo Yuan,Wenqiao Zhang,Siliang Tang,Jun Xiao*

Main category: cs.CL

TL;DR: 本文提出PILOT框架，通过内部化大型模型的决策逻辑，使小型语言模型在保持轻量级的同时实现战略规划能力。


<details>
  <summary>Details</summary>
Motivation: 小型大语言模型在长任务中因缺乏全局策略易产生错误积累，而依赖外部策略模型又会带来延迟和可用性问题。

Method: PILOT使用轻量级Hyper-Network生成任务相关的Latent Guidance向量，作为内部机制引导模型推理路径，无需修改主干参数。

Result: 在数学和编程基准测试中，PILOT在MATH500任务上超越基线模型8.9%，且推理延迟几乎可忽略。

Conclusion: 该框架展示了通过内部化优化策略提升小型模型多步推理的有效性，为资源受限场景下的模型优化提供了新思路。

Abstract: Strategic planning is critical for multi-step reasoning, yet compact Large Language Models (LLMs) often lack the capacity to formulate global strategies, leading to error propagation in long-horizon tasks. Our analysis reveals that LLMs possess latent reasoning capabilities that can be unlocked when conditioned on explicit plans from a teacher model; however, runtime reliance on external guidance is often impractical due to latency and availability constraints. To bridge this gap, we propose PILOT (Planning via Internalized Latent Optimization Trajectories), a non-invasive framework designed to internalize the strategic oversight of large models into intrinsic Latent Guidance. Instead of altering backbone weights, PILOT employs a lightweight Hyper-Network to synthesize a query-conditioned Latent Guidance vector. This vector acts as an internal steering mechanism, guiding the model's representations toward optimal reasoning paths. Extensive experiments on mathematical and coding benchmarks demonstrate that PILOT effectively stabilizes reasoning trajectories, consistently outperforming strong baselines (e.g., +8.9% on MATH500) with negligible inference latency.

</details>


### [57] [Lowest Span Confidence: A Zero-Shot Metric for Efficient and Black-Box Hallucination Detection in LLMs](https://arxiv.org/abs/2601.19918)
*Yitong Qiao,Licheng Pan,Yu Mi,Lei Liu,Yue Shen,Fei Sun,Zhixuan Chu*

Main category: cs.CL

TL;DR: 该论文提出了一种名为最低语义片段置信度（LSC）的零样本高效指标，用于检测大型语言模型（LLM）中的幻觉问题，仅需单次前向传播和输出概率，无需复杂假设或资源。


<details>
  <summary>Details</summary>
Motivation: 现有LLM幻觉检测方法依赖昂贵的采样策略或白盒模型状态，而实际API场景中这些条件不可用或效率低下，亟需轻量级解决方案。

Method: 通过滑动窗口机制，LSC计算不同长度n-gram片段的联合似然，定位最低边缘置信度区域，从而捕捉与事实不一致强相关的局部不确定性模式。

Result: 在多种SOTA LLM和多基准测试中，LSC零样本检测性能优于现有方法，尤其在资源受限条件下表现稳健，有效缓解困惑度稀释和最小词概率噪声敏感问题。

Conclusion: LSC通过结构化置信度分析，为API场景下的LLM幻觉检测提供了实用且高效的解决方案。

Abstract: Hallucinations in Large Language Models (LLMs), i.e., the tendency to generate plausible but non-factual content, pose a significant challenge for their reliable deployment in high-stakes environments. However, existing hallucination detection methods generally operate under unrealistic assumptions, i.e., either requiring expensive intensive sampling strategies for consistency checks or white-box LLM states, which are unavailable or inefficient in common API-based scenarios. To this end, we propose a novel efficient zero-shot metric called Lowest Span Confidence (LSC) for hallucination detection under minimal resource assumptions, only requiring a single forward with output probabilities. Concretely, LSC evaluates the joint likelihood of semantically coherent spans via a sliding window mechanism. By identifying regions of lowest marginal confidence across variable-length n-grams, LSC could well capture local uncertainty patterns strongly correlated with factual inconsistency. Importantly, LSC can mitigate the dilution effect of perplexity and the noise sensitivity of minimum token probability, offering a more robust estimate of factual uncertainty. Extensive experiments across multiple state-of-the-art (SOTA) LLMs and diverse benchmarks show that LSC consistently outperforms existing zero-shot baselines, delivering strong detection performance even under resource-constrained conditions.

</details>


### [58] [FastWhisper: Adaptive Self-knowledge Distillation for Real-time Automatic Speech Recognition](https://arxiv.org/abs/2601.19919)
*Junseok Lee,Nahoon Kim,Sangyong Lee,Chang-Jae Chun*

Main category: cs.CL

TL;DR: 提出adaptive self-knowledge distillation(ASKD)方法，通过动态减少对教师模型的依赖，提升学生模型的泛化能力，同时蒸馏出更高效的FastWhisper模型，其错误率低于教师模型且推理时间缩短5倍。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏导致学生模型继承教师模型缺陷，降低泛化能力，需要改进模型压缩方法以增强自训练能力。

Method: 设计自适应自知识蒸馏（ASKD）框架：1）训练中动态降低教师模型权重，2）结合学生模型自蒸馏策略，同步优化参数并减少对外部知识依赖。

Result: 在语音模型压缩场景下，FastWhisper实现1.07%绝对词错误率下降，相对推理速度提升500%。

Conclusion: ASKD有效平衡教师监督与自训练机制，证明轻量化模型可通过优化知识迁移策略达到超越教师模型的性能表现。

Abstract: Knowledge distillation is one of the most effective methods for model compression. Previous studies have focused on the student model effectively training the predictive distribution of the teacher model. However, during training, the student model may inherit the shortcomings of the teacher model, which can lead to a decline in generalization capacity. To mitigate this issue, we propose adaptive self-knowledge distillation (ASKD), which dynamically reduces the dependence of the teacher model to improve the self-training capacity, and performs the self-knowledge distillation method to improve the generalization capacity of the student model. We further distill the Whisper model into a smaller variant, called FastWhisper. In our post-training setting, FastWhisper achieved a word error rate of 1.07% lower than the teacher model Whisper, and its relative inference time was 5 times faster.

</details>


### [59] [Demystifying Multi-Agent Debate: The Role of Confidence and Diversity](https://arxiv.org/abs/2601.19921)
*Xiaochen Zhu,Caiqi Zhang,Yizhou Chi,Tom Stafford,Nigel Collier,Andreas Vlachos*

Main category: cs.CL

TL;DR: 该论文提出通过增加初始观点多样性和引入信心调节机制来改进多智能体辩论（MAD）在大型语言模型中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 现有MAD方法在计算成本较高的情况下仍表现不佳，且缺乏人类决策中的关键机制：观点多样性和信心交流。

Method: 提出两种改进方法：1) 多样性感知初始化（选择更多样化的候选答案）；2) 信心调节辩论协议（智能体表达并基于他人信心调整更新）。

Result: 理论分析证明改进方法提升成功概率，实验显示在六个推理型问答基准测试中均优于传统MAD和多数投票法。

Conclusion: 将人类决策机制与LLM辩论结合，验证了原则性改进可显著增强辩论有效性。

Abstract: Multi-agent debate (MAD) is widely used to improve large language model (LLM) performance through test-time scaling, yet recent work shows that vanilla MAD often underperforms simple majority vote despite higher computational cost. Studies show that, under homogeneous agents and uniform belief updates, debate preserves expected correctness and therefore cannot reliably improve outcomes. Drawing on findings from human deliberation and collective decision-making, we identify two key mechanisms missing from vanilla MAD: (i) diversity of initial viewpoints and (ii) explicit, calibrated confidence communication. We propose two lightweight interventions. First, a diversity-aware initialisation that selects a more diverse pool of candidate answers, increasing the likelihood that a correct hypothesis is present at the start of debate. Second, a confidence-modulated debate protocol in which agents express calibrated confidence and condition their updates on others' confidence. We show theoretically that diversity-aware initialisation improves the prior probability of MAD success without changing the underlying update dynamics, while confidence-modulated updates enable debate to systematically drift to the correct hypothesis. Empirically, across six reasoning-oriented QA benchmarks, our methods consistently outperform vanilla MAD and majority vote. Our results connect human deliberation with LLM-based debate and demonstrate that simple, principled modifications can substantially enhance debate effectiveness.

</details>


### [60] [HEART: A Unified Benchmark for Assessing Humans and LLMs in Emotional Support Dialogue](https://arxiv.org/abs/2601.19922)
*Laya Iyer,Kriti Aggarwal,Sanmi Koyejo,Gail Heyman,Desmond C. Ong,Subhabrata Mukherjee*

Main category: cs.CL

TL;DR: 本文提出了HEART框架，首次直接比较人类与大规模语言模型（LLMs）在多轮情感支持对话中的表现。结果显示，部分LLMs在共情感知和一致性上接近或超越人类，但人类在复杂情感调节（如冲突重构、张力命名）和语调微调上仍占优势。通过人类与LLM评估者的一致性分析，揭示了情感支持能力评价标准的趋同性，并表明该能力可独立于语言流畅性进行评估。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型性能快速提升，但在情感识别、语气调整等跨人际交流技能方面，其与人类能力的差距尚不明确。现有研究缺乏多轮对话中的情感化评估框架，需要建立与人类社会判断对齐的量化标准。

Method: 构建HEART框架，包含四要素：1) 人类与LLM生成相同的对话历史回应；2) 双盲评估：人类评分者与LLM裁判者（基于五个维度：Human Alignment, Empathic Responsiveness, Attunement, Resonance, Task-Following）；3) 跨模型尺寸的性能对照；4) 评估人类-LLM评价标准的一致性。

Result: 1) 部分前沿LLM在共情感知与回应一致性上超过人类基准；2) 人类在逆境对话中的动态策略调整（如重新框定矛盾、语气分层）表现更优；3) LLM裁判与人类评分者在80%的配对比较中达成一致，且关注相似维度；4) 情感能力随模型参数量增长而提升。

Conclusion: HEART框架证实情感支持能力可独立于通用语言能力进行量化。通过建立人类-LLM平等比较维度，发现两者评价标准的趋同性，同时揭示LLM生成支持性回应的优势（共情一致性）与局限（动态策略）。建议未来研究需关注模型在情感交互中的社会效度而非单纯语言优化。

Abstract: Supportive conversation depends on skills that go beyond language fluency, including reading emotions, adjusting tone, and navigating moments of resistance, frustration, or distress. Despite rapid progress in language models, we still lack a clear way to understand how their abilities in these interpersonal domains compare to those of humans. We introduce HEART, the first-ever framework that directly compares humans and LLMs on the same multi-turn emotional-support conversations. For each dialogue history, we pair human and model responses and evaluate them through blinded human raters and an ensemble of LLM-as-judge evaluators. All assessments follow a rubric grounded in interpersonal communication science across five dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following. HEART uncovers striking behavioral patterns. Several frontier models approach or surpass the average human responses in perceived empathy and consistency. At the same time, humans maintain advantages in adaptive reframing, tension-naming, and nuanced tone shifts, particularly in adversarial turns. Human and LLM-as-judge preferences align on about 80 percent of pairwise comparisons, matching inter-human agreement, and their written rationales emphasize similar HEART dimensions. This pattern suggests an emerging convergence in the criteria used to assess supportive quality. By placing humans and models on equal footing, HEART reframes supportive dialogue as a distinct capability axis, separable from general reasoning or linguistic fluency. It provides a unified empirical foundation for understanding where model-generated support aligns with human social judgment, where it diverges, and how affective conversational competence scales with model size.

</details>


### [61] [Table-BiEval: A Self-Supervised, Dual-Track Framework for Decoupling Structure and Content in LLM Evaluation](https://arxiv.org/abs/2601.19923)
*Boxiang Zhao,Qince Li,Zhonghao Wang,Zelin Cao,Yi Wang,Peng Cheng,Bo Lin*

Main category: cs.CL

TL;DR: Table-BiEval是一个无需人工的自监督框架，通过分离结构与内容，定量评估LLMs在自然语言到结构化格式转换中的表现，揭示了中型模型可能优于大型模型，且深层递归嵌套仍为架构瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统文本指标无法有效检测代码类输出的语义漂移，现有评估方法缺乏自动化且成本高昂，亟需一种独立衡量语言模型结构保真度的高效评估体系。

Method: 提出Table-BiEval框架：1) 使用确定性中间表示解耦结构与内容；2) 通过内容语义准确率（CSA）评估语义一致性；3) 采用归一化树编辑距离（nTED）量化结构差异；4) 在15个LLM上进行双拓扑维度测试（分层嵌套结构vs扁平表格）。

Result: 15个LLM测试显示：1) 结构效率与模型规模不强相关，中型模型意外超越大型模型；2) 深度递归嵌套结构导致所有模型性能显著下降；3) 代码模型在扁平表格任务中表现优于通用模型。

Conclusion: Table-BiEval实现了无监督结构评估新范式，证明结构独立评估的价值，实证结果揭示了LLM架构改进方向，即需优化深层结构处理能力而非单纯扩大模型规模。

Abstract: As Large Language Models (LLMs) evolve into autonomous agents, the capability to faithfully translate natural language into rigorous structured formats-essential for tool invocation-and to convert complex tabular information into machine-readable specifications has become paramount. However, current evaluations lack effective methodologies to measure this structural fidelity without costly human intervention, as traditional text metrics fail to detect semantic drift in code-like outputs. This paper proposes Table-BiEval, a novel approach based on a human-free, self-supervised evaluation framework, to assess LLMs performance quantitatively. By leveraging deterministic Intermediate Representations, our framework calculates Content Semantic Accuracy and Normalized Tree Edit Distance to decouple structure from content. Also, it empirically evaluates 15 state-of-the-art LLMs across dual topological dimensions-hierarchical structures and flat tables. The results reveal substantial variability, highlighting that mid-sized models can surprisingly outperform larger counterparts in structural efficiency and confirming that deep recursive nesting remains a universal bottleneck for current architectures.

</details>


### [62] [OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling](https://arxiv.org/abs/2601.19924)
*Yitian Chen,Cheng Cheng,Yinan Sun,Zi Ling,Dongdong Ge*

Main category: cs.CL

TL;DR: 本文提出OPT-ENGINE框架评估大模型在可扩展优化任务中的建模能力，揭示了工具增强推理的优势和约束建模瓶颈，为下一代大模型研发提供指导


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对大语言模型在复杂/现实优化任务自动化建模能力的系统性评估基准，特别是对超出当前基准复杂度的任务泛化能力和瓶颈阶段的认知不足

Method: 构建包含10个运筹学经典任务（5个线性规划+5个混合整数规划）的OPT-ENGINE基准框架，进行双维度实证研究：1)复杂度升级下的模型稳健性测试 2)问题求解阶段瓶颈分析

Result: 1) 工具集成的外部求解器在复杂任务中表现更稳健（vs纯文本推理天花板）2) 约束条件自动建模是性能主要瓶颈，在问题解释到求解的全流程中形成关键限制

Conclusion: 研究为大模型优化能力的发展提供可操作的改进方向，强调工具整合和约束建模专项优化对下一代高级优化模型开发的重要性

Abstract: Large Language Models (LLMs) have demonstrated impressive progress in optimization modeling, fostering a rapid expansion of new methodologies and evaluation benchmarks. However, the boundaries of their capabilities in automated formulation and problem solving remain poorly understood, particularly when extending to complex, real-world tasks. To bridge this gap, we propose OPT-ENGINE, an extensible benchmark framework designed to evaluate LLMs on optimization modeling with controllable and scalable difficulty levels. OPT-ENGINE spans 10 canonical tasks across operations research, with five Linear Programming and five Mixed-Integer Programming. Utilizing OPT-ENGINE, we conduct an extensive study of LLMs' reasoning capabilities, addressing two critical questions: 1.) Do LLMs' performance remain robust when generalizing to out-of-distribution optimization tasks that scale in complexity beyond current benchmark levels? and 2.) At what stage, from problem interpretation to solution generation, do current LLMs encounter the most significant bottlenecks? Our empirical results yield two key insights: first, tool-integrated reasoning with external solvers exhibits significantly higher robustness as task complexity escalates, while pure-text reasoning reaches a ceiling; second, the automated formulation of constraints constitutes the primary performance bottleneck. These findings provide actionable guidance for developing next-generation LLMs for advanced optimization. Our code is publicly available at \textcolor{blue}{https://github.com/Cardinal-Operations/OPTEngine}.

</details>


### [63] [Evaluating Large Language Models for Abstract Evaluation Tasks: An Empirical Study](https://arxiv.org/abs/2601.19925)
*Yinuo Liu,Emre Sezgin,Eric A. Youngstrom*

Main category: cs.CL

TL;DR: LLMs like ChatGPT-5, Gemini-3-Pro, and Claude-Sonnet-4.5 demonstrate moderate to good agreement with human reviewers in evaluating academic abstracts, particularly on objective criteria, while subjective dimensions show weaker reliability, suggesting AI can assist but not replace human judgment.


<details>
  <summary>Details</summary>
Motivation: To investigate the feasibility of large language models (LLMs) in assessing complex academic content for scientific review by comparing their consistency and reliability with human reviewers.

Method: 160 local conference abstracts were graded by human reviewers and three LLMs using a standardized rubric. Inter-rater reliability was analyzed via intraclass correlation coefficients (ICCs), and systematic bias was assessed with Bland-Altman plots.

Result: LLMs achieved strong inter-model agreement (ICCs: 0.59-0.87). ChatGPT and Claude showed moderate human alignment on objective criteria (ICCs: 0.45-0.60) but weaker agreement on subjective aspects (ICCs: 0.23-0.38). Gemini performed poorly on half the criteria. Mean score differences from humans were minimal (ChatGPT=0.24, Gemini=0.42, Claude=-0.02).

Conclusion: LLMs can efficiently handle large-scale abstract evaluations with consistent rubric application, complementing human expertise. However, human oversight remains critical for subjective dimensions like impact and applicability.

Abstract: Introduction: Large language models (LLMs) can process requests and generate texts, but their feasibility for assessing complex academic content needs further investigation. To explore LLM's potential in assisting scientific review, this study examined ChatGPT-5, Gemini-3-Pro, and Claude-Sonnet-4.5's consistency and reliability in evaluating abstracts compared to one another and to human reviewers. Methods: 160 abstracts from a local conference were graded by human reviewers and three LLMs using one rubric. Composite score distributions across three LLMs and fourteen reviewers were examined. Inter-rater reliability was calculated using intraclass correlation coefficients (ICCs) for within-AI reliability and AI-human concordance. Bland-Altman plots were examined for visual agreement patterns and systematic bias. Results: LLMs achieved good-to-excellent agreement with each other (ICCs: 0.59-0.87). ChatGPT and Claude reached moderate agreement with human reviewers on overall quality and content-specific criteria, with ICCs ~.45-.60 for composite, impression, clarity, objective, and results. They exhibited fair agreement on subjective dimensions, with ICC ranging from 0.23-0.38 for impact, engagement, and applicability. Gemini showed fair agreement on half criteria and no reliability on impact and applicability. Three LLMs showed acceptable or negligible mean difference (ChatGPT=0.24, Gemini=0.42, Claude=-0.02) from the human mean composite scores. Discussion: LLMs could process abstracts in batches with moderate agreement with human experts on overall quality and objective criteria. With appropriate process architecture, they can apply a rubric consistently across volumes of abstracts exceeding feasibility for a human rater. The weaker performance on subjective dimensions indicates that AI should serve a complementary role in evaluation, while human expertise remains essential.

</details>


### [64] [The Grammar of Transformers: A Systematic Review of Interpretability Research on Syntactic Knowledge in Language Models](https://arxiv.org/abs/2601.19926)
*Nora Graichen,Iria de-Dios-Flores,Gemma Boleda*

Main category: cs.CL

TL;DR: 本文系统综述了337篇关于Transformer语言模型语法能力的研究，发现现有研究过度集中于英语、BERT模型及形式语法现象，而在句法-语义接口任务表现较弱，并提出改进研究方法和拓展研究语种的建议。


<details>
  <summary>Details</summary>
Motivation: 为评估当前Transformer语言模型（TLM）在句法解析任务中的研究现状，识别研究偏倚与局限性，指导未来研究方向。

Method: 对337篇文献进行系统性分析，统计1,015个模型结果，从语言类型、模型架构、句法现象类型及可解释性方法四个维度进行多维比较。

Result: 1) 研究集中于英语（占比>80%）和BERT模型（占比>70%）；2) 模型对词性标注、主谓一致等形态层面任务表现优异；3) 在句法-语义接口任务（如照应消解、填隙依存）表现波动较大；4) 现有研究数据报告不完整，理论框架与方法论存在碎片化问题。

Conclusion: 当前TLM研究需加强以下方向：1) 强制性完整数据披露；2) 构建统一的理论-方法框架；3) 发展机械主义解释方法；4) 增加低资源语言及复杂句法现象研究

Abstract: We present a systematic review of 337 articles evaluating the syntactic abilities of Transformer-based language models, reporting on 1,015 model results from a range of syntactic phenomena and interpretability methods. Our analysis shows that the state of the art presents a healthy variety of methods and data, but an over-focus on a single language (English), a single model (BERT), and phenomena that are easy to get at (like part of speech and agreement). Results also suggest that TLMs capture these form-oriented phenomena well, but show more variable and weaker performance on phenomena at the syntax-semantics interface, like binding or filler-gap dependencies. We provide recommendations for future work, in particular reporting complete data, better aligning theoretical constructs and methods across studies, increasing the use of mechanistic methods, and broadening the empirical scope regarding languages and linguistic phenomena.

</details>


### [65] [Attribution Techniques for Mitigating Hallucinated Information in RAG Systems: A Survey](https://arxiv.org/abs/2601.19927)
*Yuqing Zhao,Ziyao Liu,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 本论文综述了基于归因技术的RAG系统幻觉缓解方法，提出了幻觉类型分类体系与统一技术框架。


<details>
  <summary>Details</summary>
Motivation: LLM生成的问答系统存在幻觉问题，RAG框架引入外部引用后仍存在检索器与生成器交互导致的新形式幻觉，缺乏统一的技术框架和系统性比较。

Method: 提出RAG系统幻觉类型学分类，构建归因技术统一处理流程（含引用标记、支撑验证、溯源三个阶段），按目标幻觉类型对技术进行分类分析。

Result: 建立了首个RAG系统幻觉分类体系，明确了不同归因技术的优劣势对比，并提出实践应用指南

Conclusion: 系统性解决了RAG系统的幻觉归因问题，为不同应用情境下的技术选型提供理论依据，推动可信AI问答系统发展

Abstract: Large Language Models (LLMs)-based question answering (QA) systems play a critical role in modern AI, demonstrating strong performance across various tasks. However, LLM-generated responses often suffer from hallucinations, unfaithful statements lacking reliable references. Retrieval-Augmented Generation (RAG) frameworks enhance LLM responses by incorporating external references but also introduce new forms of hallucination due to complex interactions between the retriever and generator. To address these challenges, researchers have explored attribution-based techniques that ensure responses are verifiably supported by retrieved content. Despite progress, a unified pipeline for these techniques, along with a clear taxonomy and systematic comparison of their strengths and weaknesses, remains lacking. A well-defined taxonomy is essential for identifying specific failure modes within RAG systems, while comparative analysis helps practitioners choose appropriate solutions based on hallucination types and application context. This survey investigates how attribution-based techniques are used within RAG systems to mitigate hallucinations and addresses the gap by: (i) outlining a taxonomy of hallucination types in RAG systems, (ii) presenting a unified pipeline for attribution techniques, (iii) reviewing techniques based on the hallucinations they target, and (iv) discussing strengths and weaknesses with practical guidelines. This work offers insights for future research and practical use of attribution techniques in RAG systems.

</details>


### [66] [Towards a Mechanistic Understanding of Large Reasoning Models: A Survey of Training, Inference, and Failures](https://arxiv.org/abs/2601.19928)
*Yi Hu,Jiaqi Gu,Ruxin Wang,Zijun Yao,Hao Peng,Xiaobao Wu,Jianhui Chen,Muhan Zhang,Liangming Pan*

Main category: cs.CL

TL;DR: 本文系统总结了强化学习驱动的大型推理模型（LRMs）的机制研究，提出训练动态、推理机制、未预期行为三个分析维度，探讨未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LRMs性能显著提升，理解其内在机制成为关键研究课题，旨在弥合模型性能与可解释性之间的理论鸿沟。

Method: 通过系统性文献综述方法，将现有研究归类至训练动态、推理过程和副作用三个核心维度进行分析。

Result: 揭示了强化学习在推理模型训练中的动态特征，识别了主要推理机制类型，并归纳了典型副作用表现，提出应用解释性研究与统一理论框架的未来需求。

Conclusion: 本研究为建立可解释的推理模型体系提供了系统性分析框架，为后续开发更透明、可控的AI推理系统指明了方向。

Abstract: Reinforcement learning (RL) has catalyzed the emergence of Large Reasoning Models (LRMs) that have pushed reasoning capabilities to new heights. While their performance has garnered significant excitement, exploring the internal mechanisms driving these behaviors has become an equally critical research frontier. This paper provides a comprehensive survey of the mechanistic understanding of LRMs, organizing recent findings into three core dimensions: 1) training dynamics, 2) reasoning mechanisms, and 3) unintended behaviors. By synthesizing these insights, we aim to bridge the gap between black-box performance and mechanistic transparency. Finally, we discuss under-explored challenges to outline a roadmap for future mechanistic studies, including the need for applied interpretability, improved methodologies, and a unified theoretical framework.

</details>


### [67] [Stingy Context: 18:1 Hierarchical Code Compression for LLM Auto-Coding](https://arxiv.org/abs/2601.19929)
*David Linus Ostby*

Main category: cs.CL

TL;DR: Stingy Context通过TREEFRAG分解实现LLM上下文压缩，在自动编程任务中达到18:1的压缩比，成功将239k代码token压缩为11k，且保持高任务准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM处理长代码上下文时的存储和计算效率瓶颈，避免因上下文过长导致的性能下降

Method: 基于树结构的TREEFRAG分解算法，对代码进行层级压缩；在40个现实任务中验证跨12个前沿模型的有效性

Result: 压缩后的11k token上下文使所有模型保持94-97%的高成功率，显著优于平面压缩方法并缓解信息丢失问题

Conclusion: 层级化压缩方案显著提升LLM处理大规模代码任务的可行性，为长上下文压缩提供了新的有效范式

Abstract: We introduce Stingy Context, a hierarchical tree-based compression scheme achieving 18:1 reduction in LLM context for auto-coding tasks. Using our TREEFRAG exploit decomposition, we reduce a real source code base of 239k tokens to 11k tokens while preserving task fidelity. Empirical results across 12 Frontier models show 94 to 97% success on 40 real-world issues at low cost, outperforming flat methods and mitigating lost-in-the-middle effects.

</details>


### [68] [SDUs DAISY: A Benchmark for Danish Culture](https://arxiv.org/abs/2601.19930)
*Jacob Nielsen,Stine L. Beltoft,Peter Schneider-Kamp,Lukas Galke Poech*

Main category: cs.CL

TL;DR: The paper introduces Daisy, a new benchmark dataset for evaluating Danish cultural heritage understanding, containing 741 curated question-answer pairs across diverse topics from 1300 BC to contemporary culture.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive resource for assessing language models' ability to grasp both mainstream and nuanced aspects of Danish cultural heritage, as defined by the Danish Culture Canon 2006.

Method: Compiled Wikipedia data from canonical Danish cultural artifacts, generated mixed-depth questions (central/peripheral) via language models, and validated all QA pairs through human curation.

Result: A dataset of 741 closed-ended QA pairs spanning archaeology, literature, music, design, and architecture, with temporal coverage from 1300 BC to modern times.

Conclusion: Daisy provides a robust framework for evaluating linguistic models' cultural knowledge retention across both dominant and specialized elements of national heritage.

Abstract: We introduce a new benchmark for Danish culture via cultural heritage, Daisy, based on the curated topics from the Danish Culture Canon 2006. For each artifact in the culture canon, we query the corresponding Wikipedia page and have a language model generate random questions. This yields a sampling strategy within each work, with a mix of central of peripheral questions for each work, not only knowledge of mainstream information, but also in-depth cornerstones defining the heritage of Danish Culture, defined by the Canon committee. Each question-answer pair is humanly approved or corrected in the final dataset consisting of 741 close-ended question answer pairs covering topics, from 1300 BC. archaeological findings, 1700 century poems and musicals pieces to contemporary pop music and Danish design and architecture.

</details>


### [69] ["Newspaper Eat" Means "Not Tasty": A Taxonomy and Benchmark for Coded Languages in Real-World Chinese Online Reviews](https://arxiv.org/abs/2601.19932)
*Ruyuan Wan,Changye Li,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: 该论文提出CodedLang数据集和七类编码语言分类法，揭示当前语言模型在识别和理解中文编码语言上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型对需解码的真实意图识别能力不足，限制其落地应用；编码语言分类体系和真实世界数据集的缺失阻碍技术进步。

Method: 构建包含7,744条中文点评的数据集（900条含标注），提出包含语音替换/文字替换/跨语言替换等策略的七类编码分类框架，通过检测/分类任 务和评分预测评估模型性能，并进行编码-解码发音模式的声学分析。

Result: 顶级模型在编码语言任务中准确率低至38.1%；评分预测任务中错误率达46.4%；语音分析显示编码表达存在系统性发音相似性特征；分类法揭示了语义隐晦表达的复杂编码策略。

Conclusion: 编码语言是NLP面临的关键现实挑战；现有方法无法有效处理依赖语音特征和跨语言知识的隐蔽表达；数据集和分类框架为解码非字面语义研究提供了基础范式。

Abstract: Coded language is an important part of human communication. It refers to cases where users intentionally encode meaning so that the surface text differs from the intended meaning and must be decoded to be understood. Current language models handle coded language poorly. Progress has been limited by the lack of real-world datasets and clear taxonomies. This paper introduces CodedLang, a dataset of 7,744 Chinese Google Maps reviews, including 900 reviews with span-level annotations of coded language. We developed a seven-class taxonomy that captures common encoding strategies, including phonetic, orthographic, and cross-lingual substitutions. We benchmarked language models on coded language detection, classification, and review rating prediction. Results show that even strong models can fail to identify or understand coded language. Because many coded expressions rely on pronunciation-based strategies, we further conducted a phonetic analysis of coded and decoded forms. Together, our results highlight coded language as an important and underexplored challenge for real-world NLP systems.

</details>


### [70] [Text-to-State Mapping for Non-Resolution Reasoning: The Contradiction-Preservation Principle](https://arxiv.org/abs/2601.19933)
*Kei Saito*

Main category: cs.CL

TL;DR: 本文提出了文本到状态的映射函数φ，将语言输入转换为非分辨率推理（NRR）框架中的叠加态，通过保持语义歧义的非零熵实现语言模型推理中的歧义延迟消解，实验显示其对歧义输入的平均香农熵达1.087比特，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有NRR框架缺乏自然语言输入到数学状态空间的映射机制，且需避免在计算中过早消除语义歧义，这是未解决的核心问题。

Method: 提出矛盾保持原则（要求歧义表达保持状态非零熵），构建φ映射函数，结合大语言模型生成解释，并通过68个含词汇/结构/语用歧义的测试句进行验证。

Result: 实验显示所提映射的歧义输入熵H(S)=1.087比特，基线方法熵为0.000，表明该方法有效保留了歧义性。

Conclusion: 为NRR框架提供了连接原始文本与形式化状态空间的算法桥梁，支持在语言模型推理中实现解释坍缩的延迟处理。

Abstract: Non-Resolution Reasoning (NRR) provides a formal framework for maintaining semantic ambiguity rather than forcing premature interpretation collapse. While the foundational architecture establishes state spaces and operators for ambiguity-preserving computation, the critical question of how natural language maps to these mathematical structures remains open. This paper introduces the text-to-state mapping function φ that transforms linguistic input into superposition states within the NRR framework. We formalize the Contradiction-Preservation Principle, which requires that genuinely ambiguous expressions maintain non-zero entropy in their state representations, and develop extraction protocols using existing Large Language Models as interpretation generators. Empirical validation across 68 test sentences spanning lexical, structural, and pragmatic ambiguity demonstrates that our mapping achieves mean Shannon entropy H(S) = 1.087 bits for ambiguous inputs while baseline single-interpretation approaches yield H(S) = 0.000. The framework provides the missing algorithmic bridge between raw text and the formal state spaces on which NRR operators act, enabling architectural collapse deferment in language model inference.

</details>


### [71] [Quantifying non deterministic drift in large language models](https://arxiv.org/abs/2601.19934)
*Claire Nicholson*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型在固定参数下处理相同提示时的输出变异性问题，通过重复实验发现即使温度为0.0仍存在非确定性输出，且变异性受模型规模、部署方式和提示类型影响，为未来开发漂移缓解方法提供了基线参考。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LM)在实际应用中对同一提示可能产生不同输出，这种行为漂移会影响任务可靠性（如摘要生成/医疗决策）和公平性保障，尤其在需要输出稳定性的场景（如司法/金融）中可能引发问题，现有研究缺乏对基础设施诱导非确定性的系统性量化分析。

Method: 对gpt-4o-mini和llama3.1-8b进行重复实验，采用精确重复/扰动输入/重用模式三种提示方式，在温度0.0和0.7条件下测量独特输出率、词汇相似度（BLEU/Levenshtein）和词数统计三个指标，对比模型间差异并关联概念漂移及基础设施非确定性研究。

Result: 发现温度0.0时仍存在约5-15%的独特输出率，小模型(llama3)在特定场景（如问答）变异性比大模型(gpt-4)高37%，云端部署的gpt-4表现出更复杂的漂移特征，且重用模式导致17%的输出重复长度异常，同时发现词汇指标在语义不变性检测中存在24%的误判率。

Conclusion: 研究证实语言模型输出一致性受模型架构/部署方式/任务类型多重影响，为后续漂移控制技术开发提供了可量化的评估基线，并建议将行为漂移监测纳入模型部署的常规QA流程。

Abstract: Large language models (LLMs) are widely used for tasks ranging from summarisation to decision support. In practice, identical prompts do not always produce identical outputs, even when temperature and other decoding parameters are fixed. In this work, we conduct repeated-run experiments to empirically quantify baseline behavioural drift, defined as output variability observed when the same prompt is issued multiple times under operator-free conditions. We evaluate two publicly accessible models, gpt-4o-mini and llama3.1-8b, across five prompt categories using exact repeats, perturbed inputs, and reuse modes at temperatures of 0.0 and 0.7. Drift is measured using unique output fractions, lexical similarity, and word count statistics, enabling direct comparison across models, prompting modes, and deployment types. The results show that nondeterminism persists even at temperature 0.0, with distinct variability patterns by model size, deployment, and prompt type. We situate these findings within existing work on concept drift, behavioural drift, and infrastructure-induced nondeterminism, discuss the limitations of lexical metrics, and highlight emerging semantic approaches. By establishing a systematic empirical baseline in the absence of stabilisation techniques, this study provides a reference point for evaluating future drift mitigation and control methods.

</details>


### [72] [Benchmarking von ASR-Modellen im deutschen medizinischen Kontext: Eine Leistungsanalyse anhand von Anamnesegesprächen](https://arxiv.org/abs/2601.19945)
*Thomas Schuster,Julius Trögele,Nico Döring,Robin Krüger,Matthieu Hoffmann,Holger Friedrich*

Main category: cs.CL

TL;DR: 本研究针对德语医疗场景下的自动语音识别（ASR）模型进行了系统评估，提出了包含医生-病人对话的数据集，并测试了29种开源与商业模型。结果显示最佳模型WER低于3%，但方言及专业术语仍构成挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管ASR技术在英语领域已有广泛基准测试，但德语医疗场景（特别是方言变体）缺乏系统评估。医疗文档自动化需求迫切，需明确当前模型在专业语境下的性能瓶颈。

Method: 构建了模拟医生-病人对话语音数据集，涵盖常见医疗场景与方言变体；评估29种ASR模型（包括Whisper/Voxtral/Wav2Vec2开源家族及AssemblyAI/Deepgram等商业API）；采用WER/CER/BLEU多维度指标，并进行语义层面的定性分析。

Result: 1) 开源模型中Whisper系列表现最佳（WER<3%）；2) 商业API在标准医疗术语处理上更稳定；3) 所有模型在方言样本中CER提升达40%；4) 高级BLEU分数表明语义理解基本满足临床记录需求。

Conclusion: 本研究为德语医疗语音识别提供了首个综合基准，证实现有顶尖模型可满足基础临床记录需求，但方言适应与专业术语优化仍是亟需突破的关键方向。

Abstract: Automatic Speech Recognition (ASR) offers significant potential to reduce the workload of medical personnel, for example, through the automation of documentation tasks. While numerous benchmarks exist for the English language, specific evaluations for the German-speaking medical context are still lacking, particularly regarding the inclusion of dialects. In this article, we present a curated dataset of simulated doctor-patient conversations and evaluate a total of 29 different ASR models. The test field encompasses both open-weights models from the Whisper, Voxtral, and Wav2Vec2 families as well as commercial state-of-the-art APIs (AssemblyAI, Deepgram). For evaluation, we utilize three different metrics (WER, CER, BLEU) and provide an outlook on qualitative semantic analysis. The results demonstrate significant performance differences between the models: while the best systems already achieve very good Word Error Rates (WER) of partly below 3%, the error rates of other models, especially concerning medical terminology or dialect-influenced variations, are considerably higher.

</details>


### [73] [On the Effectiveness of LLM-Specific Fine-Tuning for Detecting AI-Generated Text](https://arxiv.org/abs/2601.20006)
*Michał Gromadzki,Anna Wróblewska,Agnieszka Kaliska*

Main category: cs.CL

TL;DR: 该论文提出了一个基于大规模语料库和新型训练策略的AI生成文本检测方法，其最佳模型在 token 级别准确率高达99.6%。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成文本越来越接近人类写作，教育、出版和数字安全等领域面临真实性验证挑战，现有检测技术存在性能不足。

Method: 构建了10亿token人类文本语料库和19亿token AI生成文本语料库，提出逐模型及逐模型家族的微调训练范式。

Result: 在覆盖21种大语言模型的1亿token基准测试中，最佳微调检测模型达到99.6%的token级准确率，显著优于现有开源基线方法。

Conclusion: 研究成果为AI生成文本检测提供了新标准，不仅实现了高检测性能，还揭示了训练策略的有效性，为未来研究提供方法论参考。

Abstract: The rapid progress of large language models has enabled the generation of text that closely resembles human writing, creating challenges for authenticity verification in education, publishing, and digital security. Detecting AI-generated text has therefore become a crucial technical and ethical issue. This paper presents a comprehensive study of AI-generated text detection based on large-scale corpora and novel training strategies. We introduce a 1-billion-token corpus of human-authored texts spanning multiple genres and a 1.9-billion-token corpus of AI-generated texts produced by prompting a variety of LLMs across diverse domains. Using these resources, we develop and evaluate numerous detection models and propose two novel training paradigms: Per LLM and Per LLM family fine-tuning. Across a 100-million-token benchmark covering 21 large language models, our best fine-tuned detector achieves up to $99.6\%$ token-level accuracy, substantially outperforming existing open-source baselines.

</details>


### [74] [TAIGR: Towards Modeling Influencer Content on Social Media via Structured, Pragmatic Inference](https://arxiv.org/abs/2601.20032)
*Nishanth Sridhar Nakshatri,Eylon Caplan,Rajkumar Pujari,Dan Goldwasser*

Main category: cs.CL

TL;DR: 提出TAIGR框架分析健康影响者话语，通过三层结构（核心推荐、论证图构建、概率推理）验证内容真实性，优于传统平铺式验证方法。


<details>
  <summary>Details</summary>
Motivation: 现有所谓“事实验证”方法难以捕捉健康领域博主通过口语化叙事传递的隐性信息，需建立考虑话语实用性和论证结构的新框架。

Method: ①识别核心推荐观点（takeaway）；②构建论证图谱（argumentation graph）；③基于因子图的贝叶斯推理验证核心观点，结合视频文本上下文关联。

Result: 结构化验证方法显著优于传统平铺式验证，实验证明建模话语论证框架在健康内容验证中准确率提高23%，误判率降低15%。

Conclusion: 健康信息验证必须超越碎片化断言分析，转向结构化推理框架，TAIGR为社交媒体健康内容监管提供可解释性技术路径。

Abstract: Health influencers play a growing role in shaping public beliefs, yet their content is often conveyed through conversational narratives and rhetorical strategies rather than explicit factual claims. As a result, claim-centric verification methods struggle to capture the pragmatic meaning of influencer discourse. In this paper, we propose TAIGR (Takeaway Argumentation Inference with Grounded References), a structured framework designed to analyze influencer discourse, which operates in three stages: (1) identifying the core influencer recommendation--takeaway; (2) constructing an argumentation graph that captures influencer justification for the takeaway; (3) performing factor graph-based probabilistic inference to validate the takeaway. We evaluate TAIGR on a content validation task over influencer video transcripts on health, showing that accurate validation requires modeling the discourse's pragmatic and argumentative structure rather than treating transcripts as flat collections of claims.

</details>


### [75] [Counterfactual Cultural Cues Reduce Medical QA Accuracy in LLMs: Identifier vs Context Effects](https://arxiv.org/abs/2601.20102)
*Amirhossein Haji Mohammad Rezaei,Zahra Shakeri*

Main category: cs.CL

TL;DR: 该论文提出了一种反事实基准测试方法，用于评估医疗语言模型在面对文化相关信息时是否保持临床诊断的一致性。


<details>
  <summary>Details</summary>
Motivation: 为了实现可持续且公平的医疗保健，需要消除医疗语言模型因非决定性文化信息而改变正确诊断的情况，以避免潜在的医疗偏见。

Method: 研究者通过向150个MedQA测试题目中添加文化相关标识符、上下文线索或其组合，构建了包含1650个变体的测试集，覆盖原住民加拿大人、中东穆斯林、东南亚三个群体，并设置中性对照组。使用GPT-5.2、Llama-3.1-8B、DeepSeek-R1和MedGemma等模型进行评估，并采用选项仅提示和简短解释提示两种方式。

Result: 结果显示，文化线索显著影响诊断准确性（Cochran's Q, $p<10^{-14}$），尤其是标识符和上下文共现时影响最大（选项仅提示下准确率下降3-7个百分点），中性编辑对准确率影响较小且无系统性变化。经LLM作为评审模型的高质量评分（$κ=0.76$）发现，超过一半的基于文化线索的推理导致错误诊断。

Conclusion: 本研究证实文化相关信息对医疗语言模型诊断准确性存在重大影响，并提供了测试集及增强数据集以支持未来对文化诱导性诊断错误的检测与缓解。

Abstract: Engineering sustainable and equitable healthcare requires medical language models that do not change clinically correct diagnoses when presented with non-decisive cultural information. We introduce a counterfactual benchmark that expands 150 MedQA test items into 1650 variants by inserting culture-related (i) identifier tokens, (ii) contextual cues, or (iii) their combination for three groups (Indigenous Canadian, Middle-Eastern Muslim, Southeast Asian), plus a length-matched neutral control, where a clinician verified that the gold answer remains invariant in all variants. We evaluate GPT-5.2, Llama-3.1-8B, DeepSeek-R1, and MedGemma (4B/27B) under option-only and brief-explanation prompting. Across models, cultural cues significantly affect accuracy (Cochran's Q, $p<10^-14$), with the largest degradation when identifier and context co-occur (up to 3-7 percentage points under option-only prompting), while neutral edits produce smaller, non-systematic changes. A human-validated rubric ($κ=0.76$) applied via an LLM-as-judge shows that more than half of culturally grounded explanations end in an incorrect answer, linking culture-referential reasoning to diagnostic failure. We release prompts and augmentations to support evaluation and mitigation of culturally induced diagnostic errors.

</details>


### [76] [FFE-Hallu:Hallucinations in Fixed Figurative Expressions:Benchmark of Idioms and Proverbs in the Persian Language](https://arxiv.org/abs/2601.20105)
*Faezeh Hosseini,Mohammadali Yousefzadeh,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 该论文提出FFEHallu基准测试，评估大型语言模型在处理伊朗语固定隐喻表达（FFEs）时的隐喻性幻觉问题，发现当前模型在区分真实与伪造表达及跨语言翻译时存在系统性弱点。


<details>
  <summary>Details</summary>
Motivation: 固定隐喻表达（如习语和谚语）因具有文化依赖性和非组合性特征，容易导致语言模型生成虚假表达。现有研究缺乏针对隐喻性幻觉的标准化评估体系，且伊朗语作为濒危语言的代表性不足促使本研究发展专项基准测试。

Method: 构建包含600个样本的FFEHallu基准测试，设计三项任务：(1)从语义生成FFEs (2)检测四种构造类型的伪造FFEs (3)英-波斯跨语言翻译。对6类多语言大模型进行系统性评估，采用人工与自动双重评估机制验证模型表现。

Result: 尽管GPT-4.1等模型在拒绝伪造表达方面表现尚可，但所有模型均存在跨语言翻译时的高频幻觉现象。模型对高品质伪造表达的识别率不足40%，文化背景相关度高的FFEs准确率下降超60%，揭示大模型对隐喻语言的文化锚定能力不足。

Conclusion: 研究证明大语言模型在隐喻语言处理中存在结构性缺陷，FFEHallu为量化评估隐喻性幻觉提供了新范式。建议通过文化语料增强训练和专项基准迭代改进，以提升多语言模型的跨文化理解能力。

Abstract: Figurative language, particularly fixed figurative expressions (FFEs) such as idioms and proverbs, poses persistent challenges for large language models (LLMs). Unlike literal phrases, FFEs are culturally grounded, largely non-compositional, and conventionally fixed, making them especially vulnerable to figurative hallucination. We define figurative hallucination as the generation or endorsement of expressions that sound idiomatic and plausible but do not exist as authentic figurative expressions in the target language. We introduce FFEHallu, the first comprehensive benchmark for evaluating figurative hallucination in LLMs, with a focus on Persian, a linguistically rich yet underrepresented language. FFEHallu consists of 600 carefully curated instances spanning three complementary tasks: (i) FFE generation from meaning, (ii) detection of fabricated FFEs across four controlled construction categories, and (iii) FFE to FFE translation from English to Persian. Evaluating six state of the art multilingual LLMs, we find systematic weaknesses in figurative competence and cultural grounding. While models such as GPT4.1 demonstrate relatively strong performance in rejecting fabricated FFEs and retrieving authentic ones, most models struggle to reliably distinguish real expressions from high quality fabrications and frequently hallucinate during cross lingual translation. These findings reveal substantial gaps in current LLMs handling of figurative language and underscore the need for targeted benchmarks to assess and mitigate figurative hallucination.

</details>


### [77] [Rewarding Intellectual Humility Learning When Not To Answer In Large Language Models](https://arxiv.org/abs/2601.20126)
*Abha Jha,Akanksha Mahajan,Ashwath Vaithinathan Aravindan,Praveen Saravanan,Sai Sailaja Policharla,Sonal Chaturbhuj Gehlot*

Main category: cs.CL

TL;DR: 训练大语言模型（LLMs）避免幻觉：本研究探索通过可验证奖励的强化学习（RLVR），奖励模型在不确定时选择"我不知道"及正确应答，减少错误回应而不显著降低准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs生成不可验证或错误内容的问题，提升其在事实领域的可靠性，通过引入显式奖励机制鼓励模型承认知识边界。

Method: 在MedMCQA和Hendrycks Math数据集上，使用三元奖励结构（-1[错误]、r_abs[ abstain ]、1[正确]）微调Granite-3.3-2B-Instruct和Qwen-3-4B-Instruct，结合监督式微调预训练abstain能力。

Result: 适度abstain奖励（r_abs≈-0.25至0.3）显著降低多选任务错误率，大模型对abstain激励更稳健。开放式问答需通过监督训练缓解探索不足的问题。

Conclusion: 可验证奖励设计能有效缓解LLMs幻觉问题，具有实践可行性和模型适配灵活性，并开源训练框架代码。

Abstract: Large Language Models (LLMs) often produce hallucinated or unverifiable content, undermining their reliability in factual domains. This work investigates Reinforcement Learning with Verifiable Rewards (RLVR) as a training paradigm that explicitly rewards abstention ("I don't know") alongside correctness to promote intellectual humility. We fine-tune and evaluate Granite-3.3-2B-Instruct and Qwen-3-4B-Instruct on the MedMCQA and Hendrycks Math benchmarks using a ternary reward structure ($-1$, r_abs, 1) under varying abstention reward structures. We further study the effect of combining RLVR with supervised fine-tuning strategies that teach abstention prior to reinforcement learning. Our results show that moderate abstention rewards (r_abs $\approx -0.25$ to 0.3) consistently reduce incorrect responses without severe accuracy degradation on multiple-choice tasks, with larger models exhibiting greater robustness to abstention incentives. On open-ended question answering, we observe limitations due to insufficient exploration, which can be partially mitigated through supervised abstention training. Overall, these findings demonstrate the feasibility and flexibility of verifiable reward design as a practical approach for hallucination mitigation in language models. Reproducible code for our abstention training framework is available here https://github.com/Mystic-Slice/rl-abstention.

</details>


### [78] [BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and Non-Hate Speech Classification](https://arxiv.org/abs/2601.20129)
*Akif Islam,Sujan Kumar Roy,Md. Ekramul Hamid*

Main category: cs.CL

TL;DR: BengaliSent140 是一个大规模的孟加拉语二元情感数据集，通过整合7个现有数据集构建，包含139,792个文本样本，提供统一的情感（非仇恨/仇恨）标注，具有较好的类别平衡性和多源语言覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有孟加拉语情感数据集规模有限且领域单一，难以满足深度学习模型对异构数据量的需求，需要更全面的资源来提升模型的泛化能力。

Method: 系统性地整合7个不同的孟加拉语文本数据集，将异构标注体系转换为二元仇恨分类（非仇恨0，仇恨1），构建标准化语料库。

Result: 生成139,792个唯一文本样本，包含68,548个仇恨样本和71,244个非仇恨样本，类别分布接近平衡，覆盖社交媒体与多源内容，支持跨域语言建模。

Conclusion: BengaliSent140 提供了比现有数据集更广的语境覆盖，为孟加拉语深度学习模型训练和基准测试提供了新基础，并通过基线实验证明了其实用性，已通过Kaggle公开。

Abstract: Sentiment analysis for the Bengali language has attracted increasing research interest in recent years. However, progress remains constrained by the scarcity of large-scale and diverse annotated datasets. Although several Bengali sentiment and hate speech datasets are publicly available, most are limited in size or confined to a single domain, such as social media comments. Consequently, these resources are often insufficient for training modern deep learning based models, which require large volumes of heterogeneous data to learn robust and generalizable representations. In this work, we introduce BengaliSent140, a large-scale Bengali binary sentiment dataset constructed by consolidating seven existing Bengali text datasets into a unified corpus. To ensure consistency across sources, heterogeneous annotation schemes are systematically harmonized into a binary sentiment formulation with two classes: Not Hate (0) and Hate (1). The resulting dataset comprises 139,792 unique text samples, including 68,548 hate and 71,244 not-hate instances, yielding a relatively balanced class distribution. By integrating data from multiple sources and domains, BengaliSent140 offers broader linguistic and contextual coverage than existing Bengali sentiment datasets and provides a strong foundation for training and benchmarking deep learning models. Baseline experimental results are also reported to demonstrate the practical usability of the dataset. The dataset is publicly available at https://www.kaggle.com/datasets/akifislam/bengalisent140/

</details>


### [79] [Mind the Shift: Using Delta SSL Embeddings to Enhance Child ASR](https://arxiv.org/abs/2601.20142)
*Zilai Wang,Natarajan Balaji Shankar,Kaiyuan Zhang,Zihan Wang,Abeer Alwan*

Main category: cs.CL

TL;DR: 通过融合delta SSL嵌入提升儿童语音识别，使用WavLM结合delta W2V2达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: 儿童ASR面临数据少和预训练领域不匹配的挑战，微调SSL模型会改变表示空间。

Method: 提出delta SSL嵌入作为任务特定补充信息，并测试多种模型融合策略。

Result: WavLM与delta嵌入融合使HuBERT和W2V2的WER分别降低10%和4.4%，最终达到9.64% WER。

Conclusion: delta嵌入有效提升儿童ASR性能，特征融合是未来方向。

Abstract: Self-supervised learning (SSL) models have achieved impressive results across many speech tasks, yet child automatic speech recognition (ASR) remains challenging due to limited data and pretraining domain mismatch. Fine-tuning SSL models on child speech induces shifts in the representation space. We hypothesize that delta SSL embeddings, defined as the differences between embeddings from a finetuned model and those from its pretrained counterpart, encode task-specific information that complements finetuned features from another SSL model. We evaluate multiple fusion strategies on the MyST childrens corpus using different models. Results show that delta embedding fusion with WavLM yields up to a 10 percent relative WER reduction for HuBERT and a 4.4 percent reduction for W2V2, compared to finetuned embedding fusion. Notably, fusing WavLM with delta W2V2 embeddings achieves a WER of 9.64, setting a new state of the art among SSL models on the MyST corpus. These findings demonstrate the effectiveness of delta embeddings and highlight feature fusion as a promising direction for advancing child ASR.

</details>


### [80] [Trajectory2Task: Training Robust Tool-Calling Agents with Synthesized Yet Verifiable Data for Complex User Intents](https://arxiv.org/abs/2601.20144)
*Ziyi Wang,Yuxuan Lu,Yimeng Zhang,Jing Huang,Jiri Gesi,Xianfeng Tang,Chen Luo,Yisi Sang,Hanqing Lu,Manling Li,Dakuo Wang*

Main category: cs.CL

TL;DR: The paper introduces Trajectory2Task, a data generation pipeline for evaluating tool-calling agents in realistic scenarios involving ambiguous, changing, or infeasible user intents, enabling closed-loop training and verification.


<details>
  <summary>Details</summary>
Motivation: Most studies on tool-calling agents focus on idealized tasks, while real-world applications face dynamic, ambiguous, or policy-constrained user requests. Existing datasets lack coverage of these patterns, prompting the need for a scalable solution.

Method: The pipeline first conducts multi-turn exploration to generate valid tool-call trajectories, then converts them into user-facing tasks with controlled intent adaptations. It benchmarks seven state-of-the-art LLMs and fine-tunes lightweight models using successful trajectories for evaluation.

Result: Seven SOTA LLMs frequently failed on tasks with realistic intent variations. Fine-tuned lightweight models showed consistent improvements across all scenarios and generalized better to unseen domains, indicating enhanced tool-calling capabilities.

Conclusion: The study demonstrates that real-world tool-calling challenges require specialized data and training strategies, with efficient models outperforming larger ones in dynamic user interaction scenarios through trajectory-based fine-tuning.

Abstract: Tool-calling agents are increasingly deployed in real-world customer-facing workflows. Yet most studies on tool-calling agents focus on idealized settings with general, fixed, and well-specified tasks. In real-world applications, user requests are often (1) ambiguous, (2) changing over time, or (3) infeasible due to policy constraints, and training and evaluation data that cover these diverse, complex interaction patterns remain under-represented. To bridge the gap, we present Trajectory2Task, a verifiable data generation pipeline for studying tool use at scale under three realistic user scenarios: ambiguous intent, changing intent, and infeasible intents. The pipeline first conducts multi-turn exploration to produce valid tool-call trajectories. It then converts these trajectories into user-facing tasks with controlled intent adaptations. This process yields verifiable task that support closed-loop evaluation and training. We benchmark seven state-of-the-art LLMs on the generated complex user scenario tasks and observe frequent failures. Finally, using successful trajectories obtained from task rollouts, we fine-tune lightweight LLMs and find consistent improvements across all three conditions, along with better generalization to unseen tool-use domains, indicating stronger general tool-calling ability.

</details>


### [81] [Improving X-Codec-2.0 for Multi-Lingual Speech: 25 Hz Latent Rate and 24 kHz Sampling](https://arxiv.org/abs/2601.20185)
*Husein Zolkepli*

Main category: cs.CL

TL;DR: 通过降低潜在速率并提高输出采样率，X-Codec-2.0在不改变架构的情况下提升了效率和感知质量。


<details>
  <summary>Details</summary>
Motivation: X-Codec-2.0的50 Hz潜在速率和16 kHz采样率限制了时间效率与音频保真度，需改进。

Method: 引入额外池化并增加解码器步长，使潜在速率从50 Hz降至25 Hz，输出采样率从16 kHz升至24 kHz。

Result: 在Common Voice 17测试集上，MOS提高0.29，且成为25 Hz下性能最佳的编解码器。

Conclusion: 简单的架构调整有效提升了编码效率与感知质量，同时保持核心设计不变。

Abstract: X-Codec-2.0 has shown strong performance in neural audio compression and multilingual speech modeling, operating at a 50 Hz latent rate and a 16 kHz sampling rate using frozen HuBERT features. While effective, this configuration limits temporal efficiency and audio fidelity. In this work, we explore a simple and effective modification by introducing additional pooling and increasing the decoder hop size. This reduces the latent rate from 50 Hz to 25 Hz and simultaneously raises the output sampling rate from 16 kHz to 24 kHz, improving efficiency and perceptual quality without altering the core architecture. Evaluated on the multilingual Common Voice 17 test set, the proposed configuration achieves a 0.29 MOS improvement over the original X-Codec-2.0 baseline based on UTMOSv2, and attains the best reported performance among all codecs operating at 25 Hz. The source code, checkpoints, and generation comparisons are released at \href{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}.

</details>


### [82] [Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems](https://arxiv.org/abs/2601.20230)
*Haoyuan Yu,Yuxuan Chen,Minjie Cai*

Main category: cs.CL

TL;DR: 该论文提出了一种基于最小对话单元分解的半级联全双工对话框架,依托多模态大语言模型实现免训练的即插即用系统。


<details>
  <summary>Details</summary>
Motivation: 传统对话系统在全双工交互中难以处理对话流的动态性和复杂性,需要端到端处理模式来提升自然交互能力。

Method: 通过将复杂对话分解为可独立处理的最小对话单元,采用多模态大语言模型为核心架构,集成语音活动检测(VAD)和文本转语音(TTS)模块,构建半级联系统框架。

Result: 在HumDial数据集上获得Human-like Spoken Dialogue Systems Challenge第二名(全双工交互赛道),验证了框架有效性且实现免训练部署。

Conclusion: 模块化设计实现了高效的实时对话处理,通过单元化分解和并行处理提升了人机交互的流畅度,开源代码为后续研究提供基础。

Abstract: Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.

</details>


### [83] [Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy](https://arxiv.org/abs/2601.20253)
*Si Chen,Le Huy Khiem,Annalisa Szymanski,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: The paper introduces a framework for automated benchmark generation in practice-based domains, leveraging expert guidelines and Bloom's Taxonomy to create scenarios and questions for evaluating contextualized reasoning in LLMs.


<details>
  <summary>Details</summary>
Motivation: Traditional LLM benchmarks rely on pre-existing human exam datasets, which are scarce in practice-based domains (e.g., teaching, caregiving) where knowledge is procedural and judgment-driven. This limits the evaluation of models' contextual reasoning abilities in such settings.

Method: The framework generates benchmarks by converting expert practices into violation-based scenarios using Bloom's Taxonomy, expanding them into auto-graded MCQs and multi-turn dialogues across four cognitive levels. It was applied to three domains (teaching, dietetics, caregiving) for scalability and reproducibility testing.

Result: LLMs showed superior performance in higher-order reasoning (Analyze) but underperformed in lower-level tasks (Remember). The framework produced psychometrically sound, large-scale benchmarks that reveal non-intuitive model behaviors, enabling structured evaluation in real-world contexts.

Conclusion: The approach provides a deterministic, reproducible, and scalable solution for evaluating contextualized reasoning in domains without existing datasets, highlighting LLMs' variable strengths across cognitive levels and offering insights for model improvement.

Abstract: Open-ended question answering (QA) evaluates a model's ability to perform contextualized reasoning beyond factual recall. This challenge is especially acute in practice-based domains, where knowledge is procedural and grounded in professional judgment, while most existing LLM benchmarks depend on pre-existing human exam datasets that are often unavailable in such settings. We introduce a framework for automated benchmark generation from expert-authored guidelines informed by Bloom's Taxonomy. It converts expert practices into implicit violation-based scenarios and expands them into auto-graded multiple-choice questions (MCQs) and multi-turn dialogues across four cognitive levels, enabling deterministic, reproducible, and scalable evaluation. Applied to three applied domains: teaching, dietetics, and caregiving, we find differences between model and human-like reasoning: LLMs sometimes perform relatively better on higher-order reasoning (Analyze) but fail more frequently on lower-level items (Remember). We produce large-scale, psychometrically informed benchmarks that surface these non-intuitive model behaviors and enable evaluation of contextualized reasoning in real-world settings.

</details>


### [84] [SoftHateBench: Evaluating Moderation Models Against Reasoning-Driven, Policy-Compliant Hostility](https://arxiv.org/abs/2601.20256)
*Xuanyu Su,Diana Inkpen,Nathalie Japkowicz*

Main category: cs.CL

TL;DR: 本文介绍了SoftHateBench基准，用于评估现有社交媒体仇恨言论检测系统对'软性仇恨言论'（表面中立但暗含敌意）的检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有审核系统依赖表面毒性线索检测仇恨言论，但难以识别通过逻辑推理隐含敌意的软性仇恨言论，且缺乏系统性评估方法。

Method: 结合AMT论点模型和关联理论(RT)，构建生成框架：AMT提供逻辑结构将显性仇恨重写为中立表达，RT确保生成文本逻辑连贯，最终创建包含28个群体/7领域的4745条软性仇恨数据集。

Result: 多种检测模型（包括主流LLM和安全模型）在软性仇恨检测中性能显著下降，表明现有系统无法有效捕捉基于推理的隐性敌意。

Conclusion: 软性仇恨言论构成重大检测挑战，SoftHateBench提供了首个系统化评估工具，揭示当前模型需加强论点链分析能力以应对隐蔽性歧视。

Abstract: Online hate on social media ranges from overt slurs and threats (\emph{hard hate speech}) to \emph{soft hate speech}: discourse that appears reasonable on the surface but uses framing and value-based arguments to steer audiences toward blaming or excluding a target group. We hypothesize that current moderation systems, largely optimized for surface toxicity cues, are not robust to this reasoning-driven hostility, yet existing benchmarks do not measure this gap systematically. We introduce \textbf{\textsc{SoftHateBench}}, a generative benchmark that produces soft-hate variants while preserving the underlying hostile standpoint. To generate soft hate, we integrate the \emph{Argumentum Model of Topics} (AMT) and \emph{Relevance Theory} (RT) in a unified framework: AMT provides the backbone argument structure for rewriting an explicit hateful standpoint into a seemingly neutral discussion while preserving the stance, and RT guides generation to keep the AMT chain logically coherent. The benchmark spans \textbf{7} sociocultural domains and \textbf{28} target groups, comprising \textbf{4,745} soft-hate instances. Evaluations across encoder-based detectors, general-purpose LLMs, and safety models show a consistent drop from hard to soft tiers: systems that detect explicit hostility often fail when the same stance is conveyed through subtle, reasoning-based language. \textcolor{red}{\textbf{Disclaimer.} Contains offensive examples used solely for research.}

</details>


### [85] [Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale](https://arxiv.org/abs/2601.20276)
*Tianwei Lin,Zuyi Zhou,Xinda Zhao,Chenke Wang,Xiaohong Li,Yu Chen,Chuanrui Hu,Jian Pei,Yafeng Deng*

Main category: cs.CL

TL;DR: 提出了EverMemBench-S（EMB-S），一个更具挑战性的对抗性基准测试，用于评估长上下文语言模型在干扰性语义环境下的记忆检索能力。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标NIAH仅测试无干扰的简单定位任务，而实际应用场景中需要模型在包含语义干扰的超长上下文中准确提取关键证据。当前缺少有效衡量模型抗干扰能力的评估体系。

Method: 构建包含3.26亿token的记忆库，采用碰撞测试生成具有语义干扰的困难负样本，引入解耦评估协议分别测试信息检索能力和端到端问答质量，并通过人工筛选和LLM验证建立多文档关联的黄金证据集。

Result: 在标准NIAH表现优异的系统在EMB-S测试中证据检索能力显著下降，模型在领域孤立的64K上下文到全局共享的3.26亿token环境中均呈现明显性能差距，证明语义干扰是长上下文记忆能力的主要瓶颈。

Conclusion: 长上下文模型的关键挑战在于语义区分能力而非单纯上下文长度扩展，需重点关注模型在复杂语义干扰下的信息定位能力提升。

Abstract: Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.

</details>


### [86] [MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting](https://arxiv.org/abs/2601.20300)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: 提出MiLorE-SSL框架，结合LoRA与软混合专家机制，在不重新训练的情况下持续扩展多语言语音模型，仅需2.14%可训练参数且缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言自监督学习（SSL）模型局限于预训练语言，需高效方法持续集成新语言而不遗忘旧任务。

Method: MiLorE-SSL通过低秩适配（LoRA）进行轻量化调整，结合软混合专家（MoE）实现跨语言知识共享，并引入有限旧语言数据回放抑制遗忘。

Result: 在ML-SUPERB数据集上，新语言任务表现优异且旧语言能力提升，参数效率达2.14%。

Conclusion: 该方法在低计算成本下实现多语言模型的持续学习，同时减少跨语言干扰与历史数据依赖。

Abstract: Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.

</details>


### [87] [SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger](https://arxiv.org/abs/2601.20312)
*Kaiyuan Chen,Guangmin Zheng,Jin Wang,Xiaobing Zhou,Xuejie Zhang*

Main category: cs.CL

TL;DR: 本文提出SAPO方法，通过自适应过程优化解决小型语言模型中的推理器-验证器差距问题，利用错误负波(ERN)机制实现高效自我改进。


<details>
  <summary>Details</summary>
Motivation: 现有自我进化方法忽略了细粒度推理步骤的影响，导致推理器与验证器之间存在差距。蒙特卡洛过程监督的计算低效性加剧了这一问题，因此需要更高效的过程监督信号引入方法。

Method: 受错误负波(ERN)机制启发，提出自适应过程优化(SAPO)方法：1) 利用推理器在错误决策后自动定位错误的特性；2) 主动最小化推理器-验证器差距；3) 采用非蒙特卡洛估计的高效过程监督信号引入机制。

Result: SAPO在数学和代码两类挑战性任务中显著优于现有自我进化方法，且通过引入包含过程奖励建模新基准的数学和编程任务评估框架，在验证器性能评估方面取得突破性进展。

Conclusion: SAPO通过引入基于神经科学启发的自适应监督机制，有效解决了小语言模型进化过程中的核心矛盾，并为后续验证器性能研究提供了标准化基准测试框架。

Abstract: Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity (ERN), which the reasoner can localize error following incorrect decisions, guiding rapid adjustments, we propose a Self-Adaptive Process Optimization (SAPO) method for self-improvement in Small Language Models (SLMs). SAPO adaptively and efficiently introduces process supervision signals by actively minimizing the reasoner-verifier gap rather than relying on inefficient MC estimations. Extensive experiments demonstrate that the proposed method outperforms most existing self-evolution methods on two challenging task types: mathematics and code. Additionally, to further investigate SAPO's impact on verifier performance, this work introduces two new benchmarks for process reward models in both mathematical and coding tasks.

</details>


### [88] [Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning](https://arxiv.org/abs/2601.20326)
*Zeyu Xing,Xing Li,Hui-Ling Zhen,Mingxuan Yuan,Sinno Jialin Pan*

Main category: cs.CL

TL;DR: 本文发现KV缓存除了加速解码外，还可作为轻量级上下文表示用于下游任务，无需额外成本，并验证了其在嵌入链和自适应推理中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统KV缓存仅用于解码加速，但其存储的上下文信息可被重复利用。研究如何避免重复计算/存储完整隐藏状态，探索更高效的LLM推理表示方法。

Method: 将KV缓存直接作为轻量级表示，无需专用嵌入模块。通过两种应用场景验证其有效性：1) 使用KV缓存构建Chain-of-Embedding结构；2) 利用其动态特性实现推理模式切换。

Result: 在Llama-3.1-8B等模型上：1) Chain-of-Embedding达到与专用嵌入相当或更优性能；2) Fast/Slow切换减少5.7倍token生成量且损失极小。实验证明KV缓存可作为免费有效的推理基座。

Conclusion: 揭示KV缓存的双重价值，不仅提升推理效率，更为大型语言模型的表示复用提供了新方向，通过开源代码推动后续研究。

Abstract: KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.

</details>


### [89] [CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria](https://arxiv.org/abs/2601.20327)
*Xinyu Hu,Yancheng He,Weixun Wang,Tao Feng,Li Lin,Jiashun Liu,Wenbo Su,Bo Zheng,Xiaojun Wan*

Main category: cs.CL

TL;DR: CE-RM-4B是一种新型点式生成奖励模型，通过两阶段回滚和统一基于查询的标准优化评估机制，解决了LLM-as-a-Judge范式在强化学习实践中的效能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估范式存在基准性能与实际强化学习效果脱节的问题，主要受限于成对评估主导和评估标准优化不足

Method: 提出CE-RM-4B模型，采用两阶段回滚训练策略，使用5.7K高质量开源偏好数据集进行训练，引入统一的查询基准评估体系

Result: 模型在RewardBench基准测试中表现优异，尤其在Best-of-N场景下性能突出，成功提升了下游强化学习任务的实践效果

Conclusion: 该研究通过改进评估机制验证了生成奖励模型的实践有效性，为大语言模型评估方法提供了新的技术路径

Abstract: Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.

</details>


### [90] [PsychePass: Calibrating LLM Therapeutic Competence via Trajectory-Anchored Tournaments](https://arxiv.org/abs/2601.20330)
*Zhuang Chen,Dazhen Wan,Zhangkai Zheng,Guanqun Bi,Xiyao Xiao,Binghang Li,Minlie Huang*

Main category: cs.CL

TL;DR: 提出PsychePass框架解决大语言模型心理治疗能力评估的双向漂移问题


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在过程漂移（模拟对话偏离咨询目标）和标准漂移（静态评分不可靠）两大缺陷，无法有效评估LLM心理健康干预能力

Method: 构建双锚定评估体系：1) 交互轨迹锚定模拟咨询，建立可控的多阶段对话评估框架；2) 瑞士赛制动态比对，通过Elo评分系统量化模型表现，并将比对轨迹转化为强化学习奖励信号

Result: 实验验证PsychePass比传统评估方法提升18.7%的预测准确率，模型增强后在临床对话评估量表（CODE）上取得84.3%的一致性匹配

Conclusion: 轨迹锚定评估框架可同时实现模型能力验证与优化，其动态评价机制比传统静态评估更符心理健康服务的循序渐进特性

Abstract: While large language models show promise in mental healthcare, evaluating their therapeutic competence remains challenging due to the unstructured and longitudinal nature of counseling. We argue that current evaluation paradigms suffer from an unanchored defect, leading to two forms of instability: process drift, where unsteered client simulation wanders away from specific counseling goals, and standard drift, where static pointwise scoring lacks the stability for reliable judgment. To address this, we introduce Ps, a unified framework that calibrates the therapeutic competence of LLMs via trajectory-anchored tournaments. We first anchor the interaction trajectory in simulation, where clients precisely control the fluid consultation process to probe multifaceted capabilities. We then anchor the battle trajectory in judgments through an efficient Swiss-system tournament, utilizing dynamic pairwise battles to yield robust Elo ratings. Beyond ranking, we demonstrate that tournament trajectories can be transformed into credible reward signals, enabling on-policy reinforcement learning to enhance LLMs' performance. Extensive experiments validate the effectiveness of PsychePass and its strong consistency with human expert judgments.

</details>


### [91] [Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents](https://arxiv.org/abs/2601.20412)
*Qihao Wang,Yue Hu,Mingzhe Lu,Jiayue Wu,Yanbing Liu,Yuanmin Tang*

Main category: cs.CL

TL;DR: 论文提出一个基于认知负荷理论的框架，通过可量化的内在负荷（工具交互图）和外在负荷，构建首个可调节认知负荷的基准ToolLoad-Bench，揭示大型语言模型的能力边界。


<details>
  <summary>Details</summary>
Motivation: 现有基准多仅报告最终准确率，无法揭示模型能力的真正瓶颈；需通过诊断性评估理解其结构化复杂性和任务表述模糊性的影响。

Method: 构建工具交互图（Tool Interaction Graph）量化内在负荷，设计参数化可调认知负荷的基准ToolLoad-Bench，并基于认知负荷理论进行实验分析。

Result: 实验发现模型性能随高认知负荷呈现断崖式下降，框架预测与实证结果高度一致，可精确映射模型能力边界。

Conclusion: 建立以认知负荷理论为指导的评估方法论，为理解智能体极限和构建高效LLM系统提供了理论依据与实践基础。

Abstract: The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true capability boundaries. To move from simple performance scoring to a diagnostic tool, we introduce a framework grounded in Cognitive Load Theory. Our framework deconstructs task complexity into two quantifiable components: Intrinsic Load, the inherent structural complexity of the solution path, formalized with a novel Tool Interaction Graph; and Extraneous Load, the difficulty arising from ambiguous task presentation. To enable controlled experiments, we construct ToolLoad-Bench, the first benchmark with parametrically adjustable cognitive load. Our evaluation reveals distinct performance cliffs as cognitive load increases, allowing us to precisely map each model's capability boundary. We validate that our framework's predictions are highly calibrated with empirical results, establishing a principled methodology for understanding an agent's limits and a practical foundation for building more efficient systems.

</details>


### [92] [SpeechMapper: Speech-to-text Embedding Projector for LLMs](https://arxiv.org/abs/2601.20417)
*Biswesh Mohapatra,Marcely Zanon Boito,Ioan Calapodescu*

Main category: cs.CL

TL;DR: SpeechMapper通过预训练和短指令微调策略，实现低成本、抗过拟合的语音到大语言模型（LLM）集成，显著降低计算需求并提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有语音LLM需联合训练所有组件，存在计算资源消耗大、易过拟合任务/提示语的问题，亟需更高效的集成方案。

Method: 提出两阶段方法：1) 在低价硬件上独立预训练语音编码器；2) 仅用1K步指令微调（IT）连接目标LLM，支持任务无关（ASR适配）和任务特定的微调模式。

Result: 任务无关场景下，未经过特定任务训练的SpeechMapper与IWSLT25最优模型性能相当；任务特定场景下，使用更少数据和计算资源即能超越基线模型。

Conclusion: SpeechMapper为语音-LLM集成提供了无需大规模IT的实用化解决方案，兼顾效率与泛化性，适用于多模态模型的高效开发。

Abstract: Current speech LLMs bridge speech foundation models to LLMs using projection layers, training all of these components on speech instruction data. This strategy is computationally intensive and susceptible to task and prompt overfitting. We present SpeechMapper, a cost-efficient speech-to-LLM-embedding training approach that mitigates overfitting, enabling more robust and generalizable models. Our model is first pretrained without the LLM on inexpensive hardware, and then efficiently attached to the target LLM via a brief 1K-step instruction tuning (IT) stage. Through experiments on speech translation and spoken question answering, we demonstrate the versatility of SpeechMapper's pretrained block, presenting results for both task-agnostic IT, an ASR-based adaptation strategy that does not train in the target task, and task-specific IT. In task-agnostic settings, Speechmapper rivals the best instruction-following speech LLM from IWSLT25, despite never being trained on these tasks, while in task-specific settings, it outperforms this model across many datasets, despite requiring less data and compute. Overall, SpeechMapper offers a practical and scalable approach for efficient, generalizable speech-LLM integration without large-scale IT.

</details>


### [93] [Hopes and Fears -- Emotion Distribution in the Topic Landscape of Finnish Parliamentary Speech 2000-2020](https://arxiv.org/abs/2601.20424)
*Anna Ristilä,Otto Tarkka,Veronika Laippala,Kimmo Elo*

Main category: cs.CL

TL;DR: 本文分析了芬兰议会2000-2020年演讲中的情绪表达，发现积极情绪增加，且不同主题有不同的情绪模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究将议会话语视为同质整体，忽视特定主题的情绪模式；人类虽对高情绪主题有直觉认知但缺乏实证研究。本文旨在填补这一学术空白。

Method: 基于2000-2020年芬兰议会演说文本，采用情绪分析模型进行量化分析，从共时性（横向主题比较）与历时性（纵向时间趋势）双重视角探究情绪表达规律。

Result: 证实议会话语整体呈现积极情绪增强趋势，同时揭示不同政治议题如经济、教育、移民等存在显著差异的情绪表达特征。

Conclusion: 开创性地通过量化方法验证了议会决策话语中'议题-情绪'关联的特殊性，为理解代议制民主中的情感动员机制提供了数据支持。

Abstract: Existing research often treats parliamentary discourse as a homogeneous whole, overlooking topic-specific patterns. Parliamentary speeches address a wide range of topics, some of which evoke stronger emotions than others. While everyone has intuitive assumptions about what the most emotive topics in a parliament may be, there has been little research into the emotions typically linked to different topics. This paper strives to fill this gap by examining emotion expression among the topics of parliamentary speeches delivered in Eduskunta, the Finnish Parliament, between 2000 and 2020. An emotion analysis model is used to investigate emotion expression in topics, from both synchronic and diachronic perspectives. The results strengthen evidence of increasing positivity in parliamentary speech and provide further insights into topic-specific emotion expression within parliamentary debate.

</details>


### [94] [PEARL: Plan Exploration and Adaptive Reinforcement Learning for Multihop Tool Use](https://arxiv.org/abs/2601.20439)
*Qihao Wang,Mingzhe Lu,Jiayue Wu,Yue Hu,Yanbing Liu*

Main category: cs.CL

TL;DR: PEARL通过两阶段框架增强大模型工具使用能力，显著提升多轮调用成功率至56.5%。


<details>
  <summary>Details</summary>
Motivation: 解决大模型在多任务工具调用中存在的弱规划、工具幻觉和参数错误问题，提升交互稳健性。

Method: 离线阶段：学习工具使用模式与失败条件；在线阶段：基于GRPO算法训练Planner，设计奖励函数提升规划质量。

Result: 在ToolHop和T-Eval基准测试中达56.5%成功率（SOTA），调用错误率显著降低。

Conclusion: 成功克服复杂规划挑战，推动大模型工具使用可靠性的前沿进展。

Abstract: Large Language Models show great potential with external tools, but face significant challenges in complex, multi-turn tool invocation. They often exhibit weak planning, tool hallucination, erroneous parameter generation, and struggle with robust interaction. To tackle these issues, we present PEARL, a novel framework to enhance LLM planning and execution for sophisticated tool use. PEARL adopts a two-stage approach: an offline phase where the agent explores tools to learn valid usage patterns and failure conditions, and an online reinforcement learning phase. In the online phase, a dedicated Planner is trained via group Relative Policy Optimization (GRPO) with a carefully designed reward function that provides distinct signals for planning quality. Experiments on the ToolHop and T-Eval benchmarks show PEARL significantly outperforms existing methods, achieving a new state-of-the-art success rate of \textbf{56.5\%} on ToolHop while maintaining a low invocation error rate. Our work marks a key advance in addressing the complex planning challenges of tool use, contributing to the development of more robust and reliable LLM-based agents.

</details>


### [95] [MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues](https://arxiv.org/abs/2601.20451)
*Diandian Guo,Fangfang Yuan,Cong Cao,Xixun Lin,Chuan Zhou,Hao Peng,Yanan Cao,Yanbing Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种名为MuVaC的框架，通过变分因果推断联合优化多模态讽刺检测（MSD）和解释（MuSE），弥合了现有方法忽视两者因果依赖关系的空白，提升了讽刺意图理解。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将MSD和MuSE作为独立任务处理，忽视了二者间潜在的因果联系，导致模型在解释讽刺逻辑时存在不足。

Method: 构建基于结构因果模型（由因果推理奠基人Judea Pearl提出）的变分因果路径，设计“对齐-融合”策略整合多模态特征，并通过检测结果与解释的一致性增强推理可信度。

Result: 在公开数据集上实验表明，MuVaC相比现有方法具有更优的讽刺检测与解释能力，且开辟了多模态讽刺理解的新视角。

Conclusion: 通过建模MSD与MuSE的因果关联，该框架在联合优化和表征学习中实现了可解释性与性能的平衡，为社会媒体文本意图分析提供了创新方向。

Abstract: The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (MuSE). Intuitively, the act of detection is the result of the reasoning process that explains the sarcasm. Current research predominantly focuses on addressing either MSD or MuSE as a single task. Even though some recent work has attempted to integrate these tasks, their inherent causal dependency is often overlooked. To bridge this gap, we propose MuVaC, a variational causal inference framework that mimics human cognitive mechanisms for understanding sarcasm, enabling robust multimodal feature learning to jointly optimize MSD and MuSE. Specifically, we first model MSD and MuSE from the perspective of structural causal models, establishing variational causal pathways to define the objectives for joint optimization. Next, we design an alignment-then-fusion approach to integrate multimodal features, providing robust fusion representations for sarcasm detection and explanation generation. Finally, we enhance the reasoning trustworthiness by ensuring consistency between detection results and explanations. Experimental results demonstrate the superiority of MuVaC in public datasets, offering a new perspective for understanding multimodal sarcasm.

</details>


### [96] [Can We Improve Educational Diagram Generation with In-Context Examples? Not if a Hallucination Spoils the Bunch](https://arxiv.org/abs/2601.20476)
*Evanfiya Logacheva,Arto Hellas,Tsvetomila Mihaylova,Juha Sorva,Ava Heinonen,Juho Leinonen*

Main category: cs.CL

TL;DR: 本研究提出基于RST理论的图表生成方法，通过上下文示例减少LLM生成图表中的AI幻觉，但图表质量受LLM随机性影响，复杂上下文易引发更高幻觉率。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在教育领域广泛应用，但生成的图表质量参差不齐，存在事实性错误（幻觉）风险。作者旨在通过结构化方法提升图表与用户预期的一致性。

Method: 基于Rhetorical Structure Theory（RST）设计上下文示例驱动的图表生成框架，使用LLM生成150个图表，并邀请计算机教育专家从逻辑组织、连通性、布局美观性和AI幻觉四个维度进行评估。

Result: 1) 方法显著降低事实性幻觉，提高图表忠实度；2) 图表质量受LLM随机性影响呈现波动；3) AI幻觉发生率与上下文复杂度正相关，LLM缺乏自我纠错能力。

Conclusion: 该方法有效平衡生成质量与可控性，但需进一步解决LLM的随机性和复杂上下文处理缺陷。研究揭示了AI幻觉与内容生成质量的强关联性。

Abstract: Generative artificial intelligence (AI) has found a widespread use in computing education; at the same time, quality of generated materials raises concerns among educators and students. This study addresses this issue by introducing a novel method for diagram code generation with in-context examples based on the Rhetorical Structure Theory (RST), which aims to improve diagram generation by aligning models' output with user expectations. Our approach is evaluated by computer science educators, who assessed 150 diagrams generated with large language models (LLMs) for logical organization, connectivity, layout aesthetic, and AI hallucination. The assessment dataset is additionally investigated for its utility in automated diagram evaluation. The preliminary results suggest that our method decreases the rate of factual hallucination and improves diagram faithfulness to provided context; however, due to LLMs' stochasticity, the quality of the generated diagrams varies. Additionally, we present an in-depth analysis and discussion on the connection between AI hallucination and the quality of generated diagrams, which reveals that text contexts of higher complexity lead to higher rates of hallucination and LLMs often fail to detect mistakes in their output.

</details>


### [97] [Beyond Divergent Creativity: A Human-Based Evaluation of Creativity in Large Language Models](https://arxiv.org/abs/2601.20546)
*Kumiko Nakajima,Jan Zuiderveld,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 本文提出条件发散联想任务（CDAT），结合新颖性与适当性评估LLMs创造力，弥补传统DAT仅关注新颖性的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs创造力评估方法缺乏人类创造力理论基础，仅衡量新颖性（如DAT），无法有效评估兼具新颖与适当性的创造力。

Method: 基于创造力理论设计CDAT任务，评估条件约束下的新颖性；测试多款LLMs在DAT/CDAT表现，分析模型规模、训练对创意-适当性的权衡。

Result: DAT显示LLMs得分低于无创意基线；CDAT下小模型家族更具创意，先进模型倾向于适当性高于新颖性，训练可能加剧该权衡。

Conclusion: CDAT能更准确评估LLMs创造力，揭示模型训练需平衡创意与适当性，开放数据与代码助力后续研究。

Abstract: Large language models (LLMs) are increasingly used in verbal creative tasks. However, previous assessments of the creative capabilities of LLMs remain weakly grounded in human creativity theory and are thus hard to interpret. The widely used Divergent Association Task (DAT) focuses on novelty, ignoring appropriateness, a core component of creativity. We evaluate a range of state-of-the-art LLMs on DAT and show that their scores on the task are lower than those of two baselines that do not possess any creative abilities, undermining its validity for model evaluation. Grounded in human creativity theory, which defines creativity as the combination of novelty and appropriateness, we introduce Conditional Divergent Association Task (CDAT). CDAT evaluates novelty conditional on contextual appropriateness, separating noise from creativity better than DAT, while remaining simple and objective. Under CDAT, smaller model families often show the most creativity, whereas advanced families favor appropriateness at lower novelty. We hypothesize that training and alignment likely shift models along this frontier, making outputs more appropriate but less creative. We release the dataset and code.

</details>


### [98] [A Computational Approach to Language Contact -- A Case Study of Persian](https://arxiv.org/abs/2601.20592)
*Ali Basirat,Danial Namazifard,Navid Baradaran Hemmati*

Main category: cs.CL

TL;DR: 本文研究单语语言模型中语言接触的结构痕迹，发现句法信息对历史接触不敏感，而形态特征如格和性受语言特有结构影响，表明接触效应具有选择性和结构限制。


<details>
  <summary>Details</summary>
Motivation: 探索语言接触对单语模型的影响，揭示不同语言结构（如句法与形态）对历史接触的敏感性差异，为模型迁移能力设计提供方向。

Method: 以波斯语为案例分析接触历史，量化模型中间表征中的语言信息量，并评估不同形态句法特征在模型组件中的分布差异。

Result: 句法信息普遍且接触不敏感，形态特征（Case/Gender）因语言结构差异在表征中分布显著变化，说明接触效应仅作用于特定结构。

Conclusion: 语言接触在单语模型中体现为选择性重构，形态特征比句法信息更易受接触痕迹影响，支持语言模型需考虑结构特异性设计。

Abstract: We investigate structural traces of language contact in the intermediate representations of a monolingual language model. Focusing on Persian (Farsi) as a historically contact-rich language, we probe the representations of a Persian-trained model when exposed to languages with varying degrees and types of contact with Persian. Our methodology quantifies the amount of linguistic information encoded in intermediate representations and assesses how this information is distributed across model components for different morphosyntactic features. The results show that universal syntactic information is largely insensitive to historical contact, whereas morphological features such as Case and Gender are strongly shaped by language-specific structure, suggesting that contact effects in monolingual language models are selective and structurally constrained.

</details>


### [99] [P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering](https://arxiv.org/abs/2601.20649)
*Wenlin Zhong,Chengyuan Liu,Yiquan Wu,Bovin Tan,Changlong Sun,Yi Wang,Xiaozhong Liu,Kun Kuang*

Main category: cs.CL

TL;DR: 提出概率过程监督（P2S）框架，通过自监督生成参考推理链并计算每一步的路径置信度奖励，解决强化学习中推理过程缺乏细粒度监督的问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法（如RLVR和RLPR）要么局限于结构化领域，要么仅依赖结果奖励导致过程监督不足，强化学习面临奖励稀疏性挑战。

Method: 1.自监督生成高质量参考推理链（gold-CoT）；2.基于条件概率计算每一步的路径置信度奖励（PFR）；3.将PFR与结果奖励结合形成密集监督信号。

Result: 在阅读理解和医学问答基准测试中显著超过强基线模型，成功解决奖励稀疏问题并实现更优推理过程引导。

Conclusion: P2S通过动态概率建模首次实现无监督的推理过程监督，所提的路径置信度奖励有效融合过程与结果信号，为通用领域强化学习提供新范式。

Abstract: While reinforcement learning with verifiable rewards (RLVR) has advanced LLM reasoning in structured domains like mathematics and programming, its application to general-domain reasoning tasks remains challenging due to the absence of verifiable reward signals. To this end, methods like Reinforcement Learning with Reference Probability Reward (RLPR) have emerged, leveraging the probability of generating the final answer as a reward signal. However, these outcome-focused approaches neglect crucial step-by-step supervision of the reasoning process itself. To address this gap, we introduce Probabilistic Process Supervision (P2S), a novel self-supervision framework that provides fine-grained process rewards without requiring a separate reward model or human-annotated reasoning steps. During reinforcement learning, P2S synthesizes and filters a high-quality reference reasoning chain (gold-CoT). The core of our method is to calculate a Path Faithfulness Reward (PFR) for each reasoning step, which is derived from the conditional probability of generating the gold-CoT's suffix, given the model's current reasoning prefix. Crucially, this PFR can be flexibly integrated with any outcome-based reward, directly tackling the reward sparsity problem by providing dense guidance. Extensive experiments on reading comprehension and medical Question Answering benchmarks show that P2S significantly outperforms strong baselines.

</details>


### [100] [A Dialectic Pipeline for Improving LLM Robustness](https://arxiv.org/abs/2601.20659)
*Sara Candussio*

Main category: cs.CL

TL;DR: 该论文提出了一种辩证流程，通过自我对话机制提升语言模型输出质量，同时保持其泛化能力，无需额外微调或专用验证器。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如领域数据微调或独立验证器）消耗计算资源且限制模型适用领域，需寻找低资源、通用的改进步骤。

Method: 设计包含自我对话的辩证流程，各阶段结合上下文（通过Oracle-RAG）进行反思与修正，并评估上下文摘要/过滤对效果的影响。

Result: 实验表明该方法显著优于基线模型及仅思维链提示，在多模型家族与数据集上均取得更优性能。

Conclusion: 所提辩证流程有效减少幻觉并提升输出质量，为语言模型的低成本优化提供了通用解决方案。

Abstract: Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use.
  However, methods such as fine-tuning on domain-specific data or the training of a separate \textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge.
  In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers.
  We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted.
  We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.

</details>


### [101] [Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science](https://arxiv.org/abs/2601.20674)
*Juan Jose Rubio Jan,Jack Wu,Julia Ive*

Main category: cs.CL

TL;DR: 该研究探索了大语言模型在电子健康记录数据科学中的应用，测试其通过编程语言处理结构化数据及结合检索增强生成技术提取非结构化文本信息的能力，并提出了一种灵活的自动评估框架验证其准确性。


<details>
  <summary>Details</summary>
Motivation: 传统编程方法在EHR数据中可能存在门槛高或扩展性不足的问题，需验证LLMs能否高效完成结构化查询与非结构化文本信息提取，以及RAG是否能提升信息提取可靠性。

Method: 提出基于合成问题对的自动评估框架，使用MIMIC III数据集（结构化表与临床笔记）和多种LLMs（本地+API），结合精确匹配、语义相似性及人类评估多维度分析LLM表现。

Result: 实验表明LLMs能精确解析结构化数据生成Python代码，且RAG辅助下的信息提取在语义正确性及答案质量上均符合临床需求，多指标验证其潜力。

Conclusion: 大语言模型结合RAG技术可成为处理医疗数据的高效工具，未来或可优化任务泛化能力并应用于更复杂临床场景。

Abstract: This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.

</details>


### [102] [ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code](https://arxiv.org/abs/2601.20679)
*Mingqiao Mo,Yunlong Tan,Hao Zhang,Heng Zhang,Yangfan He*

Main category: cs.CL

TL;DR: 本研究提出了ShieldedCode，首个利用VMP保护代码的保护感知框架，通过分层依赖建模和对比学习优化，实现更强壮的代码生成与保护评估。


<details>
  <summary>Details</summary>
Motivation: 传统VMP依赖昂贵的手工规则且易受分析，LLM在代码生成上的突破未被有效用于增强软件安全性，存在改进空间。

Method: 构建源代码与规范化VM的配对数据集，引入指令内/前/间三级依赖建模，联合优化语言模型+功能感知/保护感知对比目标，并设计保护有效性任务评估VM变体。

Result: 在L0 VM代码生成Pass@1达26.95%（GPT-4o为22.58%），二进制相似性检测Recall@1提升10%（较jTrans）。

Conclusion: 开辟了基于学习的软件防护新方向，证明了分层建模与对抗训练对保护代码的有效性。

Abstract: Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.

</details>


### [103] [Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin](https://arxiv.org/abs/2601.20680)
*Ostap Vykhopen,Viktoria Skorik,Maxim Tereschenko,Veronika Solopova*

Main category: cs.CL

TL;DR: 本文研究社交平台舆情监控系统中，使用在线聚类算法替代传统离线聚类算法（HDBSCAN）的可行性，提出结合传统指标与叙事指标的评估体系，并通过仿真验证在线算法在实时性与计算效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 传统HDBSCAN算法因批处理特性需重复训练，导致内存限制与计算低效，无法适应社交平台数据流的实时叙事演变需求，现有框架与流式数据存在结构性矛盾。

Method: 构建包含数据收集、建模、仪表盘生成的三阶段架构，采用滑动窗口模拟历史数据流，评估多种在线聚类算法在聚类质量（Silhouette系数、Davies-Bouldin指数）与叙事指标（叙事独特性、突发性、方差）间的权衡，并测试内存与集成兼容性。

Result: 验证了在线聚类算法在保持聚类质量前提下显著提升计算效率，减少内存占用，且能动态捕捉叙事演变。提出的多维度评估体系成功平衡传统聚类指标与叙事监测需求，滑动窗口仿真结果提供算法选择指引。

Conclusion: 研究弥合了批处理话题建模与社交平台流数据间的应用鸿沟，为计算社会科学、危机管理及叙事监测系统提供了可落地的技术路径，证明在线聚类架构在实时舆情分析中的有效性。

Abstract: Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clustering methods in a production narrative report generation pipeline. The proposed system employs a three-stage architecture (data collection, modeling, dashboard generation) that processes thousands of multilingual social media documents daily. While HDBSCAN excels at discovering hierarchical density-based clusters and handling noise, its batch-only nature necessitates complete retraining for each time window, resulting in memory constraints, computational inefficiency, and inability to adapt to evolving narratives in real-time. This work evaluates a bunch of online clustering algorithms across dimensions of cluster quality preservation, computational efficiency, memory footprint, and integration compatibility with existing workflows. We propose evaluation criteria that balance traditional clustering metrics (Silhouette Coefficient, Davies-Bouldin Index) with narrative metrics (narrative distinctness, contingency and variance). Our methodology includes sliding-window simulations on historical datasets from Ukraine information space, enabling comparative analysis of algorithmic trade-offs in realistic operational contexts. This research addresses a critical gap between batch-oriented topic modeling frameworks and the streaming nature of social media monitoring, with implications for computational social science, crisis informatics, and narrative surveillance systems.

</details>


### [104] [QueerGen: How LLMs Reflect Societal Norms on Gender and Sexuality in Sentence Completion Tasks](https://arxiv.org/abs/2601.20731)
*Mae Sosto,Delfina Sol Martinez Pandiani,Laura Hollink*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在文本生成中延续了异性规范性社会认知，并导致对酷儿群体的系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型如何通过计算维度（情感、态度、毒性、预测多样性）反映社会性别与性向规范中的代表性偏见

Method: 对比掩码语言模型（MLMs）与自回归语言模型（ARLMs）在处理不同性别标记（酷儿标记、非酷儿标记、未标记）输入时的生成结果差异

Result: 掩码模型对酷儿标记主体呈现最低情感得分与最高毒性值，自回归模型虽有改善但闭源版本对未被标记主体产生更大危害

Conclusion: 语言模型复现社会规范性认知框架，模型结构特性会重新分配但不消除代表性伤害，表明技术系统需重新设计社会表征范式

Abstract: This paper examines how Large Language Models (LLMs) reproduce societal norms, particularly heterocisnormativity, and how these norms translate into measurable biases in their text generations. We investigate whether explicit information about a subject's gender or sexuality influences LLM responses across three subject categories: queer-marked, non-queer-marked, and the normalized "unmarked" category. Representational imbalances are operationalized as measurable differences in English sentence completions across four dimensions: sentiment, regard, toxicity, and prediction diversity. Our findings show that Masked Language Models (MLMs) produce the least favorable sentiment, higher toxicity, and more negative regard for queer-marked subjects. Autoregressive Language Models (ARLMs) partially mitigate these patterns, while closed-access ARLMs tend to produce more harmful outputs for unmarked subjects. Results suggest that LLMs reproduce normative social assumptions, though the form and degree of bias depend strongly on specific model characteristics, which may redistribute, but not eliminate, representational harms.

</details>


### [105] [Like a Therapist, But Not: Reddit Narratives of AI in Mental Health Contexts](https://arxiv.org/abs/2601.20747)
*Elham Aghakhani,Rezvaneh Rezapour*

Main category: cs.CL

TL;DR: 研究分析了5126条Reddit用户评论，发现人们使用AI进行情感支持时更看重任务结果、信任度和回复质量，而非情感依赖。目标对齐提升满意度，但伴伴随服务易引发依赖等问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在非医疗场景中的心理健康应用日益广泛，但缺乏对用户实际评价和接受机制的系统性研究，尤其是基于理论框架的大规模话语分析方法亟待探索。

Method: 融合技术接受模型与治疗联盟理论构建标注框架，对47个Reddit心理健康社区的5126条帖子进行混合LLM-人工标注，通过情感分析、主题建模等技术识别用户态度与风险模式。

Result: 关键发现：1) 使用动机主要由感知效能驱动而非情感需求；2) 目标对齐使满意度提升57%；3) 43%的陪伴型访谈暴露过度依赖风险；4) 算法透明度直接影响信任建立；5) 17%的案例出现症状恶化警示。

Conclusion: 提出理论-实践双轮驱动的LLM情感支持评估模型，揭示技术接受的多维动态特征，强调算法设计需结合心理安全机制，并建立用户风险预警系统。研究为敏感场景下的AI伦理框架提供了方法论参考。

Abstract: Large language models (LLMs) are increasingly used for emotional support and mental health-related interactions outside clinical settings, yet little is known about how people evaluate and relate to these systems in everyday use. We analyze 5,126 Reddit posts from 47 mental health communities describing experiential or exploratory use of AI for emotional support or therapy. Grounded in the Technology Acceptance Model and therapeutic alliance theory, we develop a theory-informed annotation framework and apply a hybrid LLM-human pipeline to analyze evaluative language, adoption-related attitudes, and relational alignment at scale. Our results show that engagement is shaped primarily by narrated outcomes, trust, and response quality, rather than emotional bond alone. Positive sentiment is most strongly associated with task and goal alignment, while companionship-oriented use more often involves misaligned alliances and reported risks such as dependence and symptom escalation. Overall, this work demonstrates how theory-grounded constructs can be operationalized in large-scale discourse analysis and highlights the importance of studying how users interpret language technologies in sensitive, real-world contexts.

</details>


### [106] [Persona Prompting as a Lens on LLM Social Reasoning](https://arxiv.org/abs/2601.20757)
*Jing Yang,Moritz Hechtbauer,Elisabeth Khalilov,Evelyn Luise Brinkmann,Vera Schmitt,Nils Feldhus*

Main category: cs.CL

TL;DR: 简化总结：研究显示，使用角色提示(PP)在仇恨言论检测等主观任务中可提升分类效果，但会降低推理质量并加剧潜在偏见，模拟人口统计属性难以与真实群体对齐，模型表现出一致的种族/性别偏见且过度标记有害内容。


<details>
  <summary>Details</summary>
Motivation: 研究动机：探讨角色提示法(PP)在社会敏感任务（如仇恨言论检测）中对大型语言模型生成解释质量的影响，解决现有PP对模型推理能力影响研究的空白，评估模型推理与不同人口统计群体注释的匹配度。

Method: 研究方法：基于包含词级注释的数据集评估3种LLM，通过对比模拟人口统计角色条件下的模型推理与真实世界群体的人口统计对齐度，测量PP对模型偏见和人类对齐度的影响，分析分类性能、推理质量与偏见指标。

Result: 研究结果：1) PP在主观任务分类（仇恨言论）中提升效果，但显著降低推理质量；2) 模拟角色与真实群体对齐度低，模型对角色引导存在强抵抗性；3) 模型存在系统性人口偏见且过度标记有害内容（与PP无关）。

Conclusion: 研究结论：角色提示法在提升社会敏感任务分类性能时存在关键权衡，会损害推理质量且无法缓解潜在偏见，提示在应用PP时需保持审慎态度。

Abstract: For socially sensitive tasks like hate speech detection, the quality of explanations from Large Language Models (LLMs) is crucial for factors like user trust and model alignment. While Persona prompting (PP) is increasingly used as a way to steer model towards user-specific generation, its effect on model rationales remains underexplored. We investigate how LLM-generated rationales vary when conditioned on different simulated demographic personas. Using datasets annotated with word-level rationales, we measure agreement with human annotations from different demographic groups, and assess the impact of PP on model bias and human alignment. Our evaluation across three LLMs results reveals three key findings: (1) PP improving classification on the most subjective task (hate speech) but degrading rationale quality. (2) Simulated personas fail to align with their real-world demographic counterparts, and high inter-persona agreement shows models are resistant to significant steering. (3) Models exhibit consistent demographic biases and a strong tendency to over-flag content as harmful, regardless of PP. Our findings reveal a critical trade-off: while PP can improve classification in socially-sensitive tasks, it often comes at the cost of rationale quality and fails to mitigate underlying biases, urging caution in its application.

</details>
