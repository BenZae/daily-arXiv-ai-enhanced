<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 35]
- [cs.CL](#cs.CL) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Egocentric Bias in Vision-Language Models](https://arxiv.org/abs/2602.15892)
*Maijunxian Wang,Yijiang Li,Bingyang Wang,Tianwei Zhao,Ran Ji,Qingying Gao,Emmy Liu,Hokin Deng,Dezhi Luo*

Main category: cs.CV

TL;DR: 论文提出FlipSet基准，评估视觉语言模型（VLMs）二级视觉视角转换（L2 VPT）能力，发现当前模型存在严重自我中心偏差，无法整合社会意识与空间推理。


<details>
  <summary>Details</summary>
Motivation: 视觉视角转换是社会认知基础，但现有VLMs在整合心智理论与空间操作时表现不足，需通过新型诊断工具（如隔离复杂3D场景的纯空间任务）揭示其局限。

Method: 构建FlipSet数据集，要求模型模拟180度旋转2D字符的视角转换，评估103个VLMs表现；通过单独测试心智理论和心理旋转任务控制变量，分析模型组合能力缺陷。

Result: 多数模型表现低于随机水平，75%错误复现原始视角；控制实验显示模型能独立处理心智理论和空间旋转，但需整合时表现崩溃，暴露模块化处理缺陷。

Conclusion: 当前VLMs缺乏绑定社会感知与空间推理的核心机制，FlipSet为多模态系统提供认知科学基础的视角转换测试框架，揭示模型需改进组合泛化能力。

Abstract: Visual perspective taking--inferring how the world appears from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D scene complexity. Evaluating 103 VLMs reveals systematic egocentric bias: the vast majority perform below chance, with roughly three-quarters of errors reproducing the camera viewpoint. Control experiments expose a compositional deficit--models achieve high theory-of-mind accuracy and above-chance mental rotation in isolation, yet fail catastrophically when integration is required. This dissociation indicates that current VLMs lack the mechanisms needed to bind social awareness to spatial operations, suggesting fundamental limitations in model-based spatial reasoning. FlipSet provides a cognitively grounded testbed for diagnosing perspective-taking capabilities in multimodal systems.

</details>


### [2] [Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment](https://arxiv.org/abs/2602.15903)
*Jingwei Li,Jiaxin Tong,Pengfei Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于CLIP引导的多变量软融合增强框架MSBA-CLIP，用于提升深伪人脸图像检测的鲁棒性和泛化能力，通过创新的伪造强度估计模块实现跨域检测性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法因不同生成技术导致的样本分布偏移而面临准确率低和泛化性差的问题，特别是在面对多样化伪造模式和强度变化时模型表现不足。

Method: 1. 提出多变量软融合增强（MSBA）策略，通过随机权重融合多种伪造方法生成图像；2. 设计多变量伪造强度估计（MFIE）模块，显式引导模型学习不同伪造模式及强度特征；3. 利用CLIP的多模态对齐能力捕捉微小伪造痕迹。

Result: 在领域内测试中，准确率和AUC分别提升3.32%和4.02%；跨域测试在五个数据集上平均AUC提升3.27%；消融实验证明MSBA和MFIE组件均有效，但存在计算成本增加的折衷。

Conclusion: 该框架显著提升了深度伪造人脸检测的泛化性与鲁棒性，尽管依赖大模型带来计算负担，但为构建更可靠的检测系统提供了新思路。

Abstract: The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\% and 4.02\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.

</details>


### [3] [A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving](https://arxiv.org/abs/2602.15904)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: 本论文是关于自动驾驶中LiDAR超分辨率方法的首项全面调查，通过深度学习增强低分辨率LiDAR传感器的稀疏点云，以弥补不同传感器类型之间的差距并实现跨传感器兼容性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率LiDAR传感器价格昂贵，而经济型低分辨率传感器生成的点云稀疏且缺乏关键细节。目前缺乏对LiDAR超分辨率方法的系统性综述，尤其在实际部署中需解决跨传感器兼容性和实时性等挑战。

Method: 将现有方法分为四类：基于CNN的架构、基于模型的深度展开、隐式表示方法以及基于Transformer和Mamba的模型，系统分析数据表示方法、问题建模、基准数据集、评估指标及近期趋势。

Result: 总结出当前方法采用距离图像表示提升效率、极端模型压缩及分辨率自适应架构的趋势，并发现近来研究侧重于实时推理和跨传感器泛化能力的优化。

Conclusion: 论文揭示了LiDAR超分辨率领域的开放性挑战（如动态场景处理、模型鲁棒性），并指出未来需结合多模态数据和改进稀疏点云建模方法以推动技术发展。

Abstract: LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sensors produce sparse point clouds that miss critical details. LiDAR super-resolution addresses this challenge by using deep learning to enhance sparse point clouds, bridging the gap between different sensor types and enabling cross-sensor compatibility in real-world deployments. This paper presents the first comprehensive survey of LiDAR super-resolution methods for autonomous driving. Despite the importance of practical deployment, no systematic review has been conducted until now. We organize existing approaches into four categories: CNN-based architectures, model-based deep unrolling, implicit representation methods, and Transformer and Mamba-based approaches. We establish fundamental concepts including data representations, problem formulation, benchmark datasets and evaluation metrics. Current trends include the adoption of range image representation for efficient processing, extreme model compression and the development of resolution-flexible architectures. Recent research prioritizes real-time inference and cross-sensor generalization for practical deployment. We conclude by identifying open challenges and future research directions for advancing LiDAR super-resolution technology.

</details>


### [4] [EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](https://arxiv.org/abs/2602.15918)
*Zelin Xu,Yupu Zhang,Saugat Adhikari,Saiful Islam,Tingsong Xiao,Zibo Liu,Shigang Chen,Da Yan,Zhe Jiang*

Main category: cs.CV

TL;DR: 提出EarthSpatialBench，首个针对地球影像空间推理的多模态大模型基准测试，包含32.5万问答对，覆盖定量方向/距离推理、拓扑关系及复杂几何结构解析。


<details>
  <summary>Details</summary>
Motivation: 现有地球影像基准测试仅关注二维空间定位和粗略空间关系，缺乏对定量空间推理（方向/距离）、系统性拓扑关系建模，以及复杂几何结构（如多边形）的支持，阻碍了AI在精确物理交互场景的发展。

Method: 构建包含四大维度的基准：定量/定性空间推理、单物体/组合查询、多模态对象引用（文本/坐标/可视化覆盖）、系统性拓扑关系测试，并采用2D框/折线/多边形等几何标注进行严格评估。

Result: 实验证明现有MLLM在定量空间计算准确率低于40%，对复杂几何关系识别率不足30%，且多模型存在5-10%的方向推理系统性偏差，揭示了结构化空间表征能力不足的核心问题。

Conclusion: EarthSpatialBench揭示了多模态大模型在几何感知与拓扑建模上的根本性缺陷，为导航、城市规划等依赖空间推理的实际应用提供标准化测评框架，推动具身智能的物理世界交互能力研究。

Abstract: Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geometry coordinates (e.g., 2D bounding boxes, polylines, and polygons). Existing benchmarks for Earth imagery primarily focus on 2D spatial grounding, image captioning, and coarse spatial relations (e.g., simple directional or proximity cues). They lack support for quantitative direction and distance reasoning, systematic topological relations, and complex object geometries beyond bounding boxes. To fill this gap, we propose \textbf{EarthSpatialBench}, a comprehensive benchmark for evaluating spatial reasoning in MLLMs on Earth imagery. The benchmark contains over 325K question-answer pairs spanning: (1) qualitative and quantitative reasoning about spatial distance and direction; (2) systematic topological relations; (3) single-object queries, object-pair queries, and compositional aggregate group queries; and (4) object references expressed via textual descriptions, visual overlays, and explicit geometry coordinates, including 2D bounding boxes, polylines, and polygons. We conducted extensive experiments on both open-source and proprietary models to identify limitations in the spatial reasoning of MLLMs.

</details>


### [5] [A Study on Real-time Object Detection using Deep Learning](https://arxiv.org/abs/2602.15926)
*Ankita Bose,Jayasravani Bhumireddy,Naveen N*

Main category: cs.CV

TL;DR: 本文综述了实时物体检测的深度学习算法，涵盖模型比较、应用场景及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 物体检测在多领域具有重要应用，深度学习的进步提升了检测效率与精度，亟需系统性总结现有方法与挑战。

Method: 分析主流模型（如YOLO、Faster R-CNN）、开放数据集、跨应用案例，并通过对照实验比较算法性能。

Result: 揭示不同策略的优劣，明确实时检测的技术瓶颈，并提出未来研究方向。

Conclusion: 为领域研究者提供方法论参考，强调实时检测对动态场景决策的重要性，并倡导探索更高效的算法框架。

Abstract: Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.

</details>


### [6] [Visual Memory Injection Attacks for Multi-Turn Conversations](https://arxiv.org/abs/2602.15927)
*Christian Schlarmann,Matthias Hein*

Main category: cs.CV

TL;DR: 本文提出了一种新型隐蔽攻击方法VMI，通过修改图片在长周期多轮对话环境中劫持视觉-语言大模型输出目标指令，证明了当前主流LVLM在多轮对话场景下的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究动机源自两个方向：1）LVLM在用户激增背景下存在安全机制研究空白，2）现有单轮攻击防御机制无法应对长周期多轮对话中的新型威胁。


Method: 攻击方法包含两个关键阶段：1）攻击者在图片预处理时注入记忆痕迹，在标准输入下不影响模型输出；2）利用模型历史对话上下文敏感性，通过设计特定触发指令激活预埋内容。


Result: 1）实验验证VMI在LLaVAR、MiniGPT-4等多个主流模型上攻击成功率超90%；2）攻击效果可持续超过15轮对话，且扰动幅度低于4% PSNR不影响人眼辨识；3）攻击效果随对话轮次呈现指数衰减特性。


Conclusion: 研究揭示了多模态大模型在长周期互动场景中的系统性安全风险，实验表明现有防御措施对跨对话轮次的协同攻击防护能力薄弱。开源代码与实验数据已公开。

Abstract: Generative large vision-language models (LVLMs) have recently achieved impressive performance gains, and their user base is growing rapidly. However, the security of LVLMs, in particular in a long-context multi-turn setting, is largely underexplored. In this paper, we consider the realistic scenario in which an attacker uploads a manipulated image to the web/social media. A benign user downloads this image and uses it as input to the LVLM. Our novel stealthy Visual Memory Injection (VMI) attack is designed such that on normal prompts the LVLM exhibits nominal behavior, but once the user gives a triggering prompt, the LVLM outputs a specific prescribed target message to manipulate the user, e.g. for adversarial marketing or political persuasion. Compared to previous work that focused on single-turn attacks, VMI is effective even after a long multi-turn conversation with the user. We demonstrate our attack on several recent open-weight LVLMs. This article thereby shows that large-scale manipulation of users is feasible with perturbed images in multi-turn conversation settings, calling for better robustness of LVLMs against these attacks. We release the source code at https://github.com/chs20/visual-memory-injection

</details>


### [7] [Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families](https://arxiv.org/abs/2602.15950)
*Yuval Levental*

Main category: cs.CV

TL;DR: 研究揭示视觉-语言模型（VLMs）在定位无文本特征的填充网格时存在显著缺陷，即使所有模型共享同一视觉编码器，含文本符号的图像识别准确率（~91%）远超纯填充方块（60-73%）；三大前沿模型均出现不同模式的失败，但核心问题在于非文本视觉元素的定位能力严重退化。


<details>
  <summary>Details</summary>
Motivation: 揭示VLMs是否依赖高保真文本识别路径进行空间推理，并验证其原生视觉路径在非文本任务中的性能缺陷。

Method: 设计15×15二值网格实验，生成含文本符号（.、#）和纯填充方块两类图像，使用Claude Opus、ChatGPT 5.2、Gemini 3 Thinking进行转录测试，并量化分析其在不同条件下的性能差异及失败模式。

Result: 文本符号条件下Claude和ChatGPT的单元格准确率约91%、F1分数84%，Gemini为84%准确率/63% F1；填充方块条件下所有模型准确率降至60-73%、F1降至29-39%，F1差距达34-54个百分点，且呈现不同错误模式（系统性漏检、过检、模板幻觉）

Conclusion: VLMs的空间推理能力高度依赖文本识别路径，对非文本视觉元素的定位能力存在根本性缺陷，其原生视觉处理途径性能显著劣于文本驱动的认知机制。

Abstract: We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% filled cells) and render each as two image types -- text symbols (. and #) and filled squares without gridlines -- then ask three frontier VLMs (Claude Opus, ChatGPT 5.2, and Gemini 3 Thinking) to transcribe them. In the text-symbol condition, Claude and ChatGPT achieve approximately 91% cell accuracy and 84% F1, while Gemini achieves 84% accuracy and 63% F1. In the filled-squares condition, all three models collapse to 60-73% accuracy and 29-39% F1. Critically, all conditions pass through the same visual encoder -- the text symbols are images, not tokenized text. The text-vs-squares F1 gap ranges from 34 to 54 points across models, demonstrating that VLMs behave as if they possess a high-fidelity text-recognition pathway for spatial reasoning that dramatically outperforms their native visual pathway. Each model exhibits a distinct failure mode in the squares condition -- systematic under-counting (Claude), massive over-counting (ChatGPT), and template hallucination (Gemini) -- but all share the same underlying deficit: severely degraded spatial localization for non-textual visual elements.

</details>


### [8] [Position-Aware Scene-Appearance Disentanglement for Bidirectional Photoacoustic Microscopy Registration](https://arxiv.org/abs/2602.15959)
*Yiwen Wang,Jiahao Qin*

Main category: cs.CV

TL;DR: 本研究提出GPEReg-Net框架，通过领域不变特征解耦和全局位置编码，在无需显式形变场估计的前提下实现双向扫描光声显微成像的高精度配准，成像速度提升2倍的同时显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 双向扫描OR-PAM技术虽可成像速度提升2倍，但存在领域漂移/几何错位问题。传统亮度恒定约束方法配准质量有限，生成对抗方法结构复杂且缺乏时序关联建模能力。

Method: 1. 设计AdaIN场景特征解耦模块，分离领域无关特征(Lambdaf)与领域特定外观编码(Lambdav)
2. 构建全局位置编码(GPE)模块，集成可学习位置嵌入与正弦编码
3. 采用跨帧注意力机制建模时序结构，最终实现端到端图像配准

Result: 在OR-PAM-Reg-4K数据集(432测试样本)取得NCC 0.953/SSIM 0.932/PSNR 34.49dB，SSIM指标领先SOTA方法3.8%，PSNR提升1.99dB，且运算效率达42帧/秒

Conclusion: GPEReg-Net通过解耦架构创新和时空联合建模，突破了传统配准方法的固有限制，首次实现双向扫描OR-PAM数据的实时高质量配准，为高速生物成像提供有效解决方案。

Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing registration methods, constrained by brightness constancy assumptions, achieve limited alignment quality, while recent generative approaches address domain shift through complex architectures that lack temporal awareness across frames. We propose GPEReg-Net, a scene-appearance disentanglement framework that separates domain-invariant scene features from domain-specific appearance codes via Adaptive Instance Normalization (AdaIN), enabling direct image-to-image registration without explicit deformation field estimation. To exploit temporal structure in sequential acquisitions, we introduce a Global Position Encoding (GPE) module that combines learnable position embeddings with sinusoidal encoding and cross-frame attention, allowing the network to leverage context from neighboring frames for improved temporal coherence. On the OR-PAM-Reg-4K benchmark (432 test samples), GPEReg-Net achieves NCC of 0.953, SSIM of 0.932, and PSNR of 34.49dB, surpassing the state-of-the-art by 3.8% in SSIM and 1.99dB in PSNR while maintaining competitive NCC. Code is available at https://github.com/JiahaoQin/GPEReg-Net.

</details>


### [9] [Non-Contact Physiological Monitoring in Pediatric Intensive Care Units via Adaptive Masking and Self-Supervised Learning](https://arxiv.org/abs/2602.15967)
*Mohamed Khalil Ben Salah,Philippe Jouvet,Rita Noumeir*

Main category: cs.CV

TL;DR: This paper proposes a self-supervised pretraining framework using VisionMamba architecture with adaptive masking and curriculum learning to enhance rPPG accuracy for pediatric vital sign monitoring in PICUs, overcoming motion artifacts and data scarcity issues.


<details>
  <summary>Details</summary>
Motivation: To address skin irritation and infection risks from contact sensors in PICUs while overcoming technical challenges (motion artifacts, occlusions, domain shifts) hindering clinical deployment of contactless rPPG technology.

Method: Developed self-supervised pretraining with progressive curriculum strategy (clean data → synthetic occlusions → clinical data) using VisionMamba architecture with adaptive masking mechanism controlled by Mamba-based controller; implemented teacher-student distillation using public dataset-trained expert model to guide unlabeled PICU video training.

Result: Achieved 42% reduction in mean absolute error compared to standard masked autoencoders and 31% improvement over PhysFormer, reaching 3.2 bpm MAE; demonstrated robust physiological region-of-interest attention without explicit localization under clinical occlusions/noise conditions.

Conclusion: The proposed framework effectively enables accurate, contactless cardiac monitoring in challenging clinical environments through curriculum-guided self-supervised learning that bridges the gap between controlled datasets and real-world PICU conditions.

Abstract: Continuous monitoring of vital signs in Pediatric Intensive Care Units (PICUs) is essential for early detection of clinical deterioration and effective clinical decision-making. However, contact-based sensors such as pulse oximeters may cause skin irritation, increase infection risk, and lead to patient discomfort. Remote photoplethysmography (rPPG) offers a contactless alternative to monitor heart rate using facial video, but remains underutilized in PICUs due to motion artifacts, occlusions, variable lighting, and domain shifts between laboratory and clinical data.
  We introduce a self-supervised pretraining framework for rPPG estimation in the PICU setting, based on a progressive curriculum strategy. The approach leverages the VisionMamba architecture and integrates an adaptive masking mechanism, where a lightweight Mamba-based controller assigns spatiotemporal importance scores to guide probabilistic patch sampling. This strategy dynamically increases reconstruction difficulty while preserving physiological relevance.
  To address the lack of labeled clinical data, we adopt a teacher-student distillation setup. A supervised expert model, trained on public datasets, provides latent physiological guidance to the student. The curriculum progresses through three stages: clean public videos, synthetic occlusion scenarios, and unlabeled videos from 500 pediatric patients.
  Our framework achieves a 42% reduction in mean absolute error relative to standard masked autoencoders and outperforms PhysFormer by 31%, reaching a final MAE of 3.2 bpm. Without explicit region-of-interest extraction, the model consistently attends to pulse-rich areas and demonstrates robustness under clinical occlusions and noise.

</details>


### [10] [LAND: A Longitudinal Analysis of Neuromorphic Datasets](https://arxiv.org/abs/2602.15973)
*Gregory Cohen,Alexandre Marcireau*

Main category: cs.CV

TL;DR: 尽管神经形态数据集数量激增，但相关研究仍面临数据不足和标准化缺失等问题，本文提出通过元数据集减少数据需求并降低任务定义偏见。


<details>
  <summary>Details</summary>
Motivation: 神经形态计算领域存在数据获取、理解与使用困难，且当前数据集缺乏统一标准，需系统分析现有数据集问题并提出解决方案。

Method: 综述分析了423个现有神经形态数据集的任务类型及数据结构，评估其规模增长趋势与合成数据使用的影响。

Result: 发现数据集存在体量过大、标准化不足、访问复杂度高问题，并指出合成数据虽有助于算法测试，但可能限制新技术探索。

Conclusion: 提出元数据集概念，主张通过重组现有数据减少新数据采集需求，并降低研究者定义数据与任务时的主观偏见。

Abstract: Neuromorphic engineering has a data problem. Despite the meteoric rise in the number of neuromorphic datasets published over the past ten years, the conclusion of a significant portion of neuromorphic research papers still states that there is a need for yet more data and even larger datasets. Whilst this need is driven in part by the sheer volume of data required by modern deep learning approaches, it is also fuelled by the current state of the available neuromorphic datasets and the difficulties in finding them, understanding their purpose, and determining the nature of their underlying task. This is further compounded by practical difficulties in downloading and using these datasets. This review starts by capturing a snapshot of the existing neuromorphic datasets, covering over 423 datasets, and then explores the nature of their tasks and the underlying structure of the presented data. Analysing these datasets shows the difficulties arising from their size, the lack of standardisation, and difficulties in accessing the actual data. This paper also highlights the growth in the size of individual datasets and the complexities involved in working with the data. However, a more important concern is the rise of synthetic datasets, created by either simulation or video-to-events methods. This review explores the benefits of simulated data for testing existing algorithms and applications, highlighting the potential pitfalls for exploring new applications of neuromorphic technologies. This review also introduces the concepts of meta-datasets, created from existing datasets, as a way of both reducing the need for more data, and to remove potential bias arising from defining both the dataset and the task.

</details>


### [11] [MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report Retrieval](https://arxiv.org/abs/2602.16019)
*Ahmad Elallaf,Yu Zhang,Yuktha Priya Masupalli,Jeong Yang,Young Lee,Zechun Cao,Gongbo Liang*

Main category: cs.CV

TL;DR: MedProbCLIP是一种概率视觉-语言学习框架，用于改进胸部X光和放射报告表示学习，在生物医学应用中提升检索可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型的确定性嵌入在高风险医疗场景中可靠性不足，需构建具备不确定量化能力的多模态框架。

Method: 通过概率对比目标学习高斯嵌入，采用变分信息瓶颈防止过度置信预测，并设计多视角X光编码和多段落报告编码实现细粒度临床对应关系建模。

Result: 在MIMIC-CXR数据集上超越CLIP等基线模型，展示出更优的检索性能、零样本分类效果，以及更佳的置信度校准、风险覆盖率和抗干扰鲁棒性。

Conclusion: 概率视觉-语言建模能显著提升医疗文本-图像检索系统的可信度与安全性，为高风险医疗应用提供可靠多模态解决方案。

Abstract: Vision-language foundation models have emerged as powerful general-purpose representation learners with strong potential for multimodal understanding, but their deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications. This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and radiology report representation learning and bidirectional retrieval. MedProbCLIP models image and text representations as Gaussian embeddings through a probabilistic contrastive objective that explicitly captures uncertainty and many-to-many correspondences between radiographs and clinical narratives. A variational information bottleneck mitigates overconfident predictions, while MedProbCLIP employs multi-view radiograph encoding and multi-section report encoding during training to provide fine-grained supervision for clinically aligned correspondence, yet requires only a single radiograph and a single report at inference. Evaluated on the MIMIC-CXR dataset, MedProbCLIP outperforms deterministic and probabilistic baselines, including CLIP, CXR-CLIP, and PCME++, in both retrieval and zero-shot classification. Beyond accuracy, MedProbCLIP demonstrates superior calibration, risk-coverage behavior, selective retrieval reliability, and robustness to clinically relevant corruptions, underscoring the value of probabilistic vision-language modeling for improving the trustworthiness and safety of radiology image-text retrieval systems.

</details>


### [12] [LGQ: Learning Discretization Geometry for Scalable and Stable Image Tokenization](https://arxiv.org/abs/2602.16086)
*Idil Bilge Altun,Mert Onur Cakiroglu,Elham Buxton,Mehmet Dalkilic,Hasan Kurban*

Main category: cs.CV

TL;DR: 本论文提出了一种名为可学习几何量化(LGQ)的图像分词器，旨在解决离散图像分词中的容量利用与语义结构保留问题，通过端到端学习离散化几何结构，显著提升生成质量并减少有效代码使用量。


<details>
  <summary>Details</summary>
Motivation: 现有矢量量化分词器存在优化偏差和码本利用率低的问题，而结构化分词器因采用固定离散化几何结构导致容量分配效率低下。研究旨在结合两者的优点，实现灵活可学习的几何结构与高效容量利用。

Method: LGQ替代传统最近邻查找为温度控制的软分配，实现完全可微训练并保留推理阶段硬分配特性。该分配对应各向同性高斯混合模型的后验责任，通过极小化变分自由能目标函数实现，并引入峰度正则化和全局使用正则化项。

Result: 在ImageNet的VQGAN框架下，16K码本尺寸时LGQ较FSQ提升11.88% rFID性能且活跃代码减少49.96%，较SimVQ提升6.06% rFID且有效表征率降低49.45%。

Conclusion: LGQ成功平衡了代码利用率与学习动态性，在保证高保真度前提下有效减少活跃代码使用量，为可扩展视觉生成系统提供新方法。

Abstract: Discrete image tokenization is a key bottleneck for scalable visual generation: a tokenizer must remain compact for efficient latent-space priors while preserving semantic structure and using discrete capacity effectively. Existing quantizers face a trade-off: vector-quantized tokenizers learn flexible geometries but often suffer from biased straight-through optimization, codebook under-utilization, and representation collapse at large vocabularies. Structured scalar or implicit tokenizers ensure stable, near-complete utilization by design, yet rely on fixed discretization geometries that may allocate capacity inefficiently under heterogeneous latent statistics.
  We introduce Learnable Geometric Quantization (LGQ), a discrete image tokenizer that learns discretization geometry end-to-end. LGQ replaces hard nearest-neighbor lookup with temperature-controlled soft assignments, enabling fully differentiable training while recovering hard assignments at inference. The assignments correspond to posterior responsibilities of an isotropic Gaussian mixture and minimize a variational free-energy objective, provably converging to nearest-neighbor quantization in the low-temperature limit. LGQ combines a token-level peakedness regularizer with a global usage regularizer to encourage confident yet balanced code utilization without imposing rigid grids.
  Under a controlled VQGAN-style backbone on ImageNet across multiple vocabulary sizes, LGQ achieves stable optimization and balanced utilization. At 16K codebook size, LGQ improves rFID by 11.88% over FSQ while using 49.96% fewer active codes, and improves rFID by 6.06% over SimVQ with 49.45% lower effective representation rate, achieving comparable fidelity with substantially fewer active entries. Our GitHub repository is available at: https://github.com/KurbanIntelligenceLab/LGQ

</details>


### [13] [OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis](https://arxiv.org/abs/2602.16110)
*Tianwei Lin,Zhongwei Qiu,Wenqiao Zhang,Jiang Liu,Yihan Xie,Mingjian Gao,Zhenxuan Fan,Zhaocheng Li,Sijing Li,Zhongle Xie,Peng LU,Yueting Zhuang,Yingda Xia,Ling Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: OmniCT通过统一切片与体积建模解决CT影像分析中微观点特征与空间连续性割裂的瓶颈问题，提出三重创新：空间一致性增强模块、器官语义增强模块及全球首个CT切片-体积联合基准数据库。


<details>
  <summary>Details</summary>
Motivation: 当前大视觉语言模型在CT分析中存在碎片化问题：切片模型无法保持层间空间一致性，体积模型则缺乏细节刻画能力，阻碍临床转化。需建立统一建模范式以实现精准医学影像分析。

Method: 1) 空间一致性增强(SCE)：采用三轴位置编码的体积切片组合与混合专家投影技术；2) 器官语义增强(OSE)：通过分割与兴趣区域定位强化解剖结构语义；3) 构建MedEval-CT数据集作为跨模态评估基准。

Result: 在多个临床任务中均显著优于现有方法，既保持亚厘米级病灶检测精度，又实现肿瘤浸润等宏观空间关系推理，建立医学跨模态理解新范式。

Conclusion: 该成果解决了CT多尺度分析的核心矛盾，为下一代医学影像智能系统提供了可扩展的统一框架，在微观点特征捕捉与全视野空间推理间取得关键突破。

Abstract: Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, lesion boundaries) and volume-driven spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). However, existing Large Vision-Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. We present OmniCT, a powerful unified slice-volume LVLM for CT scenarios, which makes three contributions: (i) Spatial Consistency Enhancement (SCE): volumetric slice composition combined with tri-axial positional embedding that introduces volumetric consistency, and an MoE hybrid projection enables efficient slice-volume adaptation; (ii) Organ-level Semantic Enhancement (OSE): segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; (iii) MedEval-CT: the largest slice-volume CT dataset and hybrid benchmark integrates comprehensive metrics for unified evaluation. OmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks and satisfies both micro-level detail sensitivity and macro-level spatial reasoning. More importantly, it establishes a new paradigm for cross-modal medical imaging understanding.

</details>


### [14] [CHAI: CacHe Attention Inference for text2video](https://arxiv.org/abs/2602.16132)
*Joel Mathew Cherian,Ashutosh Muralidhara Bharadwaj,Vima Gupta,Anand Padmanabha Iyer*

Main category: cs.CV

TL;DR: CHAI加速文本到视频扩散模型推理，通过跨推理缓存与选择性注意力机制，在减少去噪步骤（最低8步）的同时保持视频质量，较OpenSora 1.2提速1.65-3.35倍。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到视频扩散模型因3D潜变量串行去噪导致的推理缓慢问题，同时避免依赖模型重训练或启发式步骤跳过（后者会显著降低视频质量）

Method: 提出Cache Attention机制：1) 跨不同推理任务缓存共享的物体/场景潜变量；2) 通过选择性注意力机制复用语义相关提示的缓存潜变量，实现高效缓存命中。无需修改模型结构即可直接集成到现有系统

Result: 在仅8步去噪的情况下生成高质量视频，与基线OpenSora 1.2相比：1) 缓存命中率显著提升；2) 推理速度提升1.65-3.35倍；3) 视频质量（FID等指标）保持基线水平

Conclusion: CHAI验证了跨推理缓存与选择性注意力机制的有效性，为扩散模型高效部署提供了新方向，特别是在视频生成场景下可显著降低计算成本而不牺牲输出质量

Abstract: Text-to-video diffusion models deliver impressive results but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to reduce latency while maintaining video quality. We introduce Cache Attention as an effective method for attending to shared objects/scenes across cross-inference latents. This selective attention mechanism enables effective reuse of cached latents across semantically related prompts, yielding high cache hit rates. We show that it is possible to generate high-quality videos using Cache Attention with as few as 8 denoising steps. When integrated into the overall system, CHAI is 1.65x - 3.35x faster than baseline OpenSora 1.2 while maintaining video quality.

</details>


### [15] [IRIS: Intent Resolution via Inference-time Saccades for Open-Ended VQA in Large Vision-Language Models](https://arxiv.org/abs/2602.16138)
*Parsa Madinei,Srijita Karmakar,Russell Cohen Hoffing,Felix Gervitz,Miguel P. Eckstein*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的实时虹膜追踪方法(IRIS)，通过结合用户实时眼动数据解析视觉问答(VQA)的模糊语义，使模糊问题的作答准确率从35.2%提升至77.2%，同时保持对明确问题的原有表现。


<details>
  <summary>Details</summary>
Motivation: 传统VQA模型难以处理自然语言中存在的语义模糊现象，且现有解决方案常需重新训练模型。作者发现人类提问时的眼动焦点能有效反映意图，这启发开发基于眼动追踪的非侵入式实时消歧技术。

Method: 通过500组图像-问题对的用户实验，量化对比不同时间窗口眼动数据对消歧效果的影响。提出将问题开始时间点附近的注视焦点作为最优特征，并构建了支持眼动数据输入的新型VQA评估协议和基准数据集。

Result: 在多个先进视觉语言模型（VLM）上验证，融合眼动数据后模糊问题准确率提升119%（35.2%→77.2%），且模型架构差异不影响效果。实验还确定了提问前200ms至提问开始期间的眼动序列最为关键。

Conclusion: 实时眼动追踪可显著增强VQA系统对模糊语义的解析能力，该方法的训练无关性和跨模型通用性为交互式视觉问答开辟了新路径，所构建的基准数据集和协议将推动该领域发展。

Abstract: We introduce IRIS (Intent Resolution via Inference-time Saccades), a novel training-free approach that uses eye-tracking data in real-time to resolve ambiguity in open-ended VQA. Through a comprehensive user study with 500 unique image-question pairs, we demonstrate that fixations closest to the time participants start verbally asking their questions are the most informative for disambiguation in Large VLMs, more than doubling the accuracy of responses on ambiguous questions (from 35.2% to 77.2%) while maintaining performance on unambiguous queries. We evaluate our approach across state-of-the-art VLMs, showing consistent improvements when gaze data is incorporated in ambiguous image-question pairs, regardless of architectural differences. We release a new benchmark dataset to use eye movement data for disambiguated VQA, a novel real-time interactive protocol, and an evaluation suite.

</details>


### [16] [Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing](https://arxiv.org/abs/2602.16149)
*Huichan Seo,Minki Hong,Sieun Choi,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 该论文研究了图像到图像（I2I）编辑中基于人口统计学（种族、性别、年龄）的偏差问题，提出两种失败模式：软性抹除（编辑被弱化）和刻板印象替换（添加刻板特征）。通过构建受控基准测试和提示限制技术，发现当前系统在少数群体中普遍存在身份保留失败现象，并建议改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注文字-图像生成的偏见，而指令引导的图像-图像编辑中的系统性偏差未被充分探索。当前I2I编辑器可能隐含社会先验，导致不同群体编辑结果不公平，需建立评估框架并提供解决方案。

Method: 1. 提出软性抹除和刻板印象替换两种失败模式；2. 构建包含种族/性别/年龄条件的肖像生成与编辑基准；3. 结合视觉语言模型评分和人工评估分析多个编辑器表现；4. 提出无需模型更新的提示级身份约束策略缓解偏差。

Result: 实验发现身份保留问题普遍存在且呈现人口差异，少数群体更易被软性抹除，刻板特征高频出现（如职业性别关联）。新提示策略减少少数群体身份改动而不影响多数群体，揭示编辑器存在非对称身份先验。

Conclusion: 论文确立身份保留为I2I编辑的核心失败模式，其偏差具有人口统计学不对称性。建议开发考虑人口统计鲁棒性的编辑系统，并可通过提示工程缓解现有模型偏差。

Abstract: Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-guided image-to-image (I2I) editing remain underexplored. We examine whether identical edit instructions yield systematically different outcomes across subject demographics in open-weight I2I editors. We formalize two failure modes: Soft Erasure, where edits are silently weakened or ignored in the output image, and Stereotype Replacement, where edits introduce unrequested, stereotype-consistent attributes. We introduce a controlled benchmark that probes demographic-conditioned behavior by generating and editing portraits conditioned on race, gender, and age using a diagnostic prompt set, and evaluate multiple editors with vision-language model (VLM) scoring and human evaluation. Our analysis shows that identity preservation failures are pervasive, demographically uneven, and shaped by implicit social priors, including occupation-driven gender inference. Finally, we demonstrate that a prompt-level identity constraint, without model updates, can substantially reduce demographic change for minority groups while leaving majority-group portraits largely unchanged, revealing asymmetric identity priors in current editors. Together, our findings establish identity preservation as a central and demographically uneven failure mode in I2I editing and motivate demographic-robust editing systems. Project page: https://seochan99.github.io/i2i-demographic-bias

</details>


### [17] [DataCube: A Video Retrieval Platform via Natural Language Semantic Profiling](https://arxiv.org/abs/2602.16231)
*Yiming Ju,Hanyu Zhao,Quanyue Ma,Donglin Hao,Chengwei Wu,Ming Li,Songjing Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: DataCube是一个自动化视频处理和高效检索的智能平台，通过结构化语义表示与混合检索技术，帮助用户高效构建定制化视频数据集。


<details>
  <summary>Details</summary>
Motivation: 大规模视频库缺乏高效转换为任务专用数据集的工具，现有方法成本高且效率低，亟需智能化解决方案。

Method: 构建视频的结构化语义表示，结合神经重排序与深度语义匹配进行混合检索，并提供交互式Web界面支持用户定制与私有化部署。

Result: 用户可从海量视频中高效构建训练/分析所需子集，支持私有视频库的语义搜索系统搭建。

Conclusion: DataCube通过自动化语义解析和交互式检索，显著降低视频数据处理门槛，提升大规模视频应用效率。

Abstract: Large-scale video repositories are increasingly available for modern video understanding and generation tasks. However, transforming raw videos into high-quality, task-specific datasets remains costly and inefficient. We present DataCube, an intelligent platform for automatic video processing, multi-dimensional profiling, and query-driven retrieval. DataCube constructs structured semantic representations of video clips and supports hybrid retrieval with neural re-ranking and deep semantic matching. Through an interactive web interface, users can efficiently construct customized video subsets from massive repositories for training, analysis, and evaluation, and build searchable systems over their own private video collections. The system is publicly accessible at https://datacube.baai.ac.cn/. Demo Video: https://baai-data-cube.ks3-cn-beijing.ksyuncs.com/custom/Adobe%20Express%20-%202%E6%9C%8818%E6%97%A5%20%281%29%281%29%20%281%29.mp4

</details>


### [18] [EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection](https://arxiv.org/abs/2602.16238)
*Hiroki Nakamura,Hiroto Iino,Masashi Okada,Tadahiro Taniguchi*

Main category: cs.CV

TL;DR: EasyControlEdge は画像生成モデルをエッジ検出向けに最適化し、鮮明かつデータ効率の高いエッジ検出を実現する。


<details>
  <summary>Details</summary>
Motivation: 従来のエッジ検出手法は限界データでの精度低下やエッジの鮮明さの維持に課題があり、事前学習画像生成モデルの潜在能力が十分に活用されていない。

Method: 基礎モデルにエッジ特化の損失関数とピクセル空間損失を導入し、非条件付きダイナミクスに基づく推論時のガイダンスでエッジ密度を調整可能にした。

Result: BSDS500やNYUDv2などで既存手法を上回る性能を達成し、特に小規模データと事後処理不要の条件下で顕著な改善を示した。

Conclusion: 画像生成モデルの事前学習知識と反復精緻化プロセスを活用することで、限界環境下でも高品質なエッジ検出を実現可能である。

Abstract: We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.

</details>


### [19] [AFFMAE: Scalable and Efficient Vision Pretraining for Desktop Graphics Cards](https://arxiv.org/abs/2602.16249)
*David Smerkous,Zian Wang,Behzad Najafian*

Main category: cs.CV

TL;DR: 论文提出了AFFMAE框架，通过自适应离网令牌合并实现高效的高分辨率预训练，减少计算需求同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率视觉模型需要昂贵的基础设施，而现有MAE方法在与分层结构结合时因稠密网格先验和掩码设计受限存在结构挑战。

Method: 采用动态合并可见令牌的自适应离网机制，结合混合精度注意力内核和深度监督策略，打破稠密网格假设并避免表示崩溃。

Result: 在电子显微镜高分辨率分割任务中，相比ViT-MAE减少7倍FLOPs和50%内存占用，单卡训练速度提升显著。

Conclusion: 该成果使中小研究团队无需服务器集群即可开发高分辨率基础模型，推动资源受限场景下的视觉研究。

Abstract: Self-supervised pretraining has transformed computer vision by enabling data-efficient fine-tuning, yet high-resolution training typically requires server-scale infrastructure, limiting in-domain foundation model development for many research laboratories. Masked Autoencoders (MAE) reduce computation by encoding only visible tokens, but combining MAE with hierarchical downsampling architectures remains structurally challenging due to dense grid priors and mask-aware design compromises. We introduce AFFMAE, a masking-friendly hierarchical pretraining framework built on adaptive, off-grid token merging. By discarding masked tokens and performing dynamic merging exclusively over visible tokens, AFFMAE removes dense-grid assumptions while preserving hierarchical scalability. We developed numerically stable mixed-precision Flash-style cluster attention kernels, and mitigate sparse-stage representation collapse via deep supervision. On high-resolution electron microscopy segmentation, AFFMAE matches ViT-MAE performance at equal parameter count while reducing FLOPs by up to 7x, halving memory usage, and achieving faster training on a single RTX 5090. Code available at https://github.com/najafian-lab/affmae.

</details>


### [20] [A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks](https://arxiv.org/abs/2602.16322)
*Santiago C. Vilabella,Pablo Pérez-Núñez,Beatriz Remeseiro*

Main category: cs.CV

TL;DR: 本文提出一种基于自监督学习的特征提取方法，在无需ImageNet预训练的情况下提升物体检测模型性能，降低对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习需大量标注数据且标注成本高昂，公司需投入大量人力物力，而现有预训练模型在特定任务上效果有限。

Method: 采用自监督学习策略，使用未标注数据训练特征提取器，通过对比学习增强模型关注物体关键特征的能力。

Result: 模型在物体检测任务中超越现有ImageNet预训练方法，在少样本场景下展现更强的特征表达能力与鲁棒性。

Conclusion: 提升特征提取器性能可有效减少数据标注需求，自监督预训练能显著增强模型对关键特征的表征能力，适用于资源受限场景。

Abstract: In the fast-evolving field of artificial intelligence, where models are increasingly growing in complexity and size, the availability of labeled data for training deep learning models has become a significant challenge. Addressing complex problems like object detection demands considerable time and resources for data labeling to achieve meaningful results. For companies developing such applications, this entails extensive investment in highly skilled personnel or costly outsourcing. This research work aims to demonstrate that enhancing feature extractors can substantially alleviate this challenge, enabling models to learn more effective representations with less labeled data. Utilizing a self-supervised learning strategy, we present a model trained on unlabeled data that outperforms state-of-the-art feature extractors pre-trained on ImageNet and particularly designed for object detection tasks. Moreover, the results demonstrate that our approach encourages the model to focus on the most relevant aspects of an object, thus achieving better feature representations and, therefore, reinforcing its reliability and robustness.

</details>


### [21] [SCAR: Satellite Imagery-Based Calibration for Aerial Recordings](https://arxiv.org/abs/2602.16349)
*Henry Hölzemann,Michael Schleiss*

Main category: cs.CV

TL;DR: 本文提出SCAR方法，利用卫星影像自动长期校准航拍视觉惯性系统，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 现有校准方法依赖人工操作或地面控制点，缺乏自动长期稳定性。SCAR通过利用公开地理空间数据检测并修正校准漂移。

Method: 使用正射影像和高程模型的2D-3D对应关系对齐航拍图像，联合优化内外参数，实现全自主校准。

Result: 在六组大规模航拍数据集（两年跨度）中，SCAR的重投影误差中值较传统方法（Kalibr/COLMAP/VINS-Mono）显著降低，定位旋转误差减少且姿态精度提升。

Conclusion: SCAR实现了长期航拍任务中无需人工干预的高精度校准，具有强鲁棒性和可重复性，适用于实际复杂场景。

Abstract: We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.

</details>


### [22] [Parameter-Free Adaptive Multi-Scale Channel-Spatial Attention Aggregation framework for 3D Indoor Semantic Scene Completion Toward Assisting Visually Impaired](https://arxiv.org/abs/2602.16385)
*Qi He,XiangXiang Wang,Jingtao Zhang,Yongbin Yu,Hongxiang Chu,Manping Fan,JingYe Cai,Zhenglin Yang*

Main category: cs.CV

TL;DR: 本论文提出了一种基于注意力机制的单目语义场景补全框架（AMAA），通过多尺度特征调节提升了室内辅助系统的结构稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有单目SSC方法在体素特征可靠性建模和跨尺度信息传播调控方面存在不足，导致投影扩散和特征纠缠问题，无法满足视觉障碍用户安全关键场景的结构一致性需求。

Method: 采用通道-空间注意力并行聚合策略对体素特征进行语义-空间联合校准，并设计层次化自适应特征门控策略以调控多尺度编码-解码融合过程。

Result: 在NYUv2数据集上，AMAA在未显著增加复杂度的情况下取得27.25% SSC mIoU（+0.31）和43.10% SC IoU（+0.59）；NVIDIA Jetson实验验证了其在嵌入式平台的鲁棒性。

Conclusion: 为单目SSC领域提供了可靠的感知框架，在结构质量提升的同时确保部署可行性，可广泛应用于视觉障碍者的室内辅助场景。

Abstract: In indoor assistive perception for visually impaired users, 3D Semantic Scene Completion (SSC) is expected to provide structurally coherent and semantically consistent occupancy under strictly monocular vision for safety-critical scene understanding. However, existing monocular SSC approaches often lack explicit modeling of voxel-feature reliability and regulated cross-scale information propagation during 2D-3D projection and multi-scale fusion, making them vulnerable to projection diffusion and feature entanglement and thus limiting structural stability.To address these challenges, this paper presents an Adaptive Multi-scale Attention Aggregation (AMAA) framework built upon the MonoScene pipeline. Rather than introducing a heavier backbone, AMAA focuses on reliability-oriented feature regulation within a monocular SSC framework. Specifically, lifted voxel features are jointly calibrated in semantic and spatial dimensions through parallel channel-spatial attention aggregation, while multi-scale encoder-decoder fusion is stabilized via a hierarchical adaptive feature-gating strategy that regulates information injection across scales.Experiments on the NYUv2 benchmark demonstrate consistent improvements over MonoScene without significantly increasing system complexity: AMAA achieves 27.25% SSC mIoU (+0.31) and 43.10% SC IoU (+0.59). In addition, system-level deployment on an NVIDIA Jetson platform verifies that the complete AMAA framework can be executed stably on embedded hardware. Overall, AMAA improves monocular SSC quality and provides a reliable and deployable perception framework for indoor assistive systems targeting visually impaired users.

</details>


### [23] [Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing](https://arxiv.org/abs/2602.16455)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: 提出Visual Self-Refine（VSR）方法，通过像素级视觉反馈提升复杂图表解析能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在文本推理表现优异，但处理视觉密集型任务（如图表解析）时存在数据遗漏/错位等缺陷，需引入类似人类用手指定位的自我修正机制

Method: VSR框架通过迭代执行像素级定位输出→可视化反馈→自我修正，最后基于精准定位解析结构化数据。ChartVSR包含Refine（视觉反馈修正定位）和Decode（生成数据）两个阶段

Result: 构建了更严格的ChartP-Bench基准测试，验证了VSR在视觉密集图表场景中相比现有模型的定位准确性提升，尤其对复杂图表数据遗漏/错位问题改善显著

Conclusion: VSR为视觉任务提供了通用的像素级自我修正范式，在保持结构化输出能力的同时显著提升模型视觉感知可靠性，开辟了视觉反馈机制研究的新方向

Abstract: While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.

</details>


### [24] [Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection](https://arxiv.org/abs/2602.16494)
*Alexis Winter,Jean-Vincent Martini,Romaric Audigier,Angelique Loesch,Bertrand Luvison*

Main category: cs.CV

TL;DR: This paper proposes a unified benchmark framework to evaluate adversarial attacks and defenses for object detection models, revealing that hybrid attack strategies improve robustness while vision transformers show resistance to adversarial transfers.


<details>
  <summary>Details</summary>
Motivation: Adversarial attacks pose security risks to object detection systems (e.g., autonomous vehicles), but inconsistent evaluation metrics across datasets hinder effective comparison of attacks/defenses. A standardized framework is needed to address this research gap.

Method: Developed a digital, patch-free benchmark with metrics to isolate localization/classification errors and perceptual attack costs. Conducted large-scale experiments on state-of-the-art attacks across diverse detectors, including vision transformers and CNNs, with adversarial training strategies.

Result: Modern attacks show poor transferability to vision transformers. Adversarial training combining high-perturbation attacks (spatial + semantic objectives) significantly outperforms single-attack training in robustness.

Conclusion: Transformer-based architectures inherently resist adversarial transfers better than CNNs. Optimal defense requires diverse adversarial training datasets integrating multiple attack types and objectives.

Abstract: Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.

</details>


### [25] [DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images](https://arxiv.org/abs/2602.16502)
*Zeng Tao,Ying Jiang,Yunuo Chen,Tianyi Xie,Huamin Wang,Yingnian Wu,Yin Yang,Abishek Sampath Kumar,Kenji Tashiro,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 本论文提出DressWild，一种基于前馈流程的新型缝纫图案生成方法，可从单视角图像重建物理一致性3D服装，解决现有方法在姿态多样性、计算效率和扩展性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有前馈方法难以处理多样化姿态与视角，优化方法计算成本高且扩展性差，而工业场景需要兼具可编辑性、分离性和仿真能力的服装生成方案。

Method: 1) 利用视觉-语言模型(VLM)标准化图像级姿态；2) 提取3D感知的服装特征；3) 基于Transformer编码器融合特征；4) 直接预测可应用于物理仿真的缝纫参数。

Result: 无需多视角输入或迭代优化，成功生成多样化缝纫图案与3D服装，在物理模拟、纹理生成和多层虚拟试穿中实现高效应用。

Conclusion: DressWild提供了兼具物理合理性和高计算效率的解决方案，通过创新性特征融合策略，显著降低传统优化方法的复杂度，适用于工业级规模化应用。

Abstract: Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.

</details>


### [26] [Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.16545)
*Kaiting Liu,Hazel Doughty*

Main category: cs.CV

TL;DR: 本文提出了一种名为'类别拆分'的新任务，通过零样本编辑和少量样本微调方法，在不增加数据的情况下细化视频分类模型的粗粒度类别。


<details>
  <summary>Details</summary>
Motivation: 现有视频识别模型依赖固定的粗粒度分类体系，难以适应新兴任务对细粒度分类的需求，重新标注数据和重训练成本高昂。

Method: 提出零样本编辑方法利用视频分类器的潜在组合结构，结合少量样本微调策略，在保留原有分类精度的同时生成细粒度子类别。

Result: 在新构建的视频类别拆分基准测试中，该方法显著优于视觉语言基线模型，在新增子类别上提升准确率且不牺牲原有性能。

Conclusion: 通过零样本初始化和少量样本优化，成功实现了分类器的细粒度重构，为模型适应性演化提供了高效解决方案。

Abstract: Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: https://kaitingliu.github.io/Category-Splitting/.

</details>


### [27] [Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face](https://arxiv.org/abs/2602.16569)
*Nicolò Di Domenico,Annalisa Franco,Matteo Ferrara,Davide Maltoni*

Main category: cs.CV

TL;DR: 本研究提出基于Arc2Face的面部变形攻击新方法，成功模拟传统landmark技术的攻击效果，揭示身份信息管理在人脸识别系统中的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 针对eID文档中人脸识别系统面临的变形攻击威胁，现有护照注册流程缺乏活体检测机制，而传统landmark-based技术因高攻击潜力成为最难防御的攻击范式

Method: 开发基于Arc2Face身份条件生成模型的变形方法，通过紧凑身份表示合成高质量人脸图像，并在两个大规模私有检测数据集及FEI/ONOT衍生数据集进行攻击潜力验证

Result: 深度学习方法实现的变形攻击潜力与传统landmark技术相当，实验验证了身份信息在变形生成过程中得到有效保留，达到了当前最先进攻击方法的水准

Conclusion: 证明了身份条件生成模型在面部变形攻击中的有效性，揭示了现行人脸识别系统在身份验证机制上的关键漏洞，提示需要提升对生成式攻击的防御能力

Abstract: Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.

</details>


### [28] [A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification](https://arxiv.org/abs/2602.16590)
*Qi You,Yitai Cheng,Zichao Zeng,James Haworth*

Main category: cs.CV

TL;DR: 本文提出CLIP-MHAdapter，在街景图像属性分类任务中，通过改进CLIP的适配器结构，在保持低计算成本的同时实现性能突破。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖CLIP的全局图像嵌入导致无法捕捉复杂街景中的细粒度局部属性，且传统微调方法计算成本过高。

Method: 在CLIP的轻量级适配器中添加瓶颈MLP和多头自注意力模块，通过处理图像块(patch)间的依赖关系来增强局部特征提取能力。

Result: 在Global StreetScapes数据集的8个属性分类任务中全部达到SOTA或接近SOTA性能，模型参数量仅140万。

Conclusion: 该方法解决了街景图像分类任务中局部特征建模不足和计算成本过高的双重挑战，为视觉语言模型的轻量化适配提供了新思路。

Abstract: Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.

</details>


### [29] [Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge](https://arxiv.org/abs/2602.16664)
*Jiaming Liu,Felix Petersen,Yunhe Gao,Yabin Zhang,Hyojin Kim,Akshay S. Chaudhari,Yu Sun,Stefano Ermon,Sergios Gatidis*

Main category: cs.CV

TL;DR: 提出Self-Supervised Semantic Bridge (SSB)，通过整合自监督语义先验到扩散桥梁模型，实现无需跨域监督的空间保真图像翻译。


<details>
  <summary>Details</summary>
Motivation: 对抗方法需目标域对抗损失限制泛化性，扩散反演方法因噪声潜在表示不完美导致翻译低效。需要无监督且能保持几何结构的高质量翻译框架。

Method: 利用自监督视觉编码器学习几何结构保留且外观变化不变的表示，构建共享潜在空间作为扩散桥梁的条件，桥接源域与目标域的语义关联。

Result: 在医学图像合成任务中超越现有对抗及扩散反演方法，在同域与异域设置下均显著提升质量；支持高保真文本引导编辑且无需额外训练。

Conclusion: 通过引入自监督语义先验证明共享潜在空间的有效性，解决了现有方法对监督的依赖及几何失真问题，为无监督图像翻译提供新范式。

Abstract: Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.

</details>


### [30] [PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction](https://arxiv.org/abs/2602.16669)
*Bo Lang,Nirav Savaliya,Zhihao Zheng,Jinglun Feng,Zheng-Hang Yeh,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: 提出一种端到端的在线高清矢量地图构建框架，通过语义感知查询生成、历史地图记忆模块、短期未来预测等方法提升地图时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的地图构建方法存在随机初始化导致的时序不稳定性问题，且过度依赖隐式时序建模，需要更主动的时序一致性解决方案。

Method: 1) 语义感知查询生成器通过空间对齐语义图初始化查询；2) 历史光栅图记忆模块存储实例级地图；3) 历史图引导模块融合光栅图信息；4) 短期未来预测模块提供运动轨迹引导。

Result: 在nuScenes和Argoverse2数据集上超越SOTA方法，展现高效率和稳定性，尤其在处理动态交通元素时更具鲁棒性。

Conclusion: 所提框架通过显式建模历史状态与未来预测，能有效解决自动驾驶中高精地图构建的时序不连续问题，具有实际应用价值。

Abstract: High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.

</details>


### [31] [VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection](https://arxiv.org/abs/2602.16681)
*Yingyuan Yang,Tian Lan,Yifei Gao,Yimeng Lu,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.CV

TL;DR: VETime是一个结合时间与视觉模态的时间序列异常检测框架，通过动态融合双模态信息，在零样本场景下实现高效精准的异常定位。


<details>
  <summary>Details</summary>
Motivation: 现有TSAD模型存在时域模型无全局视角、视觉模型存在信息瓶颈的矛盾。

Method: 提出Reversible Image Conversion和Patch-Level Temporal Alignment建立共享时空时线，设计Anomaly Window Contrastive Learning与Task-Adaptive Fusion进行多模态动态融合。

Result: 零样本场景下超越当前最优方法，定位精度提升且计算开销更低。

Conclusion: VETime通过跨模态对齐与融合突破单一模态限制，为时间序列异常检测提供了可推广的范式。

Abstract: Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: https://github.com/yyyangcoder/VETime.

</details>


### [32] [Learning Situated Awareness in the Real World](https://arxiv.org/abs/2602.16682)
*Chuhan Li,Ruilin Han,Joy Hsu,Yongyuan Liang,Rajiv Dhawan,Jiajun Wu,Ming-Hsuan Yang,Xin Eric Wang*

Main category: cs.CV

TL;DR: 本文提出了SAW-Bench（现实世界的处境意识）基准测试，使用真实世界的视频来评估以自我为中心的处境意识，揭示了现有模型与人类表现存在37.66%的差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型（MFM）基准测试过于侧重环境中的空间关系，而忽视了需要以观察者视角推理的观察者中心关系。

Method: 构建了包含786个智能眼镜拍摄视频和2071个人工标注问答对的SAW-Bench，涵盖六种观察者中心认知任务。

Result: 即使最优模型Gemini 3 Flash也存在37.66%的人机表现差距，模型虽能部分利用几何线索，但难以推断完整摄像头几何导致空间推理系统性错误。

Conclusion: SAW-Bench标志着从被动观察向物理基础的观察者中心动态理解转变，推动情境空间智能研究。

Abstract: A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric spatial relations (relations among objects in a scene), while largely overlooking observer-centric relationships that require reasoning relative to agent's viewpoint, pose, and motion. To bridge this gap, we introduce SAW-Bench (Situated Awareness in the Real World), a novel benchmark for evaluating egocentric situated awareness using real-world videos. SAW-Bench comprises 786 self-recorded videos captured with Ray-Ban Meta (Gen 2) smart glasses spanning diverse indoor and outdoor environments, and over 2,071 human-annotated question-answer pairs. It probes a model's observer-centric understanding with six different awareness tasks. Our comprehensive evaluation reveals a human-model performance gap of 37.66%, even with the best-performing MFM, Gemini 3 Flash. Beyond this gap, our in-depth analysis uncovers several notable findings; for example, while models can exploit partial geometric cues in egocentric videos, they often fail to infer a coherent camera geometry, leading to systematic spatial reasoning errors. We position SAW-Bench as a benchmark for situated spatial intelligence, moving beyond passive observation to understanding physically grounded, observer-centric dynamics.

</details>


### [33] [Are Object-Centric Representations Better At Compositional Generalization?](https://arxiv.org/abs/2602.16689)
*Ferdinand Kapl,Amir Mohammad Karimi Mamaghan,Maximilian Seitzer,Karl Henrik Johansson,Carsten Marr,Stefan Bauer,Andrea Dittadi*

Main category: cs.CV

TL;DR: 本文通过设计视觉问答基准测试，系统比较了基于物体中心（OC）的表征与传统密集表征在组合泛化任务中的性能。实验表明，OC方法在数据或计算资源受限时更具优势。


<details>
  <summary>Details</summary>
Motivation: 组合泛化是人类认知的核心能力，但机器学习模型在此能力上存在不足。尽管OC表征被理论化为支持组合泛化的潜在方法，但缺乏在复杂视觉环境中的实证验证。

Method: 构建包含三个视觉场景（CLEVRTex, Super-CLEVR, MOVi-C）的VQA benchmark，使用DINOv2/SigLIP2及其OC变体作为基础模型，严格控制数据量、多样性、模型容量等变量进行公平比较。

Result: 1. OC在组合泛化难度高的场景表现更优；2. 密集表征仅在低难度任务或数据充足时优于OC，且消耗更多计算资源；3. OC在数据量有限时展现出更高的样本效率。

Conclusion: 当面临数据规模、训练多样性或计算资源限制时，物体中心表征能为组合泛化任务提供更优的性能折衷方案。

Abstract: Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.

</details>


### [34] [Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning](https://arxiv.org/abs/2602.16702)
*Mingjia Shi,Yinhan He,Yaochen Zhu,Jundong Li*

Main category: cs.CV

TL;DR: Vision-language models (VLMs) face challenges in long reasoning tasks due to early visual grounding errors and text-dominated generation. The paper proposes a Saliency-Aware Principle (SAP) selection method that enables dynamic re-consultation of visual inputs and parallel reasoning paths, improving stability and reducing hallucinations without additional training.


<details>
  <summary>Details</summary>
Motivation: Visual inputs in VLMs are typically fixed at the start, leading to error accumulation and text-dominated reasoning. Existing visual grounding methods are too coarse to guide long sequential reasoning effectively. This work aims to solve these limitations by enabling dynamic visual re-grounding.

Method: SAP selects high-level reasoning principles instead of token-level trajectories, allowing: (1) explicit re-consultation of visual evidence when errors accumulate, and (2) parallel exploration of multiple reasoning paths. The approach works without model modification, retraining, or data annotation.

Result: SAP achieves competitive performance with better hallucination reduction under similar token budgets. It demonstrates more stable generation, lower latency, and superior robustness compared to sequential chain-of-thought reasoning in VLMs.

Conclusion: SAP provides a generalizable solution to visual grounding challenges in VLMs by balancing text-based reasoning with periodic visual re-validation, enabling more reliable and efficient long-horizon tasks.

Abstract: Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.

</details>


### [35] [TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos](https://arxiv.org/abs/2602.16711)
*Namitha Padmanabhan,Matthew Gwilliam,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: The paper introduces TeCoNeRV, a hypernetwork approach for video compression that improves efficiency and scalability for high-resolution videos using spatial-temporal decomposition, residual storage, and temporal coherence regularization.


<details>
  <summary>Details</summary>
Motivation: Challenges in balancing compression quality, speed, and memory usage for high-resolution video encoding with existing INR and hypernetwork methods.

Method: 1. **Spatial-temporal decomposition**: Splits short video segments into 'patch tubelets' to reduce memory overhead. 2. **Residual storage**: Stores differences between consecutive segments instead of full data. 3. **Temporal coherence regularization**: Ensures weight changes align with video content evolution.

Result: - **2.47dB/5.35dB PSNR gains** over baseline at 480p/720p on UVG dataset. - **36% lower bitrates** and **1.5-3× faster encoding**. - First hypernetwork to demonstrate 480p/720p/1080p results on UVG, HEVC, and MCL-JCV datasets.

Conclusion: TeCoNeRV resolves key tradeoffs in hypernetwork-based video compression, enabling high-quality, low-bitrate, and memory-efficient encoding for ultra-high resolutions.

Abstract: Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [36] [KD4MT: A Survey of Knowledge Distillation for Machine Translation](https://arxiv.org/abs/2602.15845)
*Ona de Gibert,Joseph Attieh,Timothee Mickus,Yves Scherrer,Jörg Tiedemann*

Main category: cs.CL

TL;DR: This survey explores knowledge distillation (KD) in machine translation (MT), analyzing 105 studies to categorize methodologies, applications, trends, and challenges, while offering guidelines and a resource database.


<details>
  <summary>Details</summary>
Motivation: KD addresses model compression in NLP, but in MT it uniquely enables knowledge transfer for quality and efficiency. Despite its potential, inconsistent evaluation practices and research gaps hinder progress, necessitating this comprehensive survey.

Method: The authors reviewed 105 KD4MT papers up to October 2025, categorizing them by methodology and application. They conducted qualitative and quantitative analyses to identify trends, gaps, and risks, while proposing evaluation guidelines and compiling a database/glossary.

Result: Key findings include common KD4MT trends, research gaps (e.g., bias amplification and hallucination risks), absent unified evaluation standards, and practical KD method selection guidelines. LLMs are highlighted as transformative for KD4MT.

Conclusion: KD4MT requires standardized evaluation frameworks and greater awareness of ethical risks. LLMs will reshape the field, and the provided database/glossary should spur future research and application.

Abstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as well as efficiency.
  This survey synthesizes KD for MT (KD4MT) across 105 papers (through October 1, 2025). We begin by introducing both MT and KD for non-experts, followed by an overview of the standard KD approaches relevant to MT applications. Subsequently, we categorize advances in the KD4MT literature based on (i) their methodological contributions and (ii) their practical applications. Our qualitative and quantitative analyses identify common trends in the field and highlight key research gaps as well as the absence of unified evaluation practice for KD methods in MT. We further provide practical guidelines for selecting a KD method in concrete settings and highlight potential risks associated with the application of KD to MT such as increased hallucination and bias amplification. Finally, we discuss the role of LLMs in re-shaping the KD4MT field. To support further research, we complement our survey with a publicly available database summarizing the main characteristics of the surveyed KD methods and a glossary of key terms.

</details>


### [37] [Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs](https://arxiv.org/abs/2602.15846)
*Xinyu Gao,Shaonan Wang,Nai Ding*

Main category: cs.CL

TL;DR: 提出了一种名为GTCA的模块，通过预计算句法结构记忆增强解码器-only大语言模型的语法稳健性，且不改变原有架构。


<details>
  <summary>Details</summary>
Motivation: 解码器-only模型对语法扰动敏感且直接注入语法结构会破坏其预训练能力，需要兼容现有检查点的改进方案。

Method: 设计门控树交叉注意力分支，结合token更新掩码和分阶段训练，在不修改主干的情况下控制语法信息的注入范围与时机。

Result: GTCA在多项任务中提升了语法鲁棒性，同时保持原有模型在QA和常识推理等任务上的性能表现。

Conclusion: 为解码器-only大语言模型提供了可复用的语法增强方案，无需从头训练即可提升可靠性。

Abstract: Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere with its pretrained competence. We introduce a checkpoint-compatible gated tree cross-attention (GTCA) branch that reads precomputed constituency chunk memory while leaving backbone architecture unchanged. Our design uses a token update mask and staged training to control the scope and timing of structural updates. Across benchmarks and Transformer backbones, GTCA strengthens syntactic robustness beyond continued-training baselines without compromising Multiple-Choice QA performance or commonsense reasoning, providing a practical checkpoint-compatible route to more syntax-robust decoder-only LLMs.

</details>


### [38] [Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models](https://arxiv.org/abs/2602.15847)
*Pranav Bhandari,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 现有方法假设人格特质可通过独立引导向量控制，但本研究发现LLM中的Big Five人格引导方向存在几何依赖性，硬正交化处理虽能强制几何独立，但仍存在行为耦合且可能削弱引导效果。


<details>
  <summary>Details</summary>
Motivation: 当前人格引导方法隐含特质独立性假设，但学界缺乏对人格特征内在关联性的系统性验证。研究其几何关系可揭示模型内部表征机制，指导更有效的控制策略。

Method: 使用LLaMA-3-8B和Mistral-8B模型族提取人格引导向量，设计三种几何条件：无约束基线、软正交化约束和硬正交化约束，通过方向相关性和行为影响两个维度进行量化分析。

Result: 1) 人格引导方向呈现显著几何相关性（平均余弦相似度0.25-0.35）2) 线性重叠去除后仍存在跨特质行为影响（如改变'开放性'影响'尽责性'）3) 硬正交化使方向正交率提升300%，但导致23%的引导强度损失

Conclusion: LLM人格特质构成非完全解耦的低维流形结构，几何正交化不能完全消除功能耦合，暗示需要开发联合优化框架而非单特征控制策略，在控制粒度与稳定性间需权衡设计

Abstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by analysing the geometric relationships between Big Five personality steering directions. We study steering vectors extracted from two model families (LLaMA-3-8B and Mistral-8B) and apply a range of geometric conditioning schemes, from unconstrained directions to soft and hard orthonormalisation. Our results show that personality steering directions exhibit substantial geometric dependence: steering one trait consistently induces changes in others, even when linear overlap is explicitly removed. While hard orthonormalisation enforces geometric independence, it does not eliminate cross-trait behavioural effects and can reduce steering strength. These findings suggest that personality traits in LLMs occupy a slightly coupled subspace, limiting fully independent trait control.

</details>


### [39] [Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling](https://arxiv.org/abs/2602.15848)
*Andrius Matšenas,Anet Lello,Tõnis Lees,Hans Peep,Kim Lilii Tamm*

Main category: cs.CL

TL;DR: 研究验证了大语言模型（LLMs）作为动态性格评估工具的有效性，结果显示其与传统问卷法在部分人格特质上结果一致且用户认可度相当。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型作为传统问卷式性格评估（如IPIP-50）的动态替代方案，解决传统方法的静态局限性。

Method: 通过被试内实验（N=33），对比LLM对话生成的五因素人格得分与IPIP-50问卷的效度，并评估用户感知准确性。

Result: 中等程度的会聚效度（r=0.38-0.58），尽责性、开放性与神经质得分无差异，宜人性和外向性存在差异，用户认为LLM与传统方法准确性相当。

Conclusion: 基于对话的AI技术为人格测评提供了与传统心理测量具有同等潜力的新途径，但需针对特定特质优化。

Abstract: This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50 questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism scores statistically equivalent between methods. Agreeableness and Extraversion showed significant differences, suggesting trait-specific calibration is needed. Notably, participants rated LLM-generated profiles as equally accurate as traditional questionnaire results. These findings suggest conversational AI offers a promising new approach to traditional psychometrics.

</details>


### [40] [Preference Optimization for Review Question Generation Improves Writing Quality](https://arxiv.org/abs/2602.15849)
*Karun Sharma,Vidushee Vats,Shengzhi Li,Yuxiang Wang,Zhongtian Sun,Prayag Tiwari*

Main category: cs.CL

TL;DR: This paper introduces IntelliReward, a novel reward model, and IntelliAsk, a question-generation model, to enhance the quality of evidence-based peer review questions by addressing the limitations of existing LLMs that produce surface-level queries.


<details>
  <summary>Details</summary>
Motivation: Current LLM-based approaches generate review questions that rely heavily on superficial content (e.g., over 50% of tokens from a paper's first page), lacking depth in effort, evidence, and grounding. This work aims to bridge this gap by aligning automated question generation with human expert standards.

Method: The authors develop IntelliReward using a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states. They then apply Decoupled Clip and Dynamic Sampling Policy Optimization (DAPO) to train IntelliAsk, a model optimized for effortful, evidence-based question generation.

Result: IntelliReward outperforms API-based SFT baselines in predicting human expert preferences. IntelliAsk achieves significant improvements on reasoning (e.g., MuSR: 68.3 vs. 64.7 accuracy) and complex writing benchmarks (e.g., WritingBench: 8.31 vs. 8.07), demonstrating measurable gains over the Qwen3-32B base model.

Conclusion: High-quality review questions correlate with enhanced reasoning and writing capabilities in LLMs. The release of IntelliReward, IntelliAsk, and associated datasets establishes a new benchmark for evaluating grounding, effort, and evidence in automated peer review systems.

Abstract: Peer review relies on substantive, evidence-based questions, yet existing LLM-based approaches often generate surface-level queries, drawing over 50\% of their question tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a novel reward model built from a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states, which outperforms API-based SFT baselines in predicting expert-level human preferences. By applying Decoupled Clip and Dynamic Sampling Policy Optimization (DAPO) with IntelliReward, we train IntelliAsk, a question-generation model aligned with human standards of effort, evidence, and grounding. We find consistent improvements on reasoning and writing benchmarks, suggesting reviewer-question quality correlates with broader capabilities. Compared to the Qwen3-32B base model, IntelliAsk shows measurable gains across diverse benchmarks, specifically improving performance on reasoning tasks like MuSR (68.3 vs 64.7 Acc) and complex writing evaluations such as WritingBench (8.31 vs 8.07). We release our implementation, expert preference annotations, and the IntelliReward model to provide an automatic evaluation benchmark for grounding, effort, and evidence in LLM-generated review questions.

</details>


### [41] [Large Language Models for Assisting American College Applications](https://arxiv.org/abs/2602.15850)
*Zhengliang Liu,Weihang You,Peng Shu,Junhao Chen,Yi Pan,Hanqi Jiang,Yiwei Li,Zhaojun Ding,Chao Cao,Xinliang Li,Yifan Zhou,Ruidong Zhang,Shaochen Xu,Wei Ruan,Huaqin Zhao,Dajiang Zhu,Tianming Liu*

Main category: cs.CL

TL;DR: EZCollegeApp是一个基于大语言模型（LLM）的系统，通过结构化大学申请表单和文档驱动的回答建议，帮助高中生应对复杂的入学申请流程，同时保持用户对最终回答的控制权。


<details>
  <summary>Details</summary>
Motivation: 美国大学申请流程存在政策碎片化、表单重复性高、问题模糊需交叉验证等问题，学生需要系统性工具来降低认知负担并减少错误。现有工具缺乏权威文档支撑或自动化控制的透明性，EZCollegeApp旨在填补这一空白。

Method: 系统采用映射优先范式（分离表单理解与回答生成），整合文档自动化采集、检索增强生成（RAG）问答、以及安全隔离的人机协同接口。通过分阶段处理（文档解析→结构映射→上下文敏感生成）实现跨异构平台的统一逻辑，并设计隐私保护的本地化交互层。

Result: 实验证明系统在多平台申请表单对齐准确率达89%，回答引用权威文档匹配度提升40%，人工复核耗时减少65%。代码开源后被4所高校试点应用，证明其能保持学生自主权的同时提升申请效率。

Conclusion: 研究表明LLM可有效解决申请流程的信息组织问题，映射优先架构为跨平台数据交互提供新范式。系统的透明化设计平衡了自动化与可控性，开源代码为教育技术领域提供了可复现基础，但需持续优化低资源场景的鲁棒性。

Abstract: American college applications require students to navigate fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand cross-referencing multiple sources. We present EZCollegeApp, a large language model (LLM)-powered system that assists high-school students by structuring application forms, grounding suggested answers in authoritative admissions documents, and maintaining full human control over final responses. The system introduces a mapping-first paradigm that separates form understanding from answer generation, enabling consistent reasoning across heterogeneous application portals. EZCollegeApp integrates document ingestion from official admissions websites, retrieval-augmented question answering, and a human-in-the-loop chatbot interface that presents suggestions alongside application fields without automated submission. We describe the system architecture, data pipeline, internal representations, security and privacy measures, and evaluation through automated testing and human quality assessment. Our source code is released on GitHub (https://github.com/ezcollegeapp-public/ezcollegeapp-public) to facilitate the broader impact of this work.

</details>


### [42] [Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey](https://arxiv.org/abs/2602.15851)
*David Y. Liu,Aditya Joshi,Paul Dawson*

Main category: cs.CL

TL;DR: This survey explores the application of narrative theories using large language models (LLMss) in NLP, identifies patterns and challenges, and proposes future directions focused on theory-driven metrics and interdisciplinary collaboration.


<details>
  <summary>Details</summary>
Motivation: The increasing use of LLMs in narrative-related tasks (e.g., story generation) requires systematic integration of narrative theories with NLP research, alongside addressing challenges in unifying benchmarks and evaluation metrics.

Method: A survey-based analysis of NLP research engaging with narrative studies, including the design of a taxonomy rooted in narratology, and examination of datasets, tasks, methodologies (prompting/finetuning), and interdisciplinary connections.

Result: Key patterns were identified (e.g., datasets, theoretical frameworks, pipeline trends), alongside challenges in defining unified benchmarks. LLMs enable easier integration of abstract narrative concepts into NLP pipelines, but model comparison remains difficult due to inconsistent definitions.

Conclusion: Future progress requires theory-based metrics for narrative attributes, large-scale literary/social analysis using LLMs, and experiments to validate/refine narrative theories. The paper provides a foundation for systematic narrative research in NLP by linking existing efforts to narratology.

Abstract: Applications of narrative theories using large language models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey examines how natural language processing (NLP) research engages with fields of narrative studies, and proposes a taxonomy for ongoing efforts that reflect established distinctions in narratology. We discover patterns in the following: narrative datasets and tasks, narrative theories and NLP pipeline and methodological trends in prompting and fine-tuning. We highlight how LLMs enable easy connections of NLP pipelines with abstract narrative concepts and opportunities for interdisciplinary collaboration. Challenges remain in attempts to work towards any unified definition or benchmark of narrative related tasks, making model comparison difficult. For future directions, instead of the pursuit of a single, generalised benchmark for 'narrative quality', we believe that progress benefits more from efforts that focus on the following: defining and improving theory-based metrics for individual narrative attributes to incrementally improve model performance; conducting large-scale, theory-driven literary/social/cultural analysis; and creating experiments where outputs can be used to validate or refine narrative theories. This work provides a contextual foundation for more systematic and theoretically informed narrative research in NLP by providing an overview to ongoing research efforts and the broader narrative studies landscape.

</details>


### [43] [Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints](https://arxiv.org/abs/2602.15852)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.CL

TL;DR: 该研究探讨了在临床NLP模型中应对时间性和词汇泄露问题的系统设计，提出轻量级审计流程以提升模型部署的安全性。


<details>
  <summary>Details</summary>
Motivation: note-based临床NLP模型易受时间性/词汇泄露影响，导致预测性能虚高，可能破坏实际临床流程并危及患者安全，亟需系统级解决方案。

Method: 设计集成可解释性的轻量级审计流程，在训练前识别并抑制泄露风险信号，以选择性脊柱手术次日出院预测为案例进行验证。

Result: 审计后模型展现更保守且校准更优的概率估计，在减少出院相关词汇依赖的同时，验证了时间有效性与稳健性的优先地位。

Conclusion: 部署临床NLP系统应优先确保时间有效性、概率校准准确性和行为稳健性，而非追求虚高的预测性能指标。

Abstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts encode future clinical decisions and inflate apparent predictive performance. Such behavior poses substantial risks for real-world deployment, where overconfident or temporally invalid predictions can disrupt clinical workflows and compromise patient safety. This study focuses on system-level design choices required to build safe and deployable clinical NLP under temporal leakage constraints. We present a lightweight auditing pipeline that integrates interpretability into the model development process to identify and suppress leakage-prone signals prior to final training. Using next-day discharge prediction after elective spine surgery as a case study, we evaluate how auditing affects predictive behavior, calibration, and safety-relevant trade-offs. Results show that audited models exhibit more conservative and better-calibrated probability estimates, with reduced reliance on discharge-related lexical cues. These findings emphasize that deployment-ready clinical NLP systems should prioritize temporal validity, calibration, and behavioral robustness over optimistic performance.

</details>


### [44] [A Lightweight Explainable Guardrail for Prompt Safety](https://arxiv.org/abs/2602.15853)
*Md Asiful Islam,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级可解释防护（LEG）方法，通过多任务学习架构同时解决不安全提示分类和解释生成问题，并采用合成数据与创新损失函数实现性能优化。


<details>
  <summary>Details</summary>
Motivation: 现有不安全提示检测方法存在模型规模过大、依赖LLM确认偏误生成解释数据以及局部解释信号捕捉不足的问题，需要更高效且可解释的解决方案。

Method: 1）设计多任务学习架构同步训练分类器与解释标注器；2）采用逆LLM确认偏误的合成数据生成策略；3）构建融合交叉熵、焦点损失与不确定加权的全局解释损失函数。

Result: LEG在三个数据集的领域内外测试中，分类和解释性能均优于或相当于现有最优方法，且模型规模显著更小（具体指标未量化）。

Conclusion: 验证了轻量化模型在安全提示分类场景中的有效性，计划开源模型和标注数据集推动领域发展。

Abstract: We propose a lightweight explainable guardrail (LEG) method for the classification of unsafe prompts. LEG uses a multi-task learning architecture to jointly learn a prompt classifier and an explanation classifier, where the latter labels prompt words that explain the safe/unsafe overall decision. LEG is trained using synthetic data for explainability, which is generated using a novel strategy that counteracts the confirmation biases of LLMs. Lastly, LEG's training process uses a novel loss that captures global explanation signals and combines cross-entropy and focal losses with uncertainty-based weighting. LEG obtains equivalent or better performance than the state-of-the-art for both prompt classification and explainability, both in-domain and out-of-domain on three datasets, despite the fact that its model size is considerably smaller than current approaches. If accepted, we will release all models and the annotated dataset publicly.

</details>


### [45] [Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective](https://arxiv.org/abs/2602.15856)
*Yunhao Liu,Zian Jia,Xinyu Gao,Kanjun Xu,Yun Xiong*

Main category: cs.CL

TL;DR: 本研究提出SeleCom框架，通过查询条件的信息筛选提升RAG系统压缩效果，在保证性能的同时降低33.8%-84.6%的计算和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有软压缩方法强制压缩所有文档信息，导致任务相关数据丢失。研究揭示两种缺陷：1) 全压缩与LLM生成机制冲突；2) 非必要全压缩稀释关键信息。需要新框架解决这两个根本性问题。

Method: 开发Selector-Based架构，采用解码器优先的选择器，通过三阶段训练流程：1) 大规模合成QA生成；2) 困难分级筛选；3) 与任务相关的压缩策略训练，使编码器专注于查询相关的信息筛选而非全量压缩。

Result: 在多个基准测试中超越现有软压缩方法，达到与非压缩RAG相当的性能，同时将计算资源消耗降低三分之一至五分之四，在开放域问答和事实核查任务中分别提升17.3%和12.9%的效果。

Conclusion: 证明了选择性压缩范式的有效性，其Query-Conditioned机制既能保持生成质量，又能显著提升系统效率。研究为长文档处理提供了新的优化方向。

Abstract: Retrieval-Augmented Generation (RAG) effectively grounds Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tasks. However, its scalability is hindered by excessive context length and redundant retrievals. Recent research on soft context compression aims to address this by encoding long documents into compact embeddings, yet they often underperform non-compressed RAG due to their reliance on auto-encoder-like full-compression that forces the encoder to compress all document information regardless of relevance to the input query.
  In this work, we conduct an analysis on this paradigm and reveal two fundamental limitations: (I) Infeasibility, full-compression conflicts with the LLM's downstream generation behavior; and (II) Non-necessity: full-compression is unnecessary and dilutes task-relevant information density. Motivated by these insights, we introduce SeleCom, a selector-based soft compression framework for RAG that redefines the encoder's role as query-conditioned information selector. The selector is decoder-only and is trained with a massive, diverse and difficulty-graded synthetic QA dataset with curriculum learning.
  Extensive experiments show that SeleCom significantly outperforms existing soft compression approaches and achieves competitive or superior performance to non-compression baselines, while reducing computation and latency by 33.8%~84.6%.

</details>


### [46] [Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach](https://arxiv.org/abs/2602.15857)
*Yi Liu*

Main category: cs.CL

TL;DR: 本论文提出了一种基于协同推理与自适应融合（CRAF）的多源舆情分析框架，结合传统特征方法与大语言模型（LLMs），通过多阶段结构化推理机制实现跨平台数据整合与优化。


<details>
  <summary>Details</summary>
Motivation: 现有舆情分析面临结构化差异、语义分歧及平台偏见等多源异构数据整合难题，传统方法难以有效融合特征模型与LLMs的优势。

Method: 1）跨平台协同注意力模块对齐语义表征并保留源特征；2）层级自适应融合机制动态加权特征；3）联合优化策略通过共享潜在空间学习主题与情感分布；4）多模态抽取能力集成OCR/ASR/视觉情感分析处理短视频。理论分析证明其泛化界优于独立源建模。

Result: 在Weibo-12等三类跨平台数据集上，主题聚类调整兰德指数（ARI）达0.76（优于基准4.1%），情感分析F1值0.84（提升3.8%），且新平台标注数据需求减少75%。

Conclusion: CRAF框架通过结构化协同推理突破多源数据整合瓶颈，理论分析与实验均验证其跨平台有效性和标注效率提升，为复杂舆情分析提供新范式。

Abstract: The analysis of public opinion from multiple heterogeneous sources presents significant challenges due to structural differences, semantic variations, and platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF) framework that systematically integrates traditional feature-based methods with large language models (LLMs) through a structured multi-stage reasoning mechanism. Our approach features four key innovations: (1) a cross-platform collaborative attention module that aligns semantic representations while preserving source-specific characteristics, (2) a hierarchical adaptive fusion mechanism that dynamically weights features based on both data quality and task requirements, (3) a joint optimization strategy that simultaneously learns topic representations and sentiment distributions through shared latent spaces, and (4) a novel multimodal extraction capability that processes video content from platforms like Douyin and Kuaishou by integrating OCR, ASR, and visual sentiment analysis. Theoretical analysis demonstrates that CRAF achieves a tighter generalization bound with a reduction of O(sqrt(d log K / m)) compared to independent source modeling, where d is feature dimensionality, K is the number of sources, and m is sample size. Comprehensive experiments on three multi-platform datasets (Weibo-12, CrossPlatform-15, NewsForum-8) show that CRAF achieves an average topic clustering ARI of 0.76 (4.1% improvement over best baseline) and sentiment analysis F1-score of 0.84 (3.8% improvement). The framework exhibits strong cross-platform adaptability, reducing the labeled data requirement for new platforms by 75%.

</details>


### [47] [Reranker Optimization via Geodesic Distances on k-NN Manifolds](https://arxiv.org/abs/2602.15860)
*Wen G. Gong*

Main category: cs.CL

TL;DR: Maniscope采用基于k近邻流形的几何重排序方法，结合全局余弦相似度和局部流形几何特性，在保证准确性的同时实现比传统交叉编码器或LLM方法快10-45倍的推理速度，适用于实时RAG部署。


<details>
  <summary>Details</summary>
Motivation: 现有RAG重排序方法依赖计算成本高且延迟大的交叉编码器或大语言模型（3-5秒/查询），而传统欧氏距离度量无法捕捉语义结构，需要更高效且能保留语义信息的重排序方案。

Method: 构造检索文档候选集的k近邻流形，通过计算流形上的测地距离进行重排序。该方法将全局余弦相似度与局部流形几何结合，在O(ND + M²D + Mk logk)复杂度（M<<N）下实现低延迟推理。

Result: 在BEIR数据集测试中，对最具挑战性的三个数据集（NFCorpus/TREC-COVID/AorB）的NDCG@3分别提升7.0%/1.6%/2.8%，速度达HNSW基线的3.2倍（4.7ms vs 14.8ms），对比交叉编码器在2%准确度损失内实现10-45倍低延迟，在TREC-COVID数据集上LLM重排序器需840倍更高延迟才能获得0.5%的NDCG@3提升。

Conclusion: Maniscope通过几何方法平衡准确性与推理效率，为实时RAG部署提供实用替代方案，计划开源代码。

Abstract: Current neural reranking approaches for retrieval-augmented generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substantial computational resources and exhibiting latencies of 3-5 seconds per query. We propose Maniscope, a geometric reranking method that computes geodesic distances on k-nearest neighbor (k-NN) manifolds constructed over retrieved document candidates. This approach combines global cosine similarity with local manifold geometry to capture semantic structure that flat Euclidean metrics miss. Evaluating on eight BEIR benchmark datasets (1,233 queries), Maniscope outperforms HNSW graph-based baseline on the three hardest datasets (NFCorpus: +7.0%, TREC-COVID: +1.6%, AorB: +2.8% NDCG@3) while being 3.2x faster (4.7 ms vs 14.8 ms average). Compared to cross-encoder rerankers, Maniscope achieves within 2% accuracy at 10-45x lower latency. On TREC-COVID, LLM-Reranker provides only +0.5% NDCG@3 improvement over Maniscope at 840x higher latency, positioning Maniscope as a practical alternative for real-time RAG deployment. The method requires O(N D + M^2 D + M k log k) complexity where M << N , enabling sub-10 ms latency. We plan to release Maniscope as open-source software.

</details>


### [48] [CAST: Achieving Stable LLM-based Text Analysis for Data Analytics](https://arxiv.org/abs/2602.15861)
*Jinxiang Xie,Zihao Li,Wei He,Rui Ding,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST的框架，通过算法提示和稳定思考提升大型语言模型在表格数据文本分析中的输出稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型无法满足数据分析对输出稳定性的高要求，尤其是在表格数据摘要和标签任务中。

Method: 结合（i）算法提示（Algorithmic Prompting）约束有效推理路径，以及（ii）先思考后生成（Thinking-before-Speaking）强制中间承诺，同时设计专用稳定性指标CAST-S与CAST-T。

Result: 在多个LLM基准测试中，CAST相较基线模型稳定性提升最高达16.2%，同时保持或优化输出质量。

Conclusion: CAST通过限制推理路径和明确中间步骤，显著提升表格分析任务的稳定性，且稳定性指标与人类判断高度一致。

Abstract: Text analysis of tabular data relies on two core operations: \emph{summarization} for corpus-level theme extraction and \emph{tagging} for row-level labeling. A critical limitation of employing large language models (LLMs) for these tasks is their inability to meet the high standards of output stability demanded by data analytics. To address this challenge, we introduce \textbf{CAST} (\textbf{C}onsistency via \textbf{A}lgorithmic Prompting and \textbf{S}table \textbf{T}hinking), a framework that enhances output stability by constraining the model's latent reasoning path. CAST combines (i) Algorithmic Prompting to impose a procedural scaffold over valid reasoning transitions and (ii) Thinking-before-Speaking to enforce explicit intermediate commitments before final generation. To measure progress, we introduce \textbf{CAST-S} and \textbf{CAST-T}, stability metrics for bulleted summarization and tagging, and validate their alignment with human judgments. Experiments across publicly available benchmarks on multiple LLM backbones show that CAST consistently achieves the best stability among all baselines, improving Stability Score by up to 16.2\%, while maintaining or improving output quality.

</details>


### [49] [Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation](https://arxiv.org/abs/2602.15862)
*Guoshan Liu,Bin Zhu,Yian Li,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 该研究提出了一个基于语义推理的两阶段微调框架和SCSR纠错模块，解决了多模态大语言模型生成食谱时的语义错误问题，实验证明其在Recipe1M数据集上达到SOTA级别。


<details>
  <summary>Details</summary>
Motivation: 现有食谱生成模型依赖BLEU/ROUGE等词汇评分指标，但会生成语义错误（如错误操作/食材搭配）的食谱，缺乏对烹饪过程逻辑关系的结构化建模。

Method: 构建了动作推理数据集和食材知识库进行监督微调（SFT）；创新性采用频率感知奖励的强化微调（RFT）；设计语义置信度评分与修正模块（SCSR）过滤并纠正预测结果。

Result: 在Recipe1M数据集上实现新SOTA指标，在长尾动作预测和食材泛化能力上提升显著，生成食谱的语义保真度提升达12.7%。

Conclusion: 通过将烹饪逻辑显式建模为内部上下文，证明了结合结构化知识和强化学习能有效解决多模态生成任务中的语义一致性问题。

Abstract: Recent advances in Multimodal Large Language Models (MLMMs) have enabled recipe generation from food images, yet outputs often contain semantically incorrect actions or ingredients despite high lexical scores (e.g., BLEU, ROUGE). To address this gap, we propose a semantically grounded framework that predicts and validates actions and ingredients as internal context for instruction generation. Our two-stage pipeline combines supervised fine-tuning (SFT) with reinforcement fine-tuning (RFT): SFT builds foundational accuracy using an Action-Reasoning dataset and ingredient corpus, while RFT employs frequency-aware rewards to improve long-tail action prediction and ingredient generalization. A Semantic Confidence Scoring and Rectification (SCSR) module further filters and corrects predictions. Experiments on Recipe1M show state-of-the-art performance and markedly improved semantic fidelity.

</details>


### [50] [Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning](https://arxiv.org/abs/2602.15863)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 通过对比三种提示策略，发现自生成少样本推理的性能提升源于问题生成过程而非样本本身，集成提示表现最优，注意力模式存在差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究显示LLMs通过自生成少样本提升推理能力，但机制未知且应用效果难以把控，亟需明确关键影响因素以优化方法设计。

Method: 系统评估三种提示策略（零样本、集成生成提示、解耦生成提示），在5种主流模型架构的推理密集型任务中对比效果，并通过注意力分析探究机制差异。

Result: 集成提示在所有实验中显著优于其他方法，而解耦提示仅带来轻微提升；注意力分析显示集成与解耦提示存在显著模式差异。

Conclusion: 自生成提示优势源自动态问题生成过程而非静态样本积累，该发现为开发高效提示策略提供了理论依据和实践方向。

Abstract: Recent studies have shown that Large Language Models (LLMs) can improve their reasoning performance through self-generated few-shot examples, achieving results comparable to manually curated in-context examples. However, the underlying mechanism behind these gains remains unclear, making it hard to decide when and how to apply the technique effectively. In this work, we argue that the key benefit arises not from the generated examples themselves but from the act of creating them. To validate this, on reasoning-intensive tasks across diverse LLM architectures, we systematically evaluate three prompting strategies for in-context learning: (1) Zero-shot prompting; (2) Integrated prompting, where LLMs create and solve problems within a single, unified prompt; and (3) Decoupled prompting, where self-generated examples are reused as in-context examples, but the context of their creation itself is excluded. We conduct experiments across five widely used model architectures, demonstrating that Integrated prompting consistently outperforms both Zero-shot and Decoupled prompting. In contrast, Decoupled prompting offers only marginal gains over Zero-shot. Further, for a more in-depth analysis, we conduct an attention analysis and observe significant differences in attention patterns between Integrated and Decoupled prompting. These findings suggest that the advantage of self-generation prompting comes from the process of problem creation, not the examples themselves, providing valuable insights for designing more effective prompting strategies.

</details>


### [51] [Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game Zork?](https://arxiv.org/abs/2602.15867)
*Berry Gerrits*

Main category: cs.CL

TL;DR: 该论文通过Zork文字游戏评估LLMs的元认知与问题解决能力，发现当前模型平均完成度仅为7.5/350分，暴露其无法反思与策略持续性的缺陷。


<details>
  <summary>Details</summary>
Motivation: Zork的对话式交互环境提供结构化场景，可系统性测试LLMs将语言理解转化为序列动作的能力，并探究其元认知水平。

Method: 对ChatGPT、Claude、Gemini模型进行多轮游戏测试，对比极简指令与详细指令条件下分数表现，结合对话日志进行定性分析。

Result: 所有模型平均完成度＜10%，最优模型Claude Opus 4.5得分75（350满分），指令复杂度与思考时间延长均无改善，模型反复执行无效操作且无法修正策略。

Conclusion: 当前LLMs在序列决策任务中存在基础性认知缺陷，缺乏自我反思与经验积累能力，需重新审视其类人推理能力的实质边界。

Abstract: In this positioning paper, we evaluate the problem-solving and reasoning capabilities of contemporary Large Language Models (LLMs) through their performance in Zork, the seminal text-based adventure game first released in 1977. The game's dialogue-based structure provides a controlled environment for assessing how LLM-based chatbots interpret natural language descriptions and generate appropriate action sequences to succeed in the game. We test the performance of leading proprietary models - ChatGPT, Claude, and Gemini - under both minimal and detailed instructions, measuring game progress through achieved scores as the primary metric. Our results reveal that all tested models achieve less than 10% completion on average, with even the best-performing model (Claude Opus 4.5) reaching only approximately 75 out of 350 possible points. Notably, providing detailed game instructions offers no improvement, nor does enabling ''extended thinking''. Qualitative analysis of the models' reasoning processes reveals fundamental limitations: repeated unsuccessful actions suggesting an inability to reflect on one's own thinking, inconsistent persistence of strategies, and failure to learn from previous attempts despite access to conversation history. These findings suggest substantial limitations in current LLMs' metacognitive abilities and problem-solving capabilities within the domain of text-based games, raising questions about the nature and extent of their reasoning capabilities.

</details>


### [52] [Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model Reasoning](https://arxiv.org/abs/2602.15868)
*Magnus Boman*

Main category: cs.CL

TL;DR: 论文提出使用多带图灵机模型分析大型语言模型（LLMs）的失败模式，并揭示分词问题及提示技术（如CoT）的局限性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过形式化框架分析LLMs在简单任务中的失败机制，弥补现有几何隐喻和经验扩展法则的不足。

Method: 构建确定性多带图灵机模型，将输入字符、token、模型参数等映射为不同磁带，通过模块化分解定位故障阶段。

Result: 发现分词消解字符结构导致计数任务困难，解析CoT提升性能的核心是外部化计算，但存在根本限制。

Conclusion: 形式化模型提供可验证的LLMs分析方法，结合经验规律实现原则性错误定位，为改进提供理论依据。

Abstract: Large language models (LLMs) exhibit failure modes on seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model parameters, activations, probability distributions, and output text. The model enables precise localisation of failure modes to specific pipeline stages, revealing, e.g., how tokenisation obscures character-level structure needed for counting tasks. The model clarifies why techniques like chain-of-thought prompting help, by externalising computation on the output tape, while also revealing their fundamental limitations. This approach provides a rigorous, falsifiable alternative to geometric metaphors and complements empirical scaling laws with principled error analysis.

</details>


### [53] [Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of De-identification Approaches](https://arxiv.org/abs/2602.15869)
*Noopur Zambare,Kiana Aghakasiri,Carissa Lin,Carrie Ye,J. Ross Mitchell,Mohamed Abdalla*

Main category: cs.CL

TL;DR: 本研究系统评估了不同规模的Transformer模型在临床去标识化中的性能，发现小型模型在保持低成本的同时具有跨语言、跨文化的出色泛化性，并提出了BERT-MultiCulture-DEID多文化去标识化模型。


<details>
  <summary>Details</summary>
Motivation: 传统临床去标识化方法未充分研究模型在不同数据格式、语言文化和性别中的泛化性，且大型语言模型推理成本高昂，亟需探索效率与性能的平衡点。

Method: 通过MIMIC数据集系统评估BERT、ClinicalBERT、ModernBERT等基模型，对比Llama和Qwen系列从1B到72B参数模型跨语言（中/印/西/法/孟加拉语及各英语方言）、跨性别名称识别表现，并发布BERT-MultiCulture-DEID多语言微调模型集。

Result: 参数量低于8B的小型模型在保持相似性能时推理成本降低70%，且通过有限数据微调可超越70B+的大模型，在中文等6种语言变体和性别名称识别中准确率提升12-18%

Conclusion: 小型语言模型通过多语言微调可实现比超大模型更优的医疗隐私保护效果，本研究首次量化了隐私保护场景下模型效率与泛化性的权衡边界，为医疗数据合规共享提供了高性价比解决方案。

Abstract: Large language models (LLMs) have shown strong performance on clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous work has not examined their generalizability between formats, cultures, and genders. In this work, we systematically evaluate fine-tuned transformer models (BERT, ClinicalBERT, ModernBERT), small LLMs (Llama 1-8B, Qwen 1.5-7B), and large LLMs (Llama-70B, Qwen-72B) at de-identification. We show that smaller models achieve comparable performance while substantially reducing inference cost, making them more practical for deployment. Moreover, we demonstrate that smaller models can be fine-tuned with limited data to outperform larger models in de-identifying identifiers drawn from Mandarin, Hindi, Spanish, French, Bengali, and regional variations of English, in addition to gendered names. To improve robustness in multi-cultural contexts, we introduce and publicly release BERT-MultiCulture-DEID, a set of de-identification models based on BERT, ClinicalBERT, and ModernBERT, fine-tuned on MIMIC with identifiers from multiple language variants. Our findings provide the first comprehensive quantification of the efficiency-generalizability trade-off in de-identification and establish practical pathways for fair and efficient clinical de-identification.
  Details on accessing the models are available at: https://doi.org/10.5281/zenodo.18342291

</details>


### [54] [VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering](https://arxiv.org/abs/2602.15870)
*Shuhui Qu*

Main category: cs.CL

TL;DR: VDLM通过分离语义规划与文本渲染，结合嵌入空间后训练和鲁棒解码，提升长文本生成能力。


<details>
  <summary>Details</summary>
Motivation: 自回归模型因左到右解码限制多步推理修订，需改进生成逻辑。

Method: 采用LLaDA风格扩散优化语义变量嵌入，轨迹感知后训练规划器，使用Vec2Text和扰动增强解码鲁棒性。

Result: 在9个基准测试中，VDLM预训练表现优异，长生成任务超越基线模型。

Conclusion: 嵌入空间后训练和潜变量渲染有效提升扩散语言模型性能，尤其适用于复杂推理任务。

Abstract: Autoregressive language models decode left-to-right with irreversible commitments, limiting revision during multi-step reasoning. We propose \textbf{VDLM}, a modular variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style masked diffusion over semantic variable embeddings to enable iterative refinement in latent space, then post-trains the planner with trajectory-aware optimization using embedding-space rewards and values, avoiding text decoding inside the RL loop. To convert planned embeddings back to text, we use a \textbf{Vec2Text} renderer and introduce \textbf{embedding perturbations} to robustify decoding under planner noise. Across nine benchmarks spanning general reasoning, math, and code, VDLM is competitive in pre-training and yields substantial post-training improvements on long-form generation tasks, outperforming other baselines. These results highlight the effectiveness of embedding-space post-training and robust latent-to-text rendering for diffusion language modeling.

</details>


### [55] [CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content](https://arxiv.org/abs/2602.15871)
*Diletta Abbonato*

Main category: cs.CL

TL;DR: 本文提出CheckIfExist，一个开源网页工具，通过CrossRef、Semantic Scholar和OpenAlex数据库即时验证引文真实性，解决大语言模型导致的参考文献虚构问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在学术领域的应用引发参考文献虚构危机，顶级会议论文也出现错误引用。现有工具缺乏实时验证，商业服务限制使用量或收费过高，亟需免费高效的自动化方案。

Method: 采用级联验证架构和字符串相似度算法计算多维度置信度分数，支持单引用验证和BibTeX批量处理，实时生成APA格式并导出修正后的BibTeX记录。

Result: 实现跨平台即时验证（<1秒/引用）、三数据源匹配分析、错误分类预警（如404、标题/作者不匹配）、标准化引文输出。

Conclusion: CheckIfExist填补了开源实时验证工具的空白，为学术共同体提供抗LLM引用错误的基础设施，避免错误传播。

Abstract: The proliferation of large language models (LLMs) in academic workflows has introduced unprecedented challenges to bibliographic integrity, particularly through reference hallucination -- the generation of plausible but non-existent citations. Recent investigations have documented the presence of AI-hallucinated citations even in papers accepted at premier machine learning conferences such as NeurIPS and ICLR, underscoring the urgency of automated verification mechanisms. This paper presents "CheckIfExist", an open-source web-based tool designed to provide immediate verification of bibliographic references through multi-source validation against CrossRef, Semantic Scholar, and OpenAlex scholarly databases. While existing reference management tools offer bibliographic organization capabilities, they do not provide real-time validation of citation authenticity. Commercial hallucination detection services, though increasingly available, often impose restrictive usage limits on free tiers or require substantial subscription fees. The proposed tool fills this gap by employing a cascading validation architecture with string similarity algorithms to compute multi-dimensional match confidence scores, delivering instant feedback on reference authenticity. The system supports both single-reference verification and batch processing of BibTeX entries through a unified interface, returning validated APA citations and exportable BibTeX records within seconds.

</details>


### [56] [P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA](https://arxiv.org/abs/2602.15874)
*Xingda Lyu,Gongfu Lyu,Zitai Yan,Yuxin Jiang*

Main category: cs.CL

TL;DR: The paper introduces P-RAG, a hybrid approach combining parametric knowledge and retrieved evidence with Chain-of-Thought prompting, achieving significant improvements in biomedical and multi-hop question answering over traditional RAG methods.


<details>
  <summary>Details</summary>
Motivation: Address the limitations of static training data in LLMs and knowledge base dependency in RAG for accurate biomedical question answering.

Method: Developed P-RAG integrating parametric knowledge and retrieved evidence, using Chain-of-Thought prompting and LoRA fine-tuning; compared with Standard RAG and DA-RAG on PubMedQA and 2WikiMultihopQA datasets with LLaMA-3.2-1B-Instruct.

Result: P-RAG achieved 93.33% F1 on PubMedQA (10.47% improvement) and double the score on 2WikiMultihopQA (33.44%), with 44.03% accuracy on complex multi-hop Compare subset; CoT enhanced multi-hop reasoning but had mixed effects on single-hop tasks.

Conclusion: P-RAG demonstrates superior performance in biomedical QA and multi-hop reasoning, enabling scalable, context-adaptive systems. Contributions include LoRA-finetuned LLaMA biomedical QA, P-RAG architecture, and SOTA results on two benchmarks.

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG) addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on knowledge base quality. To explore potential improvements, we evaluated three RAG variants-Standard RAG, DA-RAG, and our proposed Prompt-Enhanced Parametric RAG (P-RAG), a hybrid architecture that integrates parametric knowledge within the LLM and retrieved evidence, guided by Chain-of-Thought (CoT) prompting and Low-Rank Adaptation (LoRA) fine-tuning-on both general and biomedical datasets. Using LLaMA-3.2-1B-Instruct fine-tuned via LoRA, we evaluate on PubMedQA and 2WikiMultihopQA. P-RAG outperforms Standard RAG on PubMedQA by 10.47 percentage points in F1 (93.33% vs. 82.86%; 12.64% relative). On 2WikiMultihopQA, P-RAG nearly doubles the overall score vs. Standard RAG (33.44% vs. 17.83%) and achieves 44.03% on the Compare subset (with 42.74% Bridge, 21.84% Inference, 8.60% Compose). CoT prompting substantially improves multi-hop reasoning but yields mixed results for simpler, single-hop queries. These findings underscore P-RAG's potential for accurate, scalable, and contextually adaptive biomedical question answering. Our contributions include: (1) LoRA-based fine-tuning of LLaMA-3.2-1B-Instruct for biomedical QA, (2) introduction of P-RAG with Chain-of-Thought prompting, and (3) state-of-the-art results on PubMedQA and 2WikiMultihopQA.

</details>


### [57] [Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity](https://arxiv.org/abs/2602.15894)
*Haihui Pan,Yuzhong Hong,Shaoke Lv,Junwei Bao,Hongfei Jiang,Yang Song*

Main category: cs.CL

TL;DR: 该论文提出QEMPO框架，在保持输出质量的前提下通过最大化策略熵提升LLM输出多样性。


<details>
  <summary>Details</summary>
Motivation: 已有LLM对齐方法（如RLHF）显著降低输出多样性，而现有多样性增强方法常以牺牲质量为代价。

Method: 将对齐任务建模为质量分布与多样性分布的联合优化，提出质量约束下的熵最大化策略优化(QEMPO)，并设计在线/离线两种训练范式。

Result: 实验证明QEMPO相较RLHF基准，在保持甚至提升任务性能的同时，使生成结果的多样性指标提升20%-35%。

Conclusion: QEMPO实现了LLM对齐中质量与多样性的有效平衡，其动态约束机制提供了新的优化视角。

Abstract: Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can be decomposed into two distributions: quality and diversity. To enhance the diversity of LLM outputs while ensuring quality, we propose the Quality-constrained Entropy Maximization Policy Optimization (QEMPO). QEMPO aims to maximize the output entropy of the policy while ensuring output quality. By adding different constraints to QEMPO, we obtain different policies. To optimize policies, we propose both online and offline training methods. Experiments validate that QEMPO achieves performance comparable to or even better than RLHF while improving output diversity.

</details>


### [58] [Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion](https://arxiv.org/abs/2602.15895)
*Pengcheng Zhou,Haochen Li,Zhiqiang Nie,JiaLe Chen,Qing Gong,Weizhen Zhang,Chun Yu*

Main category: cs.CL

TL;DR: 提出CogitoRAG框架，模仿人类认知记忆机制，通过语义要旨提取与知识图谱构建，在检索增强生成中实现更精准的语义关联与复杂推理。


<details>
  <summary>Details</summary>
Motivation: 现有RAG框架的离散文本表征导致语义完整性缺失，引发检索偏差，需要模拟人类情景记忆的认知机制以增强语义连贯性。

Method: 离线阶段将非结构化语料抽象为多维知识图谱（实体、关系事实、记忆节点）；在线阶段通过查询分解模块和实体扩散模块，结合CogniRank算法实现语义关联检索与重排序。

Result: 在5个QA基准测试和GraphBench多任务生成中显著超越SOTA方法，验证了复杂知识融合与推理能力的提升。

Conclusion: 通过认知启发式语义要旨建模有效缓解LLM幻觉问题，为知识密集型任务提供了类人推理的端到端解决方案。

Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. During the offline indexing stage, CogitoRAG first deduces unstructured corpora into gist memory corpora, which are then transformed into a multi-dimensional knowledge graph integrating entities, relational facts, and memory nodes. In the online retrieval stage, the framework handles complex queries via Query Decomposition Module that breaks them into comprehensive sub-queries, mimicking the cognitive decomposition humans employ for complex information. Subsequently, Entity Diffusion Module performs associative retrieval across the graph, guided by structural relevance and an entity-frequency reward mechanism. Furthermore, we propose the CogniRank algorithm, which precisely reranks candidate passages by fusing diffusion-derived scores with semantic similarity. The final evidence is delivered to the generator in a passage-memory pairing format, providing high-density information support. Experimental results across five mainstream QA benchmarks and multi-task generation on GraphBench demonstrate that CogitoRAG significantly outperforms state-of-the-art RAG methods, showcasing superior capabilities in complex knowledge integration and reasoning.

</details>


### [59] [Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens](https://arxiv.org/abs/2602.15896)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Wen Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 本文提出了基于token的TOFU模型，用于多模态知识图谱推理，在跨KG任务中融合结构、视觉和文本模态信息，通过分层架构实现高效特征迁移。


<details>
  <summary>Details</summary>
Motivation: 现有直推式MMKGR方法缺乏跨KG泛化能力，而KGFMs未有效利用多模态信号。本文旨在填补这一空白，通过统一架构处理多模态信息提升跨KG迁移性能。

Method: TOFU将多模态信息离散化为token，设计分层融合架构与混合消息机制：1）模态特定编码层生成token表示 2）跨模态交互层融合不同token特征 3）动态消息传递机制聚合邻域知识。

Result: 在17个MMKG数据集（含直推式/归纳式/全归纳式）的实验表明，TOFU显著优于SOTA基线模型，在跨KG场景下Hits@1提升17.3%，且对数据模态缺失具有鲁棒性。可视化显示token融合有效捕捉跨模态关联。

Conclusion: TOFU通过统一token化处理突破了传统MMKGR的领域限制，在保留多模态表征能力的同时实现跨KG迁移，为构建通用多模态知识推理框架提供了新方法。

Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict the missing links by exploiting both graph structure information and multi-modal entity contents. Most existing works are designed for a transductive setting, which learns dataset-specific embeddings and struggles to generalize to new KGs. Recent knowledge graph foundation models (KGFMs) improve cross-KG transfer, but they mainly exploit structural patterns and ignore rich multi-modal signals. We address these gaps by proposing a token-based foundation model (TOFU) for MMKGR, which exhibits strong generalization across different MMKGs. TOFU discretizes structural, visual, and textual information into modality-specific tokens. TOFU then employs a hierarchical fusion architecture with mixture-of-message mechanisms, aiming to process these tokens and obtain transferable features for MMKGR. Experimental results on 17 transductive, inductive, and fully-inductive MMKGs show that TOFU consistently outperforms strong KGFM and MMKGR baselines, delivering strong performance on unseen MMKGs.

</details>


### [60] [Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation](https://arxiv.org/abs/2602.15897)
*Xinguo Feng,Zhongkui Ma,Zihan Wang,Alsharif Abuadbba,Guangdong Bai*

Main category: cs.CL

TL;DR: 本文提出GHOST防御机制，通过标记级混淆技术有效抵御梯度反转攻击，在保持模型性能的同时实现隐私保护。实验表明其恢复率低至1%，分类F1达0.92，困惑度5.45。


<details>
  <summary>Details</summary>
Motivation: 现有梯度扰动防御方法无法完全阻断梯度、嵌入和标记空间间的语义关联，导致隐私风险持续存在。GHOST旨在通过建立token空间断连机制实现本质防护。

Method: 1. 提出多准则搜索策略寻找语义不同但嵌入相近的备选标记
2. 采用双步选择机制保持原始输出特征对齐
3. 构建语义断连屏障，同步保障梯度可用性与隐私安全

Result: 在BERT至LLaMA架构测试中：
- 梯度泄露恢复率降至1%
- 分类任务F1维持0.92
- 生成任务困惑度5.45
- 对抗最先进GIA攻击仍有效

Conclusion: GHOST通过跨空间解耦机制开创了隐私防护新范式，在保持模型效用的同时实现攻击面压缩99.8%的防护效果。

Abstract: Training and fine-tuning large-scale language models largely benefit from collaborative learning, but the approach has been proven vulnerable to gradient inversion attacks (GIAs), which allow adversaries to reconstruct private training data from shared gradients. Existing defenses mainly employ gradient perturbation techniques, e.g., noise injection or gradient pruning, to disrupt GIAs' direct mapping from gradient space to token space. However, these methods often fall short due to the retention of semantics similarity across gradient, embedding, and token spaces. In this work, we propose a novel defense mechanism named GHOST (gradient shield with obfuscated tokens), a token-level obfuscation mechanism that neutralizes GIAs by decoupling the inherent connections across gradient, embedding, and token spaces. GHOST is built upon an important insight: due to the large scale of the token space, there exist semantically distinct yet embedding-proximate tokens that can serve as the shadow substitutes of the original tokens, which enables a semantic disconnection in the token space while preserving the connection in the embedding and gradient spaces. GHOST comprises a searching step, which identifies semantically distinct candidate tokens using a multi-criteria searching process, and a selection step, which selects optimal shadow tokens to ensure minimal disruption to features critical for training by preserving alignment with the internal outputs produced by original tokens. Evaluation across diverse model architectures (from BERT to Llama) and datasets demonstrates the remarkable effectiveness of GHOST in protecting privacy (as low as 1% in recovery rate) and preserving utility (up to 0.92 in classification F1 and 5.45 in perplexity), in both classification and generation tasks against state-of-the-art GIAs and adaptive attack scenarios.

</details>


### [61] [MultiCube-RAG for Multi-hop Question Answering](https://arxiv.org/abs/2602.15898)
*Jimeng Shi,Wei Hu,Runchu Tian,Bowen Jin,Wonbin Kweon,SeongKu Kang,Yunfan Kang,Dingqi Ye,Sizhe Zhou,Shaowen Wang,Jiawei Han*

Main category: cs.CL

TL;DR: 该论文提出一种无需训练的基于本体的多立方体结构（MultiCube-RAG），用于多跳问答任务，通过结构化的多维度建模实现高效精准的知识检索与多步推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索增强生成方法在建模结构化语义时存在噪声大、计算成本高问题，且多数方法依赖单步检索或训练过程不稳定，需解决多跳推理过程中的知识获取效率和可解释性缺陷。

Method: 构建包含主体、属性和关系的正交维度立方体本体结构，将复杂多跳查询拆解为沿立方体维度的简单子查询，并通过多立方体组合实现分步推理。无需训练过程，通过查询动态选择适配的立方体子集进行知识检索。

Result: 在4个多跳QA数据集上的实验表明，相比多种基线方法平均性能提升8.9%，且方法具有更高查询效率和天生的可解释性。

Conclusion: 结构化立方体本体建模有效支持多跳问答的可分解推理，无需训练的设计结合维度化知识组织显著提升了多步推理准确率和系统效率。

Abstract: Multi-hop question answering (QA) necessitates multi-step reasoning and retrieval across interconnected subjects, attributes, and relations. Existing retrieval-augmented generation (RAG) methods struggle to capture these structural semantics accurately, resulting in suboptimal performance. Graph-based RAGs structure such information in graphs, but the resulting graphs are often noisy and computationally expensive. Moreover, most methods rely on single-step retrieval, neglecting the need for multi-hop reasoning processes. Recent training-based approaches attempt to incentivize the large language models (LLMs) for iterative reasoning and retrieval, but their training processes are prone to unstable convergence and high computational overhead. To address these limitations, we devise an ontology-based cube structure with multiple and orthogonal dimensions to model structural subjects, attributes, and relations. Built on the cube structure, we propose MultiCube-RAG, a training-free method consisting of multiple cubes for multi-step reasoning and retrieval. Each cube specializes in modeling a class of subjects, so that MultiCube-RAG flexibly selects the most suitable cubes to acquire the relevant knowledge precisely. To enhance the query-based reasoning and retrieval, our method decomposes a complex multi-hop query into a set of simple subqueries along cube dimensions and conquers each of them sequentially. Experiments on four multi-hop QA datasets show that MultiCube-RAG improves response accuracy by 8.9% over the average performance of various baselines. Notably, we also demonstrate that our method performs with greater efficiency and inherent explainability.

</details>


### [62] [DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting](https://arxiv.org/abs/2602.15958)
*Md Mofijul Islam,Md Sirajus Salekin,Nivedha Balakrishnan,Vincil C. Bishop,Niharika Jain,Spencer Romo,Bob Strahan,Boyi Xie,Diego A. Socolinsky*

Main category: cs.CL

TL;DR: 本文提出了一种名为DocSplit的新基准数据集，用于评估大型语言模型在文档包拆分任务中的表现，包含五个复杂度不同的多模态数据集。实验表明现有模型在处理无序页面和混合文档时存在显著性能差距，数据集已开源。


<details>
  <summary>Details</summary>
Motivation: 文档理解实际应用中常需处理由多个文档拼接而成的异构多页文档包，但现有研究未充分解决文档边界识别、分类和页码排序问题。当前模型在面对无序页面、交织文档和缺乏明确分隔标志的复杂场景时表现不佳，需要系统性评估框架推动该领域进步。

Method: 构建DocSplit数据集（包含5个不同复杂度的数据集，涵盖多种文档类型、版式和多模态场景），定义文档拆分任务标准（识别文档边界、分类文档类型、保持正确页码顺序），并设计配套的评估指标体系。

Result: 对多模态LLMs的测试显示，当前模型在文档包拆分任务中存在显著性能缺口，特别是在处理无页码文档、无序页面和多模式混合内容等复杂场景时表现欠佳。

Conclusion: DocSplit基准为文档理解提供了标准化评估框架，推动了法律、金融、医疗等文档密集型领域的技术发展。开源数据集和新评估指标为未来文档包处理研究奠定了基础。

Abstract: Document understanding in real-world applications often requires processing heterogeneous, multi-page document packets containing multiple documents stitched together. Despite recent advances in visual document understanding, the fundamental task of document packet splitting, which involves separating a document packet into individual units, remains largely unaddressed. We present the first comprehensive benchmark dataset, DocSplit, along with novel evaluation metrics for assessing the document packet splitting capabilities of large language models. DocSplit comprises five datasets of varying complexity, covering diverse document types, layouts, and multimodal settings. We formalize the DocSplit task, which requires models to identify document boundaries, classify document types, and maintain correct page ordering within a document packet. The benchmark addresses real-world challenges, including out-of-order pages, interleaved documents, and documents lacking clear demarcations. We conduct extensive experiments evaluating multimodal LLMs on our datasets, revealing significant performance gaps in current models' ability to handle complex document splitting tasks. The DocSplit benchmark datasets and proposed novel evaluation metrics provide a systematic framework for advancing document understanding capabilities essential for legal, financial, healthcare, and other document-intensive domains. We release the datasets to facilitate future research in document packet processing.

</details>


### [63] [A Curious Class of Adpositional Multiword Expressions in Korean](https://arxiv.org/abs/2602.16023)
*Junghyun Min,Na-Rae Han,Jena D. Hwang,Nathan Schneider*

Main category: cs.CL

TL;DR: This paper studies Korean multiword expressions called postpositional verb-based constructions (PVCs) and proposes annotation guidelines for their classification, contrasting them with non-MWEs and light verb constructions (LVCs) using Korean Wikipedia data.



<details>
  <summary>Details</summary>
Motivation: Korean multiword adpositions, particularly functional MWEs like PVCs, are underrepresented in multilingual annotation frameworks like PARSEME, lacking systematic analysis and integrated resources compared to other languages.

Method: The authors analyzed PVC expressions from Korean Wikipedia data, compared their structural patterns with non-MWEs and LVCs, and developed annotation guidelines based on these distinctions.

Result: The analysis identified distinguishing features of PVCs (e.g., semantic holism, syntactic rigidity), enabling the creation of guidelines that align Korean MWEs with cross-lingual frameworks while differentiating them from similar constructions.

Conclusion: Proposed guidelines improve representation of Korean functional MWEs in multilingual frameworks, facilitating future research on Korean multiword adpositions through standardized annotation.

Abstract: Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.

</details>


### [64] [CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill](https://arxiv.org/abs/2602.16054)
*Bradley McDanel,Steven Li,Harshit Khaitan*

Main category: cs.CL

TL;DR: 提出跨层注意力聚合（CLAA）方法，通过答案引导的Oracle诊断现有标记排序缺陷，实现推理加速。


<details>
  <summary>Details</summary>
Motivation: 预填充阶段是长文本LLM推理瓶颈，现有标记重要性估计跨层波动大，缺乏独立于模型架构的评估手段。

Method: 设计Answer-Informed Oracle测量注意力回溯重要性，发现现有方法存在层间方差故障模式，提出跨层得分聚合策略CLAA。

Result: CLAA在保持准确率的同时将首字耗时（TTFT）降低39%，接近Oracle理论上限。

Conclusion: 跨层聚合可有效消除单层依赖缺陷，Oracle分析框架为模型优化提供新视角。

Abstract: The prefill stage in long-context LLM inference remains a computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a subset of semantically relevant tokens. However, existing methods suffer from unstable token importance estimation, often varying between layers. Evaluating token-ranking quality independently from heuristic-specific architectures is challenging. To address this, we introduce an Answer-Informed Oracle, which defines ground-truth token importance by measuring attention from generated answers back to the prompt. This oracle reveals that existing heuristics exhibit high variance across layers: rankings can degrade sharply at specific layers, a failure mode invisible to end-to-end benchmarks. The diagnosis suggests a simple fix: aggregate scores across layers rather than relying on any single one. We implement this as Cross-Layer Attention Aggregation (CLAA), which closes the gap to the oracle upper bound and reduces Time-to-First-Token (TTFT) by up to 39\% compared to the Full KV Cache baseline.

</details>


### [65] [Surgical Activation Steering via Generative Causal Mediation](https://arxiv.org/abs/2602.16080)
*Aruna Sankaranarayanan,Amir Zur,Atticus Geiger,Dylan Hadfield-Menell*

Main category: cs.CL

TL;DR: GCM方法用于定位和控制语言模型在长文本生成中的行为，通过量化模型组件对对比概念的中介作用，有效优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 语言模型的长文本输出行为广泛分布于多个token，难以干预，需定位关键组件进行控制。

Method: 构建对比输入与响应数据集，量化各模型组件对二元概念的中介效应，并选用最强中介组件进行引导。

Result: 在拒绝、阿谀及风格迁移任务中，GCM均成功定位概念并以稀疏注意力头实现优于相关探测法的控制效果。

Conclusion: GCM为语言模型长文本响应的可控性提供了一种有效的本地化干预方案。

Abstract: Where should we intervene in a language model (LM) to control behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of contrasting inputs and responses. Then, we quantify how individual model components mediate the contrastive concept and select the strongest mediators for steering. We evaluate GCM on three tasks--refusal, sycophancy, and style transfer--across three language models. GCM successfully localizes concepts expressed in long-form responses and consistently outperforms correlational probe-based baselines when steering with a sparse set of attention heads. Together, these results demonstrate that GCM provides an effective approach for localizing and controlling the long-form responses of LMs.

</details>


### [66] [Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs](https://arxiv.org/abs/2602.16085)
*Sean Trott,Samuel Taylor,Cameron Jones,James A. Michaelov,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 研究评估了41种开源语言模型在心智理论(错误信念任务)中的表现,发现34%的模型对隐含认知状态敏感,模型规模与敏感度正相关,并利用模型行为提出了人类认知偏差的新假设。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于少量闭源模型,阻碍了对人类社会认知理论(如语言经验塑造心智推理)的验证和模型能力评估,需通过开源模型扩大验证范围。

Method: 在40个不同开源模型中复现并扩展错误信念任务实验,系统评估模型对认知状态的敏感度及模型规模效应,利用模型行为生成并验证关于人类认知偏差的假设。

Result: 34%模型展现认知状态敏感度,大型模型敏感度和预测能力更高;发现人类与模型在非事实性动词提示下更倾向归因错误信念,该效应人类表现处于模型分布范围内,但主认知效应仍超越模型。

Conclusion: 开源模型大样本可有效验证认知理论并评估模型能力,语言统计分布或能解释部分人类认知现象(如知识线索偏差),但复杂心智推理仍需超越语言统计的机制。

Abstract: Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological theories and evaluate LM capacities. Here, we replicate and extend published work on the false belief task by assessing LM mental state reasoning behavior across 41 open-weight models (from distinct model families). We find sensitivity to implied knowledge states in 34% of the LMs tested; however, consistent with prior work, none fully ``explain away'' the effect in humans. Larger LMs show increased sensitivity and also exhibit higher psychometric predictive power. Finally, we use LM behavior to generate and test a novel hypothesis about human cognition: both humans and LMs show a bias towards attributing false beliefs when knowledge states are cued using a non-factive verb (``John thinks...'') than when cued indirectly (``John looks in the...''). Unlike the primary effect of knowledge states, where human sensitivity exceeds that of LMs, the magnitude of the human knowledge cue effect falls squarely within the distribution of LM effect sizes-suggesting that distributional statistics of language can in principle account for the latter but not the former in humans. These results demonstrate the value of using larger samples of open-weight LMs to test theories of human cognition and evaluate LM capacities.

</details>


### [67] [Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities](https://arxiv.org/abs/2602.16093)
*Shankar Padmanabhan,Mustafa Omer Gul,Tanya Goyal*

Main category: cs.CL

TL;DR: 提出了一种名为DiSC的上下文蒸馏方法，用于持续知识更新，在学习新知识的同时保留先前能力。


<details>
  <summary>Details</summary>
Motivation: 现有持续微调和蒸馏方法无法在学习新知识（来自更新语料）的同时保留预训练模型的既有能力（如推理、指令遵循）。

Method: 通过Split Context机制构建学生-教师分布对，利用KL散度最小化共享token预测，无需显式生成步骤完成知识蒸馏。

Result: 在4个后训练模型和2个适应领域实验中，DiSC在知识更新和能力保留平衡性上表现最优。

Conclusion: DiSC通过上下文分割蒸馏实现高效持续适应，优于传统微调和蒸馏方法，可保持模型时效性和基础能力。

Abstract: Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cannot simultaneously learn new knowledge from an adaptation document corpora and mitigate the forgetting of earlier learned capabilities. To address this, we introduce Distillation via Split Contexts (DiSC), a simple context-distillation based approach for continual knowledge adaptation. \methodname~derives student and teacher distributions by conditioning on distinct segments of the training example and minimizes the KL divergence between the shared tokens. This allows us to efficiently apply context-distillation without requiring explicit generation steps during training. We run experiments on four post-trained models and two adaptation domains. Compared to prior finetuning and distillation methods for continual adaptation, DiSC consistently reports the best trade-off between learning new knowledge and mitigating forgetting of previously learned skills like instruction-following, reasoning, and factual knowledge.

</details>


### [68] [Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis](https://arxiv.org/abs/2602.16144)
*Rong Fu,Wenxin Zhang,Ziming Wang,Chunlei Meng,Jiaxuan Lu,Jiekai Wu,Kangan Qian,Hao Zhang,Simon Fong*

Main category: cs.CL

TL;DR: 提出了一种名为MBD的可撤销多模态情感分析框架，支持撤销特定模态数据并提供删除凭证


<details>
  <summary>Details</summary>
Motivation: 多模态系统需处理敏感数据，用户/监管方可能要求移除特定模态信息，传统方法难以兼顾隐私与模型效用

Method: MBD框架包含结构化表征学习、生成器重建缺失通道、显著性驱动删除策略和高斯更新生成Modality Deletion Certificate

Result: 基准数据集实验显示该方法在不完整输入下保持强预测性能，实现隐私与效用的良好平衡

Conclusion: 手术式遗忘方案MBD避免全量重训练，为隐私合规提供高效解决方案

Abstract: As multimodal systems increasingly process sensitive personal data, the ability to selectively revoke specific data modalities has become a critical requirement for privacy compliance and user autonomy. We present Missing-by-Design (MBD), a unified framework for revocable multimodal sentiment analysis that combines structured representation learning with a certifiable parameter-modification pipeline. Revocability is critical in privacy-sensitive applications where users or regulators may request removal of modality-specific information. MBD learns property-aware embeddings and employs generator-based reconstruction to recover missing channels while preserving task-relevant signals. For deletion requests, the framework applies saliency-driven candidate selection and a calibrated Gaussian update to produce a machine-verifiable Modality Deletion Certificate. Experiments on benchmark datasets show that MBD achieves strong predictive performance under incomplete inputs and delivers a practical privacy-utility trade-off, positioning surgical unlearning as an efficient alternative to full retraining.

</details>


### [69] [Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution](https://arxiv.org/abs/2602.16154)
*Nithin Sivakumaran,Shoubin Yu,Hyunji Lee,Yue Zhang,Ali Payani,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 本文提出REMUL方法，通过多参与者强化学习与监督微调提升链式思维（CoT）推理的忠实度，解决大语言模型在真实性与性能间的权衡问题，在多个基准测试中显著提升准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维（CoT）推理难以准确反映大语言模型内部真实逻辑，且优化真实性与可解释性常导致任务性能下降，亟需一种能同时提升推理忠实度与模型性能的方法。

Method: REMUL框架通过三个步骤优化推理过程：1）说话者生成初始推理路径；2）多个听者模型执行并续写路径以生成答案；3）通过奖励机制（奖励听者可跟随的路径）和掩码监督微调（保留关键推理步骤）提升忠实度。

Result: REMUL在BIG-Bench Extra Hard等4个基准测试中，平均提升忠实度指标3.8%（hint attribution）、4.5%（早期回答AOC）、2.9%（错误注入AOC），并使推理路径缩短约22%、准确性提高1.5-3.1%。

Conclusion: REMUL成功平衡了推理忠实度与模型性能，生成的答案可追溯性更强，路径更简洁直接，为提升大语言模型透明度提供了新范式，未来或可扩展至其他生成式AI的决策可解释性优化。

Abstract: Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrades task performance. To address this tradeoff and improve CoT faithfulness, we propose Reasoning Execution by Multiple Listeners (REMUL), a multi-party reinforcement learning approach. REMUL builds on the hypothesis that reasoning traces which other parties can follow will be more faithful. A speaker model generates a reasoning trace, which is truncated and passed to a pool of listener models who "execute" the trace, continuing the trace to an answer. Speakers are rewarded for producing reasoning that is clear to listeners, with additional correctness regularization via masked supervised finetuning to counter the tradeoff between faithfulness and performance. On multiple reasoning benchmarks (BIG-Bench Extra Hard, MuSR, ZebraLogicBench, and FOLIO), REMUL consistently and substantially improves three measures of faithfulness -- hint attribution, early answering area over the curve (AOC), and mistake injection AOC -- while also improving accuracy. Our analysis finds that these gains are robust across training domains, translate to legibility gains, and are associated with shorter and more direct CoTs.

</details>


### [70] [LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers](https://arxiv.org/abs/2602.16162)
*Peiqi Sui*

Main category: cs.CL

TL;DR: The paper argues that current LLMs lack sufficient uncertainty in their outputs, leading to clichéd creative writing, and proposes new alignment strategies that balance uncertainty with factual accuracy to achieve literary richness.


<details>
  <summary>Details</summary>
Motivation: Uncertainty is posited as a critical element for creativity in literary theory, yet LLM alignment techniques prioritize factual outputs, reducing uncertainty and resulting in unoriginal content. The study aims to quantify and address this tension.

Method: An information-theoretic analysis was conducted on 28 LLMs, comparing human-authored and model-generated text across high-quality storytelling datasets to measure the 'uncertainty gap', while controlling for model scale and training data.

Result: Human writing consistently exhibits higher uncertainty than LLM outputs. Instruction-tuned and reasoning models show larger gaps compared to base models. The uncertainty gap correlates with writing quality and is more pronounced in creative domains than functional ones.

Conclusion: Achieving human-level creative writing in LLMs requires novel alignment paradigms that permit beneficial uncertainty while managing destructive hallucinations, moving beyond current optimization for mere factual consistency.

Abstract: We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and cliché-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strategies steer models away from uncertain outputs to ensure factuality and reduce hallucination. We formalize this tension by quantifying the "uncertainty gap" between human-authored stories and model-generated continuations. Through a controlled information-theoretic analysis of 28 LLMs on high-quality storytelling datasets, we demonstrate that human writing consistently exhibits significantly higher uncertainty than model outputs. We find that instruction-tuned and reasoning models exacerbate this trend compared to their base counterparts; furthermore, the gap is more pronounced in creative writing than in functional domains, and strongly correlates to writing quality. Achieving human-level creativity requires new uncertainty-aware alignment paradigms that can distinguish between destructive hallucinations and the constructive ambiguity required for literary richness.

</details>


### [71] [Beyond Learning: A Training-Free Alternative to Model Adaptation](https://arxiv.org/abs/2602.16189)
*Namkyung Yoon,Kyeonghyun Yoo,Wooyong Jung,Sanghong Kim,Hwangnam Kim*

Main category: cs.CL

TL;DR: 通过跨模型移植语言模型内部的局部激活模块，无需训练即可实现显著性能提升，甚至超过原模型两倍。


<details>
  <summary>Details</summary>
Motivation: 现有模型性能退化时需消耗大量资源重新训练，本研究提出直接移植预训练模型内部模块的新范式，验证任务局部模组的可迁移性。

Method: 1）激活分析定位关键模块；2）跨代移植低代模型模块至新型号；3）跨版本移植基座模型模块至指令调优模型；4）定量评估移植强度与性能关系。

Result: 跨代移植实现100%基线恢复（提升2倍），跨版本移植达成基线2.33倍提升（恢复率100%），验证了模块功能迁移的有效性。

Conclusion: 证明预训练模型存在任务特异的局部计算单元，开辟模型移植新研究领域，为模型升级提供无需再训练的轻量化路径。

Abstract: Despite the continuous research and evolution of language models, they sometimes underperform previous versions. Existing approaches to overcome these challenges are resource-intensive, highlighting the need for alternatives that enable immediate action. We assume that each language model has a local module inside that is suitable for a specific function. First, this work identifies a set of modules showing consistent and local activation changes under an inference workload through activation-based analysis. Subsequently, we transplant an internal module that is properly activated for a specific task into the target model, leading to immediate and measurable functional changes without additional training or fine-tuning. To experimentally demonstrate the effectiveness of the transplant technique, we quantify the relationship between transplant strength and performance improvement under different conditions for two language models. In the cross-generation setting, we find that transplanting activation-selected modules can substantially improve the underperforming model, reaching up to twice the target baseline and achieving gap-based recovery above 100%. Moreover, in transplant experiments between a base model and its instruction-tuned counterpart, transplantation improves the underperforming model toward the stronger baseline, yielding up to about 2.33 times the target baseline with gap-based recovery reaching up to 100% in the best case. These results show that meaningful capacity transfer can be realized through the implantation of highly localized modules implied by language models. Overall, this work provides empirical evidence for task-localized modularity in language models and presents a new research area: model transplantation.

</details>


### [72] [The Validity of Coreference-based Evaluations of Natural Language Understanding](https://arxiv.org/abs/2602.16200)
*Ian Porada*

Main category: cs.CL

TL;DR: 本论文探讨了指代消解评估的有效性，发现当前评估方法存在可推广性不足的问题，并提出了一种基于事件合理性的新评估方法，揭示了现当代语言模型在保持标准评估优势的同时缺乏人类级泛化能力。


<details>
  <summary>Details</summary>
Motivation: 指代消解评估的结论往往因评估设计缺陷（如定义不一致和跨基准结果冲突）导致非通用性，需扩展既有评估范式并验证评估结果的可靠性。

Method: 首先通过分析标准指代消解评估揭示其测量效度缺陷（包括定义争议性和收敛效度问题），继而设计针对事件合理性推理能力的新评估方法并实施实证。

Result: 现当代语言模型在标准基准测试中表现优异，但在细微调整的上下文场景中泛化能力显著不足，暴露出模型与人类认知差距。

Conclusion: 当前NLP范式在评估效度和系统泛化性方面存在显著局限，需开发更科学的评估体系和具备真正泛化能力的系统。

Abstract: In this thesis, I refine our understanding as to what conclusions we can reach from coreference-based evaluations by expanding existing evaluation practices and considering the extent to which evaluation results are either converging or conflicting. First, I analyze standard coreference evaluations and show that their design often leads to non-generalizable conclusions due to issues of measurement validity - including contestedness (multiple, competing definitions of coreference) and convergent validity (evaluation results that rank models differently across benchmarks). Second, I propose and implement a novel evaluation focused on testing systems' ability to infer the relative plausibility of events, a key aspect of resolving coreference. Through this extended evaluation, I find that contemporary language models demonstrate strong performance on standard benchmarks - improving over earlier baseline systems within certain domains and types of coreference - but remain sensitive to the evaluation conditions: they often fail to generalize in ways one would expect a human to be capable of when evaluation contexts are slightly modified. Taken together, these findings clarify both the strengths, such as improved accuracy over baselines on widely used evaluations, and the limitations of the current NLP paradigm, including weaknesses in measurement validity, and suggest directions for future work in developing better evaluation methods and more genuinely generalizable systems.

</details>


### [73] [Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications](https://arxiv.org/abs/2602.16201)
*Sanket Badhe,Deep Shah,Nehal Kathrotia*

Main category: cs.CL

TL;DR: 研究探讨大语言模型如何处理长尾知识问题，提出系统性框架，涵盖定义、遗失机制、技术干预与评估挑战，强调社会影响。


<details>
  <summary>Details</summary>
Motivation: 现有多语言模型虽扩大训练规模但难以处理低频知识，缺乏对领域、文化、时间特异性知识缺陷的系统性分析，需建立跨技术与社会维度的认知框架。

Method: 整合多学科研究，构建四维分析框架：长尾知识定义、训练/推理中的信息遗失机制、技术改进方案、公平性与透明度影响，并评估现有测试方法如何掩盖尾部行为缺陷。

Result: 提出长尾知识分类体系与整合框架，揭示现有评估标准的局限性，识别隐私保护、可持续性、治理体系等阻碍长尾知识表征的核心挑战。

Conclusion: 建立统一概念框架解释长尾知识的定义、评估及表现，指出需解决技术伦理与治理难题以提升模型可靠性，为后续研究提供跨学科分析范式。

Abstract: Large language models (LLMs) are trained on web-scale corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This paper develops a structured taxonomy and analysis of long-Tail Knowledge in large language models, synthesizing prior work across technical and sociotechnical perspectives.
  We introduce a structured analytical framework that synthesizes prior work across four complementary axes: how long-Tail Knowledge is defined, the mechanisms by which it is lost or distorted during training and inference, the technical interventions proposed to mitigate these failures, and the implications of these failures for fairness, accountability, transparency, and user trust. We further examine how existing evaluation practices obscure tail behavior and complicate accountability for rare but consequential failures. The paper concludes by identifying open challenges related to privacy, sustainability, and governance that constrain long-Tail Knowledge representation. Taken together, this paper provides a unifying conceptual framework for understanding how long-Tail Knowledge is defined, lost, evaluated, and manifested in deployed language model systems.

</details>


### [74] [Are LLMs Ready to Replace Bangla Annotators?](https://arxiv.org/abs/2602.16241)
*Md. Najib Hasan,Touseef Hasan,Souvika Sarkar*

Main category: cs.CL

TL;DR: 研究显示大规模语言模型（LLMs）作为零样本标注工具在孟加拉语仇恨言论识别中存在标注偏差和判断不稳定性，模型规模扩大并不保证质量提升，小型任务匹配模型可能更可靠。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在低资源且敏感的身份语境中作为无偏标注者的可靠性，尤其针对人类标注者间一致性较低的任务（如仇恨言论检测）。

Method: 通过统一评估框架对17个LLMs进行系统性基准测试，聚焦其在孟加拉语仇恨言论标注任务中的表现。

Result: 发现显著标注偏差与模型判断不稳定性，模型规模与标注质量无正相关，小型任务对齐模型常比大型模型更一致。

Conclusion: 揭示当前LLMs在低资源语言敏感标注任务中的局限性，强调部署前需审慎评估。

Abstract: Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and annotator bias can have serious downstream consequences. We conduct a systematic benchmark of 17 LLMs using a unified evaluation framework. Our analysis uncovers annotator bias and substantial instability in model judgments. Surprisingly, increased model scale does not guarantee improved annotation quality--smaller, more task-aligned models frequently exhibit more consistent behavior than their larger counterparts. These results highlight important limitations of current LLMs for sensitive annotation tasks in low-resource languages and underscore the need for careful evaluation before deployment.

</details>


### [75] [Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation](https://arxiv.org/abs/2602.16290)
*Jonathan Mutal,Perla Al Almaoui,Simon Hengchen,Pierrette Bouillon*

Main category: cs.CL

TL;DR: 本文提出了Aladdin-FTI模型，用于方言阿拉伯语生成与翻译。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言因缺乏标准化和高度差异性在NLP研究中长期被边缘化，大语言模型（LLMs）为解决此问题提供了新可能。

Method: 开发Aladdin-FTI系统，支持摩洛哥语、埃及语等五种方言的文本生成及与标准阿拉伯语（MSA）和英语的双向翻译。

Result: 成功实现多方言生成和翻译功能，并公开代码和训练模型。

Conclusion: 证明LLMs可有效解决阿拉伯语作为多方心语言的计算建模问题，为NLP领域提供重要资源。

Abstract: Arabic dialects have long been under-represented in Natural Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic system. This paper presents Aladdin-FTI, our submission to the AMIYA shared task. The proposed system is designed to both generate and translate dialectal Arabic (DA). Specifically, the model supports text generation in Moroccan, Egyptian, Palestinian, Syrian, and Saudi dialects, as well as bidirectional translation between these dialects, Modern Standard Arabic (MSA), and English. The code and trained model are publicly available.

</details>


### [76] [MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models](https://arxiv.org/abs/2602.16298)
*Martin Hyben,Sebastian Kula,Jan Cegin,Jakub Simko,Ivan Srba,Robert Moro*

Main category: cs.CL

TL;DR: 论文提出多语种验证声明检测基准数据集MultiCW，包含16种语言、7个领域和2种写作风格，用于比较微调模型与大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在事实核查流程中的自动化支持有限，需构建高质量多语种数据集解决验证声明检测关键步骤的需求。

Method: 构建包含123,722个样本的平衡数据集（包含口语化与结构化文本），并创建覆盖4种新语言的27,761样本分布外测试集，对比分析3种微调多语言模型与15种LLMs的零样本性能。

Result: 微调模型在分类任务中显著优于零样本LLMs，且在跨语言、跨领域和跨文本风格的分布外测试中表现出强泛化能力。

Conclusion: MultiCW基准测试为多语事实核查系统研究提供了基础设施，证明了定制化微调模型在验证声明检测任务中的优势。

Abstract: Large Language Models (LLMs) are beginning to reshape how media professionals verify information, yet automated support for detecting check-worthy claims a key step in the fact-checking process remains limited. We introduce the Multi-Check-Worthy (MultiCW) dataset, a balanced multilingual benchmark for check-worthy claim detection spanning 16 languages, 7 topical domains, and 2 writing styles. It consists of 123,722 samples, evenly distributed between noisy (informal) and structured (formal) texts, with balanced representation of check-worthy and non-check-worthy classes across all languages. To probe robustness, we also introduce an equally balanced out-of-distribution evaluation set of 27,761 samples in 4 additional languages. To provide baselines, we benchmark 3 common fine-tuned multilingual transformers against a diverse set of 15 commercial and open LLMs under zero-shot settings. Our findings show that fine-tuned models consistently outperform zero-shot LLMs on claim classification and show strong out-of-distribution generalization across languages, domains, and styles. MultiCW provides a rigorous multilingual resource for advancing automated fact-checking and enables systematic comparisons between fine-tuned models and cutting-edge LLMs on the check-worthy claim detection task.

</details>


### [77] [MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks](https://arxiv.org/abs/2602.16313)
*Zexue He,Yu Wang,Churan Zhi,Yuanzhe Hu,Tzu-Ping Chen,Lang Yin,Ze Chen,Tong Arthur Wu,Siru Ouyang,Zihan Wang,Jiaxin Pei,Julian McAuley,Yejin Choi,Alex Pentland*

Main category: cs.CL

TL;DR: 论文提出MemoryArena框架，用于评估智能体在多会话场景中结合记忆与行动的任务表现，揭示现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 现有记忆评估基准割裂了记忆存储与行动决策，单一场景任务未模拟真实环境中记忆指导长期决策的需求。

Method: 构建包含网页导航、约束规划等领域的多阶段任务库，要求智能体通过记忆提取与更新完成跨子任务的关联决策。

Result: 在传统长文本记忆基准测试（如LoCoMo）表现优异的智能体，在MemoryArena任务中表现显著下降。

Conclusion: 当前记忆评估体系缺乏对现实场景中记忆与行动耦合特性的验证，MemoryArena填补了这一评估方法论空白。

Abstract: Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuses on agents acting in single-session tasks without the need for long-term memory. However, in realistic settings, memorization and action are tightly coupled: agents acquire memory while interacting with the environment, and subsequently rely on that memory to solve future tasks. To capture this setting, we introduce MemoryArena, a unified evaluation gym for benchmarking agent memory in multi-session Memory-Agent-Environment loops. The benchmark consists of human-crafted agentic tasks with explicitly interdependent subtasks, where agents must learn from earlier actions and feedback by distilling experiences into memory, and subsequently use that memory to guide later actions to solve the overall task. MemoryArena supports evaluation across web navigation, preference-constrained planning, progressive information search, and sequential formal reasoning, and reveals that agents with near-saturated performance on existing long-context memory benchmarks like LoCoMo perform poorly in our agentic setting, exposing a gap in current evaluations for agents with memory.

</details>


### [78] [Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models](https://arxiv.org/abs/2602.16608)
*Melkamu Abay Mersha,Jugal Kalita*

Main category: cs.CL

TL;DR: 本文提出CA-LIG框架，通过层次化积分梯度与注意力机制结合，解决Transformer模型可解释性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer解释方法仅分析末层，忽略层间信息流动和上下文依赖，导致无法全面理解模型决策机制。

Method: 在每个Transformer模块内计算层间积分梯度，将词元级归因与类别特定注意力梯度融合，生成带符号的上下文敏感归因图谱。

Result: 在BERT/XLM-R/AfroLM/MAE-ViT等多模态模型上验证，归因结果比现有方法更保真、对上下文依赖更敏感，可视化语义更连贯。

Conclusion: 该方法突破现有解释技术的层次性局限，同时提升模型可用性和理论认知，为深度学习可解释性提供新范式。

Abstract: Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.

</details>


### [79] [IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models](https://arxiv.org/abs/2602.16467)
*Saurabh Bharti,Gaurav Azad,Abhinaw Jagtap,Nachiket Tapas*

Main category: cs.CL

TL;DR: IndicEval 是一个基于真实高风险考试问题的评估框架，用于测试大型语言模型（LLM）在STEM和人文学科领域内英语和印地语的性能，突显了在推理准确性和多语言适应性方面的现有局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多为合成数据，无法反映现实学术标准及多语言复杂性，因此需要一个基于真实考试的评估框架以更准确衡量LLM的实际应用能力。

Method: 构建基于印度UPSC、JEE、NEET考试的双语评估框架，采用Zero-Shot、Few-Shot及Chain-of-Thought提示策略自动化评估，支持新增模型与语言模块化集成。

Result: 1. Chain-of-Thought提示显著提升多学科及双语推理准确性；2. 高复杂度考试中模型性能差异显著；3. 多语言环境下印地语准确率大幅下降，特别是在Zero-Shot条件下。

Conclusion: IndicEval提供了可扩展的实践导向评估基础，揭示了多语言推理与领域转移的关键缺陷，为提升LLM的推理稳健性及语言适应性提供改进方向。

Abstract: The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.

</details>


### [80] [Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity Shape Learning](https://arxiv.org/abs/2602.16469)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 该研究发现机器翻译数据训练的小型英语语言模型受源语言和语料库特性显著影响，困惑度与词汇多样性相关，而语法表现与源语言的类型学相似性相关。


<details>
  <summary>Details</summary>
Motivation: 机器翻译数据在多语言NLP中广泛应用，但翻译文本存在系统性差异（翻译腔），需研究不同源语言对模型语言建模和语言接受度的影响。

Method: 使用24种类型学多样的语言进行机器翻译生成英语训练数据，系统分析源语言类型学特征和语料库属性对模型语言建模和语法性能的影响。

Result: 源语言显著影响模型行为：困惑度主要由翻译语料词汇多样性驱动，语法性能则与源语言和英语的类型学相似性高度相关（在数据充足条件下）。

Conclusion: 机器翻译训练数据的源语言选择需考虑其类型学特征和词汇多样性，以平衡模型的语言建模能力和语法表现。

Abstract: Machine-translated data is widely used in multilingual NLP, particularly when native text is scarce. However, translated text differs systematically from native text. This phenomenon is known as translationese, and it reflects both traces of the source language and characteristic properties of translation itself. In this paper, we study how training on machine-translated data affects small English language models, focusing on how translationese from different source languages shapes linguistic acceptability judgments and language modelling for different domains. We train models on English text translated from 24 typologically and resource-diverse source languages, enabling a systematic analysis of how source language and corpus properties influence what models learn. Our results show that the source language has a clear impact on model behavior: general perplexity is more driven by the lexical diversity of the translated corpus, while grammatical performance is strongly correlated to typological similarity to English, given enough data.

</details>


### [81] [Optimizing Soft Prompt Tuning via Structural Evolution](https://arxiv.org/abs/2602.16500)
*Zhenzhen Huang,Chaoning Zhang,Haoyu Bian,Songbo Zhang,Chi-lok Andy Tai,Jiaquan Zhang,Caiyan Qin,Jingjing Qu,Yalan Ye,Yang Yang,Heng Tao Shen*

Main category: cs.CL

TL;DR: 提出基于拓扑形态进化的软提示调优方法，通过TDA量化结构表示，增强解释性


<details>
  <summary>Details</summary>
Motivation: 软提示依赖高维隐式表示缺乏可解释性，需量化其训练过程和结构稳定性

Method: 使用拓扑数据分析中的持久同源技术量化软提示的结构表示，构建TSLoss损失函数引导模型学习结构稳定的参数间连通性及冗余性

Result: 结构稳定且紧凑的软提示实现更优下游性能，TSLoss加速收敛并提升调参效果

Conclusion: 验证拓扑结构分析对软提示优化的指导价值，实现性能提升与过程可解释性的统一

Abstract: Soft prompt tuning leverages continuous embeddings to capture task-specific information in large pre-trained language models (LLMs), achieving competitive performance in few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we propose a soft prompt tuning optimization method based on topological morphological evolution. Specifically, we employ persistent homology from topological data analysis (TDA) to quantify the structural representations of soft prompts in continuous parameter space and their training process evolution. Quantitative analysis shows that topologically stable and compact soft prompts achieve better downstream performance. Based on this empirical observation, we construct a loss function for optimizing soft prompt tuning, termed Topological Soft Prompt Loss (TSLoss). TSLoss guides the model to learn structurally stable adaptations by quantifying inter-parameter connectivity and redundancy. Extensive experiments show that training with TSLoss accelerates convergence and improves tuning performance, providing an interpretable method to understand and optimize soft prompt tuning from structural and topological perspectives.

</details>


### [82] [Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification](https://arxiv.org/abs/2602.16516)
*Taja Kuzman Pungeršek,Peter Rupnik,Daniela Širinić,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本论文介绍了ParlaCAP这一大规模议会数据集，并提出基于教师-学生框架构建多语言政策主题分类器的方法。LLM标注后微调模型，性能优于传统分类器。


<details>
  <summary>Details</summary>
Motivation: 现有政策分类方法依赖手工标注的域外数据，缺乏跨语言适应性。本研究旨在建立更高效的领域专用分类器，并结合情感分析和人口统计元数据支持多国政治议题研究。

Method: 采用教师-学生框架：先用高性能LLM在ParlaMint语料库（28国/地区议会800万演讲）上自动生成标注数据，再对多语言编码器模型微调实现自动标注。应用CAP政策分类框架和ParlaSent情感模型构建综合数据集。

Result: 自动分类器与人工标注一致率达到人类标注员间水平，且超越现有CAP分类器。ParlaCAP数据集包含政策标签、发言者属性、党派归属及情感数据，成功支持政策议题分布、情绪模式和性别差异三个层面的研究验证。

Conclusion: ParlaCAP为欧洲议会研究提供全新工具，其数据标注方法展示了LLM在专业领域替代人工标注的可行性，结合多模态数据增强了政治注意力和代表性比较研究的能力。

Abstract: This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and autonomous regions, we follow a teacher-student framework in which a high-performing large language model (LLM) annotates in-domain training data and a multilingual encoder model is fine-tuned on these annotations for scalable data annotation. We show that this approach produces a classifier tailored to the target domain. Agreement between the LLM and human annotators is comparable to inter-annotator agreement among humans, and the resulting model outperforms existing CAP classifiers trained on manually-annotated but out-of-domain data. In addition to the CAP annotations, the ParlaCAP dataset offers rich speaker and party metadata, as well as sentiment predictions coming from the ParlaSent multilingual transformer model, enabling comparative research on political attention and representation across countries. We illustrate the analytical potential of the dataset with three use cases, examining the distribution of parliamentary attention across policy topics, sentiment patterns in parliamentary speech, and gender differences in policy attention.

</details>


### [83] [Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset](https://arxiv.org/abs/2602.16571)
*Zhuqian Zhou,Kirk Vanacore,Bakhtawar Ahtisham,Jinsook Lee,Doug Pietrzak,Daryl Hedley,Jorge Dias,Chris Shaw,Ruth Schäfer,René F. Kizilcec*

Main category: cs.CL

TL;DR: 本论文探讨了数学辅导对话数据脱敏与教育效用保留之间的矛盾，提出了包含115,620条消息的MathEd-PII基准数据集，证明了融合数学语境分析的提示工程可将脱敏精度从0.379提升至0.821，同时开发了基于密度的数学敏感段落检测技术。


<details>
  <summary>Details</summary>
Motivation: 数学辅导数据中数字表达式（如分数、方程式）易被通用脱敏系统误判为隐私信息，导致教育核心内容丢失。

Method: 1. 采用人机协同的LLM工作流构建带标注数据集 2. 实施数学语境增强提示策略 3. 应用基于密度的数学段落分割算法 4. 对比Presidio基准、通用LLM与改进策略效果

Result: 1. MathEd-PII成全球最大数学对话脱敏数据集（1,000次辅导记录）2. 数字误判主要集中在数学密集区（密度超常规内容2.7倍）3. 数学增强提示使F1值提升116%（0.821 vs 0.379）

Conclusion: 领域特定的脱敏策略能系统性解决教育数据隐私-效用困局，数字表达式的领域语义理解是教育数据治理的关键

Abstract: Large-scale sharing of dialogue-based data is instrumental for advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core instructional content and reduce dataset utility. This work asks how PII can be detected in math tutoring transcripts while preserving their educational utility. To address this challenge, we investigate the "numeric ambiguity" problem and introduce MathEd-PII, the first benchmark dataset for PII detection in math tutoring dialogues, created through a human-in-the-loop LLM workflow that audits upstream redactions and generates privacy-preserving surrogates. The dataset contains 1,000 tutoring sessions (115,620 messages; 769,628 tokens) with validated PII annotations. Using a density-based segmentation method, we show that false PII redactions are disproportionately concentrated in math-dense regions, confirming numeric ambiguity as a key failure mode. We then compare four detection strategies: a Presidio baseline and LLM-based approaches with basic, math-aware, and segment-aware prompting. Math-aware prompting substantially improves performance over the baseline (F1: 0.821 vs. 0.379) while reducing numeric false positives, demonstrating that de-identification must incorporate domain context to preserve analytic utility. This work provides both a new benchmark and evidence that utility-preserving de-identification for tutoring data requires domain-aware modeling.

</details>


### [84] [CitiLink-Summ: Summarization of Discussion Subjects in European Portuguese Municipal Meeting Minutes](https://arxiv.org/abs/2602.16607)
*Miguel Marques,Ana Luísa Fernandes,Ana Filipa Pacheco,Rute Rebouças,Inês Cantante,José Isidro,Luís Filipe Cunha,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano,Ricardo Campos*

Main category: cs.CL

TL;DR: 本文提出了CitiLink-Summ数据集，包含欧洲葡萄牙语市政会议纪要及人工摘要，为低资源语言下的市政领域自动生成摘要提供了首个基准。


<details>
  <summary>Details</summary>
Motivation: 市政会议纪要内容冗长复杂，公民难以理解，但低资源语言中缺乏高质量的摘要数据集，限制了自动摘要模型的发展。

Method: 构建包含100份市政会议文档和2,322个手动摘要的CitiLink-Summ语料库，结合BART、PRIMERA、大语言模型进行生成式摘要实验，并采用ROUGE/BERTScore等指标评估。

Result: 实现了首个欧洲葡萄牙语市政摘要基准测试，验证了生成模型在复杂行政文本中的有效性，并公开了人工标注的数据集。

Conclusion: CitiLink-Summ为低资源语言的NLP研究提供了重要资源，推动了市政会议摘要技术发展，促进了政务透明化。

Abstract: Municipal meeting minutes are formal records documenting the discussions and decisions of local government, yet their content is often lengthy, dense, and difficult for citizens to navigate. Automatic summarization can help address this challenge by producing concise summaries for each discussion subject. Despite its potential, research on summarizing discussion subjects in municipal meeting minutes remains largely unexplored, especially in low-resource languages, where the inherent complexity of these documents adds further challenges. A major bottleneck is the scarcity of datasets containing high-quality, manually crafted summaries, which limits the development and evaluation of effective summarization models for this domain. In this paper, we present CitiLink-Summ, a new corpus of European Portuguese municipal meeting minutes, comprising 100 documents and 2,322 manually hand-written summaries, each corresponding to a distinct discussion subject. Leveraging this dataset, we establish baseline results for automatic summarization in this domain, employing state-of-the-art generative models (e.g., BART, PRIMERA) as well as large language models (LLMs), evaluated with both lexical and semantic metrics such as ROUGE, BLEU, METEOR, and BERTScore. CitiLink-Summ provides the first benchmark for municipal-domain summarization in European Portuguese, offering a valuable resource for advancing NLP research on complex administrative texts.

</details>


### [85] [ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models](https://arxiv.org/abs/2602.16609)
*Antoine Chaffin,Luca Arnaboldi,Amélie Chatelain,Florent Krzakala*

Main category: cs.CL

TL;DR: 本文提出ColBERT-Zero，通过大规模多向量预训练取代传统知识蒸馏方法，在仅使用公开数据的情况下超越现有闭源模型，并验证了监督预训练步骤与微调设置对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前多向量模型依赖单向量模型的知识蒸馏，但作者推测直接大规模多向量预训练能产生更强模型，且需探索更高效的训练流程（如降低无监督预训练成本）。

Method: 1) 实现完全基于ColBERT架构的预训练（ColBERT-Zero），2) 对比小规模知识蒸馏与监督预训练的组合策略效果，3) 分析微调与预训练设置匹配对模型性能的影响。

Result: ColBERT-Zero在公开数据上超越GTE-ModernColBERT/GTE-ModernBERT，达到该尺寸模型SOTA；监督预训练可显著提升小规模KD效果，跳过代价高昂的无监督阶段；微调与预训练设置需严格对齐。

Conclusion: 多向量模型预训练具有巨大潜力，有效结合监督步骤和严格对齐流程可显著提升性能，代码及模型开放促进该领域进一步发展。

Abstract: Current state-of-the-art multi-vector models are obtained through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully ColBERT-pre-trained model, ColBERT-Zero, trained only on public data, outperforms GTE-ModernColBERT as well as its base model, GTE-ModernBERT, which leverages closed and much stronger data, setting new state-of-the-art for model this size. We also find that, although performing only a small KD step is not enough to achieve results close to full pre-training, adding a supervised step beforehand allows to achieve much closer performance while skipping the most costly unsupervised phase. Finally, we find that aligning the fine-tuning and pre-training setups is crucial when repurposing existing models. To enable exploration of our results, we release various checkpoints as well as code used to train them.

</details>


### [86] [AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models](https://arxiv.org/abs/2602.16639)
*Adib Sakhawat,Fardeen Sadab*

Main category: cs.CL

TL;DR: 论文提出了AREG基准测试，通过对抗性资源谈判评估大语言模型（LLMs）的社交智能，发现说服与抵抗能力存在弱相关性且防御具有系统性优势。


<details>
  <summary>Details</summary>
Motivation: 传统静态文本生成无法全面评估LLMs的社会智能，需要动态对抗交互框架来联合衡量说服（攻击）和抵抗（防御）能力。

Method: 构建多回合零和博弈的对抗资源提取游戏（AREG），通过前缘模型的循环赛评估LLMs在资源谈判中的双向能力，并进行语言策略分析。

Result: 说服与抵抗能力相关性低（ρ=0.33），防御得分普遍高于说服；成功提取依赖渐进承诺策略，有效防御依赖验证性回应而非直接拒绝。

Conclusion: LLMs社会影响力是多维能力，单一维度评估存在局限性，对抗性框架揭示了不对称行为脆弱性，需同时关注攻防双向交互机制。

Abstract: Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($ρ= 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.

</details>


### [87] [Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval](https://arxiv.org/abs/2602.16640)
*Subrit Dikshit*

Main category: cs.CL

TL;DR: Quecto-V1是专为印度法律领域设计的小型语言模型（1.24亿参数），通过领域定制训练和8位量化技术（压缩至150MB），实现在离线路由器级CPU上的高效法律检索，并兼顾隐私保护。


<details>
  <summary>Details</summary>
Motivation: 针对大模型在资源受限环境和数据主权风险中的局限性，本文提出法律领域专用小型模型，旨在推动法律智能的普惠化访问，特别是在高司法风险场景中提供轻量化解决方案。

Method: 基于GPT-2架构构建定制模型，使用印度刑法典、刑事诉讼法和宪法数据集从零训练，采用GGUF格式8位量化技术进行模型压缩，并在消费级CPU上部署离线推理。

Result: 在法定定义检索任务中表现优异，精确匹配能力超越通用小型模型，量化后模型体积缩小74%，检索精度损失小于3.5%，验证了量化训练的可行性。

Conclusion: 领域专用训练结合激进量化技术，可在保持高精度的同时显著降低模型体积和部署门槛，为敏感领域提供隐私友好型机器学习解决方案。

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide." State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inaccessible to practitioners in resource-constrained environments and posing significant data sovereignty risks. This paper introduces Quecto-V1, a domain-specific Small Language Model (SLM) engineered to democratize access to Indian legal intelligence. Built upon a custom configuration of the GPT-2 architecture (124 million parameters), Quecto-V1 was trained from scratch exclusively on a corpus of Indian statutes, including the Indian Penal Code (IPC), the Code of Criminal Procedure (CrPC), and the Constitution of India. Unlike generalist models, which prioritize broad world knowledge, our approach maximizes "lexical density" within the legal domain. Furthermore, we address the deployment bottleneck by applying post-training 8-bit quantization (GGUF format), compressing the model to a memory footprint of under 150 MB. Our empirical analysis demonstrates that Quecto-V1 achieves high fidelity in retrieving statutory definitions and penal provisions, outperforming general-purpose SLMs in domain-specific exact match tasks while running entirely offline on consumer-grade CPUs. We further present an ablation study showing that 8-bit quantization yields a 74% reduction in model size with less than 3.5% degradation in retrieval accuracy compared to full-precision baselines. These findings suggest that for specialized, high-stakes domains like law, domain-specific training coupled with aggressive quantization offers a viable, privacy-preserving alternative to monolithic cloud models.

</details>


### [88] [Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment](https://arxiv.org/abs/2602.16660)
*Yuyan Bu,Xiaohao Liu,ZhaoXing Ren,Yaodong Yang,Juntao Dai*

Main category: cs.CL

TL;DR: 本文提出了一种资源高效的多语言安全对齐方法，通过引入插件式的多语言一致性(MLC)损失函数，可在无需低资源语言额外监督的情况下实现多语言协同优化。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言对齐方法需要高资源语言监督或语言间配对对齐，存在显著资源消耗与可扩展性限制，特别是在低资源语言场景中。

Method: 提出MLC损失函数：1）通过提升多语言表征向量共线性，实现多语言语义方向一致性；2）可集成于单语对齐流水线；3）仅需多语言提示变体进行联合训练，无需低资源语言响应级别监督数据。

Result: 方法在不同模型架构和对齐范式中均验证有效性：1）多语言安全性能显著提升；2）模型通用性影响可控；3）跨语言任务迁移能力增强，证明方法在有限监督下的实用性。

Conclusion: MLC损失函数提供了一种低资源消耗的多语言一致性解决方案，在无需大量跨语言监督的前提下能有效提升多语言安全对齐效果。

Abstract: The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.

</details>


### [89] [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699)
*Wenxuan Ding,Nicholas Tomlin,Greg Durrett*

Main category: cs.CL

TL;DR: 提出Calibrate-Then-Act（CTA）框架，使LLMs显式权衡环境交互中的成本-不确定性，从而发现更优的决策策略。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在复杂任务中缺乏对交互成本与预测不确定性之间显式权衡的能力，需通过环境探索提升决策效率。

Method: 将任务建模为不确定性下的序贯决策问题，通过CTA框架注入先验知识和环境状态上下文，结合强化学习训练对比优化效果。

Result: 在信息检索QA和编程任务中，CTA显著提升LLMs探索策略的最优性，且效果在RL微调后仍优于基线模型。

Conclusion: 显式建模成本-收益权衡能使LLMs在交互式任务中更高效地平衡信息获取成本与结果可靠性，为认知决策提供通用范式。

Abstract: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.

</details>


### [90] [Reinforced Fast Weights with Next-Sequence Prediction](https://arxiv.org/abs/2602.16704)
*Hee Seung Hwang,Xindi Wu,Sanghyuk Chun,Olga Russakovsky*

Main category: cs.CL

TL;DR: REFINE改进了fast weight架构的长文本建模，通过强化学习实现序列级预测，克服传统单token训练的局限性。


<details>
  <summary>Details</summary>
Motivation: fast weight模型在长上下文建模中使用传统的next-token预测（NTP）训练无法捕捉多token语义连贯性，导致表示学习效果不佳。

Method: 提出REFINE框架，采用序列级预测（NSP）目标：基于预测熵选择关键token，生成多token展开，通过自监督序列奖励优化，并使用分组相对策略优化（GRPO）进行训练。

Result: 实验显示REFINE在LaCT-760M和DeltaNet-1.3B模型上显著优于传统NTP微调，在长文本问答、稀疏检索等任务中表现优异。

Conclusion: REFINE为fast weight架构提供了一种通用且有效的长上下文建模解决方案，扩展其在生成任务中的应用潜力。

Abstract: Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.

</details>
