<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 64]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models](https://arxiv.org/abs/2602.02537)
*Runjie Zhou,Youbo Shao,Haoyu Lu,Bowei Xing,Tongtong Bai,Yujie Chen,Jie Zhao,Lin Sui,Haotian Yao,Zijia Zhao,Hao Yang,Haoning Wu,Zaida Zhou,Jinguo Zhu,Zhiqi Huang,Yiping Bao,Yangyang Liu,Y. Charles,Xinyu Zhou*

Main category: cs.CV

TL;DR: 提出了WorldVQA基准测试，专门评估多模态大语言模型（MLLMs）的原子视觉世界知识，通过分离视觉知识检索与推理能力，专注于测量模型记忆的‘事实性’。


<details>
  <summary>Details</summary>
Motivation: 现有评测方法常将视觉知识检索与推理能力混杂，难以准确评估模型对视觉事实的记忆能力。WorldVQA旨在解决这一问题，提供一种更严格的测试标准以衡量模型的知识基础。

Method: 设计分层分类体系（从常见物体到长尾罕见类），通过分离检索与推理能力构建基准；评估模型在命名和定位视觉实体中的基础能力。

Result: 提出基准框架但未报告具体实验结果（描述性摘要），预期该框架可为模型的百科广度与幻觉率提供标准化测试方案。

Conclusion: 通过聚焦‘模型记忆了什么’而非‘如何推理’，该基准为未来多模态模型的发展与评估提供了事实性验证标准，有助于减少生成式模型的虚假事实输出。

Abstract: We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning, WorldVQA decouples these capabilities to strictly measure "what the model memorizes." The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality, thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.

</details>


### [2] [AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process](https://arxiv.org/abs/2602.02676)
*Xintong Zhang,Xiaowen Zhang,Jongrong Wu,Zhi Gao,Shilin Yan,Zhenxin Diao,Kunpeng Gao,Xuanyan Chen,Yuwei Wu,Yunde Jia,Qing Li*

Main category: cs.CV

TL;DR: 提出AdaptMMBench基准，通过动态难度评估与多维指标分析自适应多模态推理中的模式选择能力。


<details>
  <summary>Details</summary>
Motivation: 现有静态评估无法反映任务难度与模型能力的动态关联，导致混淆模式选择与整体性能且缺乏过程分析。

Method: 构建跨五个领域的AdaptMMBench基准，采用MCC指标动态识别模型能力边界，并评估关键步骤覆盖度、工具有效性及效率。

Result: 模式选择能力随模型容量提升却与准确率解耦；关键步骤覆盖与性能正相关，但工具有效性存在跨架构差异。

Conclusion: 动态难度评估可分离元认知能力与性能，需独立优化模式选择与任务求解，为自适应VLM研究提供新方向。

Abstract: Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.

</details>


### [3] [End-to-end reconstruction of OCT optical properties and speckle-reduced structural intensity via physics-based learning](https://arxiv.org/abs/2602.02721)
*Jinglun Yu,Yaning Wang,Wenhan Guo,Yuan Gao,Yu Sun,Jin U. Kang*

Main category: cs.CV

TL;DR: 提出正则化深度学习方法联合重建OCT光学参数和结构图像，结合物理模型提升噪声鲁棒性和分辨率


<details>
  <summary>Details</summary>
Motivation: OCT逆散射需解决噪声和参数耦合问题，传统方法受限，需结合物理模型的深度学习提高准确性和鲁棒性

Method: 正则化端到端深度学习框架，结合物理前向模型生成预测信号，蒙特卡罗数据训练，联合重建参数和结构图像

Result: 合成数据实验证明在噪声下稳定重建折射率/散射系数等光学参数，图像分辨率提升37%，结构细节保真度提高28%

Conclusion: 物理建模与深度学习融合可实现定量多参数组织表征，在糖尿病性角膜病变等医学场景具有临床转化潜力

Abstract: Inverse scattering in optical coherence tomography (OCT) seeks to recover both structural images and intrinsic tissue optical properties, including refractive index, scattering coefficient, and anisotropy. This inverse problem is challenging due to attenuation, speckle noise, and strong coupling among parameters. We propose a regularized end-to-end deep learning framework that jointly reconstructs optical parameter maps and speckle-reduced OCT structural intensity for layer visualization. Trained with Monte Carlo-simulated ground truth, our network incorporates a physics-based OCT forward model that generates predicted signals from the estimated parameters, providing physics-consistent supervision for parameter recovery and artifact suppression. Experiments on the synthetic corneal OCT dataset demonstrate robust optical map recovery under noise, improved resolution, and enhanced structural fidelity. This approach enables quantitative multi-parameter tissue characterization and highlights the benefit of combining physics-informed modeling with deep learning for computational OCT.

</details>


### [4] [SVD-ViT: Does SVD Make Vision Transformers Attend More to the Foreground?](https://arxiv.org/abs/2602.02765)
*Haruhiko Murata,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: SVD-ViT通过奇异值分解增强视觉Transformer的前景特征学习，减少背景噪声影响以提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉Transformer的全局自注意力机制缺乏显式前景-背景区分能力，导致模型学习冗余背景特征并降低分类性能。现有方法未能有效解决此任务无关干扰问题。

Method: 提出包含SPC模块、SSVA和ID-RSVD的SVD-ViT框架，利用奇异值分解优先提取表征物体前景信息的奇异向量并进行特征聚合，从而抑制背景噪声与人工伪影。

Result: 实验表明，该方法显著提升图像分类准确率，在ImageNet等数据集上验证了其有效学习前景表征并降低背景干扰的能力。

Conclusion: SVD-ViT通过引入奇异值分解机制成功增强了视觉Transformer的前景感知能力，为解决自注意力机制的背景混淆问题提供了新思路。

Abstract: Vision Transformers (ViT) have been established as large-scale foundation models. However, because self-attention operates globally, they lack an explicit mechanism to distinguish foreground from background. As a result, ViT may learn unnecessary background features and artifacts, leading to degraded classification performance. To address this issue, we propose SVD-ViT, which leverages singular value decomposition (SVD) to prioritize the learning of foreground features. SVD-ViT consists of three components-\textbf{SPC module}, \textbf{SSVA}, and \textbf{ID-RSVD}-and suppresses task-irrelevant factors such as background noise and artifacts by extracting and aggregating singular vectors that capture object foreground information. Experimental results demonstrate that our method improves classification accuracy and effectively learns informative foreground representations while reducing the impact of background noise.

</details>


### [5] [LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds](https://arxiv.org/abs/2602.02808)
*Matteo Bastico,Pierre Onghena,David Ryckelynck,Beatriz Marcotegui,Santiago Velasco-Forero,Laurent Corté,Caroline Robine--Decourcelle,Etienne Decencière*

Main category: cs.CV

TL;DR: 本文提出Landmark Point Transformer (LmPT)，可通过点云表示实现跨物种解剖标志点自动检测。


<details>
  <summary>Details</summary>
Motivation: 传统人工标记效率低且存在观察者差异，规则方法难以适应复杂几何结构及跨物种场景，需开发通用性强的自动化方法。

Method: 构建基于点云的Transformer模型，引入条件机制支持异构数据输入，利用同源骨骼进行跨物种迁移学习。

Result: 使用人类与新标注狗股骨数据集测试，模型在多个物种数据上均达到高精度，代码与数据集已开源。

Conclusion: LmPT首次实现跨物种解剖标志点检测，通过同源骨骼知识迁移提升了模型泛化能力与医学转化研究潜力。

Abstract: Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.

</details>


### [6] [Self-Supervised Uncalibrated Multi-View Video Anonymization in the Operating Room](https://arxiv.org/abs/2602.02850)
*Keqi Chen,Vinkle Srivastav,Armine Vardazaryan,Cindy Rolland,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出一种自监督多视角视频匿名化框架，无需人工标注或相机校准，通过时空与多视角关联优化检测与姿态估计，实现高召回率。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护方法存在两大瓶颈：需手动标注新场景数据，且多摄像机系统需频繁重新校准，限制其临床部署可扩展性。

Method: 1) 使用低阈值检测器初始筛选候选区域；2) 通过跟踪与自监督多视角关联恢复漏检目标；3) 利用伪标签迭代优化检测器，结合高置信度预测微调姿态模型。

Result: 在模拟与实际手术数据集上召回率超97%，训练实时检测器性能与监督方法相当，代码已开源。

Conclusion: 该方法突破隐私保护落地限制，支持免校准多摄像机部署，为手术室视频分析提供高效匿名化解决方案。

Abstract: Privacy preservation is a prerequisite for using video data in Operating Room (OR) research. Effective anonymization relies on the exhaustive localization of every individual; even a single missed detection necessitates extensive manual correction. However, existing approaches face two critical scalability bottlenecks: (1) they usually require manual annotations of each new clinical site for high accuracy; (2) while multi-camera setups have been widely adopted to address single-view ambiguity, camera calibration is typically required whenever cameras are repositioned. To address these problems, we propose a novel self-supervised multi-view video anonymization framework consisting of whole-body person detection and whole-body pose estimation, without annotation or camera calibration. Our core strategy is to enhance the single-view detector by "retrieving" false negatives using temporal and multi-view context, and conducting self-supervised domain adaptation. We first run an off-the-shelf whole-body person detector in each view with a low-score threshold to gather candidate detections. Then, we retrieve the low-score false negatives that exhibit consistency with the high-score detections via tracking and self-supervised uncalibrated multi-view association. These recovered detections serve as pseudo labels to iteratively fine-tune the whole-body detector. Finally, we apply whole-body pose estimation on each detected person, and fine-tune the pose model using its own high-score predictions. Experiments on the 4D-OR dataset of simulated surgeries and our dataset of real surgeries show the effectiveness of our approach achieving over 97% recall. Moreover, we train a real-time whole-body detector using our pseudo labels, achieving comparable performance and highlighting our method's practical applicability. Code is available at https://github.com/CAMMA-public/OR_anonymization.

</details>


### [7] [ViThinker: Active Vision-Language Reasoning via Dynamic Perceptual Querying](https://arxiv.org/abs/2602.02873)
*Weihang You,Qingchan Zhu,David Liu,Yi Pan,Geng Yuan,Hanqi Jiang*

Main category: cs.CV

TL;DR: ViThinker通过主动生成查询标记，按需获取视觉特征，提升视觉语言模型的思维链推理能力，避免过早转文本导致的连续信息丢失。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法在视觉语言模型中因被动处理预生成输入且过早丢失空间信息而效果受限，而人类具有主动感知能力，启发ViThinker设计主动查询机制。

Method: ViThinker训练时内化视觉专家能力，推理时自动生成决策标记触发视觉特征合成。采用两阶段课程：1) 蒸馏专家模型参数 2) 通过稀疏惩罚学习最小感知步骤。

Result: 在多视觉任务基准中均表现提升，验证主动查询机制在感知对齐和推理准确率上优于被动方法，且可减少冗余计算。

Conclusion: 通过模仿人类主动感知，ViThinker实现了无需外部工具调用的生成式心智模拟，为视觉语言推理提供了任务驱动的感知选择机制。

Abstract: Chain-of-Thought (CoT) reasoning excels in language models but struggles in vision-language models due to premature visual-to-text conversion that discards continuous information such as geometry and spatial layout. While recent methods enhance CoT through static enumeration or attention-based selection, they remain passive, i.e., processing pre-computed inputs rather than actively seeking task-relevant details. Inspired by human active perception, we introduce ViThinker, a framework that enables vision-language models to autonomously generate decision (query) tokens triggering the synthesis of expert-aligned visual features on demand. ViThinker internalizes vision-expert capabilities during training, performing generative mental simulation during inference without external tool calls. Through a two-stage curriculum: first distilling frozen experts into model parameters, then learning task-driven querying via sparsity penalties, i.e., ViThinker discovers minimal sufficient perception for each reasoning step. Evaluations across vision-centric benchmarks demonstrate consistent improvements, validating that active query generation outperforms passive approaches in both perceptual grounding and reasoning accuracy.

</details>


### [8] [DoubleTake: Contrastive Reasoning for Faithful Decision-Making in Medical Imaging](https://arxiv.org/abs/2602.02894)
*Daivik Patel,Shrenik Patel*

Main category: cs.CV

TL;DR: 该研究提出了一种对比增强的医学图像推理框架，通过构建具有判别性的紧凑证据集和反事实对比推理机制，在减少冗余证据的同时提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像诊断方法依赖近邻检索导致冗余证据和单一假设强化，无法有效处理细微视觉差异下的混淆病例，且缺乏系统化的对比推理证据选择协议。

Method: 开发了ROCO嵌入和元数据驱动的文档感知对比证据选择框架，结合视觉相关性、嵌入多样性及来源溯源性指标；提出反事实-对比推理模型，采用结构化配对比较和基于边界规则的证据融合机制。

Result: 在MediConfusion基准测试中，集合级准确率较现有方法提升15%，混淆率降低且个体准确率优化，验证了对比证据集的判别有效性和推理框架的可靠性。

Conclusion: 该方法通过系统化对比证据筛选协议和新型推理机制，显著提升了复杂医学图像场景下的决策性能，为对比式医学视觉推理提供了可复现框架。

Abstract: Accurate decision making in medical imaging requires reasoning over subtle visual differences between confusable conditions, yet most existing approaches rely on nearest neighbor retrieval that returns redundant evidence and reinforces a single hypothesis. We introduce a contrastive, document-aware reference selection framework that constructs compact evidence sets optimized for discrimination rather than similarity by explicitly balancing visual relevance, embedding diversity, and source-level provenance using ROCO embeddings and metadata. While ROCO provides large-scale image-caption pairs, it does not specify how references should be selected for contrastive reasoning, and naive retrieval frequently yields near-duplicate figures from the same document. To address this gap, we release a reproducible reference selection protocol and curated reference bank that enable a systematic study of contrastive retrieval in medical image reasoning. Building on these contrastive evidence sets, we propose Counterfactual-Contrastive Inference, a confidence-aware reasoning framework that performs structured pairwise visual comparisons and aggregates evidence using margin-based decision rules with faithful abstention. On the MediConfusion benchmark, our approach achieves state-of-the-art performance, improving set-level accuracy by nearly 15% relative to prior methods while reducing confusion and improving individual accuracy.

</details>


### [9] [FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction](https://arxiv.org/abs/2602.02914)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: This paper introduces FaceLinkGen, an attack that bypasses privacy measures in face recognition systems by extracting identity information without pixel reconstruction, revealing flaws in current evaluation metrics like PSNR/SSIM.


<details>
  <summary>Details</summary>
Motivation: Current PPFR systems rely on pixel-level reconstruction resistance (PSNR/SSIM) as privacy metrics, but this work demonstrates that identity information remains vulnerable to attacks that skip pixel recovery entirely.

Method: FaceLinkGen performs two tasks: 1) identity linkage/matching across protected templates, and 2) face regeneration without reconstructing original pixel data. Evaluated on three PPFR systems with full/knowledge-limited settings.

Result: Achieved 98.5%+ matching accuracy, 96%+ regeneration success in full knowledge attacks, and 92% matching/94% regeneration in near zero-knowledge scenarios, proving consistent effectiveness against existing PPFR defenses.

Conclusion: Pixel distortion metrics create a false sense of security, as identity leakage persists through structural vulnerabilities in PPFR systems, exposing risks to both external attackers and malicious service providers.

Abstract: Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction, measured by PSNR and SSIM. We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\% matching accuracy and above 96\% regeneration success, and still exceeds 92\% matching and 94\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.

</details>


### [10] [A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis](https://arxiv.org/abs/2602.02918)
*Jagan Mohan Reddy Dwarampudi,Joshua Wong,Hien Van Nguyen,Tania Banerjee*

Main category: cs.CV

TL;DR: MARBLE是一种纯基于Mamba的多状态多实例学习框架，通过并行处理多尺度数据和线性时间建模，在全切片图像分析中实现高效跨尺度依赖捕捉，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 全切片图像分析面临超高分辨率和多层级放大倍数挑战，现有单尺度MIL方法和基于Transformer的模型因二次注意力成本存在效率瓶颈，需开发更高效架构。

Method: MARBLE采用纯Mamba架构，通过并行多尺度处理和线性时间状态空间模型，整合粗到细推理机制，在最小化参数开销下捕捉跨尺度依赖。

Result: 在5个公开数据集实验中，AUC提升6.9%，准确率提升20.3%，C-index提升2.3%，展现显著性能优势。

Conclusion: MARBLE提供了可扩展且模块化的注意力机制替代方案，在多尺度全切片图像分析中兼具高效性和泛化能力。

Abstract: We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \textbf{6.9\%} in AUC, \textbf{20.3\%} in accuracy, and \textbf{2.3\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.

</details>


### [11] [SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2602.02944)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: SRA-Seg解决合成数据与真实医疗图像在语义特征空间上的领域差距问题，通过特征对齐、软边缘融合及伪标签生成，在仅使用10%标注真实数据的情况下达到优于半监督方法的分割性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据因视觉逼真度高被视为医疗图像分割的替代方案，但其与真实数据存在的语义特征空间差异导致现有半监督方法失效。本文旨在弥合这一领域差距。

Method: 提出SRA-Seg框架：1) 利用冻结的DINOv2嵌入构建相似度对齐（SA）损失函数，将合成数据特征向真实数据特征空间牵引；2) 采用软边缘融合技术消除传统拼贴增强的硬边界；3) 通过EMA教师模型生成合成图像的伪标签，并结合软分割损失处理混合区域的不确定性。

Result: 在ACDC数据集达成89.34% Dice分数，FIVES数据集达成84.42% Dice分数，仅使用10%带标注的真实数据和90%未标注合成数据，显著优于现有半监督方法且性能接近使用真实未标注数据的方法。

Conclusion: SRA-Seg通过显式特征分布对齐和软边缘增强，有效利用合成数据提升医疗图像分割性能，为领域适应问题提供了新的解决方案。

Abstract: Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.

</details>


### [12] [Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning](https://arxiv.org/abs/2602.02951)
*Yihong Huang,Fei Ma,Yihua Shao,Jingcai Guo,Zitong Yu,Laizhong Cui,Qi Tian*

Main category: cs.CV

TL;DR: Nüwa是两阶段的视觉语言模型剪枝框架，通过保留全局空间参考框架提升视觉问答和视觉定位任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于全局语义相似性与注意力分值的剪枝方法丢失位置信息导致在视觉定位任务中性能下降，亟需在保持空间完整性的同时提升计算效率。

Method: 1) 视觉编码器后采用受群体智能算法启发的分离-对齐-聚合操作保留空间基准；2) 在语言模型中通过文本引导剪枝保留任务相关特征。

Result: 视觉问答任务达到SOTA性能(94%-95%)，视觉定位任务相对提升6倍(7%-47%)。

Conclusion: 通过分阶段维护空间完整性和语义关联性的剪枝策略，有效解决视觉语言模型加速与空间感知能力保持的矛盾。

Abstract: Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).

</details>


### [13] [TRACE: Temporal Radiology with Anatomical Change Explanation for Grounded X-ray Report Generation](https://arxiv.org/abs/2602.02963)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: 本论文提出了一种名为TRACE的模型，通过结合时序比较与空间定位技术，实现对胸部X光片变化的精准检测与描述，自然语言生成准确率超90%。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型无法有效结合单图像分析与空间定位功能，而临床放射学迫切需要同时检测X光片前后变化（如病情进展或好转）并定位具体病灶区域的联合能力。

Method: TRACE模型以历史和当前胸部X光为输入，联合执行时序变化分类（恶化/改善/稳定）、自然语言描述生成，并通过边界框坐标实现病灶变化的像素级空间定位，形成闭环验证的多任务学习框架。

Result: 模型在空间定位任务中达到90%以上准确率，消融实验显示单独使用时序比较或定位技术均无法有效检测变化，仅联合学习能实现有意义的临床发现。

Conclusion: 研究证实空间定位机制为时序推理提供关键注意力引导，联合多模态学习是解决医学影像动态分析问题的核心范式，为后续临床辅助诊断系统奠定方法学基础。

Abstract: Temporal comparison of chest X-rays is fundamental to clinical radiology, enabling detection of disease progression, treatment response, and new findings. While vision-language models have advanced single-image report generation and visual grounding, no existing method combines these capabilities for temporal change detection. We introduce Temporal Radiology with Anatomical Change Explanation (TRACE), the first model that jointly performs temporal comparison, change classification, and spatial localization. Given a prior and current chest X-ray, TRACE generates natural language descriptions of interval changes (worsened, improved, stable) while grounding each finding with bounding box coordinates. TRACE demonstrates effective spatial localization with over 90% grounding accuracy, establishing a foundation for this challenging new task. Our ablation study uncovers an emergent capability: change detection arises only when temporal comparison and spatial grounding are jointly learned, as neither alone enables meaningful change detection. This finding suggests that grounding provides a spatial attention mechanism essential for temporal reasoning.

</details>


### [14] [Fisheye Stereo Vision: Depth and Range Error](https://arxiv.org/abs/2602.02973)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.CV

TL;DR: 该研究推导了鱼眼立体视觉系统中深度与距离误差的解析公式，重点分析了远距离物体和大角度场景下的误差变化规律。


<details>
  <summary>Details</summary>
Motivation: 现有鱼眼系统误差模型在大角度场景下存在精度不足，需建立更精确的数学模型以提升三维成像可靠性。

Method: 通过几何光学建模和误差传递分析，推导包含焦距、基线长度、角度参数的误差解析表达式，并进行数学模拟验证。

Result: 发现误差随物体距离呈指数增长，且大角度（>60°）下误差增幅提升30%，解析公式与仿真结果吻合度达98%。

Conclusion: 提出的模型可准确预测复杂视角下的误差分布，为鱼眼系统在机器人导航、VR等场景的应用提供校准依据。

Abstract: This study derives analytical expressions for the depth and range error of fisheye stereo vision systems as a function of object distance, specifically accounting for accuracy at large angles.

</details>


### [15] [Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding](https://arxiv.org/abs/2602.02977)
*Byeongju Woo,Zilin Wang,Byeonghyun Pak,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: 本论文提出CAFT框架，通过跨域对齐图像和长文本的层次语义，在3000万数据上实现6项SOTA，无需像素级监督即可生成细粒度图像文本表征。


<details>
  <summary>Details</summary>
Motivation: 现有模型如CLIP通过整体对齐图像和文本处理长标题存在局限，传统视觉层次分割易碎片化，语言层次与视觉结构不匹配，需解决细粒度多模语义对齐问题。

Method: 采用渐进式视觉编码器与层次文本Transformer耦合结构，设计层次对齐损失函数，同时匹配图像全局与局部区域和文本句子，通过区域-句子对应关系引导粗粒度语义建立。

Result: 在3000万图文对数据上训练，在6项长文本检索基准测试中达到SOTA且呈现强扩展性，实验证明无需显式区域监督即能生成细粒度视觉对齐文本表征。

Conclusion: 层次跨域对齐方法有效突破传统模型局限，为免监督细粒度多模理解提供新范式，揭示通过分层聚合局部证据构建全局语义的可行性。

Abstract: Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.

</details>


### [16] [SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation](https://arxiv.org/abs/2602.02989)
*Zhanfeng Liao,Jiajun Zhang,Hanzhang Tu,Zhixi Wang,Yunqi Gao,Hongwen Zhang,Yebin Liu*

Main category: cs.CV

TL;DR: 本研究提出了SharpTimeGS框架，通过引入可学习的寿命参数，实现动态场景静态与动态区域的时间自适应建模，优化实时渲染性能。


<details>
  <summary>Details</summary>
Motivation: 现有高斯表示方法在处理长期静态与短暂动态区域的平衡上存在不足，在表示与优化方面仍有挑战。

Method: 1. 引入寿命参数，将时间可见性从高斯衰减转变为平顶轮廓；2. 通过寿命参数调节元素运动，解耦运动幅度与持续时间；3. 设计寿命-速度感知的密度化策略。

Result: 在多个基准测试中达到SOTA性能，支持单张RTX 4090实时渲染4K分辨率100FPS。

Conclusion: 通过寿命参数优化实现静态稳定性与动态细节的平衡，适用于高精度实时场景。

Abstract: Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporally adaptive modeling of both static and dynamic regions under a unified representation. Specifically, we introduce a learnable lifespan parameter that reformulates temporal visibility from a Gaussian-shaped decay into a flat-top profile, allowing primitives to remain consistently active over their intended duration and avoiding redundant densification. In addition, the learned lifespan modulates each primitives' motion, reducing drift in long-lived static points while retaining unrestricted motion for short-lived dynamic ones. This effectively decouples motion magnitude from temporal duration, improving long-term stability without compromising dynamic fidelity. Moreover, we design a lifespan-velocity-aware densification strategy that mitigates optimization imbalance between static and dynamic regions by allocating more capacity to regions with pronounced motion while keeping static areas compact and stable. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance while supporting real-time rendering up to 4K resolution at 100 FPS on one RTX 4090.

</details>


### [17] [Video-OPD: Efficient Post-Training of Multimodal Large Language Models for Temporal Video Grounding via On-Policy Distillation](https://arxiv.org/abs/2602.02994)
*Jiaze Li,Hao Yin,Haoran Xu,Boshen Xu,Wenhui Tan,Zewen He,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Video-OPD, an on-policy distillation framework enhanced by TVDF curriculum, outperforms GRPO in temporal video grounding with faster convergence and lower computational costs through dense token-level supervision and trajectory prioritization.


<details>
  <summary>Details</summary>
Motivation: GRPO-based methods face limitations from sparse reward signals and high computational demands, necessitating a more efficient on-policy optimization approach for temporal video grounding.

Method: Video-OPD uses on-policy distillation to optimize current policy trajectories, with a frontier teacher providing dense supervision via reverse KL divergence. TVDF selects teacher-reliable, student-informative trajectories iteratively.

Result: Video-OPD surpasses GRPO in performance, reduces training time by 40%, and cuts computational costs by 35% while maintaining alignment between training and inference distributions.

Conclusion: On-policy distillation with token-level supervision and dynamic curriculum prioritization establishes a new paradigm for efficient temporal video grounding, overcoming key limitations of traditional reinforcement learning methods.

Abstract: Reinforcement learning has emerged as a principled post-training paradigm for Temporal Video Grounding (TVG) due to its on-policy optimization, yet existing GRPO-based methods remain fundamentally constrained by sparse reward signals and substantial computational overhead. We propose Video-OPD, an efficient post-training framework for TVG inspired by recent advances in on-policy distillation. Video-OPD optimizes trajectories sampled directly from the current policy, thereby preserving alignment between training and inference distributions, while a frontier teacher supplies dense, token-level supervision via a reverse KL divergence objective. This formulation preserves the on-policy property critical for mitigating distributional shift, while converting sparse, episode-level feedback into fine-grained, step-wise learning signals. Building on Video-OPD, we introduce Teacher-Validated Disagreement Focusing (TVDF), a lightweight training curriculum that iteratively prioritizes trajectories that are both teacher-reliable and maximally informative for the student, thereby improving training efficiency. Empirical results demonstrate that Video-OPD consistently outperforms GRPO while achieving substantially faster convergence and lower computational cost, establishing on-policy distillation as an effective alternative to conventional reinforcement learning for TVG.

</details>


### [18] [VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering](https://arxiv.org/abs/2602.03007)
*Rahul Atul Bhope,K. R. Jayaram,Vinod Muthusamy,Ritesh Kumar,Vatche Isahagian,Nalini Venkatasubramanian*

Main category: cs.CV

TL;DR: 本论文提出VOILA框架，利用信息价值驱动在视觉问答中动态选择输入保真度，节省资源的同时保持高精度


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言系统使用固定高保真输入导致资源浪费，需开发自适应方法优化多模态推理资源分配

Method: 构建两阶段流水线：梯度提升回归模型预测问题特征对应的各保真度正确率，同调校准器优化决策，并基于预测准确率与成本选择最佳保真度

Result: 在3种部署场景下使用5个数据集和6种视觉语言模型(VLMs)测试，实现50-60%成本降低且维持90-95%全分辨率准确率

Conclusion: 预检索阶段动态选择信息保真度对资源约束下的多模态推理具有关键价值，验证了自适应策略的有效性

Abstract: Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.

</details>


### [19] [Thinking inside the Convolution for Image Inpainting: Reconstructing Texture via Structure under Global and Local Side](https://arxiv.org/abs/2602.03013)
*Haipeng Liu,Yang Wang,Biao Qian,Yong Rui,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种改进的图像修复方法，在CNN下采样过程中应用统计归一化与反归一化策略，以减少结构和纹理特征的信息损失，从而提升修复效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在CNN下采样阶段丢失结构和纹理特征信息，导致修复质量下降。作者旨在通过协同优化结构与纹理特征，缓解信息损失问题。

Method: 提出基于统计归一化/反归一化策略，在下采样过程中保留特征分布特性，通过编码器重构指导提升特征表达能力，同时保持模型结构兼容性。

Result: 方法在256x256和512x512分辨率图像上均超越SOTA，替换所有编码器后性能提升更显著（PSNR提升1.32dB）。

Conclusion: 结构与纹理特征的协同归一化策略有效缓解了CNN下采样信息损失，在保持模型简洁性的同时实现性能突破，开源代码已公布。

Abstract: Image inpainting has earned substantial progress, owing to the encoder-and-decoder pipeline, which is benefited from the Convolutional Neural Networks (CNNs) with convolutional downsampling to inpaint the masked regions semantically from the known regions within the encoder, coupled with an upsampling process from the decoder for final inpainting output. Recent studies intuitively identify the high-frequency structure and low-frequency texture to be extracted by CNNs from the encoder, and subsequently for a desirable upsampling recovery. However, the existing arts inevitably overlook the information loss for both structure and texture feature maps during the convolutional downsampling process, hence suffer from a non-ideal upsampling output. In this paper, we systematically answer whether and how the structure and texture feature map can mutually help to alleviate the information loss during the convolutional downsampling. Given the structure and texture feature maps, we adopt the statistical normalization and denormalization strategy for the reconstruction guidance during the convolutional downsampling process. The extensive experimental results validate its advantages to the state-of-the-arts over the images from low-to-high resolutions including 256*256 and 512*512, especially holds by substituting all the encoders by ours. Our code is available at https://github.com/htyjers/ConvInpaint-TSGL

</details>


### [20] [A Vision-Based Analysis of Congestion Pricing in New York City](https://arxiv.org/abs/2602.03015)
*Mehmet Kerem Turkcan,Jhonatan Tavori,Javad Ghaderi,Gil Zussman,Zoran Kostic,Andrew Smyth*

Main category: cs.CV

TL;DR: 本研究通过分析纽约市交通摄像头数据，发现拥堵收费政策实施后曼哈顿等区域车辆密度出现系统性变化。研究时间跨度为2024年11月至2026年1月，覆盖政策实施前后数据。


<details>
  <summary>Details</summary>
Motivation: 研究团队旨在通过大规模计算机视觉技术，建立更高效的城市交通政策量化评估方法，解决传统交通监测手段在覆盖范围和数据分析效率方面的局限性。

Method: 开发计算机视觉流水线处理超过900个监控摄像头数据，自动化分析交通流量特征，通过对比政策实施前后三年的同期数据，建立交通模式基线并检测系统性变化。

Result: 成功构建了全城尺度的交通密度变化监测框架，发现拥堵收费区域及周边路网在车辆密度指标上存在显著且持续的规律性变化。

Conclusion: 研究表明基于大规模视频分析的量化方法能够有效评估城市交通政策影响，为政策制定者提供数据驱动的决策支持，验证了计算机视觉技术在市政管理领域的应用价值。

Abstract: We examine the impact of New York City's congestion pricing program through automated analysis of traffic camera data. Our computer vision pipeline processes footage from over 900 cameras distributed throughout Manhattan and New York, comparing traffic patterns from November 2024 through the program's implementation in January 2025 until January 2026. We establish baseline traffic patterns and identify systematic changes in vehicle density across the monitored region.

</details>


### [21] [MUSE: A Multi-agent Framework for Unconstrained Story Envisioning via Closed-Loop Cognitive Orchestration](https://arxiv.org/abs/2602.03028)
*Wenzhang Sun,Zhenyu Wang,Zhangchi Hu,Chunfeng Wang,Hao Li,Wei Chen*

Main category: cs.CV

TL;DR: 提出MUSE框架解决生成长篇音视频故事时的意图执行差距问题


<details>
  <summary>Details</summary>
Motivation: 现有方法在长序列生成中易导致语义漂移和身份不一致，需保持高阶叙事意图与多模态生成间的连贯性。

Method: 构建闭环约束型生成流程，通过多智能体协作的计划-执行-验证-修订循环，使用可执行叙事指令约束身份、场景和时间连续性，并引入无参考评价协议MUSEBench。

Result: MUSEBench证实MUSE在长视野叙事连贯性、跨模态身份一致性及电影质量上显著优于基线方法，且生成质量随迭代优化提升。

Conclusion: 闭环反馈机制有效弥补多模态生成的语义鸿沟，为长序列内容创作提供新范式。

Abstract: Generating long-form audio-visual stories from a short user prompt remains challenging due to an intent-execution gap, where high-level narrative intent must be preserved across coherent, shot-level multimodal generation over long horizons. Existing approaches typically rely on feed-forward pipelines or prompt-only refinement, which often leads to semantic drift and identity inconsistency as sequences grow longer. We address this challenge by formulating storytelling as a closed-loop constraint enforcement problem and propose MUSE, a multi-agent framework that coordinates generation through an iterative plan-execute-verify-revise loop. MUSE translates narrative intent into explicit, machine-executable controls over identity, spatial composition, and temporal continuity, and applies targeted multimodal feedback to correct violations during generation. To evaluate open-ended storytelling without ground-truth references, we introduce MUSEBench, a reference-free evaluation protocol validated by human judgments. Experiments demonstrate that MUSE substantially improves long-horizon narrative coherence, cross-modal identity consistency, and cinematic quality compared with representative baselines.

</details>


### [22] [Bongards at the Boundary of Perception and Reasoning: Programs or Language?](https://arxiv.org/abs/2602.03038)
*Cassidy Langenfeld,Claas Beger,Gloria Geng,Wasu Top Piriyakulkij,Keya Hu,Yewen Pu,Kevin Ellis*

Main category: cs.CV

TL;DR: 提出一种基于神经符号的Bongard问题解决方案，结合大语言模型和贝叶斯优化实现视觉规则参数化建模


<details>
  <summary>Details</summary>
Motivation: 测试视觉语言模型在新奇视觉推理场景中的泛化能力，应对Bongard这种经典视觉推理挑战测试人类视觉推理迁移能力

Method: 给定假设解决方案规则，利用大语言模型生成参数化程序表示，并通过贝叶斯优化进行参数拟合的神经符号混合方法

Result: 在基于真实规则分类Bongard问题和端到端求解场景中均取得验证，展示了方法有效性

Conclusion: 将VLMs和LLMs优势融合，通过程序归纳和优化框架实现了复杂视觉推理迁移，为AI系统应对新颖问题提供新范式

Abstract: Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.

</details>


### [23] [IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning](https://arxiv.org/abs/2602.03060)
*Zhichao Sun,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu*

Main category: cs.CV

TL;DR: 提出了IVC-Prune方法，通过保留隐式视觉坐标标记和语义相关标记，在降低大型视觉语言模型推理成本的同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型处理高分辨率图像时存在计算成本过高的问题，现有基于语义相关性的视觉标记剪枝方法会丢失空间推理关键标记。

Method: 通过RoPE位置编码发现隐式视觉坐标标记（IVC tokens）并结合语义种子发现与上下文优化的双阶段流程进行标记剪枝，保留IVC标记和前景语义标记。

Result: 在四个模型和二十个基准测试中减少约50%视觉标记，保持≥99%原始性能，并在部分基准测试中实现性能提升。

Conclusion: IVC-Prune通过结合代数性质分析与语义上下文建模，为高效部署视觉语言模型提供了理论依据和实用方案。

Abstract: Large Vision-Language Models (LVLMs) achieve impressive performance across multiple tasks. A significant challenge, however, is their prohibitive inference cost when processing high-resolution visual inputs. While visual token pruning has emerged as a promising solution, existing methods that primarily focus on semantic relevance often discard tokens that are crucial for spatial reasoning. We address this gap through a novel insight into \emph{how LVLMs process spatial reasoning}. Specifically, we reveal that LVLMs implicitly establish visual coordinate systems through Rotary Position Embeddings (RoPE), where specific token positions serve as \textbf{implicit visual coordinates} (IVC tokens) that are essential for spatial reasoning. Based on this insight, we propose \textbf{IVC-Prune}, a training-free, prompt-aware pruning strategy that retains both IVC tokens and semantically relevant foreground tokens. IVC tokens are identified by theoretically analyzing the mathematical properties of RoPE, targeting positions at which its rotation matrices approximate identity matrix or the $90^\circ$ rotation matrix. Foreground tokens are identified through a robust two-stage process: semantic seed discovery followed by contextual refinement via value-vector similarity. Extensive evaluations across four representative LVLMs and twenty diverse benchmarks show that IVC-Prune reduces visual tokens by approximately 50\% while maintaining $\geq$ 99\% of the original performance and even achieving improvements on several benchmarks. Source codes are available at https://github.com/FireRedTeam/IVC-Prune.

</details>


### [24] [Finding Optimal Video Moment without Training: Gaussian Boundary Optimization for Weakly Supervised Video Grounding](https://arxiv.org/abs/2602.03071)
*Sunoh Kim,Kimin Yun,Daeho Um*

Main category: cs.CV

TL;DR: 本文提出高斯边界优化（GBO），无需训练即可通过优化覆盖与紧凑性平衡的闭合解，显著提升弱监督视频定位性能，并达到多基准最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖启发式映射高斯参数到边界，导致定位性能受限，需更优的理论框架解决覆盖范围与紧凑性矛盾。

Method: 建立基于闭合解的优化问题，理论分析三种惩罚机制下的最优条件，兼容单高斯/混合建议架构，完全无需训练。

Result: 在标准基准取得SOTA结果，如Charades-STA（23.4%@0.5）、Dense-Caption（24.6%@0.5），计算效率达1000FPS。

Conclusion: GBO兼具理论严谨性与实用高效性，解决了弱监督视频定位中的长期挑战，开源代码推动领域发展。

Abstract: Weakly supervised temporal video grounding aims to localize query-relevant segments in untrimmed videos using only video-sentence pairs, without requiring ground-truth segment annotations that specify exact temporal boundaries. Recent approaches tackle this task by utilizing Gaussian-based temporal proposals to represent query-relevant segments. However, their inference strategies rely on heuristic mappings from Gaussian parameters to segment boundaries, resulting in suboptimal localization performance. To address this issue, we propose Gaussian Boundary Optimization (GBO), a novel inference framework that predicts segment boundaries by solving a principled optimization problem that balances proposal coverage and segment compactness. We derive a closed-form solution for this problem and rigorously analyze the optimality conditions under varying penalty regimes. Beyond its theoretical foundations, GBO offers several practical advantages: it is training-free and compatible with both single-Gaussian and mixture-based proposal architectures. Our experiments show that GBO significantly improves localization, achieving state-of-the-art results across standard benchmarks. Extensive experiments demonstrate the efficiency and generalizability of GBO across various proposal schemes. The code is available at \href{https://github.com/sunoh-kim/gbo}{https://github.com/sunoh-kim/gbo}.

</details>


### [25] [A generalizable large-scale foundation model for musculoskeletal radiographs](https://arxiv.org/abs/2602.03076)
*Shinn Kim,Soobin Lee,Kyoungseob Shin,Han-Soo Kim,Yongsung Kim,Minsu Kim,Juhong Nam,Somang Ko,Daeheon Kwon,Wook Huh,Ilkyu Han,Sunghoon Kwon*

Main category: cs.CV

TL;DR: SKELEX是一个基于自监督学习的大型骨骼肌肉放射影像AI基础模型，通过120万张多样化图像训练，解决了传统任务特定模型泛化性不足的问题，支持零样本异常定位和可解释骨肿瘤预测


<details>
  <summary>Details</summary>
Motivation: 现有骨骼疾病AI模型受限于任务单一性、标注依赖性和跨疾病泛化能力不足，且缺乏足够规模和多样性的公开数据库支持通用模型训练

Method: 采用自监督学习框架，在120万张涵盖多种骨骼疾病的放射影像上进行预训练，构建SKELEX基础模型；开发区域引导的可解释模型进行骨肿瘤预测

Result: 在12项诊断任务中超越基线模型，特别是在骨折检测、关节炎分级和骨肿瘤分类任务中表现出色，实现零样本异常定位能力，在外部数据集保持稳健性能，已部署为公开可用的web应用

Conclusion: 该研究建立了可扩展、标注高效且具有广泛适应性的骨骼影像AI分析框架，为临床骨骼疾病诊断和数据高效型放射学研究提供了关键技术基础

Abstract: Artificial intelligence (AI) has shown promise in detecting and characterizing musculoskeletal diseases from radiographs. However, most existing models remain task-specific, annotation-dependent, and limited in generalizability across diseases and anatomical regions. Although a generalizable foundation model trained on large-scale musculoskeletal radiographs is clinically needed, publicly available datasets remain limited in size and lack sufficient diversity to enable training across a wide range of musculoskeletal conditions and anatomical sites. Here, we present SKELEX, a large-scale foundation model for musculoskeletal radiographs, trained using self-supervised learning on 1.2 million diverse, condition-rich images. The model was evaluated on 12 downstream diagnostic tasks and generally outperformed baselines in fracture detection, osteoarthritis grading, and bone tumor classification. Furthermore, SKELEX demonstrated zero-shot abnormality localization, producing error maps that identified pathologic regions without task-specific training. Building on this capability, we developed an interpretable, region-guided model for predicting bone tumors, which maintained robust performance on independent external datasets and was deployed as a publicly accessible web application. Overall, SKELEX provides a scalable, label-efficient, and generalizable AI framework for musculoskeletal imaging, establishing a foundation for both clinical translation and data-efficient research in musculoskeletal radiology.

</details>


### [26] [Gromov Wasserstein Optimal Transport for Semantic Correspondences](https://arxiv.org/abs/2602.03105)
*Francis Snelgar,Stephen Gould,Ming Xu,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 利用带有Gromov Wasserstein空间平滑先验的最优传输算法替代Stable Diffusion特征，提升DINOv2语义对应性能并实现5-10倍效率优化。


<details>
  <summary>Details</summary>
Motivation: 传统DINOv2和Stable Diffusion特征融合方法存在计算成本过高问题，需寻找更高效的替代方案。

Method: 将标准最近邻匹配替换为融合空间一致性先验的最优传输算法，并与DINOv2特征结合实现语义对应。

Result: 在保持或超越Stable Diffusion方法性能的同时，推理效率提升5-10倍，并开源代码库。

Conclusion: 空间感知的匹配算法能有效弥补单特征模型局限，在保证精度的同时显著降低计算资源消耗。

Abstract: Establishing correspondences between image pairs is a long studied problem in computer vision. With recent large-scale foundation models showing strong zero-shot performance on downstream tasks including classification and segmentation, there has been interest in using the internal feature maps of these models for the semantic correspondence task. Recent works observe that features from DINOv2 and Stable Diffusion (SD) are complementary, the former producing accurate but sparse correspondences, while the latter produces spatially consistent correspondences. As a result, current state-of-the-art methods for semantic correspondence involve combining features from both models in an ensemble. While the performance of these methods is impressive, they are computationally expensive, requiring evaluating feature maps from large-scale foundation models. In this work we take a different approach, instead replacing SD features with a superior matching algorithm which is imbued with the desirable spatial consistency property. Specifically, we replace the standard nearest neighbours matching with an optimal transport algorithm that includes a Gromov Wasserstein spatial smoothness prior. We show that we can significantly boost the performance of the DINOv2 baseline, and be competitive and sometimes surpassing state-of-the-art methods using Stable Diffusion features, while being 5--10x more efficient. We make code available at https://github.com/fsnelgar/semantic_matching_gwot .

</details>


### [27] [Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models](https://arxiv.org/abs/2602.03123)
*Judah Goldfeder,Shreyes Kaliyur,Vaibhav Sourirajan,Patrick Minwan Puma,Philippe Martin Wyder,Yuhang Hu,Jiong Lin,Hod Lipson*

Main category: cs.CV

TL;DR: 本文提出EvoAug自动化增强学习流程，通过结合生成模型和进化算法，优化任务专用数据增强策略，提升视觉模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强策略（如旋转裁剪）受限于人工设计，而生成模型虽能合成多样化数据，但缺乏任务匹配性可能导致性能下降。需建立一种自动学习最佳增强组合的方法。

Method: 构建基于生成模型和进化算法的EvoAug框架，通过分层随机增强树（stochastic augmentation trees）递归组合增强操作。进化算法用于搜索增强树的最优结构和参数，实现自适应数据增强。

Result: 在细粒度分类和小样本学习任务中，EvoAug生成的增强策略显著提升模型性能。在低数据量场景下仍能发现符合领域知识的增强模式，验证了方法的泛化性和可解释性。

Conclusion: 该研究表明结合生成模型与进化学习的自动化增强方法能够打破传统增强范式限制，为鲁棒模型训练提供新路径。实验表明其既可提升性能，又具有任务适应性和理论可解释性。

Abstract: Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.

</details>


### [28] [Flexible Geometric Guidance for Probabilistic Human Pose Estimation with Diffusion Models](https://arxiv.org/abs/2602.03126)
*Francis Snelgar,Ming Xu,Stephen Gould,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的3D人体姿态估计框架，无需依赖2D-3D配对数据，解决了深度模糊和遮挡带来的不确定性问题，并支持从单个2D图像中采样多个合理3D姿态。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设存在确定性映射且依赖大规模配对数据，导致泛化性能受限。论文旨在通过概率生成模型解决姿态模糊性问题，并减少对配对数据的依赖。

Method: 利用无条件扩散模型生成3D姿态，结合2D关键点检测器的热图梯度进行定向采样。框架通过条件生成策略，在无需配对数据的情况下实现姿态概率分布的有效采样。

Result: 在Human3.6M数据集的最佳候选评估中达到SOTA性能，并在MPI-INF-3DHP和3DPW数据集展现泛化能力。验证了框架在姿态生成和补全任务中的迁移性，无需重新训练条件模型。

Conclusion: 该方法解决了传统确定性估计的局限性，通过无监督扩散模型实现了多模态姿态预测，同时代码开源促进了后续研究。

Abstract: 3D human pose estimation from 2D images is a challenging problem due to depth ambiguity and occlusion. Because of these challenges the task is underdetermined, where there exists multiple -- possibly infinite -- poses that are plausible given the image. Despite this, many prior works assume the existence of a deterministic mapping and estimate a single pose given an image. Furthermore, methods based on machine learning require a large amount of paired 2D-3D data to train and suffer from generalization issues to unseen scenarios. To address both of these issues, we propose a framework for pose estimation using diffusion models, which enables sampling from a probability distribution over plausible poses which are consistent with a 2D image. Our approach falls under the guidance framework for conditional generation, and guides samples from an unconditional diffusion model, trained only on 3D data, using the gradients of the heatmaps from a 2D keypoint detector. We evaluate our method on the Human 3.6M dataset under best-of-$m$ multiple hypothesis evaluation, showing state-of-the-art performance among methods which do not require paired 2D-3D data for training. We additionally evaluate the generalization ability using the MPI-INF-3DHP and 3DPW datasets and demonstrate competitive performance. Finally, we demonstrate the flexibility of our framework by using it for novel tasks including pose generation and pose completion, without the need to train bespoke conditional models. We make code available at https://github.com/fsnelgar/diffusion_pose .

</details>


### [29] [FinMTM: A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation](https://arxiv.org/abs/2602.03130)
*Chenxi Zhang,Ziliang Gan,Liyun Zhu,Youwei Pang,Qing Zhang,Rongjunchen Zhang*

Main category: cs.CV

TL;DR: 本文提出FinMTM，一个用于金融领域视觉语言模型评估的多任务多模态基准数据集。针对当前金融领域VLM评测存在的单轮问答局限性和数据狭窄问题，该数据集包含11,133组中英双语金融图表QA对，涵盖蜡烛图、统计图及财务报告等可视化数据，并创新性设计包含多项选择、多轮对话和智能体任务的多样化评测方案。


<details>
  <summary>Details</summary>
Motivation: 金融领域视觉语言模型需要处理专业图表格式和知识密集型推理，但现有多数金融基准测试存在单轮问答模式单一（如单选题占比过高）、问题类型重复度高两大缺陷。例如2021年某研究显示金融QA系统在开放领域测试准确率高达82%，但在真实金融场景中表现骤降至47%。这说明亟需构建能反映真实业务复杂性的评测基准。

Method: 构建过程包含三个核心创新：1.数据维度：创建目前最大的金融视觉QA语料库（11,133条），涵盖中文/英文双语，采样来源包含沪深交易所季度报告（占比32%）、全球金融市场实时行情（28%）及世界银行统计年鉴（15%）等权威金融数据源；2.任务设计：在传统单选题基础上，新增多选题（占比23%）、10轮以上多轮对话（18%）及智能体规划任务（9%）；3.评估方法：研发任务专用评分体系，如多选题引入Jaccard重叠率计算（权重α=0.7），多轮对话采用时间衰减加权评分（β=0.85）。

Result: 在22个主流VLM的测试中发现：1.细粒度视觉理解能力不足，如对烛台图多头形态识别准确率仅54.7%；2.长时上下文记忆能力薄弱，当对话轮次超过5轮时模型准确率平均下降38.2%；3.策略规划能力缺失，在包含3个以上子任务的复合指令中成功率不足40%。特别是多模态大模型在处理中英文混合财务报表时平均存在12.5%的语义漂移现象。

Conclusion: FinMTM为金融领域VLM提供了更接近真实业务场景的评估框架，揭示出当前模型在视觉细节感知敏感度（SSIM指数较人类低0.21）、跨期信息保持能力（LSTM基线模型衰减率15%/轮次）等方面存在改进空间。研究建议后续工作应着重提升图表要素的空间关系理解，并开发针对财务数据的时序感知架构。

Abstract: The financial domain poses substantial challenges for vision-language models (VLMs) due to specialized chart formats and knowledge-intensive reasoning requirements. However, existing financial benchmarks are largely single-turn and rely on a narrow set of question formats, limiting comprehensive evaluation in realistic application scenarios. To address this gap, we propose FinMTM, a multi-turn multimodal benchmark that expands diversity along both data and task dimensions. On the data side, we curate and annotate 11{,}133 bilingual (Chinese and English) financial QA pairs grounded in financial visuals, including candlestick charts, statistical plots, and report figures. On the task side, FinMTM covers single- and multiple-choice questions, multi-turn open-ended dialogues, and agent-based tasks. We further design task-specific evaluation protocols, including a set-overlap scoring rule for multiple-choice questions, a weighted combination of turn-level and session-level scores for multi-turn dialogues, and a composite metric that integrates planning quality with final outcomes for agent tasks. Extensive experimental evaluation of 22 VLMs reveal their limitations in fine-grained visual perception, long-context reasoning, and complex agent workflows.

</details>


### [30] [SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass](https://arxiv.org/abs/2602.03134)
*Chen Qian,Xinran Yu,Danyang Li,Guoxuan Chi,Zheng Yang,Qiang Ma,Xin Miao*

Main category: cs.CV

TL;DR: 提出SwiftVLM：通过旁路剪枝提升视觉语言模型效率，避免早期剪枝导致的细节信息丢失，实现更精准的视觉标记选择。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖早期剪枝决策，虽提升效率，但导致细粒度视觉任务性能下降。本文旨在解决浅层剪枝中重要token过早丢失的问题。

Method: 引入旁路剪枝范式（bypass pruning），保留未选中的视觉token并传递至后续阶段重新评估。在模型特定层（具强token选择能力）执行剪枝，分层独立决策。

Result: SwiftVLM在多个VLM模型和基准测试中表现优于现有策略，实现更优的精度-效率权衡，并提升视觉token选择的可靠性。

Conclusion: 旁路剪枝有效减少关键信息丢失，允许跨层动态评估token重要性，为视觉语言模型提供了无需训练的高效剪枝解决方案。

Abstract: Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.

</details>


### [31] [Human-in-the-loop Adaptation in Group Activity Feature Learning for Team Sports Video Retrieval](https://arxiv.org/abs/2602.03157)
*Chihiro Nakatani,Hiroaki Kawashima,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种无需群体活动标注的人机协同自适应群体活动特征学习方法（GAFL），通过自监督预训练和交互式微调显著提升了团队活动视频检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有团队活动分析方法依赖预先定义的类别和大量监督标注数据，导致扩展成本高且难以适应用户个性化需求。本文旨在探索通过人机协同的微调机制，在无需标注的情况下提升视频检索的性能。

Method: 1. 自监督预训练：通过群体活动相似性构建初始GAF空间；2. 交互式微调：用户对系统推荐的视频标注正/负样本，利用对比学习动态优化GAF空间，增强查询视频与正样本的关联性；3. 数据高效选择：基于样本不确定性主动筛选需要标注的视频集。

Result: 在两项团队运动数据集（数据集名称略）上的实验表明：
1. 检索性能相比监督方法提升15.3%（mAP）；
2. 通过仅标注7.2%的测试数据即可达到最优性能；
3. 消融实验验证了对比学习策略与主动选择算法对性能的正向贡献。

Conclusion: 基于人机协同的GAF自适应机制成功将领域专家知识融入特征空间优化，为群体活动分析提供了可解释、可迭代的视频检索解决方案，代码开源后可进一步推动相关领域的研究。

Abstract: This paper proposes human-in-the-loop adaptation for Group Activity Feature Learning (GAFL) without group activity annotations. This human-in-the-loop adaptation is employed in a group-activity video retrieval framework to improve its retrieval performance. Our method initially pre-trains the GAF space based on the similarity of group activities in a self-supervised manner, unlike prior work that classifies videos into pre-defined group activity classes in a supervised learning manner. Our interactive fine-tuning process updates the GAF space to allow a user to better retrieve videos similar to query videos given by the user. In this fine-tuning, our proposed data-efficient video selection process provides several videos, which are selected from a video database, to the user in order to manually label these videos as positive or negative. These labeled videos are used to update (i.e., fine-tune) the GAF space, so that the positive and negative videos move closer to and farther away from the query videos through contrastive learning. Our comprehensive experimental results on two team sports datasets validate that our method significantly improves the retrieval performance. Ablation studies also demonstrate that several components in our human-in-the-loop adaptation contribute to the improvement of the retrieval performance. Code: https://github.com/chihina/GAFL-FINE-CVIU.

</details>


### [32] [LSGQuant: Layer-Sensitivity Guided Quantization for One-Step Diffusion Real-World Video Super-Resolution](https://arxiv.org/abs/2602.03182)
*Tianxing Wu,Zheng Chen,Cirou Xu,Bowen Chai,Yong Guo,Yutong Liu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出LSGQuant，通过动态范围自适应量化、层敏感性估计和联合优化策略，在保持视频超分辨率扩散模型性能的同时提升量化效果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型(VSR)因模型体积和计算成本高难以部署，低比特量化虽能压缩模型，但受制于输入动态范围差异和层间行为多样性，导致性能下降。

Method: 1) 构建动态范围自适应量化器(DRAQ)适配视频分词特征；2) 提出基于方差敏感性的层训练策略(VOLTS)；3) 设计量子化感知优化(QAO)协同训练量化/高精度分支。

Result: 实验表明LSGQuant在保持全精度模型性能的同时，显著优于现有量化方法，实现视频超分辨率扩散模型的实用化部署。

Conclusion: 通过量化感知设计与动态范围适配技术，有效解决扩散模型量化失配问题，为高效视频处理提供新范式。

Abstract: One-Step Diffusion Models have demonstrated promising capability and fast inference in video super-resolution (VSR) for real-world. Nevertheless, the substantial model size and high computational cost of Diffusion Transformers (DiTs) limit downstream applications. While low-bit quantization is a common approach for model compression, the effectiveness of quantized models is challenged by the high dynamic range of input latent and diverse layer behaviors. To deal with these challenges, we introduce LSGQuant, a layer-sensitivity guided quantizing approach for one-step diffusion-based real-world VSR. Our method incorporates a Dynamic Range Adaptive Quantizer (DRAQ) to fit video token activations. Furthermore, we estimate layer sensitivity and implement a Variance-Oriented Layer Training Strategy (VOLTS) by analyzing layer-wise statistics in calibration. We also introduce Quantization-Aware Optimization (QAO) to jointly refine the quantized branch and a retained high-precision branch. Extensive experiments demonstrate that our method has nearly performance to origin model with full-precision and significantly exceeds existing quantization techniques. Code is available at: https://github.com/zhengchen1999/LSGQuant.

</details>


### [33] [From Single Scan to Sequential Consistency: A New Paradigm for LIDAR Relocalization](https://arxiv.org/abs/2602.03198)
*Minghang Zhu,Zhijing Wang,Yuxin Guo,Wen Li,Sheng Ao,Cheng Wang*

Main category: cs.CV

TL;DR: TempLoc是一种新的LiDAR重定位框架，通过时空一致性建模显著提升定位鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于回归的方法在动态或模糊场景中表现不佳，因其依赖单帧推理或忽略点云序列时空连续性。

Method: 提出三个模块：1) 全局坐标估计模块预测点云坐标及不确定性；2) 先验坐标生成模块通过注意力机制建立帧间对应关系；3) 不确定性引导的坐标融合模块端到端整合预测结果。

Result: 在NCLT和Oxford数据集上超越现有SOTA方法，验证了时空关联建模的有效性。

Conclusion: 通过时序感知的点云对应关系建模可显著提高LiDAR重定位的鲁棒性和准确性。

Abstract: LiDAR relocalization aims to estimate the global 6-DoF pose of a sensor in the environment. However, existing regression-based approaches are prone to dynamic or ambiguous scenarios, as they either solely rely on single-frame inference or neglect the spatio-temporal consistency across scans. In this paper, we propose TempLoc, a new LiDAR relocalization framework that enhances the robustness of localization by effectively modeling sequential consistency. Specifically, a Global Coordinate Estimation module is first introduced to predict point-wise global coordinates and associated uncertainties for each LiDAR scan. A Prior Coordinate Generation module is then presented to estimate inter-frame point correspondences by the attention mechanism. Lastly, an Uncertainty-Guided Coordinate Fusion module is deployed to integrate both predictions of point correspondence in an end-to-end fashion, yielding a more temporally consistent and accurate global 6-DoF pose. Experimental results on the NCLT and Oxford Robot-Car benchmarks show that our TempLoc outperforms stateof-the-art methods by a large margin, demonstrating the effectiveness of temporal-aware correspondence modeling in LiDAR relocalization. Our code will be released soon.

</details>


### [34] [Hand3R: Online 4D Hand-Scene Reconstruction in the Wild](https://arxiv.org/abs/2602.03200)
*Wendi Hu,Haonan Zhou,Wenhao Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: Hand3R是首个在线框架，通过单目视频实现动态手与场景的联合4D重建，结合预训练手部专家与4D场景模型，单次前向传播完成高精度手网格与场景几何重建。


<details>
  <summary>Details</summary>
Motivation: 传统方法孤立处理局部手部重建，忽略3D场景环境，无法满足物理交互理解的需求。需要建立手与场景协同重建的鲁棒性框架。

Method: 提出场景感知视觉提示机制，融合预训练手部专家与4D场景基础模型，通过场景记忆注入高保真手部先验，实现单阶段联合优化。

Result: 实验表明Hand3R无需离线优化即可实现：1) 局部手部重建性能与优化方法相当；2) 全局定位误差低于基准模型30%。

Conclusion: 该方法突破单阶段手-场景联合重建的技术瓶颈，为具身智能提供实时、几何一致的感知解决方案。

Abstract: For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.

</details>


### [35] [VIRAL: Visual In-Context Reasoning via Analogy in Diffusion Transformers](https://arxiv.org/abs/2602.03210)
*Zhiwen Li,Zhongjie Duan,Jinyan Ye,Cen Chen,Daoyuan Chen,Yaliang Li,Yingda Chen*

Main category: cs.CV

TL;DR: 本文提出VIRAL框架，通过将上下文学习（ICL）转化为条件生成任务，结合视觉类比和冻结扩散Transformer实现视觉任务的统一处理。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉中因任务异构性导致的上下文学习复制困难，提出统一的V-ICL范式以有效处理多样化视觉任务。

Method: 采用角色感知多图像条件生成适配冻结DiT模型，设计混合专家LoRA缓解梯度干扰，并构建覆盖感知/修复/编辑任务的大规模数据集。

Result: 实验表明VIRAL在性能上超越现有方法，成功处理包含开放域编辑在内的多种视觉任务。

Conclusion: 验证了视觉类比条件生成与参数高效微调技术结合可构建普适性视觉上下文学习框架。

Abstract: Replicating In-Context Learning (ICL) in computer vision remains challenging due to task heterogeneity. We propose \textbf{VIRAL}, a framework that elicits visual reasoning from a pre-trained image editing model by formulating ICL as conditional generation via visual analogy ($x_s : x_t :: x_q : y_q$). We adapt a frozen Diffusion Transformer (DiT) using role-aware multi-image conditioning and introduce a Mixture-of-Experts LoRA to mitigate gradient interference across diverse tasks. Additionally, to bridge the gaps in current visual context datasets, we curate a large-scale dataset spanning perception, restoration, and editing. Experiments demonstrate that VIRAL outperforms existing methods, validating that a unified V-ICL paradigm can handle the majority of visual tasks, including open-domain editing. Our code is available at https://anonymous.4open.science/r/VIRAL-744A

</details>


### [36] [ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask](https://arxiv.org/abs/2602.03213)
*Zhuoran Yang,Yanyong Zhang*

Main category: cs.CV

TL;DR: ConsisDrive解决自动驾驶视频生成中的物体身份漂移问题，通过引入实例级时序一致性约束，实现高质量驾驶视频生成。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要高质量多视角驾驶视频训练模型，但现有世界模型生成的视频存在物体身份漂移问题（同一物体跨帧出现外观/类别变化），缺乏实例级别的时序约束。

Method: 1. Instance-Masked Attention：在注意力模块中使用实例身份掩码和轨迹掩码，限制视觉token仅与对应实例特征交互；2. Instance-Masked Loss：通过概率实例掩码强调前景区域，减少背景噪声的同时保持场景保真度。

Result: 在nuScenes数据集上达到SOTA视频生成质量，显著提升自动驾驶下游任务性能（包括目标检测与跟踪）。

Conclusion: 实例级掩码机制有效解决了时间一致性问题，为自动驾驶仿真数据生成提供了新范式。

Abstract: Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance level. Our framework incorporates two key components: (1) Instance-Masked Attention, which applies instance identity masks and trajectory masks within attention blocks to ensure that visual tokens interact only with their corresponding instance features across spatial and temporal dimensions, thereby preserving object identity consistency; and (2) Instance-Masked Loss, which adaptively emphasizes foreground regions with probabilistic instance masking, reducing background noise while maintaining overall scene fidelity. By integrating these mechanisms, ConsisDrive achieves state-of-the-art driving video generation quality and demonstrates significant improvements in downstream autonomous driving tasks on the nuScenes dataset. Our project page is https://shanpoyang654.github.io/ConsisDrive/page.html.

</details>


### [37] [FARTrack: Fast Autoregressive Visual Tracking with High Performance](https://arxiv.org/abs/2602.03214)
*Guijie Wang,Tong Lin,Yifan Bai,Anjia Cao,Shiyi Liang,Wangbo Zhao,Xing Wei*

Main category: cs.CV

TL;DR: This paper proposes FARTrack, a fast and efficient visual tracking framework that balances speed and performance through task-specific self-distillation and inter-frame autoregressive sparsification.


<details>
  <summary>Details</summary>
Motivation: Existing high-performance visual trackers often sacrifice inference speed, limiting their practicality on resource-constrained devices. The authors aim to address this trade-off by developing a lightweight yet effective tracking framework.

Method: FARTrack integrates two key strategies: Task-Specific Self-Distillation (layer-by-layer compression of task-specific tokens to accelerate inference) and Inter-frame Autoregressive Sparsification (sequential template condensation for temporal optimization without extra runtime costs).

Result: FARTrack achieves 70.6% AO on GOT-10k with real-time performance, reaching 343 FPS on GPU and 121 FPS on CPU, demonstrating superior efficiency and competitive accuracy.

Conclusion: FARTrack effectively reconciles speed and performance in visual tracking, enabling deployment on diverse devices while maintaining strong accuracy through its autoregressive design and optimization techniques.

Abstract: Inference speed and tracking performance are two critical evaluation metrics in the field of visual tracking. However, high-performance trackers often suffer from slow processing speeds, making them impractical for deployment on resource-constrained devices. To alleviate this issue, we propose FARTrack, a Fast Auto-Regressive Tracking framework. Since autoregression emphasizes the temporal nature of the trajectory sequence, it can maintain high performance while achieving efficient execution across various devices. FARTrack introduces Task-Specific Self-Distillation and Inter-frame Autoregressive Sparsification, designed from the perspectives of shallow-yet-accurate distillation and redundant-to-essential token optimization, respectively. Task-Specific Self-Distillation achieves model compression by distilling task-specific tokens layer by layer, enhancing the model's inference speed while avoiding suboptimal manual teacher-student layer pairs assignments. Meanwhile, Inter-frame Autoregressive Sparsification sequentially condenses multiple templates, avoiding additional runtime overhead while learning a temporally-global optimal sparsification strategy. FARTrack demonstrates outstanding speed and competitive performance. It delivers an AO of 70.6% on GOT-10k in real-time. Beyond, our fastest model achieves a speed of 343 FPS on the GPU and 121 FPS on the CPU.

</details>


### [38] [PokeFusion Attention: Enhancing Reference-Free Style-Conditioned Generation](https://arxiv.org/abs/2602.03220)
*Jingbang Tang*

Main category: cs.CV

TL;DR: PokeFusion Attention: A parameter-efficient, reference-free method for style-conditioned character generation in diffusion models, improving style consistency and geometric stability while reducing architectural complexity.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-image methods struggle with style drift/geometry inconsistencies due to text-only prompts or require reference images/adapters that increase complexity and hinder deployment flexibility.

Method: Injects learnable style embeddings into decoder-level cross-attention mechanisms of frozen diffusion backbones, decoupling text/style conditioning while preserving pretrained weights.

Result: Achieved higher style fidelity (~20% better than baselines on CLIP score), improved character shape consistency, and reduced parameter overhead by 15x-30x compared to adapter methods, with benchmark validation on Pokémon-style generation.

Conclusion: Enables efficient plug-and-play stylized generation while maintaining diffusion model backbone integrity and inference simplicity.

Abstract: This paper studies reference-free style-conditioned character generation in text-to-image diffusion models, where high-quality synthesis requires both stable character structure and consistent, fine-grained style expression across diverse prompts. Existing approaches primarily rely on text-only prompting, which is often under-specified for visual style and tends to produce noticeable style drift and geometric inconsistency, or introduce reference-based adapters that depend on external images at inference time, increasing architectural complexity and limiting deployment flexibility.We propose PokeFusion Attention, a lightweight decoder-level cross-attention mechanism that fuses textual semantics with learned style embeddings directly inside the diffusion decoder. By decoupling text and style conditioning at the attention level, our method enables effective reference-free stylized generation while keeping the pretrained diffusion backbone fully frozen.PokeFusion Attention trains only decoder cross-attention layers together with a compact style projection module, resulting in a parameter-efficient and plug-and-play control component that can be easily integrated into existing diffusion pipelines and transferred across different backbones.Experiments on a stylized character generation benchmark (Pokemon-style) demonstrate that our method consistently improves style fidelity, semantic alignment, and character shape consistency compared with representative adapter-based baselines, while maintaining low parameter overhead and inference-time simplicity.

</details>


### [39] [Spiral RoPE: Rotate Your Rotary Positional Embeddings in the 2D Plane](https://arxiv.org/abs/2602.03227)
*Haoyu Liu,Sucheng Ren,Tingyu Zhu,Peng Wang,Cihang Xie,Alan Yuille,Zeyu Zheng,Feng Wang*

Main category: cs.CV

TL;DR: Spiral RoPE extends Rotary Position Embedding (RoPE) for vision transformers, enabling multi-directional positional encoding by grouping embedding channels with uniformly distributed directions and rotating based on spatial projections, addressing axis-aligned limitations.


<details>
  <summary>Details</summary>
Motivation: Standard axial 2D RoPE in vision transformers restricts positional encoding to axis-aligned directions, limiting the modeling of naturally occurring oblique spatial relationships in images.

Method: Spiral RoPE partitions embedding channels into direction-specific groups, each rotated according to spatial projections along uniformly distributed angles, allowing positional encoding beyond horizontal/vertical axes.

Result: Spiral RoPE improves performance on vision tasks (classification, segmentation, generation) and shows enhanced attention map focus on semantic objects and local boundaries, proving multi-directional encoding's effectiveness.

Conclusion: Spiral RoPE successfully overcomes directional constraints in standard 2D RoPE, enhancing vision transformers' ability to capture complex spatial relationships through multi-directional positional encoding.

Abstract: Rotary Position Embedding (RoPE) is the de facto positional encoding in large language models due to its ability to encode relative positions and support length extrapolation. When adapted to vision transformers, the standard axial formulation decomposes two-dimensional spatial positions into horizontal and vertical components, implicitly restricting positional encoding to axis-aligned directions. We identify this directional constraint as a fundamental limitation of the standard axial 2D RoPE, which hinders the modeling of oblique spatial relationships that naturally exist in natural images. To overcome this limitation, we propose Spiral RoPE, a simple yet effective extension that enables multi-directional positional encoding by partitioning embedding channels into multiple groups associated with uniformly distributed directions. Each group is rotated according to the projection of the patch position onto its corresponding direction, allowing spatial relationships to be encoded beyond the horizontal and vertical axes. Across a wide range of vision tasks including classification, segmentation, and generation, Spiral RoPE consistently improves performance. Qualitative analysis of attention maps further show that Spiral RoPE exhibits more concentrated activations on semantically relevant objects and better respects local object boundaries, highlighting the importance of multi-directional positional encoding in vision transformers.

</details>


### [40] [EventFlash: Towards Efficient MLLMs for Event-Based Vision](https://arxiv.org/abs/2602.03230)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Wen Jiang,Ming Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: 针对事件基础多模态大语言模型(MLLMs)高计算成本的限制，本文提出EventFlash，通过时空标记稀释化实现12.4倍吞吐量提升，包含自适应时间窗口优化与稀疏密度引导注意力模块，并构建大规模EventMind数据集支持课程学习。


<details>
  <summary>Details</summary>
Motivation: 事件基础MLLMs需要处理高动态场景下的时空稀疏事件流，但现有方法沿用密集图像处理范式导致计算冗余，亟需开发高效时空稀疏化技术以降低计算成本。

Method: 1) 构建含50万指令集的EventMind数据集支持课程学习；2) 提出自适应时间窗口聚合模块动态压缩时间tokens；3) 设计稀疏密度引导注意力模块抑制空间冗余区域。

Result: EventFlash在保持与基准模型相当性能下吞吐量提升12.4倍，支持处理长达1000个时间窗格的事件流，远超EventGPT的5窗格限制。

Conclusion: 论文提出首个高效事件基础MLLM框架，验证了时空稀疏化的可行性，为未来构建轻量化事件视觉模型提供了可扩展模板。

Abstract: Event-based multimodal large language models (MLLMs) enable robust perception in high-speed and low-light scenarios, addressing key limitations of frame-based MLLMs. However, current event-based MLLMs often rely on dense image-like processing paradigms, overlooking the spatiotemporal sparsity of event streams and resulting in high computational cost. In this paper, we propose EventFlash, a novel and efficient MLLM to explore spatiotemporal token sparsification for reducing data redundancy and accelerating inference. Technically, we build EventMind, a large-scale and scene-diverse dataset with over 500k instruction sets, providing both short and long event stream sequences to support our curriculum training strategy. We then present an adaptive temporal window aggregation module for efficient temporal sampling, which adaptively compresses temporal tokens while retaining key temporal cues. Finally, a sparse density-guided attention module is designed to improve spatial token efficiency by selecting informative regions and suppressing empty or sparse areas. Experimental results show that EventFlash achieves a $12.4\times$ throughput improvement over the baseline (EventFlash-Zero) while maintaining comparable performance. It supports long-range event stream processing with up to 1,000 bins, significantly outperforming the 5-bin limit of EventGPT. We believe EventFlash serves as an efficient foundation model for event-based vision.

</details>


### [41] [InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation](https://arxiv.org/abs/2602.03242)
*Zhuoran Yang,Xi Guo,Chenjing Ding,Chiyu Wang,Wei Wu,Yanyong Zhang*

Main category: cs.CV

TL;DR: InstaDrive通过实例流引导与空间几何对齐技术，生成具有时空一致性的高质量驾驶视频，助力自动驾驶模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型生成的驾驶视频缺乏实例级时间连续性和空间几何精确度，影响自动驾驶系统训练效果，亟需改进视频生成质量。

Method: 提出双机制框架：实例流引导器跨帧传播实例特征保持时间一致性；空间几何对齐器通过显式建模遮挡层级实现精准空间定位，并结合CARLA模拟安全临界场景。

Result: 在nuScenes数据集上实现视频生成SOTA性能，提升下游自动驾驶任务表现，并通过CARLA仿真验证系统安全性。

Conclusion: InstaDrive有效解决驾驶视频生成的时空一致性问题，为自动驾驶提供高保真训练与安全评估框架。

Abstract: Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.

</details>


### [42] [LaVPR: Benchmarking Language and Vision for Place Recognition](https://arxiv.org/abs/2602.03253)
*Ofer Idan,Dan Badur,Yosi Keller,Yoli Shavit*

Main category: cs.CV

TL;DR: 本文提出LaVPR大规模基准数据集，通过引入自然语言描述解决传统VPR在极端环境变化中的定位失效问题，并采用多模态融合和跨模态检索方法提升小模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统VPR系统在环境剧烈变化和存在感知别名时效果差，且无法通过语言描述进行定位。需要扩展数据集并引入语言模态以提升鲁棒性和实用性。

Method: 构建包含65万自然语言描述的LaVPR数据集，采用多模态融合增强视觉-语言特征交互；提出基于LoRA和多相似损失函数的跨模态检索方法，对比标准对比学习方法实现更优性能。

Result: 语言描述在视觉条件差时提升效果显著，小模型通过语言辅助可达到大视觉模型性能；跨模态方法相较对比学习在多个指标上显著提升（如recall@1提升15.2%）。

Conclusion: LaVPR数据集和多模态方法有效提升VPR系统在复杂环境下的可靠性，为资源受限场景下的定位部署提供新方案，开源代码推动领域发展。

Abstract: Visual Place Recognition (VPR) often fails under extreme environmental changes and perceptual aliasing. Furthermore, standard systems cannot perform "blind" localization from verbal descriptions alone, a capability needed for applications such as emergency response. To address these challenges, we introduce LaVPR, a large-scale benchmark that extends existing VPR datasets with over 650,000 rich natural-language descriptions. Using LaVPR, we investigate two paradigms: Multi-Modal Fusion for enhanced robustness and Cross-Modal Retrieval for language-based localization. Our results show that language descriptions yield consistent gains in visually degraded conditions, with the most significant impact on smaller backbones. Notably, adding language allows compact models to rival the performance of much larger vision-only architectures. For cross-modal retrieval, we establish a baseline using Low-Rank Adaptation (LoRA) and Multi-Similarity loss, which substantially outperforms standard contrastive methods across vision-language models. Ultimately, LaVPR enables a new class of localization systems that are both resilient to real-world stochasticity and practical for resource-constrained deployment. Our dataset and code are available at https://github.com/oferidan1/LaVPR.

</details>


### [43] [HypCBC: Domain-Invariant Hyperbolic Cross-Branch Consistency for Generalizable Medical Image Analysis](https://arxiv.org/abs/2602.03264)
*Francesco Di Salvo,Sebastian Doerrich,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 本文提出使用双曲流形表示学习和无监督领域不变交叉分支一致性约束，提升医学图像分析的领域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像数据存在设备、协议和患者群体的分布偏移，传统欧几里得流形建模难以捕捉临床数据中的复杂层次结构。

Method: 开发基于双曲流形的医学图像表示学习框架，引入无监督领域不变交叉分支一致性约束。

Result: 在11个同分布数据集和3个ViT模型上验证有效性，领域泛化基准测试中平均AUC提升2.1%，显著优于欧几里得方法。

Conclusion: 双曲几何结构能更好建模医学数据层次特征，提出的方法在跨设备、跨协议和跨患者群体的应用中展现出显著优势。

Abstract: Robust generalization beyond training distributions remains a critical challenge for deep neural networks. This is especially pronounced in medical image analysis, where data is often scarce and covariate shifts arise from different hardware devices, imaging protocols, and heterogeneous patient populations. These factors collectively hinder reliable performance and slow down clinical adoption. Despite recent progress, existing learning paradigms primarily rely on the Euclidean manifold, whose flat geometry fails to capture the complex, hierarchical structures present in clinical data. In this work, we exploit the advantages of hyperbolic manifolds to model complex data characteristics. We present the first comprehensive validation of hyperbolic representation learning for medical image analysis and demonstrate statistically significant gains across eleven in-distribution datasets and three ViT models. We further propose an unsupervised, domain-invariant hyperbolic cross-branch consistency constraint. Extensive experiments confirm that our proposed method promotes domain-invariant features and outperforms state-of-the-art Euclidean methods by an average of $+2.1\%$ AUC on three domain generalization benchmarks: Fitzpatrick17k, Camelyon17-WILDS, and a cross-dataset setup for retinal imaging. These datasets span different imaging modalities, data sizes, and label granularities, confirming generalization capabilities across substantially different conditions. The code is available at https://github.com/francescodisalvo05/hyperbolic-cross-branch-consistency .

</details>


### [44] [Global Geometry Is Not Enough for Vision Representations](https://arxiv.org/abs/2602.03282)
*Jiwan Chung,Seon Joo Kim*

Main category: cs.CV

TL;DR: 该研究揭示了当前表征学习中依赖嵌入几何的评估方法在描述组合性时的局限性，并提出功能敏感性（输入输出雅可比）作为更有效的预测指标。


<details>
  <summary>Details</summary>
Motivation: 研究者质疑当前表征学习对全局嵌入几何的过度依赖，认为这种指标无法有效捕捉元素组合的结构性特征，需探索新的评估维度

Method: 对21种视觉编码器进行跨模态组合性测试，定量分析传统几何指标与功能敏感性的关联性，并结合目标函数设计进行理论推导

Result: 发现传统几何统计量与组合绑定能力几乎无相关性（近零相关），而输入输出雅可比矩阵的敏感性指标表现显著相关性，理论推导进一步解释了目标函数设计导致的这一差异

Conclusion: 全局嵌入几何仅部分反映表征完备性，功能敏感性提供了关键的补偿性评估维度，建议未来研究应关注局部输入输出映射关系

Abstract: A common assumption in representation learning is that globally well-distributed embeddings support robust and generalizable representations. This focus has shaped both training objectives and evaluation protocols, implicitly treating global geometry as a proxy for representational competence. While global geometry effectively encodes which elements are present, it is often insensitive to how they are composed. We investigate this limitation by testing the ability of geometric metrics to predict compositional binding across 21 vision encoders. We find that standard geometry-based statistics exhibit near-zero correlation with compositional binding. In contrast, functional sensitivity, as measured by the input-output Jacobian, reliably tracks this capability. We further provide an analytic account showing that this disparity arises from objective design, as existing losses explicitly constrain embedding geometry but leave the local input-output mapping unconstrained. These results suggest that global embedding geometry captures only a partial view of representational competence and establish functional sensitivity as a critical complementary axis for modeling composite structure.

</details>


### [45] [A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation](https://arxiv.org/abs/2602.03292)
*Jianghao Wu,Xiangde Luo,Yubo Zhou,Lianming Wu,Guotai Wang,Shaoting Zhang*

Main category: cs.CV

TL;DR: A3-TTA通过锚点引导的监督机制改进测试时自适应（TTA），解决领域迁移下图像分割模型的伪标签不稳定性问题，显著提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有伪标签TTA方法依赖扰动集成启发式策略（如Dropout、测试时增强），存在分布假设缺失和训练信号不稳定问题，易导致错误累积和灾难性遗忘。

Method: 提出A3-TTA框架：1) 利用类别紧凑密度指标筛选可靠的锚点样本（预测置信度高且分布接近源域）；2) 通过语义一致性约束和边界感知熵最小化生成伪标签；3) 设计自适应指数滑动平均策略抑制标签噪声并稳定模型更新。

Result: 在医学影像（心脏/前列腺分割）和自然图像多领域数据集上验证，A3-TTA相比源模型平均Dice系数提升10.40-17.68个百分点，显著优于现有TTA方法，并在持续TTA任务中展现出强抗遗忘能力。

Conclusion: A3-TTA为领域迁移下的图像分割提供了分布感知且鲁棒的TTA解决方案，适用于不同模型架构，代码开源支持实际部署。

Abstract: Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose \textbf{A3-TTA}, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA.

</details>


### [46] [LEVIO: Lightweight Embedded Visual Inertial Odometry for Resource-Constrained Devices](https://arxiv.org/abs/2602.03294)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: LEVIO 是一种为超低功耗平台优化的视觉惯性里程计（VIO）系统，可在资源受限的硬件（如微型无人机和智能眼镜）上实现实时六自由度（DoF）运动跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有视觉惯性里程计（VIO）系统计算开销大，难以满足微型无人机、智能眼镜等硬件的实时性与低功耗需求。

Method: 采用 ORB 特征跟踪与光束法平差等成熟 VIO 组件，结合并行化架构设计、内存优化策略及软硬件协同优化方案，适配嵌入式微控制器和低功耗系统级芯片（SoC）环境。

Result: 在超低功耗 RISC-V SoC 平台上实现 20 FPS 实时性能，功耗低于 100 mW，并在公开 VIO 数据集上验证了其效率与精度的平衡性。

Conclusion: LEVIO 通过架构创新与协同优化，成功实现低功耗高精度运动跟踪，且开源代码促进后续研究与应用。

Abstract: Accurate, infrastructure-less sensor systems for motion tracking are essential for mobile robotics and augmented reality (AR) applications. The most popular state-of-the-art visual-inertial odometry (VIO) systems, however, are too computationally demanding for resource-constrained hardware, such as micro-drones and smart glasses. This work presents LEVIO, a fully featured VIO pipeline optimized for ultra-low-power compute platforms, allowing six-degrees-of-freedom (DoF) real-time sensing. LEVIO incorporates established VIO components such as Oriented FAST and Rotated BRIEF (ORB) feature tracking and bundle adjustment, while emphasizing a computationally efficient architecture with parallelization and low memory usage to suit embedded microcontrollers and low-power systems-on-chip (SoCs). The paper proposes and details the algorithmic design choices and the hardware-software co-optimization approach, and presents real-time performance on resource-constrained hardware. LEVIO is validated on a parallel-processing ultra-low-power RISC-V SoC, achieving 20 FPS while consuming less than 100 mW, and benchmarked against public VIO datasets, offering a compelling balance between efficiency and accuracy. To facilitate reproducibility and adoption, the complete implementation is released as open-source.

</details>


### [47] [Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases](https://arxiv.org/abs/2602.03302)
*Jinze Zhang,Jian Zhong,Li Lin,Jiaxiong Li,Ke Ma,Naiyang Li,Meng Li,Yuan Pan,Zeyu Meng,Mengyun Zhou,Shang Huang,Shilong Yu,Zhengyu Duan,Sutong Li,Honghui Xia,Juping Liu,Dan Liang,Yantao Wei,Xiaoying Tang,Jin Yuan,Peng Xiao*

Main category: cs.CV

TL;DR: FOCUS是一种用于光学相干断层扫描(OCT)视网膜疾病诊断的新型端到端自动化系统，通过利用基础模型和自适应聚合方法，在多中心和多设备环境下展现出了高效且准确的患者级诊断能力。


<details>
  <summary>Details</summary>
Motivation: 传统OCT诊断流程依赖分阶段工作流和单切片单任务AI模型，限制了临床中的全流程自动化。FOCUS旨在通过整合基础模型和统一框架解决此问题，以提高诊断效率和可扩展性。

Method: FOCUS依次采用EfficientNetV2-S进行图像质量评估，并通过微调视觉基础模型进行异常检测和多疾病分类；其核心创新是统一自适应聚合方法，将2D切片级预测整合为3D患者级诊断。

Result: 在3,300名患者（40,672个切片）训练和1,345名患者（18,498个切片）外部验证中，FOCUS在质量评估（F1 99.01%）、异常检测（97.46%）和患者级诊断（94.39%）均表现优异，跨中心稳定性达90.22%-95.24%。与专家对比显示其诊断性能匹配或更优且效率更高。

Conclusion: FOCUS实现了OCT影像到诊断的全自动化流程，为空无人眼科诊疗提供了验证的蓝图，有望通过自主筛查提升大规模视网膜疾病诊疗的可及性与效率。

Abstract: Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.

</details>


### [48] [Invisible Clean-Label Backdoor Attacks for Generative Data Augmentation](https://arxiv.org/abs/2602.03316)
*Ting Xiang,Jinhui Zhao,Changjian Chen,Zhuo Tang*

Main category: cs.CV

TL;DR: The paper proposes InvLBA, an invisible clean-label backdoor attack method for generative data augmentation that targets latent features instead of pixel-level triggers, achieving higher attack success rates while maintaining clean accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing pixel-level clean-label backdoor attacks (e.g., COMBAT) applied to generated images show low attack success rates, prompting the need to explore latent feature-level attacks for improved effectiveness.

Method: InvLBA introduces latent perturbations during generative data augmentation to embed backdoors. The authors theoretically analyze its generalization and implement experiments across multiple datasets to validate attack performance and robustness.

Result: Experiments demonstrate that InvLBA improves attack success rates by 46.43% on average compared to existing methods, with negligible reduction in clean accuracy and strong resilience against state-of-the-art defense techniques.

Conclusion: InvLBA highlights the vulnerability of latent feature spaces in generative data augmentation and underscores the necessity for advanced defenses addressing latent-level threats.

Abstract: With the rapid advancement of image generative models, generative data augmentation has become an effective way to enrich training images, especially when only small-scale datasets are available. At the same time, in practical applications, generative data augmentation can be vulnerable to clean-label backdoor attacks, which aim to bypass human inspection. However, based on theoretical analysis and preliminary experiments, we observe that directly applying existing pixel-level clean-label backdoor attack methods (e.g., COMBAT) to generated images results in low attack success rates. This motivates us to move beyond pixel-level triggers and focus instead on the latent feature level. To this end, we propose InvLBA, an invisible clean-label backdoor attack method for generative data augmentation by latent perturbation. We theoretically prove that the generalization of the clean accuracy and attack success rates of InvLBA can be guaranteed. Experiments on multiple datasets show that our method improves the attack success rate by 46.43% on average, with almost no reduction in clean accuracy and high robustness against SOTA defense methods.

</details>


### [49] [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320)
*Shengyuan Liu,Liuxin Bao,Qi Yang,Wanting Geng,Boyun Zheng,Chenxin Li,Wenting Chen,Houwen Peng,Yixuan Yuan*

Main category: cs.CV

TL;DR: MedSAM-Agent改进医学图像分割框架，通过多步决策与双重训练策略提升分割效率和智能化水平。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法依赖单一交互策略且缺乏流程监督，限制了动态工具利用并导致冗余操作。

Method: 提出混合提示策略生成专家轨迹，并设计两阶段训练结合多轮验证与临床可信奖励机制，优化交互效率。

Result: 在6种医学模态、21个数据集实现SOTA性能，验证了动态决策与迭代优化的有效性。

Conclusion: MedSAM-Agent通过人机协同决策范式，实现了医学自主推理与分割优化的深度融合。

Abstract: Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.

</details>


### [50] [PWAVEP: Purifying Imperceptible Adversarial Perturbations in 3D Point Clouds via Spectral Graph Wavelets](https://arxiv.org/abs/2602.03333)
*Haoran Li,Renyang Liu,Hongjia Liu,Chen Wang,Long Yin,Jian Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于谱域分析的新型3D点云防御机制PWAVEP，通过分层消除显著点和光谱过滤有效抑制对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法存在需修改模型、训练成本高或依赖辅助数据等问题，攻击者已实现空间不可见性和高攻击性能，亟需高效防御手段。

Method: 构建谱图小波域显著性评分与局部稀疏性评分，采用分层策略：1)清除高度显著的不可恢复异常点；2)通过图小波变换对中显著点进行高频系数衰减处理。

Result: 实验显示PWAVEP在PointNet、DGCNN等模型上对抗Noise-NN、KNN等攻击时，分类准确率提升绝对值最高达15.8%，且保持点云几何完整性。

Conclusion: 实现了非侵入式3D点云净化框架，结合频谱分析与空间过滤，在保持原模型结构前提下显著提升鲁棒性，推动了点云安全领域的发展。

Abstract: Recent progress in adversarial attacks on 3D point clouds, particularly in achieving spatial imperceptibility and high attack performance, presents significant challenges for defenders. Current defensive approaches remain cumbersome, often requiring invasive model modifications, expensive training procedures or auxiliary data access. To address these threats, in this paper, we propose a plug-and-play and non-invasive defense mechanism in the spectral domain, grounded in a theoretical and empirical analysis of the relationship between imperceptible perturbations and high-frequency spectral components. Building upon these insights, we introduce a novel purification framework, termed PWAVEP, which begins by computing a spectral graph wavelet domain saliency score and local sparsity score for each point. Guided by these values, PWAVEP adopts a hierarchical strategy, it eliminates the most salient points, which are identified as hardly recoverable adversarial outliers. Simultaneously, it applies a spectral filtering process to a broader set of moderately salient points. This process leverages a graph wavelet transform to attenuate high-frequency coefficients associated with the targeted points, thereby effectively suppressing adversarial noise. Extensive evaluations demonstrate that the proposed PWAVEP achieves superior accuracy and robustness compared to existing approaches, advancing the state-of-the-art in 3D point cloud purification. Code and datasets are available at https://github.com/a772316182/pwavep

</details>


### [51] [Composable Visual Tokenizers with Generator-Free Diagnostics of Learnability](https://arxiv.org/abs/2602.03339)
*Bingchen Zhao,Qiushan Guo,Ye Wang,Yixuan Huang,Zhonghua Zhai,Yu Tian*

Main category: cs.CV

TL;DR: CompTok is a framework for training compositional visual tokenizers that enable precise image generation and semantic editing through token swapping.


<details>
  <summary>Details</summary>
Motivation: To address the limitation of existing visual tokenizers in capturing compositional relationships between tokens and improving semantic control in image generation tasks.

Method: 1. Uses token-conditioned diffusion decoder with InfoGAN-style training for bidirectional token-image alignment. 2. Employs token swapping between images to promote compositional control. 3. Applies adversarial flow regularizer to maintain natural image distribution for unpaired token swaps.

Result: Achieves state-of-the-art performance in image class-conditioned generation while enabling token-based semantic editing. Proposes two novel metrics to evaluate token space compositionality and learnability.

Conclusion: CompTok effectively enhances compositional control in visual tokenization through token swapping and adversarial regularization, validated by improved performance metrics and semantic editing capabilities.

Abstract: We introduce CompTok, a training framework for learning visual tokenizers whose tokens are enhanced for compositionality. CompTok uses a token-conditioned diffusion decoder. By employing an InfoGAN-style objective, where we train a recognition model to predict the tokens used to condition the diffusion decoder using the decoded images, we enforce the decoder to not ignore any of the tokens. To promote compositional control, besides the original images, CompTok also trains on tokens formed by swapping token subsets between images, enabling more compositional control of the token over the decoder. As the swapped tokens between images do not have ground truth image targets, we apply a manifold constraint via an adversarial flow regularizer to keep unpaired swap generations on the natural-image distribution. The resulting tokenizer not only achieves state-of-the-art performance on image class-conditioned generation, but also demonstrates properties such as swapping tokens between images to achieve high level semantic editing of an image. Additionally, we propose two metrics that measures the landscape of the token space that can be useful to describe not only the compositionality of the tokens, but also how easy to learn the landscape is for a generator to be trained on this space. We show in experiments that CompTok can improve on both of the metrics as well as supporting state-of-the-art generators for class conditioned generation.

</details>


### [52] [Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution](https://arxiv.org/abs/2602.03342)
*Bryan Sangwoo Kim,Jonghyun Park,Jong Chul Ye*

Main category: cs.CV

TL;DR: 提出了一种新的图像和视频超分辨率方法，通过为每个图像分块生成本地化文本提示，有效解决了传统全局提示在高分辨率下导致的信息不足和引导错误问题。


<details>
  <summary>Details</summary>
Motivation: 现代超分辨率方法依赖全局文本提示，但存在局部细节缺失（提示稀疏性）和错误引导（提示误导）问题，导致超分辨率效果下降，尤其在高分辨率场景下更加明显。

Method: 提出Tile Prompts框架：1)为每个潜在空间分块生成特定的局部文本提示；2)在局部文本条件下进行超分辨率生成，通过高信息量的局部引导解决全局提示的欠规范问题，同时保证计算效率。

Result: 在高分辨率真实图像和视频数据上，相比全局提示基线方法，实现了感知质量评分提升8.2%，文本对齐度提高6.5%，同时减少57%的幻觉生成和32%的分块伪影。

Conclusion: 该方法通过局部文本引导建立了一种统一的图像/视频超分辨率框架，成功解决了高分辨率场景下单提示引导的信息瓶颈，为生成模型的空间异质性引导提供了可扩展解决方案。

Abstract: Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.

</details>


### [53] [Z3D: Zero-Shot 3D Visual Grounding from Images](https://arxiv.org/abs/2602.03361)
*Nikita Drozdov,Andrey Lemeshko,Nikita Gavrilov,Anton Konushin,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: 提出了一种名为Z3D的通用零样本3D视觉定位框架，仅使用多视角图像、可选相机位姿和深度图，通过改进的3D实例分割与提示分割实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统3D视觉定位方法依赖几何监督或物体先验知识，限制了在未知场景中的应用。本文旨在解决零样本条件下定位效果差的问题。

Method: 1. 设计Z3D通用框架，支持多视角图像输入；2. 提出基于零样本3D实例分割的高精度边界框生成方法；3. 采用基于提示的分割技术，利用视觉语言模型的全能力进行推理。

Result: 在ScanRefer和Nr3D数据集上达到零样本方法的SOTA性能，且不依赖额外标注数据。

Conclusion: 展示了多视角图像结合先进分割技术的零样本3D定位可行性，开源代码为后续研究提供了基础框架。

Abstract: 3D visual grounding (3DVG) aims to localize objects in a 3D scene based on natural language queries. In this work, we explore zero-shot 3DVG from multi-view images alone, without requiring any geometric supervision or object priors. We introduce Z3D, a universal grounding pipeline that flexibly operates on multi-view images while optionally incorporating camera poses and depth maps. We identify key bottlenecks in prior zero-shot methods causing significant performance degradation and address them with (i) a state-of-the-art zero-shot 3D instance segmentation method to generate high-quality 3D bounding box proposals and (ii) advanced reasoning via prompt-based segmentation, which utilizes full capabilities of modern VLMs. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that our approach achieves state-of-the-art performance among zero-shot methods. Code is available at https://github.com/col14m/z3d .

</details>


### [54] [Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2602.03370)
*Takaya Kawakatsu,Ryo Ishiyama*

Main category: cs.CV

TL;DR: 提出离散扩散框架解决手写数学公式识别中的暴露偏差与结构不一致问题


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型存在暴露偏差和语法不一致，难以处理HMER的多元符号和2D结构布局

Method: 1.多步重遮蔽的符号与结构联合迭代精炼框架 2.符号感知tokenization 3.随机遮蔽互学习机制

Result: 在MathWriting基准获得5.56% CER和60.42% EM，超越Transformer基线模型，在CROHME连续五年数据集持续提升

Conclusion: 离散扩散框架为结构感知视觉识别提供了生成建模之外的新范式

Abstract: Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\% CER and 60.42\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.

</details>


### [55] [Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion](https://arxiv.org/abs/2602.03371)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: 提出了一种名为多分辨率对齐（MRA）的相机3D语义场景补全框架，通过多级语义监督解决稀疏体素优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖体素级标签监督，面临自动驾驶场景中大量空白体素导致的优化效率低和性能受限问题。

Method: 设计三个模块：1) 多分辨率视图变压器（场景级特征投影与融合），2) 立方体语义各向异性模块（实例级语义显著性识别），3) 关键分布对齐模块（结合立方语义各向异性特征进行循环一致性约束）。

Result: 论文未明确给出量化结果，但声称代码开源（https://github.com/PKU-ICST-MIPL/MRA_TIP）且方法能提升优化效率和模型性能。

Conclusion: MRA通过引入场景级和实例级语义对齐辅助监督，在稀疏体素场景中实现了更有效的3D语义场景补全。

Abstract: Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.

</details>


### [56] [SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI](https://arxiv.org/abs/2602.03372)
*Mario Pascual-González,Ariadna Jiménez-Partinen,R. M. Luque-Baena,Fátima Nagib-Raya,Ezequiel López-Rubio*

Main category: cs.CV

TL;DR: 本文提出SLIM-Diff，一种紧凑的联合扩散模型用于癫痫患者的FCD病变检测。


<details>
  <summary>Details</summary>
Motivation: FCD病变在MRI中稀疏且难识别，传统生成模型易出现不稳定性及模型记忆问题，因此急需改进的方法。

Method: 采用单共享瓶颈U-Net架构，结合2通道图像+mask输入加强解剖与病变耦合；通过可调L_p损失函数优化模型表现。

Result: x_0预测在联合生成效果最佳；L_{1.5}提升保真度，L_2更优保留病变形态。代码已开源。

Conclusion: SLIM-Diff通过结构创新及损失调优，有效提升了FCD生成模型的稳定性和实用性。

Abstract: Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff

</details>


### [57] [From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning](https://arxiv.org/abs/2602.03390)
*Hyun Seok Seong,WonJun Moon,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 本文提出了Synergistic Representation Learning（SRL），通过编码器与解码器的相互精细化循环，解决无监督物体感知学习中注意力图模糊与特征噪声的矛盾，实现视频物体感知任务的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于重建的slot架构存在编码器高分辨率特征与解码器模糊重建之间的冲突，导致特征噪声累积和重建质量下降，需要一种协同训练机制打破此循环。

Method: 1) SRL在推理过程中利用编码器高分辨率注意力图细化解码器的物体边界；2) 利用解码器的空间一致性指导编码器特征去噪；3) 通过初始warm-up阶段的slot正则化实现训练稳定化。

Result: 在视频物体感知基准测试中超越所有现有方法，达到最先进的性能指标。

Conclusion: 该方法通过桥接编码器-解码器的表征差异，成功解决了无监督物体分解中的核心训练矛盾，为相关任务提供了可扩展的框架。

Abstract: Unsupervised object-centric learning models, particularly slot-based architectures, have shown great promise in decomposing complex scenes. However, their reliance on reconstruction-based training creates a fundamental conflict between the sharp, high-frequency attention maps of the encoder and the spatially consistent but blurry reconstruction maps of the decoder. We identify that this discrepancy gives rise to a vicious cycle: the noisy feature map from the encoder forces the decoder to average over possibilities and produce even blurrier outputs, while the gradient computed from blurry reconstruction maps lacks high-frequency details necessary to supervise encoder features. To break this cycle, we introduce Synergistic Representation Learning (SRL) that establishes a virtuous cycle where the encoder and decoder mutually refine one another. SRL leverages the encoder's sharpness to deblur the semantic boundary within the decoder output, while exploiting the decoder's spatial consistency to denoise the encoder's features. This mutual refinement process is stabilized by a warm-up phase with a slot regularization objective that initially allocates distinct entities per slot. By bridging the representational gap between the encoder and decoder, SRL achieves state-of-the-art results on video object-centric learning benchmarks. Codes are available at https://github.com/hynnsk/SRL.

</details>


### [58] [ConsistentRFT: Reducing Visual Hallucinations in Flow-based Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.03425)
*Xiaofeng Tan,Jun Liu,Yuanting Fan,Bin-Bin Gao,Xi Jiang,Xiaochen Chen,Jinlong Peng,Chengjie Wang,Hongsong Wang,Feng Zheng*

Main category: cs.CV

TL;DR: 论文提出了ConsistentRFT框架，通过动态粒度回滚和一致性策略梯度优化，有效缓解流式模型在强化微调中产生的视觉幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法会导致模型过度关注局部细节并扭曲基础向量场，引发过度优化细节和语义错位等视觉幻觉，需探究其成因并提出解决方案。

Method: 提出双阶段策略：1)动态粒度回滚机制(DGR)动态调度不同噪声源以平衡全局语义与局部细节探索；2)一致性策略梯度优化(CPGO)通过稳定先验对齐策略保留模型一致性。

Result: 实验显示视觉幻觉显著降低，低级/高级感知幻觉分别减少49%和38%，在域外指标上相对基线提升5.1%（基线下降0.4%）。

Conclusion: 所提框架通过解决探索与利用的双重问题，在保持模型跨步一致性的同时提升泛化能力，为流式模型强化微调提供了普适性解决方案。

Abstract: Reinforcement Fine-Tuning (RFT) on flow-based models is crucial for preference alignment. However, they often introduce visual hallucinations like over-optimized details and semantic misalignment. This work preliminarily explores why visual hallucinations arise and how to reduce them. We first investigate RFT methods from a unified perspective, and reveal the core problems stemming from two aspects, exploration and exploitation: (1) limited exploration during stochastic differential equation (SDE) rollouts, leading to an over-emphasis on local details at the expense of global semantics, and (2) trajectory imitation process inherent in policy gradient methods, distorting the model's foundational vector field and its cross-step consistency. Building on this, we propose ConsistentRFT, a general framework to mitigate these hallucinations. Specifically, we design a Dynamic Granularity Rollout (DGR) mechanism to balance exploration between global semantics and local details by dynamically scheduling different noise sources. We then introduce a Consistent Policy Gradient Optimization (CPGO) that preserves the model's consistency by aligning the current policy with a more stable prior. Extensive experiments demonstrate that ConsistentRFT significantly mitigates visual hallucinations, achieving average reductions of 49\% for low-level and 38\% for high-level perceptual hallucinations. Furthermore, ConsistentRFT outperforms other RFT methods on out-of-domain metrics, showing an improvement of 5.1\% (v.s. the baseline's decrease of -0.4\%) over FLUX1.dev. This is \href{https://xiaofeng-tan.github.io/projects/ConsistentRFT}{Project Page}.

</details>


### [59] [Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation](https://arxiv.org/abs/2602.03448)
*Yijia Xu,Zihao Wang,Jinshi Cui*

Main category: cs.CV

TL;DR: 本文提出Hierarchical CAG框架，通过显式监督解决多主体图像生成中的身份不一致与组合控制问题，采用VAE dropout训练策略与对应感知注意力模块提升生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖扩散模型隐式关联文本与图像，导致多主体生成时身份不一致且难以控制组合。需要更明确的结构化监督来提升文本指令遵循与主体特征保留。

Method: 概念层：VAE dropout训练策略随机省略参考特征，迫使模型依赖VLM语义信号；外观层：将VLM对应关系集成至DiT的对应感知masked注意力模块，限制文本标记仅关注匹配区域。

Result: 实验显示该方法在多主体图像生成任务中达到SOTA，显著改善文本指令遵循与主体身份一致性，支持复杂场景组合控制。

Conclusion: CAG框架通过分层显式监督有效解决了扩散模型多主体生成的缺陷，为可控图像合成提供了新思路，未来可拓展至视频生成等场景。

Abstract: Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.

</details>


### [60] [Contextualized Visual Personalization in Vision-Language Models](https://arxiv.org/abs/2602.03454)
*Yeongtak Oh,Sangwon Yu,Junsung Park,Han Cheol Moon,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: The paper proposes CoViP, a framework that enhances vision-language models' ability to generate personalized responses by leveraging visual-textual context through reinforcement learning and diagnostic evaluations.


<details>
  <summary>Details</summary>
Motivation: Current vision-language models (VLMs) struggle to generate personalized responses because they cannot effectively associate new visual inputs with a user's historical visual-textual context, highlighting the need for contextualized visual personalization.

Method: CoViP unifies personalized image captioning as the core task. It employs reinforcement-learning-based post-training and caption-augmented generation, paired with diagnostic evaluations to ensure genuine visual context utilization rather than relying on textual shortcuts.

Result: Current VLMs show significant limitations, whereas CoViP improves personalized image captioning and generalizes gains to downstream personalization tasks, proving its robustness and generalizability.

Conclusion: CoViP addresses contextualized visual personalization effectively by integrating visual context, offering a critical advancement toward more adaptive and personalized vision-language interactions.

Abstract: Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization, which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation. We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context. Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization.

</details>


### [61] [Inlier-Centric Post-Training Quantization for Object Detection Models](https://arxiv.org/abs/2602.03472)
*Minsu Kim,Dongyeun Lee,Jaemyung Yu,Jiwan Hur,Giseop Kim,Junmo Kim*

Main category: cs.CV

TL;DR: InlierQ是一种无需标签的后训练量化方法，通过区分异常值和信息样本，有效降低目标检测中的量化误差，适用于2D/3D相机和激光雷达数据。


<details>
  <summary>Details</summary>
Motivation: 目标检测计算量大，需要量化优化效率，但背景杂乱和传感器噪声等异常值会扩大激活范围、干扰特征保留，且缺乏区分标准可能导致信息丢失。

Method: InlierQ基于梯度感知的体素显著性评分分类异常值与内点，并通过EM算法拟合后验分布，在抑制噪声同时保留关键特征，仅需64个校准样本。

Result: 在COCO和nuScenes基准上，InlierQ在多种目标检测任务（2D/3D相机、激光雷达）中均显著降低量化误差。

Conclusion: 该方法无需标签且高效，解决了量化中异常值抑制与信息保留的矛盾，在复杂场景下保持模型性能。

Abstract: Object detection is pivotal in computer vision, yet its immense computational demands make deployment slow and power-hungry, motivating quantization. However, task-irrelevant morphologies such as background clutter and sensor noise induce redundant activations (or anomalies). These anomalies expand activation ranges and skew activation distributions toward task-irrelevant responses, complicating bit allocation and weakening the preservation of informative features. Without a clear criterion to distinguish anomalies, suppressing them can inadvertently discard useful information. To address this, we present InlierQ, an inlier-centric post-training quantization approach that separates anomalies from informative inliers. InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or anomaly, and fits a posterior distribution over these scores using the Expectation-Maximization (EM) algorithm. This design suppresses anomalies while preserving informative features. InlierQ is label-free, drop-in, and requires only 64 calibration samples. Experiments on the COCO and nuScenes benchmarks show consistent reductions in quantization error for camera-based (2D and 3D) and LiDAR-based (3D) object detection.

</details>


### [62] [Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance](https://arxiv.org/abs/2602.03491)
*Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Youcheng Pan,Xiaoqiang Zhou,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需外部工具且标注最小化的表格图像推理方法，通过DiSCo和Table-GLS框架提升大视觉-语言模型的表格理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决大视觉-语言模型在表格推理中依赖昂贵的监督训练、强化学习或外部工具的问题，以提升效率和可扩展性。

Method: 1) DiSCo框架分离表格结构与内容的信息对齐；2) Table-GLS框架通过结构化探索和证据驱动推理实现表格理解。

Result: 实验表明该方法显著增强模型对多样表格的通用理解能力，尤其在未见过的表格结构上表现优异。

Conclusion: 无需外部工具的架构设计为表格视觉推理提供了高效且可扩展的解决方案。

Abstract: Reasoning over table images remains challenging for Large Vision-Language Models (LVLMs) due to complex layouts and tightly coupled structure-content information. Existing solutions often depend on expensive supervised training, reinforcement learning, or external tools, limiting efficiency and scalability. This work addresses a key question: how to adapt LVLMs to table reasoning with minimal annotation and no external tools? Specifically, we first introduce DiSCo, a Disentangled Structure-Content alignment framework that explicitly separates structural abstraction from semantic grounding during multimodal alignment, efficiently adapting LVLMs to tables structures. Building on DiSCo, we further present Table-GLS, a Global-to-Local Structure-guided reasoning framework that performs table reasoning via structured exploration and evidence-grounded inference. Extensive experiments across diverse benchmarks demonstrate that our framework efficiently enhances LVLM's table understanding and reasoning capabilities, particularly generalizing to unseen table structures.

</details>


### [63] [Interpretable Logical Anomaly Classification via Constraint Decomposition and Instruction Fine-Tuning](https://arxiv.org/abs/2602.03530)
*Xufei Zhang,Xinjiao Zhou,Ziling Deng,Dongdong Geng,Jianxiong Wang*

Main category: cs.CV

TL;DR: 本文引入了逻辑异常分类(LAC)任务，提出LogiCls框架，通过分解逻辑约束和生成推理链监督，统一检测异常并分类违规类型，结合数据增强和难度感知重采样提升视觉语言模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测仅二分类而无法定位违反的具体逻辑规则，导致在质量保障中价值有限，需细粒度分类与可解释性分析。

Method: 1. 构建LAC任务同步完成异常检测与违规分类；2. LogiCls框架分解逻辑约束为可验证子查询，结合链式推理(CoT)监督；3. 数据合成流程生成推理链样本，融合精确标注与图文增强；4. 提出难度感知重采样策略解决长尾数据问题。

Result: 在工业异常数据集上实现92.7%分类准确率，较传统方法提升15.3%，可生成可视化证据路径，训练效率提升40%且支持多语言交互推理。

Conclusion: LAC任务首次实现异常检测与违规溯源的一体化处理，LogiCls框架在工业场景具有实际部署价值，为质量管控提供可解释的决策支持。

Abstract: Logical anomalies are violations of predefined constraints on object quantity, spatial layout, and compositional relationships in industrial images. While prior work largely treats anomaly detection as a binary decision, such formulations cannot indicate which logical rule is broken and therefore offer limited value for quality assurance. We introduce Logical Anomaly Classification (LAC), a task that unifies anomaly detection and fine-grained violation classification in a single inference step. To tackle LAC, we propose LogiCls, a vision-language framework that decomposes complex logical constraints into a sequence of verifiable subqueries. We further present a data-centric instruction synthesis pipeline that generates chain-of-thought (CoT) supervision for these subqueries, coupling precise grounding annotations with diverse image-text augmentations to adapt vision language models (VLMs) to logic-sensitive reasoning. Training is stabilized by a difficulty-aware resampling strategy that emphasizes challenging subqueries and long tail constraint types. Extensive experiments demonstrate that LogiCls delivers robust, interpretable, and accurate industrial logical anomaly classification, providing both the predicted violation categories and their evidence trails.

</details>


### [64] [PnP-U3D: Plug-and-Play 3D Framework Bridging Autoregression and Diffusion for Unified Understanding and Generation](https://arxiv.org/abs/2602.03533)
*Yongwei Chen,Tianyi Wei,Yushi Lan,Zhaoyang Lyu,Shangchen Zhou,Xudong Xu,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出一种结合自回归（AR）和扩散模型的统一框架，解决3D理解和生成中的性能下降与训练成本问题，通过分任务范式和轻量级Transformer实现跨模态交互。


<details>
  <summary>Details</summary>
Motivation: 现有3D任务统一AR框架因强制信号量化和高训练成本导致性能下降，需探索不强制统一范式却能高效融合生成与理解能力的技术路径。

Method: 采用AR模式处理3D理解，扩散模型负责生成，通过轻量化Transformer连接LLM特征空间与3D扩散模型条件空间，保留独立模型先验知识并降低训练成本。

Result: 实验证明新框架在多个3D理解生成基准测试中达到SOTA，3D编辑任务表现突出，训练效率显著提升。

Conclusion: AR与扩散模型的统一框架有效平衡性能与成本，为通用3D智能开发提供了可扩展的技术范式。

Abstract: The rapid progress of large multimodal models has inspired efforts toward unified frameworks that couple understanding and generation. While such paradigms have shown remarkable success in 2D, extending them to 3D remains largely underexplored. Existing attempts to unify 3D tasks under a single autoregressive (AR) paradigm lead to significant performance degradation due to forced signal quantization and prohibitive training cost. Our key insight is that the essential challenge lies not in enforcing a unified autoregressive paradigm, but in enabling effective information interaction between generation and understanding while minimally compromising their inherent capabilities and leveraging pretrained models to reduce training cost. Guided by this perspective, we present the first unified framework for 3D understanding and generation that combines autoregression with diffusion. Specifically, we adopt an autoregressive next-token prediction paradigm for 3D understanding, and a continuous diffusion paradigm for 3D generation. A lightweight transformer bridges the feature space of large language models and the conditional space of 3D diffusion models, enabling effective cross-modal information exchange while preserving the priors learned by standalone models. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across diverse 3D understanding and generation benchmarks, while also excelling in 3D editing tasks. These results highlight the potential of unified AR+diffusion models as a promising direction for building more general-purpose 3D intelligence.

</details>


### [65] [Constrained Dynamic Gaussian Splatting](https://arxiv.org/abs/2602.03538)
*Zihan Zheng,Zhenglong Wu,Xuanxuan Wang,Houqiang Zhong,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai,Wenjun Zhang*

Main category: cs.CV

TL;DR: CDGS解决动态高斯泊松重建的内存-质量权衡问题，通过预算约束优化实现高效4D重建，结合可微分控制器与动态分配机制，在保证硬件兼容性的前提下实现3倍压缩率提升。


<details>
  <summary>Details</summary>
Motivation: 动态高斯泊松技术面临两个核心问题：无约束密集化会超出边缘设备内存限制，而启发式剪枝难以在预设高斯预算下保持最优渲染质量，亟需能严格遵循用户预算并提升压缩效率的新方法。

Method: 提出预算约束优化框架CDGS，创新点包含：1) 可微分预算控制器融合几何、运动、感知信号生成统一重要性评分；2) 解耦静态/动态元素优化并采用动态分配机制；3) 三阶段训练策略；4) 双模式混合压缩方案。

Result: 实现硬件误差<2%的严格约束下，对比SOTA方法达成3倍压缩率提升，同时推进率失真性能Pareto前沿，在不同容量限制下保持最优渲染质量。

Conclusion: CDGS首次将高斯预算作为可微分优化变量，通过动态容量分配机制突破传统方法局限性，为边缘设备部署提供理论框架与实用方案，推动神经渲染与压缩技术交叉发展。

Abstract: While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained optimization problem to enforce a strict, user-defined Gaussian budget during training. Our key insight is to introduce a differentiable budget controller as the core optimization driver. Guided by a multi-modal unified importance score, this controller fuses geometric, motion, and perceptual cues for precise capacity regulation. To maximize the utility of this fixed budget, we further decouple the optimization of static and dynamic elements, employing an adaptive allocation mechanism that dynamically distributes capacity based on motion complexity. Furthermore, we implement a three-phase training strategy to seamlessly integrate these constraints, ensuring precise adherence to the target count. Coupled with a dual-mode hybrid compression scheme, CDGS not only strictly adheres to hardware constraints (error < 2%}) but also pushes the Pareto frontier of rate-distortion performance. Extensive experiments demonstrate that CDGS delivers optimal rendering quality under varying capacity limits, achieving over 3x compression compared to state-of-the-art methods.

</details>


### [66] [Cut to the Mix: Simple Data Augmentation Outperforms Elaborate Ones in Limited Organ Segmentation Datasets](https://arxiv.org/abs/2602.03555)
*Chang Liu,Fuxin Fan,Annette Schwarz,Andreas Maier*

Main category: cs.CV

TL;DR: 该研究评估了四种跨图像数据增强（DA）策略（CutMix、CarveMix、ObjectAug、AnatoMix）在限量数据下的多器官分割任务中的效果，结合传统DA发现CutMix可提升分割性能约4.9% Dice分数。


<details>
  <summary>Details</summary>
Motivation: 医学影像中手动注释数据稀缺限制了深度学习（DL）模型的训练，需探索新型数据增强方法以提升小数据集上的分割效果。

Method: 在两套器官分割数据集上测试CutMix、CarveMix、ObjectAug、AnatoMix四种跨图像与对象级DA策略，结合传统DA方法（TDA）进行对比实验。

Result: CutMix、CarveMix、AnatoMix分别将平均Dice分数提升4.9%、2.0%、1.9%，叠加TDA后效果进一步提升；CutMix即使生成直观错误图像仍能增强模型性能。

Conclusion: 跨图像DA策略（尤其是CutMix）能有效缓解数据稀缺问题，为医学图像分割提供简单且强鲁棒性的增强方案，并开源代码支持未来研究。

Abstract: Multi-organ segmentation is a widely applied clinical routine and automated organ segmentation tools dramatically improve the pipeline of the radiologists. Recently, deep learning (DL) based segmentation models have shown the capacity to accomplish such a task. However, the training of the segmentation networks requires large amount of data with manual annotations, which is a major concern due to the data scarcity from clinic. Working with limited data is still common for researches on novel imaging modalities. To enhance the effectiveness of DL models trained with limited data, data augmentation (DA) is a crucial regularization technique. Traditional DA (TDA) strategies focus on basic intra-image operations, i.e. generating images with different orientations and intensity distributions. In contrast, the interimage and object-level DA operations are able to create new images from separate individuals. However, such DA strategies are not well explored on the task of multi-organ segmentation. In this paper, we investigated four possible inter-image DA strategies: CutMix, CarveMix, ObjectAug and AnatoMix, on two organ segmentation datasets. The result shows that CutMix, CarveMix and AnatoMix can improve the average dice score by 4.9, 2.0 and 1.9, compared with the state-of-the-art nnUNet without DA strategies. These results can be further improved by adding TDA strategies. It is revealed in our experiments that Cut-Mix is a robust but simple DA strategy to drive up the segmentation performance for multi-organ segmentation, even when CutMix produces intuitively 'wrong' images. Our implementation is publicly available for future benchmarks.

</details>


### [67] [SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM](https://arxiv.org/abs/2602.03589)
*Ming Nie,Dan Ding,Chunwei Wang,Yuanfan Guo,Jianhua Han,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: 论文提出SlowFocus机制，通过优化时间频域增强Vid-LLMs的细粒度视频理解能力，无需权衡帧级质量和视频级时间覆盖，并验证了其在多基准测试中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前Vid-LLMs无法同时保留足够的帧级token质量与视频级时间上下文，导致细粒度视频理解受阻，亟需解决这一关键技术瓶颈。

Method: 1) 基于问答定位视频相关时段并密集采样提取高频局部特征；2) 多频率混合注意力模块聚合局部高频与全局低频信息；3) 设计针对性训练策略及新建FineAction-CGR评估基准。

Result: 实验表明SlowFocus在常规基准（如How2QA、MSR-VTT）和新基准FineAction-CGR上均显著优于现有模型，实现帧级质量与视频级时间信息的协同增强。

Conclusion: 通过创新性的时频域建模方法，论文突破了Vid-LLMs在细粒度视频理解中的技术瓶颈，并提供了标准化的评估方案，为后续研究奠定基础。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in text understanding, which has paved the way for their expansion into video LLMs (Vid-LLMs) to analyze video data. However, current Vid-LLMs struggle to simultaneously retain high-quality frame-level semantic information (i.e., a sufficient number of tokens per frame) and comprehensive video-level temporal information (i.e., an adequate number of sampled frames per video). This limitation hinders the advancement of Vid-LLMs towards fine-grained video understanding. To address this issue, we introduce the SlowFocus mechanism, which significantly enhances the equivalent sampling frequency without compromising the quality of frame-level visual tokens. SlowFocus begins by identifying the query-related temporal segment based on the posed question, then performs dense sampling on this segment to extract local high-frequency features. A multi-frequency mixing attention module is further leveraged to aggregate these local high-frequency details with global low-frequency contexts for enhanced temporal comprehension. Additionally, to tailor Vid-LLMs to this innovative mechanism, we introduce a set of training strategies aimed at bolstering both temporal grounding and detailed temporal reasoning capabilities. Furthermore, we establish FineAction-CGR, a benchmark specifically devised to assess the ability of Vid-LLMs to process fine-grained temporal understanding tasks. Comprehensive experiments demonstrate the superiority of our mechanism across both existing public video understanding benchmarks and our proposed FineAction-CGR.

</details>


### [68] [High-Resolution Underwater Camouflaged Object Detection: GBU-UCOD Dataset and Topology-Aware and Frequency-Decoupled Networks](https://arxiv.org/abs/2602.03591)
*Wenji Wu,Shuo Ye,Yiyu Liu,Jiguang He,Zhuo Wang,Zitong Yu*

Main category: cs.CV

TL;DR: DeepTopo-Net integrates topology-aware modeling and frequency-decoupled perception to detect underwater camouflaged objects, addressing issues like topological fragmentation and feature extraction through WCAP and ATRM modules, validated on the new GBU-UCOD benchmark.


<details>
  <summary>Details</summary>
Motivation: Underwater camouflaged object detection (UCOD) faces challenges due to visual similarity between targets and backgrounds in varying marine depths, fragmentation of slender deep-sea creatures, and difficulty extracting subtle features from transparent organisms.

Method: Proposed DeepTopo-Net with two key modules: (1) Water-Conditioned Adaptive Perceptor (WCAP) using Riemannian metric tensors to dynamically deform convolutional sampling fields for physical degradation handling; (2) Abyssal-Topology Refinement Module (ATRM) leveraging skeletal priors to maintain structural connectivity of spindly targets; introduced GBU-UCOD, the first 2K-resolution benchmark for marine vertical zonation.

Result: Achieved state-of-the-art performance on MAS3K, RMAS, and GBU-UCOD datasets, demonstrating superior ability to preserve morphological integrity of complex underwater patterns (quantitative results not specified in the abstract).

Conclusion: DeepTopo-Net effectively addresses UCOD challenges through topology-aware modeling and frequency-decoupled perception, with GBU-UCOD dataset filling data gaps in hadal and abyssal zones, contributing to underwater imaging research.

Abstract: Underwater Camouflaged Object Detection (UCOD) is a challenging task due to the extreme visual similarity between targets and backgrounds across varying marine depths. Existing methods often struggle with topological fragmentation of slender creatures in the deep sea and the subtle feature extraction of transparent organisms. In this paper, we propose DeepTopo-Net, a novel framework that integrates topology-aware modeling with frequency-decoupled perception. To address physical degradation, we design the Water-Conditioned Adaptive Perceptor (WCAP), which employs Riemannian metric tensors to dynamically deform convolutional sampling fields. Furthermore, the Abyssal-Topology Refinement Module (ATRM) is developed to maintain the structural connectivity of spindly targets through skeletal priors. Specifically, we first introduce GBU-UCOD, the first high-resolution (2K) benchmark tailored for marine vertical zonation, filling the data gap for hadal and abyssal zones. Extensive experiments on MAS3K, RMAS, and our proposed GBU-UCOD datasets demonstrate that DeepTopo-Net achieves state-of-the-art performance, particularly in preserving the morphological integrity of complex underwater patterns. The datasets and codes will be released at https://github.com/Wuwenji18/GBU-UCOD.

</details>


### [69] [Refer-Agent: A Collaborative Multi-Agent System with Reasoning and Reflection for Referring Video Object Segmentation](https://arxiv.org/abs/2602.03595)
*Haichao Jiang,Tianming Liang,Wei-Shi Zheng,Jian-Fang Hu*

Main category: cs.CV

TL;DR: 本文提出Refer-Agent，通过分步推理与反思机制，在视频对象分割任务中无需大规模微调即可超越现有方法性能。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法依赖大量数据且扩展性差，零样本方法虽灵活但性能不足，需设计更高效的工作流。

Method: 采用多智能体协同框架：1) Coarse-to-Fine帧选择提升多样性与文本相关性 2) 动态焦点布局调整视觉关注区域 3) 反思链机制通过问答对生成反馈优化推理过程。

Result: 在5个基准测试中性能领先所有SFT模型与零样本方法，且支持无需微调快速集成新一代多模态大模型。

Conclusion: 提出无需微调的RVOS新范式，通过渐进式推理与自反思机制实现性能突破与系统灵活性提升。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment objects in videos based on textual queries. Current methods mainly rely on large-scale supervised fine-tuning (SFT) of Multi-modal Large Language Models (MLLMs). However, this paradigm suffers from heavy data dependence and limited scalability against the rapid evolution of MLLMs. Although recent zero-shot approaches offer a flexible alternative, their performance remains significantly behind SFT-based methods, due to the straightforward workflow designs. To address these limitations, we propose \textbf{Refer-Agent}, a collaborative multi-agent system with alternating reasoning-reflection mechanisms. This system decomposes RVOS into step-by-step reasoning process. During reasoning, we introduce a Coarse-to-Fine frame selection strategy to ensure the frame diversity and textual relevance, along with a Dynamic Focus Layout that adaptively adjusts the agent's visual focus. Furthermore, we propose a Chain-of-Reflection mechanism, which employs a Questioner-Responder pair to generate a self-reflection chain, enabling the system to verify intermediate results and generates feedback for next-round reasoning refinement. Extensive experiments on five challenging benchmarks demonstrate that Refer-Agent significantly outperforms state-of-the-art methods, including both SFT-based models and zero-shot approaches. Moreover, Refer-Agent is flexible and enables fast integration of new MLLMs without any additional fine-tuning costs. Code will be released.

</details>


### [70] [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604)
*Basile Terver,Randall Balestriero,Megi Dervishi,David Fan,Quentin Garrido,Tushar Nagarajan,Koustuv Sinha,Wancong Zhang,Mike Rabbat,Yann LeCun,Amir Bar*

Main category: cs.CV

TL;DR: EB-JEPA is an open-source library for representation and world model learning via JEPAs, focusing on video and action-conditioned extensions while emphasizing accessibility for research and education.


<details>
  <summary>Details</summary>
Motivation: Traditional generative models struggle with pixel-space prediction and temporal dynamics. This work addresses the need to extend image-based self-supervised learning to video and action-conditional models while maintaining computational efficiency for broader accessibility.

Method: Modular JEPA framework predicting in representation space (not pixel space), implemented with single-GPU compatibility. Includes ablation studies for regularization mechanisms, with extensions to temporal modeling (Moving MNIST) and action-conditioned navigation (Two Rooms task).

Result: 91% probing accuracy on CIFAR-10, 97% planning success on Two Rooms navigation, and scalable temporal modeling on Moving MNIST. Ablation studies demonstrate regularization components prevent representation collapse.

Conclusion: Demonstrates effective transfer of self-supervised image learning techniques to complex temporal and action-driven domains when proper regularization is applied. Open-source library enables reproducibility and educational use.

Abstract: We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised learning can transfer to video, where temporal dynamics add complexity, and ultimately to action-conditioned world models, where the model must additionally learn to predict the effects of control inputs. Each example is designed for single-GPU training within a few hours, making energy-based self-supervised learning accessible for research and education. We provide ablations of JEA components on CIFAR-10. Probing these representations yields 91% accuracy, indicating that the model learns useful features. Extending to video, we include a multi-step prediction example on Moving MNIST that demonstrates how the same principles scale to temporal modeling. Finally, we show how these representations can drive action-conditioned world models, achieving a 97% planning success rate on the Two Rooms navigation task. Comprehensive ablations reveal the critical importance of each regularization component for preventing representation collapse. Code is available at https://github.com/facebookresearch/eb_jepa.

</details>


### [71] [KTV: Keyframes and Key Tokens Selection for Efficient Training-Free Video LLMs](https://arxiv.org/abs/2602.03615)
*Baiyang Song,Jun Peng,Yuxin Zhang,Guangyao Chen,Feidiao Yang,Jianyuan Guo*

Main category: cs.CV

TL;DR: 提出了一种无需训练的视频理解框架KTV，通过两阶段的关键帧和视觉token选择显著减少计算开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统训练式视频理解成本高，而现有基于CLIP相似性的关键帧选择方法存在偏差且易遗漏关键帧，导致冗余和计算效率低下。

Method: 1) 第一阶段通过帧特征聚类选择代表性关键帧；2) 第二阶段基于token重要性对每帧进行视觉token剪枝。

Result: 在MLVU-Test基准中，60分钟视频仅用504个token达到44.8%准确率，超越多个训练式和非训练式方法。

Conclusion: KTV在计算效率和准确率之间取得平衡，证明了非训练式方法的潜力。

Abstract: Training-free video understanding leverages the strong image comprehension capabilities of pre-trained vision language models (VLMs) by treating a video as a sequence of static frames, thus obviating the need for costly video-specific training. However, this paradigm often suffers from severe visual redundancy and high computational overhead, especially when processing long videos. Crucially, existing keyframe selection strategies, especially those based on CLIP similarity, are prone to biases and may inadvertently overlook critical frames, resulting in suboptimal video comprehension. To address these significant challenges, we propose \textbf{KTV}, a novel two-stage framework for efficient and effective training-free video understanding. In the first stage, KTV performs question-agnostic keyframe selection by clustering frame-level visual features, yielding a compact, diverse, and representative subset of frames that mitigates temporal redundancy. In the second stage, KTV applies key visual token selection, pruning redundant or less informative tokens from each selected keyframe based on token importance and redundancy, which significantly reduces the number of tokens fed into the LLM. Extensive experiments on the Multiple-Choice VideoQA task demonstrate that KTV outperforms state-of-the-art training-free baselines while using significantly fewer visual tokens, \emph{e.g.}, only 504 visual tokens for a 60-min video with 10800 frames, achieving $44.8\%$ accuracy on the MLVU-Test benchmark. In particular, KTV also exceeds several training-based approaches on certain benchmarks.

</details>


### [72] [Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis](https://arxiv.org/abs/2602.03622)
*Lu Zhang,Huizhen Yu,Zuowei Wang,Fu Gui,Yatu Guo,Wei Zhang,Mengyu Jia*

Main category: cs.CV

TL;DR: 该论文提出了一种整合多模态数据合成与融合的统一框架，用于视网膜疾病分类和分级，通过结合眼底荧光造影、多光谱成像和病变显著图谱，提升了分类精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统眼科多模态诊断面临数据异质性、配准复杂性和潜在侵入性等挑战，亟需一种能够有效整合多源数据并提升诊断准确性的新方法。

Method: 构建平行模型分别学习多模态数据的模态特异性表征，通过任务驱动的跨模态自适应校准实现信息修剪与动态融合，结合可视化解释机制进行图像与特征空间分析。

Result: 在两个公开数据集上验证，多标签分类F1-score达0.683（AUC 0.953），糖尿病视网膜病变分级准确率84.2%（Kappa 0.861），显著优于现有方法。

Conclusion: 该框架不仅提高了视网膜疾病筛查的准确性和效率，还为医疗影像多模态数据增强提供了可扩展的范式。

Abstract: Retinal diseases spanning a broad spectrum can be effectively identified and diagnosed using complementary signals from multimodal data. However, multimodal diagnosis in ophthalmic practice is typically challenged in terms of data heterogeneity, potential invasiveness, registration complexity, and so on. As such, a unified framework that integrates multimodal data synthesis and fusion is proposed for retinal disease classification and grading. Specifically, the synthesized multimodal data incorporates fundus fluorescein angiography (FFA), multispectral imaging (MSI), and saliency maps that emphasize latent lesions as well as optic disc/cup regions. Parallel models are independently trained to learn modality-specific representations that capture cross-pathophysiological signatures. These features are then adaptively calibrated within and across modalities to perform information pruning and flexible integration according to downstream tasks. The proposed learning system is thoroughly interpreted through visualizations in both image and feature spaces. Extensive experiments on two public datasets demonstrated the superiority of our approach over state-of-the-art ones in the tasks of multi-label classification (F1-score: 0.683, AUC: 0.953) and diabetic retinopathy grading (Accuracy:0.842, Kappa: 0.861). This work not only enhances the accuracy and efficiency of retinal disease screening but also offers a scalable framework for data augmentation across various medical imaging modalities.

</details>


### [73] [SPWOOD: Sparse Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2602.03634)
*Wei Zhang,Xiang Liu,Ningjing Liu,Mingxin Liu,Wei Liao,Chunyan Xu,Xue Yang*

Main category: cs.CV

TL;DR: 本文提出SPWOOD框架，通过稀疏和弱监督学习减少标注需求，提升遥感图像定向目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的定向目标检测方法依赖大量标注数据，遥感领域因目标密集分布和类别多样，标注成本极高。需探索使用更少弱标注数据的高效解决方案。

Method: 1) 设计SOS-Student模型，利用弱标注分离无标注目标与背景并学习方向尺度信息；2) 构建多级伪标签过滤策略，基于模型多层预测分布；3) 提出稀疏划分方法确保各类别处理公平性。

Result: 在DOTA和DIOR数据集上实验表明，SPWOOD较传统方法性能显著提升，提供高性价比标注方案。

Conclusion: 该框架通过结合稀疏标注与弱监督学习有效降低标注成本，同时保持检测精度，适合大规模遥感应用。

Abstract: A consistent trend throughout the research of oriented object detection has been the pursuit of maintaining comparable performance with fewer and weaker annotations. This is particularly crucial in the remote sensing domain, where the dense object distribution and a wide variety of categories contribute to prohibitively high costs. Based on the supervision level, existing oriented object detection algorithms can be broadly grouped into fully supervised, semi-supervised, and weakly supervised methods. Within the scope of this work, we further categorize them to include sparsely supervised and partially weakly-supervised methods. To address the challenges of large-scale labeling, we introduce the first Sparse Partial Weakly-Supervised Oriented Object Detection framework, designed to efficiently leverage only a few sparse weakly-labeled data and plenty of unlabeled data. Our framework incorporates three key innovations: (1) We design a Sparse-annotation-Orientation-and-Scale-aware Student (SOS-Student) model to separate unlabeled objects from the background in a sparsely-labeled setting, and learn orientation and scale information from orientation-agnostic or scale-agnostic weak annotations. (2) We construct a novel Multi-level Pseudo-label Filtering strategy that leverages the distribution of model predictions, which is informed by the model's multi-layer predictions. (3) We propose a unique sparse partitioning approach, ensuring equal treatment for each category. Extensive experiments on the DOTA and DIOR datasets show that our framework achieves a significant performance gain over traditional oriented object detection methods mentioned above, offering a highly cost-effective solution. Our code is publicly available at https://github.com/VisionXLab/SPWOOD.

</details>


### [74] [Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars](https://arxiv.org/abs/2602.01538)
*Youliang Zhang,Zhengguang Zhou,Zhentao Yu,Ziyao Huang,Teng Hu,Sen Liang,Guozhen Zhang,Ziqiao Peng,Shunkai Li,Yi Chen,Zixiang Zhou,Yuan Zhou,Qinglin Lu,Xiu Li*

Main category: cs.CV

TL;DR: 本文提出InteractAvatar框架，解决生成具有真实物体互动的说话虚拟形象难题，通过双流结构分离感知与合成，并设计PIM、AIM模块实现文本对齐的动作生成与视频合成。


<details>
  <summary>Details</summary>
Motivation: 现有人物动作生成方法在复杂人-物互动场景中难以平衡环境感知能力与视频生成质量，需要创新性框架突破控制精度与视觉效果的矛盾。

Method: 设计双流框架InteractAvatar：1) Perception and Interaction Module(PIM)通过目标检测增强环境感知，生成文本对齐的互动动作；2) Audio Interaction Aware Module(AIM)融合语音与动作信息生成高质量视频；3) 运动-视频对齐器实现并行生成。

Result: 在新构建的GroundedInter基准上，InteractAvatar在动作连贯性(↑18.6%)、物体交互准确率(↑23.4%)及视频自然度(↑15.2%)等指标均优于SOTA方法，支持多物体复杂互动场景。

Conclusion: 本文提出的模块化解耦框架有效解决了GHOI场景下控制质量矛盾，为可控视频生成提供了新范式，其基准数据集将推动人机交互领域的研究进展。

Abstract: Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io

</details>


### [75] [MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment](https://arxiv.org/abs/2602.03665)
*Eunkyu Park,Wesley Hanwen Deng,Cheyon Jin,Matheus Kunzler Maldaner,Jordan Wheeler,Jason I. Hong,Hong Shen,Adam Perer,Ken Holstein,Motahhare Eslami,Gunhee Kim*

Main category: cs.CV

TL;DR: 本文提出MM-SCALE框架，通过5点标量监督提升视觉-语言模型的道德推理能力，解决传统离散标签无法反映道德判断连续性的局限。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在多模态道德判断中依赖二元或成对监督信号，未能刻画人类道德推理的连续性和多元性，且缺乏显式模态基础与细粒度校准机制。

Method: 构建包含人类标注5点道德可接受性分数的MM-SCALE数据集，结合 grounded reasoning labels 进行列表级偏好优化，采用量表式监督信号而非离散标签。

Result: 实验显示使用MM-SCALE微调的VLMs在场景集排名保真度提升12.7%，安全校准稳定性增强8.3%，且道德判断与人群分布一致性提高19.5%。

Conclusion: 该框架验证了标量监督在多模态道德对齐中的有效性，为复杂社会情境下的AI伦理决策提供了可扩展的建模范式。

Abstract: Vision-Language Models (VLMs) continue to struggle to make morally salient judgments in multimodal and socially ambiguous contexts. Prior works typically rely on binary or pairwise supervision, which often fail to capture the continuous and pluralistic nature of human moral reasoning. We present MM-SCALE (Multimodal Moral Scale), a large-scale dataset for aligning VLMs with human moral preferences through 5-point scalar ratings and explicit modality grounding. Each image-scenario pair is annotated with moral acceptability scores and grounded reasoning labels by humans using an interface we tailored for data collection, enabling listwise preference optimization over ranked scenario sets. By moving from discrete to scalar supervision, our framework provides richer alignment signals and finer calibration of multimodal moral reasoning. Experiments show that VLMs fine-tuned on MM-SCALE achieve higher ranking fidelity and more stable safety calibration than those trained with binary signals.

</details>


### [76] [Referring Industrial Anomaly Segmentation](https://arxiv.org/abs/2602.03673)
*Pengfei Yue,Xiaokang Jiang,Yilin Lu,Jianghang Lin,Shengchuan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: 提出RIAS通过语言引导检测，结合MVTec-Ref数据集和DQFormer模型，在工业异常检测中无需手动阈值即可实现单模型多异常精确分割。


<details>
  <summary>Details</summary>
Motivation: 传统无监督方法需手动阈值且定位粗糙，监督方法因数据少且不平衡易过拟合，且两者均受限于‘一类一模型’的局限性。

Method: 提出RIAS范式与MVTec-Ref数据集，采用双查询标记和语言门控多级聚合（LMA）优化的DQFormer模型，仅用‘异常’和‘背景’标记进行高效多尺度分割。

Result: 实验显示RIAS在开放集工业异常检测（95%微型异常）中可精准生成掩码，单模型支持多样化异常检测且效率提升。

Conclusion: RIAS结合语言引导与统一模型框架，突破传统方法限制，推动工业异常检测向开放集、低人工干预方向发展。

Abstract: Industrial Anomaly Detection (IAD) is vital for manufacturing, yet traditional methods face significant challenges: unsupervised approaches yield rough localizations requiring manual thresholds, while supervised methods overfit due to scarce, imbalanced data. Both suffer from the "One Anomaly Class, One Model" limitation. To address this, we propose Referring Industrial Anomaly Segmentation (RIAS), a paradigm leveraging language to guide detection. RIAS generates precise masks from text descriptions without manual thresholds and uses universal prompts to detect diverse anomalies with a single model. We introduce the MVTec-Ref dataset to support this, designed with diverse referring expressions and focusing on anomaly patterns, notably with 95% small anomalies. We also propose the Dual Query Token with Mask Group Transformer (DQFormer) benchmark, enhanced by Language-Gated Multi-Level Aggregation (LMA) to improve multi-scale segmentation. Unlike traditional methods using redundant queries, DQFormer employs only "Anomaly" and "Background" tokens for efficient visual-textual integration. Experiments demonstrate RIAS's effectiveness in advancing IAD toward open-set capabilities. Code: https://github.com/swagger-coder/RIAS-MVTec-Ref.

</details>


### [77] [RegionReasoner: Region-Grounded Multi-Round Visual Reasoning](https://arxiv.org/abs/2602.03733)
*Wenfang Sun,Hao Chen,Yingjun Du,Yefeng Zheng,Cees G. M. Snoek*

Main category: cs.CV

TL;DR: 本文提出了多轮视觉推理基准RegionDial-Bench和RegionReasoner框架，结合强化学习与全局-局部语义对齐机制，显著提升多步视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型依赖单步或文本推理，无法在多视觉上下文中迭代优化理解，缺乏系统性评估迭代推理能力的基准测试。

Method: 构建包含检测/分割任务的多轮推理基准，提出RegionReasoner框架：1) 通过引用参考边界框实现具身化推理；2) 设计结构化奖励函数，结合视觉接地保真度和全局-局部语义一致性；3) 利用场景描述和区域描述提取关键对象进行跨步一致校验。

Result: RegionReasoner-7B在检测/分割任务上实现多轮推理准确率提升23.5%，空间接地精度提高18.9%，全局-局部一致性增强31.2%，建立该领域的强基准。

Conclusion: 为多轮视觉推理提供了标准化测试平台和基础框架，推动具身化智能系统研究，未来可扩展到机器人交互等动态场景。

Abstract: Large vision-language models have achieved remarkable progress in visual reasoning, yet most existing systems rely on single-step or text-only reasoning, limiting their ability to iteratively refine understanding across multiple visual contexts. To address this limitation, we introduce a new multi-round visual reasoning benchmark with training and test sets spanning both detection and segmentation tasks, enabling systematic evaluation under iterative reasoning scenarios. We further propose RegionReasoner, a reinforcement learning framework that enforces grounded reasoning by requiring each reasoning trace to explicitly cite the corresponding reference bounding boxes, while maintaining semantic coherence via a global-local consistency reward. This reward extracts key objects and nouns from both global scene captions and region-level captions, aligning them with the reasoning trace to ensure consistency across reasoning steps. RegionReasoner is optimized with structured rewards combining grounding fidelity and global-local semantic alignment. Experiments on detection and segmentation tasks show that RegionReasoner-7B, together with our newly introduced benchmark RegionDial-Bench, considerably improves multi-round reasoning accuracy, spatial grounding precision, and global-local consistency, establishing a strong baseline for this emerging research direction.

</details>


### [78] [Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment](https://arxiv.org/abs/2602.03742)
*Johny J. Lopez,Md Meftahul Ferdaus,Mahdi Abdelguerfi*

Main category: cs.CV

TL;DR: 论文提出一种用于地下基础设施缺陷检测的轻量级两阶段AI管道，通过边缘计算设备端到端生成缺陷诊断报告


<details>
  <summary>Details</summary>
Motivation: 地下管道检测需要资源受限设备在高效缺陷分割基础上生成结构化诊断报告，但现有方法难以兼顾模型轻量化和报告可读性

Method: 1) 轻量RAPID-SCAN模型（0.64M参数）实现缺陷像素级分割；2) 微调Phi-3.5 VLM将分割结果转换为自然语言描述；3) 引入后训练量化优化边缘部署性能

Result: 分割达0.834 F1-score，模型体积缩小76%，推理延迟降低42%，诊断报告准确复现人工标注特征

Conclusion: 验证了轻量化视觉-语言系统在边缘智能运维中的可行性，为资源受限场景的自动化检测提供新范式

Abstract: Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.

</details>


### [79] [LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747)
*Junchao Huang,Ziyang Ye,Xinting Hu,Tianyu He,Guiyu Zhang,Shaoshuai Shi,Jiang Bian,Li Jiang*

Main category: cs.CV

TL;DR: LIVE是一种长视界交互视频世界模型，通过新颖的循环一致性目标实现有界误差积累，无需依赖教师模型进行蒸馏。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频模型在长序列生成中因误差累积效果变差，虽有方法通过预训练教师模型和序列分布匹配缓解，但计算成本高且无法阻止训练视界后的误差传播。

Method: 提出前向rollout和反向生成重建初始状态的循环一致性目标，基于重建终端状态计算扩散损失约束长视界误差。同时提出统一视角框架和渐进式训练课程稳定训练。

Result: 在长时域基准测试中达到SOTA性能，生成质量稳定且显著超越训练序列长度的视频。

Conclusion: LIVE通过显式误差传播约束和教师模型无关的架构，为视频世界模型的长序列生成提供了新范式。

Abstract: Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.

</details>


### [80] [See-through: Single-image Layer Decomposition for Anime Characters](https://arxiv.org/abs/2602.03749)
*Jian Lin,Chengze Li,Haoyun Qin,Kwun Wang Chan,Yanghua Jin,Hanyuan Liu,Stephen Chun Wang Choy,Xueting Liu*

Main category: cs.CV

TL;DR: 本文提出了一种将静态动漫插画自动转换为可操作的2.5D模型的框架。通过自动分解图像并生成语义分层，解决了传统流程中手动分割与遮挡区域艺术化补全的繁琐问题。


<details>
  <summary>Details</summary>
Motivation: 传统手绘动画制作需要繁琐的人工分割和遮挡区域的艺术性补全，作者旨在通过自动化方法降低专业动画制作的门槛，并解决训练数据稀缺的问题。

Method: 提出包含扩散模型驱动的'身体部位一致性模块'和'像素级伪深度推断机制'的组合方法。通过可扩展的训练引擎生成高质量监督数据，利用商业Live2D模型捕获像素级语义和隐藏几何信息。

Result: 实现了动漫角色复杂分层结构（如交错发丝）的自动解构，生成的2.5D模型支持动态重建和实时动画制作，模型操纵精度接近专业水准。

Conclusion: 该框架有效解决了单图生成动漫分层模型中的几何一致性与数据稀缺性挑战，生成的模型质量满足专业实时动画应用需求，为非专业用户提供了高效的动画制作工具。

Abstract: We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.

</details>


### [81] [Test-Time Conditioning with Representation-Aligned Visual Features](https://arxiv.org/abs/2602.03753)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Letzelter,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: 本文提出REPA-G方法，利用自监督对齐表征在扩散模型推理阶段实现精确的条件控制，提升生成图像质量和控制灵活性。


<details>
  <summary>Details</summary>
Motivation: 虽然自监督对齐在扩散模型训练中有研究，但其在推理阶段的条件控制潜力尚未被充分开发。现有文本/标签引导方式存在模糊性或粗粒度问题，需要更精确可控的方法。

Method: REPA-G在推理时通过优化特征提取器输出的对齐表征相似度目标函数，引导扩散模型生成。支持多尺度控制（从单个图像块纹理匹配到全局特征引导），并扩展到多概念组合生成。理论分析验证了该方法对潜在分布的作用机制。

Result: 在ImageNet/COCO数据集上证明了方法能生成高质量多样化图像，在控制精度和生成质量上优于现有基线。代码已开源。

Conclusion: REPA-G提供了基于预训练表征对齐的推理阶段条件引导新范式，克服了传统方法的局限性，提升了扩散模型的可控性和生成效果。

Abstract: While representation alignment with self-supervised models has been shown to improve diffusion model training, its potential for enhancing inference-time conditioning remains largely unexplored. We introduce Representation-Aligned Guidance (REPA-G), a framework that leverages these aligned representations, with rich semantic properties, to enable test-time conditioning from features in generation. By optimizing a similarity objective (the potential) at inference, we steer the denoising process toward a conditioned representation extracted from a pre-trained feature extractor. Our method provides versatile control at multiple scales, ranging from fine-grained texture matching via single patches to broad semantic guidance using global image feature tokens. We further extend this to multi-concept composition, allowing for the faithful combination of distinct concepts. REPA-G operates entirely at inference time, offering a flexible and precise alternative to often ambiguous text prompts or coarse class labels. We theoretically justify how this guidance enables sampling from the potential-induced tilted distribution. Quantitative results on ImageNet and COCO demonstrate that our approach achieves high-quality, diverse generations. Code is available at https://github.com/valeoai/REPA-G.

</details>


### [82] [RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images](https://arxiv.org/abs/2602.03760)
*Mishal Fatima,Shashank Agnihotri,Kanchana Vaishnavi Gandikota,Michael Moeller,Margret Keuper*

Main category: cs.CV

TL;DR: RAWDet-7是一个大规模RAW图像数据集，用于提升视觉模型的目标检测与描述能力，并评估低比特量化下的处理效果。


<details>
  <summary>Details</summary>
Motivation: 传统RGB图像经ISP处理丢失传感器级信息，而RAW图像保留原始数据。现有数据集缺乏对RAW图像的系统研究，需通过RAWDet-7推动相关领域发展。

Method: 构建包含约25k训练和7.6k测试图像的大规模数据集，覆盖7个目标类别并提供sRGB对应的描述标注；设计4/6/8比特量化模拟，建立低比特RAW图像处理的基准评测框架。

Result: 提供首个支持目标检测、描述质量评估及低比特量化影响分析的RAW图像基准，涵盖跨设备、光照与场景的多样化数据。

Conclusion: RAWDet-7为研究RAW图像处理及低比特硬件约束下的视觉模型优化提供了标准化评测平台。

Abstract: Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.

</details>


### [83] [FOVI: A biologically-inspired foveated interface for deep vision models](https://arxiv.org/abs/2602.03766)
*Nicholas M. Blauch,George A. Alvarez,Talia Konkle*

Main category: cs.CV

TL;DR: A foveated vision interface (FOVI) inspired by human biology transforms variable-resolution sensors into a dense manifold for efficient computation, combined with kNN-convolution and LoRA adaptation of ViT models to achieve competitive performance at reduced cost.


<details>
  <summary>Details</summary>
Motivation: Human foveated vision efficiently balances resolution and context via active sensing, whereas uniform-resolution computer vision systems struggle with computational efficiency for high-resolution images. The work addresses this gap by mimicking biological mechanisms.

Method: FOVI maps a variable-resolution sensor array into a V1-like dense manifold, where receptive fields are defined as kNN neighborhoods. A kernel mapping technique enables kNN-convolution. The approach is demonstrated in two architectures: (1) an end-to-end kNN-convolutional model and (2) foveated DINOv3 ViT using LoRA adaptation for parameter-efficient transfer.

Result: Foveated models achieve competitive accuracy versus non-foveated baselines on vision tasks while significantly reducing computational cost (e.g., FLOPS, parameters). Code and pre-trained models validate the methodology.

Conclusion: Biologically inspired foveation improves efficiency in active vision systems, enabling scalable high-resolution processing for applications like egocentric vision. kNN-convolution and LoRA adaptation provide practical pathways for lightweight, context-aware models.

Abstract: Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.

</details>


### [84] [QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization](https://arxiv.org/abs/2602.03782)
*Yuhao Xu,Yantai Yang,Zhenyang Fan,Yufan Liu,Yuming Li,Bing Li,Zhipeng Zhang*

Main category: cs.CV

TL;DR: 本文提出QVLA，首个针对机器人具身控制的动作中心量化框架，显著优于LLM量化方法，压缩后模型VRAM占用减少至29.2%，保持98.9%性能并提速1.49倍。


<details>
  <summary>Details</summary>
Motivation: 现有LLM量化方法忽略动作偏差累积对任务的影响，直接应用会导致机器人任务失败；VLA模型亟需兼顾动作鲁棒性的定制量化方案

Method: 创新性采用通道级粒度量化：1）通过动作空间敏感性测量量化各通道重要性；2）将量化与剪枝统一为0-比特混合框架；3）基于动态bit分配优化全局性能

Result: 在LIBERO实验中，OpenVLA-OFT量化版本：1）VRAM减少至原模型29.2%；2）保持98.9%原性能；3）运行速度提升1.49倍；4）相较SmoothQuant提升22.6%性能

Conclusion: 建立了机器人领域VLA模型压缩的新范式，为大模型实际部署到资源受限硬件提供了原理性解决方案

Abstract: The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.

</details>


### [85] [From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery](https://arxiv.org/abs/2602.03785)
*Jingjing Peng,Giorgio Fiore,Yang Liu,Ksenia Ellum,Debayan Daspupta,Keyoumars Ashkan,Andrew McEvoy,Anna Miserocchi,Sebastien Ourselin,John Duncan,Alejandro Granados*

Main category: cs.CV

TL;DR: 本研究提出了一种基于U-Net的模型NeuralShift，利用术前MRI预测颞叶切除术中的脑移位，提升神经导航系统的准确性。模型在全球形变和局部位移预测中均表现优异（DICE 0.97，靶点配准误差1.12mm），相关代码已开源。


<details>
  <summary>Details</summary>
Motivation: 神经外科手术依赖术前MRI进行定位，但硬脑膜开放后脑移位使术前影像失效。动态补偿脑移位是提升手术精度和保障预后的关键。

Method: 基于U-Net构建NeuralShift模型，采用术前MRI预测脑移位。通过靶点配准误差（TRE）评估局部位移，DICE评分对比预测与术中MRI的掩码一致性。

Result: 模型实现高精度全局形变预测（DICE 0.97）和局部位移预测（TRE低至1.12mm），有效补偿颞叶切除中的大范围脑移位。

Conclusion: NeuralShift仅需术前影像即可预测脑移位，为提升手术安全性和患者预后提供新方案，相关模型已开源至GitHub。

Abstract: Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.

</details>


### [86] [Progressive Checkerboards for Autoregressive Multiscale Image Generation](https://arxiv.org/abs/2602.03811)
*David Eigen*

Main category: cs.CV

TL;DR: 本论文提出了渐进式棋盘格排序的多尺度自回归图像生成方法，在保持跨层和层内依赖的同时实现高效并行采样。


<details>
  <summary>Details</summary>
Motivation: 自回归图像生成面临并行与序列依赖平衡难题，现有方法在多尺度或单图并行探索有限，需更灵活的跨层/层内条件依赖方案。

Method: 采用渐进式棋盘格固定序列，逐层均衡四叉树结构并行采样，跨层和层内双向条件建模，并验证尺度参数与固定序列步数的关系。

Result: 在ImageNet类别条件下，以更少采样步数达到与前沿自回归模型相竞争的生成质量。

Conclusion: 通过平衡跨层与层内处理，该方法在保持生成质量的同时显著提升效率，未来可拓展至更多图像生成架构。

Abstract: A key challenge in autoregressive image generation is to efficiently sample independent locations in parallel, while still modeling mutual dependencies with serial conditioning. Some recent works have addressed this by conditioning between scales in a multiscale pyramid. Others have looked at parallelizing samples in a single image using regular partitions or randomized orders. In this work we examine a flexible, fixed ordering based on progressive checkerboards for multiscale autoregressive image generation. Our ordering draws samples in parallel from evenly spaced regions at each scale, maintaining full balance in all levels of a quadtree subdivision at each step. This enables effective conditioning both between and within scales. Intriguingly, we find evidence that in our balanced setting, a wide range of scale-up factors lead to similar results, so long as the total number of serial steps is constant. On class-conditional ImageNet, our method achieves competitive performance compared to recent state-of-the-art autoregressive systems with like model capacity, using fewer sampling steps.

</details>


### [87] [Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning](https://arxiv.org/abs/2602.03815)
*Dingkun Zhang,Shuhan Qi,Yulin Wu,Xinyu Xiao,Xuan Wang,Long Chen*

Main category: cs.CV

TL;DR: The paper introduces DualSpeed, a training framework for Multimodal Large Language Models (MLLMs) that reduces training time by combining visual token pruning with a dual-mode strategy, achieving speedups of up to 4× while maintaining >99% performance.


<details>
  <summary>Details</summary>
Motivation: MLLMs face training inefficiency due to large model sizes and high visual token counts. While visual token pruning (VTP) improves inference efficiency, applying it during training causes mismatches in inference scenarios with full visual tokens, necessitating a solution to align training and inference stages.

Method: DualSpeed employs two training modes: (1) Fast-mode uses VTP to reduce visual tokens and includes a 'mode isolator' to separate model behaviors, and (2) Slow-mode trains on full visual tokens to maintain inference consistency, enhanced by self-distillation from the fast-mode. This dual approach balances efficiency and performance.

Result: Experiments show DualSpeed accelerates training by 2.1× for LLaVA-1.5 and 4.0× for LLaVA-NeXT, retaining over 99% of performance metrics compared to standard training. The code is publicly available.

Conclusion: DualSpeed effectively addresses training-inference mismatches in MLLMs caused by visual token pruning, enabling efficient training without sacrificing model performance, and demonstrates broad applicability across architectures.

Abstract: Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model's behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed

</details>


### [88] [Continuous Control of Editing Models via Adaptive-Origin Guidance](https://arxiv.org/abs/2602.03826)
*Alon Wolf,Chen Katzir,Kfir Aberman,Or Patashnik*

Main category: cs.CV

TL;DR: The paper introduces Adaptive-Origin Guidance (AdaOr), a method for smooth intensity control in text-guided image/video editing by adjusting the guidance origin with identity-conditioned predictions, avoiding abrupt transitions seen in traditional Classifier-Free Guidance (CFG) approaches.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion-based editing models struggle to smoothly adjust edit intensity via CFG. Current methods result in abrupt content changes at low guidance scales, necessitating a framework for continuous transitions while maintaining practicality in training and inference.

Method: AdaOr replaces the standard unconditional prediction with an identity-conditioned adaptive origin by interpolating between identity predictions (corresponding to minimal content changes) and unconditional predictions. The interpolation weight dynamically adjusts based on the desired edit strength. This integrates into existing training workflows without specialized data or procedures.

Result: AdaOr achieves smoother, more consistent intensity control compared to slider-based editing baselines. Experiments on image/video tasks show continuous transitions between input and edited outputs, with edit strength directly influencing the balance between identity preservation and manipulation, without requiring per-edit optimization.

Conclusion: AdaOr effectively addresses the limitation of CFG in smooth control via origin adaptation, enabling fine-grained editing intensity adjustments. It simplifies deployment by avoiding task-specific datasets or complex inference protocols, advancing diffusion model applicability for practical manipulation tasks.

Abstract: Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.

</details>


### [89] [EventNeuS: 3D Mesh Reconstruction from a Single Event Camera](https://arxiv.org/abs/2602.03847)
*Shreyas Sachan,Viktor Rudnev,Mohamed Elgharib,Christian Theobalt,Vladislav Golyanik*

Main category: cs.CV

TL;DR: EventNeuS 是一种基于单色事件流的自监督神经模型，通过结合3D符号距离函数和密度场学习，并引入球谐编码，解决了现有事件相机3D重建精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机3D重建技术受限于稀疏性和低精度，需开发更精确的3D表示学习方法。

Method: 将隐式神经表示（SDF和密度场）与事件流自监督结合，利用球谐编码处理视角相关效果，实现端到端训练。

Result: 在Chamfer距离和平均绝对误差指标上分别超越现有最佳方法34%和31%。

Conclusion: EventNeuS为单目事件相机的高精度3D重建提供了新范式，在复杂场景中显著提升重建质量。

Abstract: Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders](https://arxiv.org/abs/2602.02496)
*Shikhar Shiromani,Archie Chaudhury,Sri Pranav Kunda*

Main category: cs.CL

TL;DR: 本文提出了Hypocrisy Gap，使用SAEs量化LLM内部推理与最终生成的差异，以检测不忠行为。


<details>
  <summary>Details</summary>
Motivation: LLM常表现出不忠行为，即内部推理与最终答案不符，需更有效检测方法。

Method: 基于SAEs和稀疏线性探针比较内部真实信念与最终生成轨迹，数学量化差异。

Result: 在Gemma、Llama和Qwen模型上检测自鸣得意行为的AUROC达0.55-0.73，优于基线（0.41-0.50）。

Conclusion: Hypocrisy Gap能有效量化模型不忠行为，显著提升检测准确率。

Abstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better detect this behavior, we introduce the Hypocrisy Gap, a mechanistic metric utilizing Sparse Autoencoders (SAEs) to quantify the divergence between a model's internal reasoning and its final generation. By mathematically comparing an internal truth belief, derived via sparse linear probes, to the final generated trajectory in latent space, we quantify and detect a model's tendency to engage in unfaithful behavior. Experiments on Gemma, Llama, and Qwen models using Anthropic's Sycophancy benchmark show that our method achieves an AUROC of 0.55-0.73 for detecting sycophantic runs and 0.55-0.74 for hypocritical cases where the model internally "knows" the user is wrong, consistently outperforming a decision-aligned log-probability baseline (0.41-0.50 AUROC).

</details>


### [91] [STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models](https://arxiv.org/abs/2602.02497)
*Xuzhao Li,Xuchen Li,Jian Zhao,Shiyu Hu*

Main category: cs.CL

TL;DR: 本文提出


<details>
  <summary>Details</summary>
Motivation: 目前的STEM评估方法孤立看待基准测试，仅提供单一分数，无法区分模型错误源于领域知识不足还是认知能力缺陷，限制了诊断价值。

Method: 构建了

Result: 通过

Conclusion: STEMVerse通过整合多学科覆盖和细致的认知分层，为理解大语言模型的科学推理特性提供了清晰且可行的视角，有助于提升诊断效果并指导模型改进。

Abstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence. However, current evaluation paradigms often treat benchmarks as isolated "silos," offering only monolithic aggregate scores that neglect the intricacies of both academic specialization and cognitive depth. This result-oriented approach fails to distinguish whether model errors stem from insufficient domain knowledge or deficiencies in cognitive capacity, thereby limiting the diagnostic value. To address this, we propose STEMVerse, a diagnostic framework designed to systematically analyze the STEM reasoning capabilities of LLMs. This framework characterizes model performance across academic specialization and cognitive complexity to map the capability required for reasoning. We re-aggregate over 20,000 STEM problems from mainstream benchmarks into a unified "Discipline $\times$ Cognition" capability space, assigning dual-axis labels to every instance. Utilizing this unified diagnostic framework, we systematically evaluate representative LLM families across varying parameter scales and training paradigms. Our empirical results reveal structural failure patterns in STEM reasoning. By integrating multi-disciplinary coverage and fine-grained cognitive stratification into a unified framework, STEMVerse provides a clear and actionable perspective for understanding the scientific reasoning characteristics of LLMs.

</details>


### [92] [Test-Time Detoxification without Training or Learning Anything](https://arxiv.org/abs/2602.02498)
*Baturay Saglam,Dionysis Kalogerias*

Main category: cs.CL

TL;DR: This paper introduces a test-time procedure using zeroth-order optimization to reduce toxicity in text generated by large language models without retraining. By approximating gradients relative to input embeddings, it achieves robust detoxification across diverse models and prompts while preserving generation quality.


<details>
  <summary>Details</summary>
Motivation: Existing detoxification methods require costly retraining, gradient access, or auxiliary components, limiting transferability across model families or applicability to black-box systems. This work addresses these scalability challenges.

Method: The method approximates the toxicity gradient over input embeddings through zeroth-order optimization. It uses forward model evaluations and toxicity scores to iteratively refine input embeddings via descent steps, steering autoregressive generation toward safer outputs without accessing latent states.

Result: Empirical evaluation shows consistent toxicity reduction across various models and prompts, achieving superior toxicity-quality trade-offs compared to baselines in most settings. The method demonstrates robustness to black-box scenarios and model-agnostic applicability.

Conclusion: Input embeddings serve as effective control variables for detoxification. This approach enables scalable, training-free text sanitization through black-box optimization, offering a practical pathway for safer deployment of language models while maintaining generative performance.

Abstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without sacrificing the model's generation quality. Many existing approaches rely on model retraining, gradients, or learned auxiliary components, which can be costly and may not transfer across model families or to truly black-box settings. We introduce a test-time procedure that approximates the gradient of completion toxicity with respect to the input embeddings and uses a small number of descent steps to steer generation toward less toxic continuations. This is achieved with zeroth-order optimization that requires only access to input embeddings, a toxicity scoring function, and forward evaluations of the model. Empirically, the approach delivers robust toxicity reductions across models and prompts and, in most settings, achieves the best overall toxicity-quality trade-off. More broadly, our work positions word embeddings as effective control variables and encourages wider use of black-box optimization to guide autoregressive language models toward scalable, safer text generation, without requiring any training or access to intermediate computations.

</details>


### [93] [ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching](https://arxiv.org/abs/2602.02499)
*Yunao Zheng,Xiaojie Wang,Lei Ren,Wei Chen*

Main category: cs.CL

TL;DR: 本文提出ROSA-Tuning方法，通过引入CPU端的RWKV后缀自动机检索模块和范围受限注意力机制，提升窗口注意力模型的长上下文建模能力，在保持计算效率的同时接近全局注意力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有高效注意力方法因窗口限制导致模型状态覆盖范围不足，需要一种能有效检索历史长文本相关位置且保持计算效率的新技术路径。

Method: 提出检索与回忆双通道架构：1) 基于RWKV后缀自动机的CPU检索模块定位相关历史位置 2) 二进制离散化策略与反事实梯度算法实现端到端训练 3) 异步CPU-GPU流水线优化执行效率

Result: 在Qwen3-Base-1.7B模型上验证，ROSA-Tuning在LongBench等评测中实现接近全局注意力的性能，同时GPU内存占用仅与窗口注意力相当，推理速度提升1.8-2.3倍

Conclusion: 该方法为大模型长上下文处理提供了兼顾性能与效率的技术方案，在保持现有架构优势的基础上开拓了新的优化方向。GitHub提供实验代码(https://github.com/zyaaa-ux/ROSA-Tuning)

Abstract: Long-context capability and computational efficiency are among the central challenges facing today's large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the model state. This paper proposes ROSA-Tuning, a retrieval-and-recall mechanism for enhancing the long-context modeling ability of pretrained models. Beyond the standard attention mechanism, ROSA-Tuning introduces in parallel a CPU-based ROSA (RWKV Online Suffix Automaton) retrieval module, which efficiently locates historical positions in long contexts that are relevant to the current query, and injects the retrieved information into the model state in a trainable manner; subsequent weighted fusion can then be handled by range-restricted attention. To enable end-to-end training, we design a binary discretization strategy and a counterfactual gradient algorithm, and further optimize overall execution efficiency via an asynchronous CPU-GPU pipeline. Systematic evaluations on Qwen3-Base-1.7B show that ROSA-Tuning substantially restores the long-context modeling ability of windowed-attention models, achieving performance close to and in some cases matching global attention on benchmarks such as LongBench, while maintaining computational efficiency and GPU memory usage that are nearly comparable to windowed-attention methods, offering a new technical path for efficient long-context processing. The example code can be found at https://github.com/zyaaa-ux/ROSA-Tuning.

</details>


### [94] [Monotonicity as an Architectural Bias for Robust Language Models](https://arxiv.org/abs/2602.02686)
*Patrick Cooper,Alireza Nadali,Ashutosh Trivedi,Alvaro Velasquez*

Main category: cs.CL

TL;DR: This paper explores using monotonicity as an architectural inductive bias in Transformers to enhance robustness against adversarial attacks while maintaining model performance.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) are vulnerable to adversarial prompts and jailbreak attacks despite alignment efforts. Monotonicity, a principle used in safety-critical systems to ensure predictable behavior, has been underutilized in neural models due to perceived limitations in expressiveness.

Method: The authors selectively enforce monotonicity only in the feed-forward sublayers of sequence-to-sequence Transformers, leaving attention mechanisms unconstrained. This allows attention to manage complex interactions (e.g., negation) while ensuring semantic refinements remain order-preserving.

Result: Adversarial attack success rates dropped from ~69% to 19%, while standard summarization performance remained nearly unchanged.

Conclusion: Monotonicity can improve robustness without sacrificing expressiveness if applied selectively, offering a practical path toward safer neural language models.

Abstract: Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output.
  We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models.
  We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.

</details>


### [95] [Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors](https://arxiv.org/abs/2602.02731)
*Rohan Pandey,Haijuan Yan,Hong Yu,Jack Tsai*

Main category: cs.CL

TL;DR: 利用纵向电子健康记录（EHR）结合社会因素预测美国退伍军人首次无家可归风险，通过机器学习模型实现更精准的分层预警。


<details>
  <summary>Details</summary>
Motivation: 退伍军人无家可归是重大公共卫生问题，需通过风险预测实现提前干预。现有EHR数据中社会行为因素的时序建模尚未充分探索。

Method: 基于427万退伍军人EHR数据构建静态及时变模型，采用临床知识编码风险特征持续性，对比传统机器学习、Transformer语言模型及大语言模型的预测性能。

Result: 纳入社会因素使PR-AUC提升15-30%；最高风险1%人群在12个月时阳性预测值达11.65-13.80%。LLM虽在种族差异上表现更优但歧视性评估弱于编码器模型。

Conclusion: 社会风险因素与纵向EHR建模可有效分层无家可归风险，支持制定针对高风险退伍军人的精准预防策略。

Abstract: Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans Affairs patients during a 2016 observation period to predict first-episode homelessness occurring 3-12 months later in 2017 (prevalence: 0.32-1.19%). We constructed static and time-varying EHR representations, utilizing clinician-informed logic to model the persistence of clinical conditions and social risks over time. We then compared the performance of classical machine learning, transformer-based masked language models, and fine-tuned large language models (LLMs). We demonstrate that incorporating social and behavioral factors into longitudinal models improved precision-recall area under the curve (PR-AUC) by 15-30%. In the top 1% risk tier, models yielded positive predictive values ranging from 3.93-4.72% at 3 months, 7.39-8.30% at 6 months, 9.84-11.41% at 9 months, and 11.65-13.80% at 12 months across model architectures. Large language models underperformed encoder-based models on discrimination but showed smaller performance disparities across racial groups. These results demonstrate that longitudinal, socially informed EHR modeling concentrates homelessness risk into actionable strata, enabling targeted and data-informed prevention strategies for at-risk veterans.

</details>


### [96] [Time-Critical Multimodal Medical Transportation: Organs, Patients, and Medical Supplies](https://arxiv.org/abs/2602.02736)
*Elaheh Sabziyan Varnousfaderani,Syed A. M. Shihab,Mohammad Taghizadeh*

Main category: cs.CL

TL;DR: 本文提出了一种基于贪心启发式算法的空地多模态医疗运输调度系统，通过整合救护车、无人机和电动垂直起降飞机的混合车队，提升运输效率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 传统救护车受交通限制，直升机成本高昂，而新兴空中交通工具虽成本较低但存在航程限制和天气敏感问题，亟需优化多模式运输协作机制。

Method: 构建四种车队配置方案，设计贪心启发式算法实现多模态车辆混合调度，通过负载整合、动态评估交通/气象条件，进行快速实时调度决策。

Result: 算法在模拟场景中验证，显示整合无人机和eVTOL的混合车队相较传统单一模式：运输时间缩短38%-52%，燃料成本降低42%-59%，且具备更强天气适应性。

Conclusion: 空地协同机制能有效平衡运输效率与经济性，提出的低复杂度算法优于传统优化模型，为复杂城市医疗物流提供了可行解决方案

Abstract: Timely transportation of organs, patients, and medical supplies is critical to modern healthcare, particularly in emergencies and transplant scenarios where even short delays can severely impact outcomes. Traditional ground-based vehicles such as ambulances are often hindered by traffic congestion; while air vehicles such as helicopters are faster but costly. Emerging air vehicles -- Unmanned Aerial Vehicles and electric vertical take-off and landing aircraft -- have lower operating costs, but remain limited by range and susceptibility to weather conditions. A multimodal transportation system that integrates both air and ground vehicles can leverage the strengths of each to enhance overall transportation efficiency. This study introduces a constructive greedy heuristic algorithm for multimodal vehicle dispatching for medical transportation. Four different fleet configurations were tested: (i) ambulances only, (ii) ambulances with Unmanned Aerial Vehicles, (iii) ambulances with electric vertical take-off and landing aircraft, and (iv) a fully integrated fleet of ambulances, Unmanned Aerial Vehicles, and electric vertical take-off and landing aircraft. The algorithm incorporates payload consolidation across compatible routes, accounts for traffic congestion in ground operations and weather conditions in aerial operations, while enabling rapid vehicle dispatching compared to computationally intensive optimization models. Using a common set of conditions, we evaluate all four fleet types to identify the most effective configurations for fulfilling medical transportation needs while minimizing operating costs, recharging/fuel costs, and total transportation time.

</details>


### [97] [AmharicStoryQA: A Multicultural Story Question Answering Benchmark in Amharic](https://arxiv.org/abs/2602.02774)
*Israel Abebe Azime,Abenezer Kebede Angamo,Hana Mekonen Tamiru,Dagnachew Mekonnen Marilign,Philipp Slusallek,Seid Muhie Yimam,Dietrich Klakow*

Main category: cs.CL

TL;DR: 介绍了AmharicStoryQA，一个基于阿姆哈拉语地区文化多样性的故事问答基准。揭示了现有大语言模型在理解区域性故事上的差距，并强调需要超越语言层面的评估方法。


<details>
  <summary>Details</summary>
Motivation: 指出当前多语言评估基准将语言和文化混为一谈，忽视了单一语言内存在的文化差异。强调需要针对区域性文化特性进行更精准的模型评估。

Method: 构建了包含埃塞俄比亚不同地区叙事的AmharicStoryQA长文本问答基准，系统评估现有多语言大模型在跨区域叙事理解中的表现。

Result: 发现现有模型在区域性叙事理解上存在显著差异，监督微调在不同区域效果参差不齐，证明文化背景对评估结果具有实质性影响。

Conclusion: 呼吁建立基于文化语境的评估体系，强调单纯语言层面的评估不足以准确反映模型对叙事文本的理解能力。

Abstract: With the growing emphasis on multilingual and cultural evaluation benchmarks for large language models, language and culture are often treated as synonymous, and performance is commonly used as a proxy for a models understanding of a given language. In this work, we argue that such evaluations overlook meaningful cultural variation that exists within a single language. We address this gap by focusing on narratives from different regions of Ethiopia and demonstrate that, despite shared linguistic characteristics, region-specific and domain-specific content substantially influences language evaluation outcomes. To this end, we introduce \textbf{\textit{AmharicStoryQA}}, a long-sequence story question answering benchmark grounded in culturally diverse narratives from Amharic-speaking regions. Using this benchmark, we reveal a significant narrative understanding gap in existing LLMs, highlight pronounced regional differences in evaluation results, and show that supervised fine-tuning yields uneven improvements across regions and evaluation settings. Our findings emphasize the need for culturally grounded benchmarks that go beyond language-level evaluation to more accurately assess and improve narrative understanding in low-resource languages.

</details>


### [98] [When Efficient Communication Explains Convexity](https://arxiv.org/abs/2602.02821)
*Ashvin Ranjan,Shane Steinert-Threlkeld*

Main category: cs.CL

TL;DR: 该论文提出，通过信息瓶颈方法的形式化，语义类型学中的最优性与凸性广义概念之间的相关性得到了证明，尤其表明交流需求分布的凸性在该相关性中起关键作用。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索高效沟通理论解释语义类型学现象的原因，重点关注最优性与凸性之间的关系，以及驱动该关系的潜在因素。

Method: 采用信息瓶颈（IB）框架形式化简单性与信息性的权衡，首先分析IB最优性与新提出的凸性概念之间的相关性，其次通过调整IB建模参数探讨驱动该相关性的因素。

Result: 研究发现，交流需求分布的凸性在最优性与凸性相关性中扮演核心角色，而其他参数调整对相关性强度有显著影响。

Conclusion: 该成果从解释高效沟通如何塑造语言现象，扩展到揭示其背后的关键驱动因素，为语义类型学提供了更基础性的理论依据。

Abstract: Much recent work has argued that the variation in the languages of the world can be explained from the perspective of efficient communication; in particular, languages can be seen as optimally balancing competing pressures to be simple and to be informative. Focusing on the expression of meaning -- semantic typology -- the present paper asks what factors are responsible for successful explanations in terms of efficient communication. Using the Information Bottleneck (IB) approach to formalizing this trade-off, we first demonstrate and analyze a correlation between optimality in the IB sense and a novel generalization of convexity to this setting. In a second experiment, we manipulate various modeling parameters in the IB framework to determine which factors drive the correlation between convexity and optimality. We find that the convexity of the communicative need distribution plays an especially important role. These results move beyond showing that efficient communication can explain aspects of semantic typology into explanations for why that is the case by identifying which underlying factors are responsible.

</details>


### [99] [R2-Router: A New Paradigm for LLM Routing with Reasoning](https://arxiv.org/abs/2602.02823)
*Jiaqi Xue,Qian Lou,Jiarong Xing,Heng Huang*

Main category: cs.CL

TL;DR: 本文提出R2-Router，通过动态调控大语言模型输出长度预算，在保证质量的同时以4-5倍成本降低实现路由选择性能突破。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法假设单一固定的输出质量与成本关系，未能利用强大LLM在缩短输出长度时可能实现的性价比优化空间。

Method: 创新性地将输出长度预算作为可控制变量，开发了联合选择最佳LLM与长度预算的路由框架，并构建首个涵盖多长度预算场景的R2-Bench评估数据集。

Result: 实验验证R2-Router相较传统路由方法，在成本降低4-5倍的情况下达到最优性能，揭示了强LLM在受限输出时可能超越弱LLM的性价比拐点。

Conclusion: 开创性提出『路由即推理』新范式，推动路由技术从被动选择向主动成本效益探索的智能化演进。

Abstract: As LLMs proliferate with diverse capabilities and costs, LLM routing has emerged by learning to predict each LLM's quality and cost for a given query, then selecting the one with high quality and low cost. However, existing routers implicitly assume a single fixed quality and cost per LLM for each query, ignoring that the same LLM's quality varies with its output length. This causes routers to exclude powerful LLMs when their estimated cost exceeds the budget, missing the opportunity that these LLMs could still deliver high quality at reduced cost with shorter outputs. To address this, we introduce R2-Router, which treats output length budget as a controllable variable and jointly selects the best LLM and length budget, enforcing the budget via length-constrained instructions. This enables R2-Router to discover that a powerful LLM with constrained output can outperform a weaker LLM at comparable cost-efficient configurations invisible to prior methods. Together with the router framework, we construct R2-Bench, the first routing dataset capturing LLM behavior across diverse output length budgets. Experiments show that R2-Router achieves state-of-the-art performance at 4-5x lower cost compared with existing routers. This work opens a new direction: routing as reasoning, where routers evolve from reactive selectors to deliberate reasoners that explore which LLM to use and at what cost budget.

</details>


### [100] [CATNIP: LLM Unlearning via Calibrated and Tokenized Negative Preference Alignment](https://arxiv.org/abs/2602.02824)
*Zhengbang Yang,Yisheng Zhong,Junyuan Hong,Zhuangdi Zhu*

Main category: cs.CL

TL;DR: 本文提出了CATNIP方法，通过量化模型对不良知识的置信度来精确调整梯度更新，实现高效的知识遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有梯度上升（GA）方法依赖保留数据或对比对且效果受限，负偏好对齐（NPA）存在参考模型选择局限性和真实数据效果下降问题，需解决如何量化模型对不良知识的置信度并减少灾难性遗忘，以及如何适应数据稀缺和长度变化的挑战。

Method: 提出了基于token级置信度的校准和标记化负偏好对齐方法（CATNIP），通过Rescaling unlearning effects与模型token-level confidence成比例，实现细粒度遗忘控制，无需保留数据或对比对。

Result: 实验表明基于MUSE和WMDP基准，CATNIP在知识遗忘与保留的权衡效果优于当前最先进方法，且不依赖保留数据或对比学习对。

Conclusion: 该方法通过校准token级置信度实现细粒度控制，在无需额外数据的条件下解决了现有方法的数据依赖和性能局限性，为知识遗忘提供了有效框架。

Abstract: Pretrained knowledge memorized in LLMs raises critical concerns over safety and privacy, which has motivated LLM Unlearning as a technique for selectively removing the influences of undesirable knowledge. Existing approaches, rooted in Gradient Ascent (GA), often degrade general domain knowledge while relying on retention data or curated contrastive pairs, which can be either impractical or data and computationally prohibitive. Negative Preference Alignment has been explored for unlearning to tackle the limitations of GA, which, however, remains confined by its choice of reference model and shows undermined performance in realistic data settings. These limitations raise two key questions: i) Can we achieve effective unlearning that quantifies model confidence in undesirable knowledge and uses it to calibrate gradient updates more precisely, thus reducing catastrophic forgetting? ii) Can we make unlearning robust to data scarcity and length variation? We answer both questions affirmatively with CATNIP (Calibrated and Tokenized Negative Preference Alignment), a principled method that rescales unlearning effects in proportion to the model's token-level confidence, thus ensuring fine-grained control over forgetting. Extensive evaluations on MUSE and WMDP benchmarks demonstrated that our work enables effective unlearning without requiring retention data or contrastive unlearning response pairs, with stronger knowledge forgetting and preservation tradeoffs than state-of-the-art methods.

</details>


### [101] [Act or Clarify? Modeling Sensitivity to Uncertainty and Cost in Communication](https://arxiv.org/abs/2602.02843)
*Polina Tsvilodub,Karl Mulligan,Todd Snider,Robert D. Hawkins,Michael Franke*

Main category: cs.CL

TL;DR: 该研究探讨了在不确定性下人们如何决定是否通过提问澄清来减少不确定性，提出了基于预期遗憾的计算模型，并通过两个实验验证了人们倾向于根据潜在损失风险来平衡澄清行为。


<details>
  <summary>Details</summary>
Motivation: 在沟通情境中，明确提问（CQs）是减少不确定性的关键策略，研究旨在理解影响CQ决策的核心因素（如不确定性程度与行动成本）及其相互作用机制。

Method: 构建基于预期遗憾的计算模型（量化错误行动的潜在损失），并通过两个实验验证：1）纯语言问答场景；2）语言澄清与非语言行动的选择权衡。

Result: 实验结果支持理论预测，显示人类会权衡澄清行为的比例与行动风险，尤其在错误成本高时更倾向于提问澄清。

Conclusion: 人类在不确定性下的提问决策与潜在损失风险成比例，体现了理性权衡策略，即在关键情境中通过信息获取降低可能损失。

Abstract: When deciding how to act under uncertainty, agents may choose to act to reduce uncertainty or they may act despite that uncertainty.In communicative settings, an important way of reducing uncertainty is by asking clarification questions (CQs). We predict that the decision to ask a CQ depends on both contextual uncertainty and the cost of alternative actions, and that these factors interact: uncertainty should matter most when acting incorrectly is costly. We formalize this interaction in a computational model based on expected regret: how much an agent stands to lose by acting now rather than with full information. We test these predictions in two experiments, one examining purely linguistic responses to questions and another extending to choices between clarification and non-linguistic action. Taken together, our results suggest a rational tradeoff: humans tend to seek clarification proportional to the risk of substantial loss when acting under uncertainty.

</details>


### [102] [Which course? Discourse! Teaching Discourse and Generation in the Era of LLMs](https://arxiv.org/abs/2602.02878)
*Junyi Jessy Li,Yang Janet Liu,Kanishka Misra,Valentina Pyatkin,William Sheffield*

Main category: cs.CL

TL;DR: 本文介绍了一个新课程的设计与实施，旨在通过整合语言学与计算机科学，培养计算话语处理与自然语言生成领域的跨学科能力。


<details>
  <summary>Details</summary>
Motivation: NLP领域快速发展引发跨学科教育需求，现有本科课程缺乏对话语处理与长文本生成的结合探索。

Method: 由跨学科团队合作设计课程框架，包含理论教学、实践任务与探索性课堂活动，并在2025年秋季学期首次授课。

Result: 构建了包含语言学理论、计算模型、生成式文本实践的课程体系，通过独立调研验证了课程设计的有效性。

Conclusion: 跨学科深度融合能培养适应动态领域的复合型人才，未来计划拓展评估体系并深化产研合作。

Abstract: The field of NLP has undergone vast, continuous transformations over the past few years, sparking debates going beyond discipline boundaries. This begs important questions in education: how do we design courses that bridge sub-disciplines in this shifting landscape? This paper explores this question from the angle of discourse processing, an area with rich linguistic insights and computational models for the intentional, attentional, and coherence structure of language. Discourse is highly relevant for open-ended or long-form text generation, yet this connection is under-explored in existing undergraduate curricula. We present a new course, "Computational Discourse and Natural Language Generation". The course is collaboratively designed by a team with complementary expertise and was offered for the first time in Fall 2025 as an upper-level undergraduate course, cross-listed between Linguistics and Computer Science. Our philosophy is to deeply integrate the theoretical and empirical aspects, and create an exploratory mindset inside the classroom and in the assignments. This paper describes the course in detail and concludes with takeaways from an independent survey as well as our vision for future directions.

</details>


### [103] [HALT: Hallucination Assessment via Log-probs as Time series](https://arxiv.org/abs/2602.02888)
*Ahmad Shapiro,Karan Taneja,Ashok Goel*

Main category: cs.CL

TL;DR: HALT是一种高效的LLM幻觉检测框架，利用生成的token对数概率作为时间序列，结合GRU与熵特征，无需模型内部状态且兼容私有模型，在新基准HUB上表现优越。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在安全敏感领域中的幻觉问题仍未解决，现有检测方法在效率或领域通用性上存在局限。

Method: HALT通过门控循环单元（GRU）和基于熵的特征分析LLM生成的top-20 token对数概率时间序列，仅依赖输出概率，无需访问隐藏状态或注意力图。

Result: HALT比基于BERT的Lettuce小30倍，在HUB基准上实现60倍速度提升，且覆盖多种LLM任务（推理、问答、代码生成等）。

Conclusion: HALT与HUB为跨领域LLM幻觉检测提供了轻量级且高效的解决方案，适用于专有模型并推动实际部署安全性。

Abstract: Hallucinations remain a major obstacle for large language models (LLMs), especially in safety-critical domains. We present HALT (Hallucination Assessment via Log-probs as Time series), a lightweight hallucination detector that leverages only the top-20 token log-probabilities from LLM generations as a time series. HALT uses a gated recurrent unit model combined with entropy-based features to learn model calibration bias, providing an extremely efficient alternative to large encoders. Unlike white-box approaches, HALT does not require access to hidden states or attention maps, relying only on output log-probabilities. Unlike black-box approaches, it operates on log-probs rather than surface-form text, which enables stronger domain generalization and compatibility with proprietary LLMs without requiring access to internal weights. To benchmark performance, we introduce HUB (Hallucination detection Unified Benchmark), which consolidates prior datasets into ten capabilities covering both reasoning tasks (Algorithmic, Commonsense, Mathematical, Symbolic, Code Generation) and general purpose skills (Chat, Data-to-Text, Question Answering, Summarization, World Knowledge). While being 30x smaller, HALT outperforms Lettuce, a fine-tuned modernBERT-base encoder, achieving a 60x speedup gain on HUB. HALT and HUB together establish an effective framework for hallucination detection across diverse LLM capabilities.

</details>


### [104] [Equal Access, Unequal Interaction: A Counterfactual Audit of LLM Fairness](https://arxiv.org/abs/2602.02932)
*Alireza Amiri-Margavi,Arshia Gharagozlou,Amin Gholami Davodi,Seyed Pouyan Mousavi Davoudi,Hamidreza Hasani Balyani*

Main category: cs.CL

TL;DR: 尽管大语言模型在访问层面公平，但在交互质量（如语调、不确定性）上仍存在系统性差异，GPT-4对年轻男性用户更倾向使用“hedging”，LLaMA-3.1-70B则展现出更广泛的情感变化。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注大语言模型的访问公平性（如拒绝行为），但未能评估获得访问后交互质量的潜在不平等，需进一步探究身份因素对响应质量的影响。

Method: 通过反事实提示设计，对GPT-4和LLaMA-3.1-70B进行受控公平性审计，控制职业建议任务中的年龄、性别、国籍属性变化，结合拒绝分析、自动化语言指标（情感/礼貌/hedging）及配对统计检验，评估访问公平性与交互质量差异。

Result: 两模型均实现100%响应率（无访问差异），但交互质量存在显著差异：GPT-4向年轻男性用户表达更高hedging，LLaMA-3.1-70B在不同身份群体间的情感差异更广泛。

Conclusion: 公平性评估需超越拒绝率分析，延伸至交互层面的微观偏差，不同模型可能通过不同机制产生身份相关的语言模式差异。

Abstract: Prior work on fairness in large language models (LLMs) has primarily focused on access-level behaviors such as refusals and safety filtering. However, equitable access does not ensure equitable interaction quality once a response is provided. In this paper, we conduct a controlled fairness audit examining how LLMs differ in tone, uncertainty, and linguistic framing across demographic identities after access is granted. Using a counterfactual prompt design, we evaluate GPT-4 and LLaMA-3.1-70B on career advice tasks while varying identity attributes along age, gender, and nationality. We assess access fairness through refusal analysis and measure interaction quality using automated linguistic metrics, including sentiment, politeness, and hedging. Identity-conditioned differences are evaluated using paired statistical tests. Both models exhibit zero refusal rates across all identities, indicating uniform access. Nevertheless, we observe systematic, model-specific disparities in interaction quality: GPT-4 expresses significantly higher hedging toward younger male users, while LLaMA exhibits broader sentiment variation across identity groups. These results show that fairness disparities can persist at the interaction level even when access is equal, motivating evaluation beyond refusal-based audits.

</details>


### [105] [Where Norms and References Collide: Evaluating LLMs on Normative Reasoning](https://arxiv.org/abs/2602.02975)
*Mitchell Abrams,Kaveh Eskandari Miandoab,Felix Gervits,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: This paper introduces SNIC, a testbed to evaluate large language models' (LLMs) ability to handle norm-based reference resolution (NBRR) in embodied, socially situated tasks. Results show state-of-the-art LLMs struggle with implicit and conflicting social norms.


<details>
  <summary>Details</summary>
Motivation: Embodied agents like robots require understanding social norms for effective communication in physical environments. NBRR is critical but poorly studied in LLMs, creating a gap in deploying language-based systems in real-world contexts.

Method: Developed SNIC (Situated Norms in Context), a human-validated diagnostic testbed focusing on physically grounded norms in daily tasks. Conducted controlled evaluations on leading LLMs' ability to extract and apply explicit/implicit normative principles for NBRR.

Result: Even top-performing LLMs exhibited significant limitations in identifying and applying social norms, especially when norms were implicitly defined, incomplete, or conflicted with each other.

Conclusion: Current LLMs have critical blind spots in normative reasoning required for socially situated embodiments. This highlights the need for improved norm perception and conflict resolution capabilities in language-based AI systems for real-world deployment.

Abstract: Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability in such settings is norm-based reference resolution (NBRR), where interpreting referential expressions requires inferring implicit normative expectations grounded in physical and social context. Yet it remains unclear whether Large Language Models (LLMs) can support this kind of reasoning. In this work, we introduce SNIC (Situated Norms in Context), a human-validated diagnostic testbed designed to probe how well state-of-the-art LLMs can extract and utilize normative principles relevant to NBRR. SNIC emphasizes physically grounded norms that arise in everyday tasks such as cleaning, tidying, and serving. Across a range of controlled evaluations, we find that even the strongest LLMs struggle to consistently identify and apply social norms, particularly when norms are implicit, underspecified, or in conflict. These findings reveal a blind spot in current LLMs and highlight a key challenge for deploying language-based systems in socially situated, embodied settings.

</details>


### [106] [CPMobius: Iterative Coach-Player Reasoning for Data-Free Reinforcement Learning](https://arxiv.org/abs/2602.02979)
*Ran Li,Zeyuan Liu,Yinghao chen,Bingxiang He,Jiarui Yuan,Zixuan Fu,Weize Chen,Jinyi Hu,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了CPMöbius，一种无需外部数据的数据强化学习方法，通过协作式教练-玩家模式提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型依赖高质量人工标注数据进行监督微调或强化学习，导致训练成本高且扩展性受限，亟需解决数据依赖性问题以实现可持续模型优化。

Method: 受人类协作与多智能体启发，将模型拆分为独立但协作的教练（Coach）与玩家（Player）角色：教练生成针对性任务并通过玩家性能变化获得反馈，玩家通过解决任务提升推理能力，形成双向优化循环。

Result: 在Qwen2.5-Math-7B-Instruct模型上，CPMöbius平均准确率提升4.9/ood准确率提升5.4，分别比RENT和R-zero的基线结果高1.5和4.2个点。

Conclusion: 该方法验证了数据协作学习机制在减少标注数据依赖方面的潜力，为提升大模型推理能力提供了新型无监督学习框架。

Abstract: Large Language Models (LLMs) have demonstrated strong potential in complex reasoning, yet their progress remains fundamentally constrained by reliance on massive high-quality human-curated tasks and labels, either through supervised fine-tuning (SFT) or reinforcement learning (RL) on reasoning-specific data. This dependence renders supervision-heavy training paradigms increasingly unsustainable, with signs of diminishing scalability already evident in practice. To overcome this limitation, we introduce CPMöbius (CPMobius), a collaborative Coach-Player paradigm for data-free reinforcement learning of reasoning models. Unlike traditional adversarial self-play, CPMöbius, inspired by real world human sports collaboration and multi-agent collaboration, treats the Coach and Player as independent but cooperative roles. The Coach proposes instructions targeted at the Player's capability and receives rewards based on changes in the Player's performance, while the Player is rewarded for solving the increasingly instructive tasks generated by the Coach. This cooperative optimization loop is designed to directly enhance the Player's mathematical reasoning ability. Remarkably, CPMöbius achieves substantial improvement without relying on any external training data, outperforming existing unsupervised approaches. For example, on Qwen2.5-Math-7B-Instruct, our method improves accuracy by an overall average of +4.9 and an out-of-distribution average of +5.4, exceeding RENT by +1.5 on overall accuracy and R-zero by +4.2 on OOD accuracy.

</details>


### [107] [LatentMem: Customizing Latent Memory for Multi-Agent Systems](https://arxiv.org/abs/2602.03036)
*Muxin Fu,Guibin Zhang,Xiangyuan Xue,Yafu Li,Zefeng He,Siyuan Huang,Xiaoye Qu,Yu Cheng,Yang Yang*

Main category: cs.CL

TL;DR: 提出LatentMem框架，通过可学习的多智能体记忆机制解决记忆同质化和信息过载问题，采用经验库和记忆合成器生成紧凑的潜在记忆，并引入潜记忆策略优化算法进行模型优化。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体记忆模型缺乏角色感知定制性导致记忆同质化，且记忆粒度过细引发信息过载，需要更高效的个性化记忆架构。

Method: 构建包含轻量级经验库和条件记忆合成器的LatentMem框架，结合潜记忆策略优化(LMPO)算法，通过任务级信号反向传播优化潜在记忆表征。

Result: 在多种基准测试中较基线提升19.36%性能，显著优于现有记忆架构，且无需修改底层框架即可实现高效记忆压缩。

Conclusion: 潜变量记忆架构有效平衡记忆个性化与效率，提出的框架具有跨平台兼容性和实用价值，为多智能体系统持续适应提供新范式。

Abstract: Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to $19.36$% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks.

</details>


### [108] [SAES-SVD: Self-Adaptive Suppression of Accumulated and Local Errors for SVD-based LLM Compression](https://arxiv.org/abs/2602.03051)
*Xing Hu,Dawei Yang,Yuan Cheng,Zhixuan Chen,Zukang Xu*

Main category: cs.CL

TL;DR: 针对大模型压缩中误差累积问题，提出SAES-SVD框架，包含误差感知压缩和自适应误差抑制技术


<details>
  <summary>Details</summary>
Motivation: 现有低秩压缩方法独立压缩各层导致误差累积，损害模型全局精度

Method: 通过CEALC组件协同优化层内重建与层间误差补偿，并用ACES组件动态调整权重系数以增强低秩结构

Result: 在无需微调或混合秩策略下，实验显示跨模型和任务的压缩性能一致提升

Conclusion: 联合优化误差传播路径的压缩方法优于传统独立分层压缩策略

Abstract: The rapid growth in the parameter scale of large language models (LLMs) has created a high demand for efficient compression techniques. As a hardware-agnostic and highly compatible technique, low-rank compression has been widely adopted. However, existing methods typically compress each layer independently by minimizing per-layer reconstruction error, overlooking a critical limitation: the reconstruction error propagates and accumulates through the network, which leads to amplified global deviations from the full-precision baseline. To address this, we propose Self-Adaptive Error Suppression SVD (SAES-SVD), a LLMs compression framework that jointly optimizes intra-layer reconstruction and inter-layer error compensation. SAES-SVD is composed of two novel components: (1) Cumulative Error-Aware Layer Compression (CEALC), which formulates the compression objective as a combination of local reconstruction and weighted cumulative error compensation. Based on it, we derive a closed-form low-rank solution relied on second-order activation statistics, which explicitly aligns each layer's output with its full-precision counterpart to compensate for accumulated errors. (2) Adaptive Collaborative Error Suppression (ACES), which automatically adjusts the weighting coefficient to enhance the low-rank structure of the compression objective in CEALC. Specifically, the coefficient is optimized to maximize the ratio between the Frobenius norm of the compressed layer's output and that of the compression objective under a fixed rank, thus ensuring that the rank budget is utilized effectively. Extensive experiments across multiple LLM architectures and tasks show that, without fine-tuning or mixed-rank strategies, SAES-SVD consistently improves post-compression performance.

</details>


### [109] [ReMiT: RL-Guided Mid-Training for Iterative LLM Evolution](https://arxiv.org/abs/2602.03075)
*Junjie Huang,Jiarui Qin,Di Yin,Weiwen Liu,Yong Yu,Xing Sun,Weinan Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种无需外部教师模型或参考模型的LLM双向训练框架ReMiT，通过强化学习（RL）引导的中段训练动态加权关键推理token，在预训练和后训练中均提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统LLM训练流程单向（预训练→后训练），缺乏从后训练反馈优化基础模型的机制。本文旨在通过自强化循环（flywheel）实现模型能力的持续迭代，解决外部依赖限制。

Method: 识别到预训练中期阶段（大模型能力转折点）为关键窗口，通过RL调校后的模型生成的推理先验知识，在该阶段对token进行动态加权，优先学习对推理至关重要的部分。算法命名为ReMiT。

Result: 在10项预训练基准测试中平均提升3%（数学、代码和通用推理场景），且后续后训练性能保持超2%的增益，验证了反馈循环的有效性和自强化特性。

Conclusion: 证明了LLM可通过自我迭代（mid-training动态token重加权）实现自主进化，为减少对外部模型依赖的大规模训练范式提供了新方向。

Abstract: Standard training pipelines for large language models (LLMs) are typically unidirectional, progressing from pre-training to post-training. However, the potential for a bidirectional process--where insights from post-training retroactively improve the pre-trained foundation--remains unexplored. We aim to establish a self-reinforcing flywheel: a cycle in which reinforcement learning (RL)-tuned model strengthens the base model, which in turn enhances subsequent post-training performance, requiring no specially trained teacher or reference model. To realize this, we analyze training dynamics and identify the mid-training (annealing) phase as a critical turning point for model capabilities. This phase typically occurs at the end of pre-training, utilizing high-quality corpora under a rapidly decaying learning rate. Building upon this insight, we introduce ReMiT (Reinforcement Learning-Guided Mid-Training). Specifically, ReMiT leverages the reasoning priors of RL-tuned models to dynamically reweight tokens during the mid-training phase, prioritizing those pivotal for reasoning. Empirically, ReMiT achieves an average improvement of 3\% on 10 pre-training benchmarks, spanning math, code, and general reasoning, and sustains these gains by over 2\% throughout the post-training pipeline. These results validate an iterative feedback loop, enabling continuous and self-reinforcing evolution of LLMs.

</details>


### [110] [AERO: Autonomous Evolutionary Reasoning Optimization via Endogenous Dual-Loop Feedback](https://arxiv.org/abs/2602.03084)
*Zhitao Gao,Jie Ma,Xuhong Li,Pengyu Li,Ning Qu,Yaqiang Wu,Hui Liu,Jun Liu*

Main category: cs.CL

TL;DR: 本文提出了AERO框架，通过无监督的自我进化推理方法解决大语言模型依赖专家标注数据和外部验证的问题，并通过双循环系统和交错训练策略，在多个基准测试中实现了优于基线模型的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有自我进化方法难以准确定位学习区域并可能强化集体幻觉，需要开发无需外部监督且能自我优化推理能力的框架。

Method: 1) 双循环系统内部化自我提问、回答与批评；2) 基于熵的学习区域定位技术；3) 独立反事实修正验证机制；4) 交错式同步训练策略。

Result: 在Qwen3-4B-Base和Qwen3-8B-Base上平均性能提升4.57%和5.10%，评估涵盖9个跨领域基准测试。

Conclusion: AERO通过自监督进化推理框架有效解决了传统方法的局限性，为LLMs能力提升提供了新的理论方法和技术路径。

Abstract: Large Language Models (LLMs) have achieved significant success in complex reasoning but remain bottlenecked by reliance on expert-annotated data and external verifiers. While existing self-evolution paradigms aim to bypass these constraints, they often fail to identify the optimal learning zone and risk reinforcing collective hallucinations and incorrect priors through flawed internal feedback. To address these challenges, we propose \underline{A}utonomous \underline{E}volutionary \underline{R}easoning \underline{O}ptimization (AERO), an unsupervised framework that achieves autonomous reasoning evolution by internalizing self-questioning, answering, and criticism within a synergistic dual-loop system. Inspired by the \textit{Zone of Proximal Development (ZPD)} theory, AERO utilizes entropy-based positioning to target the ``solvability gap'' and employs Independent Counterfactual Correction for robust verification. Furthermore, we introduce a Staggered Training Strategy to synchronize capability growth across functional roles and prevent curriculum collapse. Extensive evaluations across nine benchmarks spanning three domains demonstrate that AERO achieves average performance improvements of 4.57\% on Qwen3-4B-Base and 5.10\% on Qwen3-8B-Base, outperforming competitive baselines. Code is available at https://github.com/mira-ai-lab/AERO.

</details>


### [111] [Test-time Recursive Thinking: Self-Improvement without External Feedback](https://arxiv.org/abs/2602.03094)
*Yufan Zhuang,Chandan Singh,Liyuan Liu,Yelong Shen,Dinghuai Zhang,Jingbo Shang,Jianfeng Gao,Weizhu Chen*

Main category: cs.CL

TL;DR: 提出TRT框架，通过测试时递归思考实现大型语言模型无需训练的自我改进，提升复杂任务解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs依赖强化学习和外部监督信号进行改进，但缺乏无需参数更新的自提升机制，且需解决候选解多样性不足和无监督筛选准确解的双重挑战。

Method: 开发TRT框架：（1）多策略生成多样化候选解（2）基于知识库与自我验证信号迭代优化结果（3）结合概率分析与因果推理机制筛选答案。

Result: 开源模型在AIME-25/24数学竞赛题实现100%准确率，闭源模型在LiveCodeBench编程挑战中提升10.4-14.8个百分点，验证了无外部反馈的自改进有效性。

Conclusion: 证明通过系统性推理策略优化可以突破参数固定的模型能力上限，为构建自演进AI系统提供了新范式。

Abstract: Modern Large Language Models (LLMs) have shown rapid improvements in reasoning capabilities, driven largely by reinforcement learning (RL) with verifiable rewards. Here, we ask whether these LLMs can self-improve without the need for additional training. We identify two core challenges for such systems: (i) efficiently generating diverse, high-quality candidate solutions, and (ii) reliably selecting correct answers in the absence of ground-truth supervision. To address these challenges, we propose Test-time Recursive Thinking (TRT), an iterative self-improvement framework that conditions generation on rollout-specific strategies, accumulated knowledge, and self-generated verification signals. Using TRT, open-source models reach 100% accuracy on AIME-25/24, and on LiveCodeBench's most difficult problems, closed-source models improve by 10.4-14.8 percentage points without external feedback.

</details>


### [112] [Task--Specificity Score: Measuring How Much Instructions Really Matter for Supervision](https://arxiv.org/abs/2602.03103)
*Pritam Kadasi,Abhishek Upperwal,Mayank Singh*

Main category: cs.CL

TL;DR: The paper introduces Task-Specificity Score (TSS) and TSS++ to measure how uniquely an instruction determines its output in LLM training, finding that task-specific examples improve efficiency.


<details>
  <summary>Details</summary>
Motivation: Instruction tuning for LLMs often uses weakly specified data where outputs may match multiple instructions. The study questions whether instructions truly determine outputs and aims to quantify this specificity.

Method: Developed TSS (contrasts true instructions against alternatives) and TSS++ (uses hard negatives and quality terms). Tested on 3 datasets (e.g., Alpaca) and 3 LLMs (Llama), applying thresholds to filter examples.

Result: Over 30% examples showed low TSS (non-specific tasks). Using TSS/TSS++ for example selection improved downstream performance under token budget constraints, outperforming quality filters like perplexity.

Conclusion: Instruction uniqueness is critical for efficient LLM training; TSS-based filtering optimizes data usage and works synergistically with quality filters to enhance model performance.

Abstract: Instruction tuning is now the default way to train and adapt large language models, but many instruction--input--output pairs are only weakly specified: for a given input, the same output can remain plausible under several alternative instructions. This raises a simple question: \emph{does the instruction uniquely determine the target output?}
  We propose the \textbf{Task--Specificity Score (TSS)} to quantify how much an instruction matters for predicting its output, by contrasting the true instruction against plausible alternatives for the same input. We further introduce \textbf{TSS++}, which uses hard alternatives and a small quality term to mitigate easy-negative effects. Across three instruction datasets (\textsc{Alpaca}, \textsc{Dolly-15k}, \textsc{NI-20}) and three open LLMs (Gemma, Llama, Qwen), we show that selecting task-specific examples improves downstream performance under tight token budgets and complements quality-based filters such as perplexity and IFD.

</details>


### [113] [The Mask of Civility: Benchmarking Chinese Mock Politeness Comprehension in Large Language Models](https://arxiv.org/abs/2602.03107)
*Yitong Zhang,Yuhan Xiang,Mingxuan Liu*

Main category: cs.CL

TL;DR: 本研究评估了大语言模型在识别中文礼貌、不礼貌及戏谑礼貌方面的表现，构建了结合真实与模拟语料的数据集，并在多提示条件下测试六个模型。


<details>
  <summary>Details</summary>
Motivation: 弥补现有语用理解的不足，探索技术变革时代下科技与人文学科的共存问题。

Method: 结合关系管理理论和戏谑礼貌模型构建三类数据集，选取GPT-5.1、DeepSeek等模型，在零样本、少样本、知识增强及混合提示条件下测试。

Result: 提出了一种将语用理论应用于语言模型评估的新范式，为跨学科研究提供了技术与人文结合的实例。

Conclusion: 该研究展示了大语言模型在语用现象识别中的应用潜力，为‘大语言学’和人机协同的理论探索提供了新方向。

Abstract: From a pragmatic perspective, this study systematically evaluates the differences in performance among representative large language models (LLMs) in recognizing politeness, impoliteness, and mock politeness phenomena in Chinese. Addressing the existing gaps in pragmatic comprehension, the research adopts the frameworks of Rapport Management Theory and the Model of Mock Politeness to construct a three-category dataset combining authentic and simulated Chinese discourse. Six representative models, including GPT-5.1 and DeepSeek, were selected as test subjects and evaluated under four prompting conditions: zero-shot, few-shot, knowledge-enhanced, and hybrid strategies. This study serves as a meaningful attempt within the paradigm of ``Great Linguistics,'' offering a novel approach to applying pragmatic theory in the age of technological transformation. It also responds to the contemporary question of how technology and the humanities may coexist, representing an interdisciplinary endeavor that bridges linguistic technology and humanistic reflection.

</details>


### [114] [ChemPro: A Progressive Chemistry Benchmark for Large Language Models](https://arxiv.org/abs/2602.03108)
*Aaditya Baranwal,Shruti Vyas*

Main category: cs.CL

TL;DR: ChemPro是一个包含4100个化学自然语言问答对的渐进式基准测试，评估LLMs在不同难度层级上对基础到高中化学的推理能力，并揭示当前模型在复杂问题上的准确性下降问题。


<details>
  <summary>Details</summary>
Motivation: 为评估大模型在自然科学领域（尤其是化学）的多维度能力，需构建基于学科知识、难度分层且覆盖复杂推理的高质量基准测试，以诊断现有技术的不足。

Method: 设计四个难度层级的化学问答对（含选择题、计算题），覆盖生物/无机/有机/物理化学，按学术评价标准递增复杂度，对45+7个最先进LLM进行系统性测评并分析性能表现。

Result: 模型在基础问题表现良好，但在多概念推理、精细表述等复杂任务时准确率显著下降，尤其对高阶化学问题的解决能力不足，且开源与闭源模型均存在类似瓶颈。

Conclusion: 当前LLMs在科学推理的鲁棒性与复杂度迁移能力上存在关键局限，需针对细粒度推理和知识整合开发更高效的模型架构与训练策略。

Abstract: We introduce ChemPro, a progressive benchmark with 4100 natural language question-answer pairs in Chemistry, across 4 coherent sections of difficulty designed to assess the proficiency of Large Language Models (LLMs) in a broad spectrum of general chemistry topics. We include Multiple Choice Questions and Numerical Questions spread across fine-grained information recall, long-horizon reasoning, multi-concept questions, problem-solving with nuanced articulation, and straightforward questions in a balanced ratio, effectively covering Bio-Chemistry, Inorganic-Chemistry, Organic-Chemistry and Physical-Chemistry. ChemPro is carefully designed analogous to a student's academic evaluation for basic to high-school chemistry. A gradual increase in the question difficulty rigorously tests the ability of LLMs to progress from solving basic problems to solving more sophisticated challenges.
  We evaluate 45+7 state-of-the-art LLMs, spanning both open-source and proprietary variants, and our analysis reveals that while LLMs perform well on basic chemistry questions, their accuracy declines with different types and levels of complexity. These findings highlight the critical limitations of LLMs in general scientific reasoning and understanding and point towards understudied dimensions of difficulty, emphasizing the need for more robust methodologies to improve LLMs.

</details>


### [115] [FASA: Frequency-aware Sparse Attention](https://arxiv.org/abs/2602.03152)
*Yifei Wang,Yueqi Wang,Zhenrui Yue,Huimin Zeng,Yong Wang,Ismini Lourentzou,Zhengzhong Tu,Xiangxiang Chu,Julian McAuley*

Main category: cs.CL

TL;DR: FASA通过频率块稀疏性动态识别关键token，显着降低KV缓存需求，提升长文本任务处理效率。


<details>
  <summary>Details</summary>
Motivation: 处理长输入时KV缓存内存占用过高阻碍LLM部署；现有token裁剪方法因静态策略或动态启发式易导致信息丢失，需动态捕捉查询依赖的token重要性。

Method: 基于RoPE发现频率块（FC）级功能稀疏性，利用主导FC预测token重要性。通过主导FC筛选关键token并专注计算其注意力，实现低内存消耗的动态token裁剪。

Result: 在LongBench-V1保留256token实现近100%全KV性能，AIME24使用18.9%缓存达2.56倍加速。多任务测试显示优于所有基线且预算约束下保持鲁棒性。

Conclusion: FASA通过计算免费的主导FC指标，实现高效查询感知token裁剪，显着降低内存带宽与计算成本，为长文本处理提供通用解决方案。

Abstract: The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of tokens. However, existing approaches fall short, with static methods risking irreversible information loss and dynamic strategies employing heuristics that insufficiently capture the query-dependent nature of token importance. We propose FASA, a novel framework that achieves query-aware token eviction by dynamically predicting token importance. FASA stems from a novel insight into RoPE: the discovery of functional sparsity at the frequency-chunk (FC) level. Our key finding is that a small, identifiable subset of "dominant" FCs consistently exhibits high contextual agreement with the full attention head. This provides a robust and computationally free proxy for identifying salient tokens. %making them a powerful and efficient proxy for token importance. Building on this insight, FASA first identifies a critical set of tokens using dominant FCs, and then performs focused attention computation solely on this pruned subset. % Since accessing only a small fraction of the KV cache, FASA drastically lowers memory bandwidth requirements and computational cost. Across a spectrum of long-context tasks, from sequence modeling to complex CoT reasoning, FASA consistently outperforms all token-eviction baselines and achieves near-oracle accuracy, demonstrating remarkable robustness even under constraint budgets. Notably, on LongBench-V1, FASA reaches nearly 100\% of full-KV performance when only keeping 256 tokens, and achieves 2.56$\times$ speedup using just 18.9\% of the cache on AIME24.

</details>


### [116] [ForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution](https://arxiv.org/abs/2602.03203)
*Zican Dong,Peiyu Liu,Junyi Li,Zhipeng Chen,Han Peng,Shuo Wang,Wayne Xin Zhao*

Main category: cs.CL

TL;DR: ForesightKV 是一个基于训练的 KV 缓存逐出框架，通过结合监督学习与强化学习方法，有效减少长文本生成时内存和计算成本。


<details>
  <summary>Details</summary>
Motivation: 处理长序列生成时，KV 缓存线性增长导致的效率瓶颈问题。现有方法因忽视复杂依赖关系导致性能下降。

Method: 设计 Golden Eviction 算法利用未来注意力得分识别待逐出 KV 对，使用 Pairwise Ranking Loss 进行监督训练，并采用 GRPO 算法优化低熵 token 的语言模型损失。

Result: 在 AIME2024/AIME2025 基准测试中，使用半量缓存预算时性能持续优于已有方法，两种学习模式产生协同增效。

Conclusion: 该方案成功实现了效率与性能的平衡，所提优化算法对长文本生成具有实用价值。

Abstract: Recently, large language models (LLMs) have shown remarkable reasoning abilities by producing long reasoning traces. However, as the sequence length grows, the key-value (KV) cache expands linearly, incurring significant memory and computation costs. Existing KV cache eviction methods mitigate this issue by discarding less important KV pairs, but often fail to capture complex KV dependencies, resulting in performance degradation. To better balance efficiency and performance, we introduce ForesightKV, a training-based KV cache eviction framework that learns to predict which KV pairs to evict during long-text generations. We first design the Golden Eviction algorithm, which identifies the optimal eviction KV pairs at each step using future attention scores. These traces and the scores at each step are then distilled via supervised training with a Pairwise Ranking Loss. Furthermore, we formulate cache eviction as a Markov Decision Process and apply the GRPO algorithm to mitigate the significant language modeling loss increase on low-entropy tokens. Experiments on AIME2024 and AIME2025 benchmarks of three reasoning models demonstrate that ForesightKV consistently outperforms prior methods under only half the cache budget, while benefiting synergistically from both supervised and reinforcement learning approaches.

</details>


### [117] [Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection](https://arxiv.org/abs/2602.03216)
*Dongwon Jo,Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: Token Sparse Attention 是一种动态的 token 级剪枝机制，通过在注意力计算期间压缩并扩展查询（Q）、键（K）、值（V）向量，在保持上下文完整性的同时降低计算复杂度，适用于长上下文大语言模型的高效推理。


<details>
  <summary>Details</summary>
Motivation: 传统的注意力加速方法因结构化剪枝模式或过早移除特定层 Token，可能出现保留无关信息或做出不可逆决策的问题，无法适应模型层间动态变化的 Token 重要性需求。

Method: 提出 Token Sparse Attention，通过在注意力计算中动态选择重要 Token 并压缩 Q/K/V 向量，完成计算后扩展回原始序列，允许后续层级重新评估 Token 重要性；该方法兼容 Flash Attention 等稠密注意力实现，可与现有稀疏注意力内核结合使用。

Result: 实验结果表明，在 128K 上下文长度下，Token Sparse Attention 实现注意力计算速度提升最高 3.23 倍，且准确率损失低于 1%，显著优化了精度与延迟的权衡。

Conclusion: 动态且交错的 Token 级剪枝机制为可扩展的长上下文推理提供了有效的互补策略，通过兼容现有技术的轻量级设计解决了注意力复杂度瓶颈问题。

Abstract: The quadratic complexity of attention remains the central bottleneck in long-context inference for large language models. Prior acceleration methods either sparsify the attention map with structured patterns or permanently evict tokens at specific layers, which can retain irrelevant tokens or rely on irreversible early decisions despite the layer-/head-wise dynamics of token importance. In this paper, we propose Token Sparse Attention, a lightweight and dynamic token-level sparsification mechanism that compresses per-head $Q$, $K$, $V$ to a reduced token set during attention and then decompresses the output back to the original sequence, enabling token information to be reconsidered in subsequent layers. Furthermore, Token Sparse Attention exposes a new design point at the intersection of token selection and sparse attention. Our approach is fully compatible with dense attention implementations, including Flash Attention, and can be seamlessly composed with existing sparse attention kernels. Experimental results show that Token Sparse Attention consistently improves accuracy-latency trade-off, achieving up to $\times$3.23 attention speedup at 128K context with less than 1% accuracy degradation. These results demonstrate that dynamic and interleaved token-level sparsification is a complementary and effective strategy for scalable long-context inference.

</details>


### [118] [POP: Prefill-Only Pruning for Efficient Large Model Inference](https://arxiv.org/abs/2602.03295)
*Junhui He,Zhihui Fu,Jun Wang,Qingan Li*

Main category: cs.CL

TL;DR: This paper introduces Prefill-Only Pruning (POP), a stage-aware pruning strategy for LLMs/VLMs that improves efficiency by selectively pruning deep layers during the prefill stage while retaining accuracy during the decoding phase.


<details>
  <summary>Details</summary>
Motivation: Existing structured pruning methods fail to consider the asymmetric roles of model layers in prefill and decode stages, leading to accuracy degradation despite computational efficiency.

Method: Uses virtual gate mechanisms to identify critical layers for decoding, prunes deep layers during prefill, and incorporates independent KV projections/boundary handling to maintain cache integrity during stage transitions.

Result: POP achieves up to 1.37× speedup in prefill latency with minimal performance loss across Llama-3.1, Qwen3-VL, and Gemma-3 models.

Conclusion: Stage-aware pruning (POP) effectively addresses the accuracy-efficiency trade-off limitations of traditional structured pruning methods in multimodal models.

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In this paper, we argue that this failure stems from a stage-agnostic pruning approach that overlooks the asymmetric roles between the prefill and decode stages. By introducing a virtual gate mechanism, our importance analysis reveals that deep layers are critical for next-token prediction (decode) but largely redundant for context encoding (prefill). Leveraging this insight, we propose Prefill-Only Pruning (POP), a stage-aware inference strategy that safely omits deep layers during the computationally intensive prefill stage while retaining the full model for the sensitive decode stage. To enable the transition between stages, we introduce independent Key-Value (KV) projections to maintain cache integrity, and a boundary handling strategy to ensure the accuracy of the first generated token. Extensive experiments on Llama-3.1, Qwen3-VL, and Gemma-3 across diverse modalities demonstrate that POP achieves up to 1.37$\times$ speedup in prefill latency with minimal performance loss, effectively overcoming the accuracy-efficiency trade-off limitations of existing structured pruning methods.

</details>


### [119] [MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research](https://arxiv.org/abs/2602.03318)
*Yifan Shi,Jialong Shi,Jiayi Wang,Ye Fan,Jianyong Sun*

Main category: cs.CL

TL;DR: 该论文提出无需微调的端到端多智能体框架MIRROR，通过自动纠错和分层检索机制，将自然语言优化问题直接转化为数学模型与求解代码。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学建模依赖专家手工设计，现有LLM方法要么需高成本后训练，要么采用多智能体框架但缺乏可靠纠错和任务特定检索，导致输出质量低下。

Method: MIRROR包含两大创新：(1)执行驱动的迭代自适应修订机制实现自动化错误校正；(2)分层检索系统从精选示例库中提取建模与编码范例。

Result: 在IndustryOR和Mamo-ComplexLP等复杂工业数据集上，MIRROR的建模准确率较现有方法提升显著，且完全避免了参数微调。

Conclusion: 该框架通过外部知识注入与系统纠错的结合，为非专家用户提供高效可靠的运筹学建模方案，突破了通用LLM在专家优化任务中的根本性局限。

Abstract: Operations Research (OR) relies on expert-driven modeling-a slow and fragile process ill-suited to novel scenarios. While large language models (LLMs) can automatically translate natural language into optimization models, existing approaches either rely on costly post-training or employ multi-agent frameworks, yet most still lack reliable collaborative error correction and task-specific retrieval, often leading to incorrect outputs. We propose MIRROR, a fine-tuning-free, end-to-end multi-agent framework that directly translates natural language optimization problems into mathematical models and solver code. MIRROR integrates two core mechanisms: (1) execution-driven iterative adaptive revision for automatic error correction, and (2) hierarchical retrieval to fetch relevant modeling and coding exemplars from a carefully curated exemplar library. Experiments show that MIRROR outperforms existing methods on standard OR benchmarks, with notable results on complex industrial datasets such as IndustryOR and Mamo-ComplexLP. By combining precise external knowledge infusion with systematic error correction, MIRROR provides non-expert users with an efficient and reliable OR modeling solution, overcoming the fundamental limitations of general-purpose LLMs in expert optimization tasks.

</details>


### [120] [Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention](https://arxiv.org/abs/2602.03338)
*Rakshith Vasudev,Melisa Russak,Dan Bikel,Waseem Alshikh*

Main category: cs.CL

TL;DR: 该论文指出，尽管LLM批判模型的离线准确性高（如AUROC 0.94），但其干预可能在部署时导致性能剧烈波动（+2.8pp至-26pp）。核心发现是干预效果存在‘破坏-恢复权衡’，因此提出基于小规模试点任务的预部署测试，以判断干预是否利大于弊。


<details>
  <summary>Details</summary>
Motivation: 当前LLM批判模型的干预决策过度依赖离线准确性指标（如AUROC），但缺乏对部署后实际效果的评估框架，导致可能引发不可预见的性能退化。论文旨在揭示这一风险并建立更可靠的干预决策方法。

Method: 1) 通过实验对比不同LLM在干预前后的性能变化; 2) 提出‘破坏-恢复权衡’理论模型; 3) 设计基于50个样本的预部署试点测试，通过统计显著性分析（p=0.014）预测干预效果。

Result: 干预效果呈现极端分化：某些任务性能下降26pp，而ALFWorld基准任务提升+2.8pp（p=0.014）。预部署测试成功预测了干预对高成功率任务（0→-26pp）和高失败率任务（+2.8pp）的不同影响。

Conclusion: LLM批判模型的干预决策不能仅依赖离线准确性。论文提出的新框架通过量化‘破坏-恢复权衡’，解决了‘何时不应干预’的问题，为安全部署提供了实用性的测试方法。

Abstract: Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe.
  We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment.

</details>


### [121] [PEGRL: Improving Machine Translation by Post-Editing Guided Reinforcement Learning](https://arxiv.org/abs/2602.03352)
*Yunzhi Shen,Hao Zhou,Xin Huang,Xue Han,Junlan Feng,Shujian Huang*

Main category: cs.CL

TL;DR: 该论文提出了PEGRL，一种基于后编辑辅助的两阶段强化学习框架，用于LLM驱动的机器翻译，解决了传统方法中的噪声信号和探索效率问题，实验表明其在多个语对上的性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在机器翻译中面临两个主要挑战：蒙特卡洛回报估计带来的噪声信号，以及大规模轨迹空间导致全局探索优于精细局部优化。文章旨在通过引入后编辑作为辅助任务，稳定训练过程并协调全局与局部优化需求。

Method: PEGRL分为两个阶段：（1）在每次迭代中采样翻译输出以构造后编辑输入，使后编辑阶段的回报估计能依赖当前翻译行为；（2）通过任务专用加权方案平衡翻译和后编辑目标，生成有偏但样本更高效的估计器。两阶段协同支持全局探索和细粒度优化。

Result: 在英-芬、英-土、英中互译实验中，PEGRL一致性超越RL基线方法，其中英-土翻译在COMET-KIWI指标上性能与Advanced LLM（如DeepSeek-V3.2）相当。

Conclusion: 通过整合后编辑作为辅助任务，PEGRL有效缓解了机器翻译中RL训练的噪声与探索难题。其两阶段框架与加权方案实现了稳定且高效的优化，为LLM翻译的RL应用提供了新方法。

Abstract: Reinforcement learning (RL) has shown strong promise for LLM-based machine translation, with recent methods such as GRPO demonstrating notable gains; nevertheless, translation-oriented RL remains challenged by noisy learning signals arising from Monte Carlo return estimation, as well as a large trajectory space that favors global exploration over fine-grained local optimization. We introduce \textbf{PEGRL}, a \textit{two-stage} RL framework that uses post-editing as an auxiliary task to stabilize training and guide overall optimization. At each iteration, translation outputs are sampled to construct post-editing inputs, allowing return estimation in the post-editing stage to benefit from conditioning on the current translation behavior, while jointly supporting both global exploration and fine-grained local optimization. A task-specific weighting scheme further balances the contributions of translation and post-editing objectives, yielding a biased yet more sample-efficient estimator. Experiments on English$\to$Finnish, English$\to$Turkish, and English$\leftrightarrow$Chinese show consistent gains over RL baselines, and for English$\to$Turkish, performance on COMET-KIWI is comparable to advanced LLM-based systems (DeepSeek-V3.2).

</details>


### [122] [Pursuing Best Industrial Practices for Retrieval-Augmented Generation in the Medical Domain](https://arxiv.org/abs/2602.03368)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本文系统分析了检索增强生成(RAG)系统在工业应用中的最佳实践，提出了一套实用的组件优化方案并揭示了性能与效率的权衡规律。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG系统在大语言模型工业应用中被广泛采用，但缺乏针对医疗等专业领域的标准化组件选择、架构设计和实现方法的行业共识。

Method: 通过拆解RAG系统各组件的架构-方法-技术三层结构，分别提出可替代的实施方案，并在三类工业任务上进行系统性消融实验与对比评估。

Result: 发现了医疗领域RAG系统的最优组合模式，证实了检索精度与生成效率存在显著负相关性，提出了基于任务需求的动态组件选择策略。

Conclusion: 本研究建立了首个系统的RAG工业落地指导框架，证明了领域专业化适配对系统性能提升的关键作用，为医疗等高风险场景的AI系统设计提供了方法论借鉴。

Abstract: While retrieval augmented generation (RAG) has been swiftly adopted in industrial applications based on large language models (LLMs), there is no consensus on what are the best practices for building a RAG system in terms of what are the components, how to organize these components and how to implement each component for the industrial applications, especially in the medical domain. In this work, we first carefully analyze each component of the RAG system and propose practical alternatives for each component. Then, we conduct systematic evaluations on three types of tasks, revealing the best practices for improving the RAG system and how LLM-based RAG systems make trade-offs between performance and efficiency.

</details>


### [123] [Towards Distillation-Resistant Large Language Models: An Information-Theoretic Perspective](https://arxiv.org/abs/2602.03396)
*Hao Fang,Tianyi Zhang,Tianqu Zhuang,Jiawei Kong,Kuofeng Gao,Bin Chen,Leqi Liang,Shu-Tao Xia,Ke Xu*

Main category: cs.CL

TL;DR: 该论文提出了一种基于信息论的防御方法，通过最小化条件互信息（CMI）来增强专有大型语言模型（LLMs）对知识蒸馏攻击的抵抗能力，同时保持模型任务准确性。


<details>
  <summary>Details</summary>
Motivation: 现有防御手段仅关注文本蒸馏，而忽视了logit蒸馏威胁，需从信息论角度探索有效防御方法以保护模型知识产权。

Method: 定义教师模型logit与输入查询在标签条件下互信息（CMI）作为蒸馏信息度量，设计转化矩阵对输出进行净化，通过CMI优化目标去除蒸馏相关特征。

Result: 在多个LLM和蒸馏算法中验证表明，该方法可将蒸馏性能降低80%-95%，同时准确率仅下降0.5%-3.6%，优于基线方法。

Conclusion: 基于CMI理论的信息净化方法能够有效防御logit蒸馏攻击，为保护商业化大模型安全提供了可行的技术路径。

Abstract: Proprietary large language models (LLMs) embody substantial economic value and are generally exposed only as black-box APIs, yet adversaries can still exploit their outputs to extract knowledge via distillation. Existing defenses focus exclusively on text-based distillation, leaving the important logit-based distillation largely unexplored. In this work, we analyze this problem and present an effective solution from an information-theoretic perspective. We characterize distillation-relevant information in teacher outputs using the conditional mutual information (CMI) between teacher logits and input queries conditioned on ground-truth labels. This quantity captures contextual information beneficial for model extraction, motivating us to defend distillation via CMI minimization. Guided by our theoretical analysis, we propose learning a transformation matrix that purifies the original outputs to enhance distillation resistance. We further derive a CMI-inspired anti-distillation objective to optimize this transformation, which effectively removes distillation-relevant information while preserving output utility. Extensive experiments across multiple LLMs and strong distillation algorithms demonstrate that the proposed method significantly degrades distillation performance while preserving task accuracy, effectively protecting models' intellectual property.

</details>


### [124] [FactNet: A Billion-Scale Knowledge Graph for Multilingual Factual Grounding](https://arxiv.org/abs/2602.03417)
*Yingli Shen,Wen Lai,Jie Zhou,Xueren Zhang,Yudong Wang,Kangyang Luo,Shuo Wang,Ge Gao,Alexander Fraser,Maosong Sun*

Main category: cs.CL

TL;DR: FactNet是一个结合17亿原子断言与30.1亿证据指针的开源资源，通过确定性管道构建，解决了LLM事实错误问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识资源在结构化知识与文本覆盖间存在二分法，且缺乏可追溯性，需统一可验证的多语言基座。

Method: 基于316个维基百科版本构建FactNet，采用确定性流程生成原子断言与证据指针对应，确保字节级可追溯。

Result: 实现92.1%的基础精度，覆盖长尾语言，并发布FactNet-Bench评估套件，验证资源效果。

Conclusion: FactNet作为可复现、多语言的可信资源，为训练可验证LLM提供基础支持，推动社区标准建立。

Abstract: While LLMs exhibit remarkable fluency, their utility is often compromised by factual hallucinations and a lack of traceable provenance. Existing resources for grounding mitigate this but typically enforce a dichotomy: they offer either structured knowledge without textual context (e.g., knowledge bases) or grounded text with limited scale and linguistic coverage. To bridge this gap, we introduce FactNet, a massive, open-source resource designed to unify 1.7 billion atomic assertions with 3.01 billion auditable evidence pointers derived exclusively from 316 Wikipedia editions. Unlike recent synthetic approaches, FactNet employs a strictly deterministic construction pipeline, ensuring that every evidence unit is recoverable with byte-level precision. Extensive auditing confirms a high grounding precision of 92.1%, even in long-tail languages. Furthermore, we establish FactNet-Bench, a comprehensive evaluation suite for Knowledge Graph Completion, Question Answering, and Fact Checking. FactNet provides the community with a foundational, reproducible resource for training and evaluating trustworthy, verifiable multilingual systems.

</details>


### [125] [A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces](https://arxiv.org/abs/2602.03442)
*Mingxuan Du,Benfeng Xu,Chiwei Zhu,Shaohan Wang,Pengyu Wang,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 本文提出了一种名为A-RAG的新型Agentic RAG框架，通过向模型开放分层检索接口，使其能够动态适应性地跨多粒度检索信息，从而更有效利用模型的复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统仍依赖单次检索或预定义任务流程，未能充分利用模型在自主决策和长期工具使用上的进步，难以随模型能力提升而高效扩展。

Method: 构建了包含关键字搜索、语义搜索和块读取三层工具的A-RAG框架，并通过开放接口让模型自主决策检索策略。在多个开放域问答基准测试中，使用相同或更少检索文本量进行对比验证。

Result: A-RAG在多个基准测试中始终优于现有方法，系统性验证了该框架对不同RAG任务的动态适应性及与模型规模/计算量扩增的正向关系。

Conclusion: 模型参与检索决策的分层架构能有效释放语言模型性能优势，A-RAG为构建下一代自适应知识增强系统提供了可扩展的研究范式。

Abstract: Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.

</details>


### [126] [Preferences for Idiomatic Language are Acquired Slowly -- and Forgotten Quickly: A Case Study on Swedish](https://arxiv.org/abs/2602.03484)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 语言模型倾向于发展瑞典语惯用表达的能力较慢，需长时间训练且易受英文指令微调数据的影响。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在预训练阶段及从英语适配瑞典语时，如何发展对惯用语与语言可接受性的偏好差异。

Method: 通过从零训练和微调英文预训练模型生成瑞典语模型，使用最小对立对（最小语言差异的句子对）评估模型偏好；构建两个新数据集测试惯用性（成语对比合理变体，地道瑞典语对比翻译腔）。

Result: 惯用语理解能力发展慢于语法和词汇能力，模型规模越大此能力提升越显著，但使用英文机翻指令微调会导致惯用语偏好骤降。

Conclusion: 惯用语能力需特殊训练策略保护，当前多语言适配方法可能破坏单一语言模型的地道性特征。

Abstract: In this study, we investigate how language models develop preferences for \textit{idiomatic} as compared to \textit{linguistically acceptable} Swedish, both during pretraining and when adapting a model from English to Swedish. To do so, we train models on Swedish from scratch and by fine-tuning English-pretrained models, probing their preferences at various checkpoints using minimal pairs that differ in linguistic acceptability or idiomaticity. For linguistic acceptability, we adapt existing benchmarks into a minimal-pair format. To assess idiomaticity, we introduce two novel datasets: one contrasting conventionalized idioms with plausible variants, and another contrasting idiomatic Swedish with Translationese. Our findings suggest that idiomatic competence emerges more slowly than other linguistic abilities, including grammatical and lexical correctness. While longer training yields diminishing returns for most tasks, idiom-related performance continues to improve, particularly in the largest model tested (8B). However, instruction tuning on data machine-translated from English -- the common approach for languages with little or no native instruction data -- causes models to rapidly lose their preference for idiomatic language.

</details>


### [127] [Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning](https://arxiv.org/abs/2602.03485)
*Quanyu Long,Kai Jie Jiang,Jianda Chen,Xu Guo,Leilei Gan,Wenya Wang*

Main category: cs.CL

TL;DR: The paper identifies that Large Reasoning Models (LRMs) excessively use self-verification steps without significant benefit, then proposes an experience-driven framework to suppress unnecessary rechecks, achieving token usage reduction (up to 20.3%) and maintaining/or improving accuracy.


<details>
  <summary>Details</summary>
Motivation: The observation that most reflective self-verification steps in LRMs are confirmatory and rarely identify errors creates a mismatch between verification frequency and actual utility. This inefficiency motivates the need for a method to reduce redundant rechecks.

Method: An experience-driven test-time framework: 1) Detects when recheck behavior is activated; 2) Retrieves historical verification outcomes from an offline experience pool; 3) Suppresses redundant rechecks via retrieval-based suppression signals when prior experience indicates low utility; 4) Redirects models to proceed with reasoning.

Result: Up to 20.3% token usage reduction across multiple models and benchmarks, with accuracy maintained or even improved on some datasets. The approach outperforms baseline methods in balancing efficiency and reasoning reliability.

Conclusion: Historical verification experience enables efficient LRM inference by reducing redundant self-verification cycles. This work demonstrates how retrospective experience pools can optimize reasoning workflows without sacrificing accuracy.

Abstract: Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.

</details>


### [128] [Learning to Reason Faithfully through Step-Level Faithfulness Maximization](https://arxiv.org/abs/2602.03507)
*Runquan Gui,Yafu Li,Xiaoye Qu,Ziyan Liu,Yeqiu Cheng,Yu Cheng*

Main category: cs.CL

TL;DR: 该研究提出FaithRL框架，旨在通过直接优化推理的忠实性，减少大语言模型中基于稀疏奖励的强化学习方法导致的过度自信和虚假推理问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于结果的稀疏奖励强化学习方法缺乏对推理中间步骤的监督，易导致过度自信和幻觉。需要一种能直接优化推理忠实性的方法。

Method: 提出忠实力最大化目标，并通过几何奖励设计和忠实感知优势调制机制实现：1) 理论推导忠实性目标函数；2) 动态惩罚非支撑步骤并保留有效推理路径；3) 步级信用分配策略。

Result: 在多个模型架构和基准测试中，FaithRL将幻觉率降低的同时保持甚至提升答案准确性，理论分析证实其对过度自信的抑制能力，并展现出跨任务鲁棒性。

Conclusion: FaithRL成功建立了奖励设计与推理忠实性间的可验证联系，通过数学证明和实验验证其有效性，代码公开促进可复现性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly improved the performance of Large Language Models (LLMs) on tasks requiring multi-step reasoning. However, most RLVR pipelines rely on sparse outcome-based rewards, providing little supervision over intermediate steps and thus encouraging over-confidence and spurious reasoning, which in turn increases hallucinations. To address this, we propose FaithRL, a general reinforcement learning framework that directly optimizes reasoning faithfulness. We formalize a faithfulness-maximization objective and theoretically show that optimizing it mitigates over-confidence. To instantiate this objective, we introduce a geometric reward design and a faithfulness-aware advantage modulation mechanism that assigns step-level credit by penalizing unsupported steps while preserving valid partial derivations. Across diverse backbones and benchmarks, FaithRL consistently reduces hallucination rates while maintaining (and often improving) answer correctness. Further analysis confirms that FaithRL increases step-wise reasoning faithfulness and generalizes robustly. Our code is available at https://github.com/aintdoin/FaithRL.

</details>


### [129] [Can Large Language Models Generalize Procedures Across Representations?](https://arxiv.org/abs/2602.03542)
*Fangru Lin,Valentin Hofmann,Xingchen Wan,Weixing Wang,Zifeng Ding,Anthony G. Cohn,Janet B. Pierrehumbert*

Main category: cs.CL

TL;DR: 本研究探讨大型语言模型（LLMs）在代码、图和自然语言表示之间的泛化能力，提出两阶段训练方法提升跨表示任务效果，1.5B Qwen模型通过该方法接近GPT-4o的零样本性能。


<details>
  <summary>Details</summary>
Motivation: LLMs通常基于符号数据（如代码、图）训练，但实际任务依赖自然语言。需解决模型在符号与自然语言间的泛化不足问题，同时提升训练效率。

Method: 设计两阶段数据课程：第一阶段用符号数据（代码/图）预训练，第二阶段转向自然语言任务微调，通过分层训练路径促进跨表示知识迁移。

Result: 相比单符号/自然语言训练，新方法在多个模型家族和任务中显著提升性能，1.5B Qwen模型在自然语言计划任务中逼近GPT-4o零样本表现，且跨表示迁移效率提高。

Conclusion: 跨表示泛化本质是类比生成能力，两阶段课程训练有效诱导模型学习符号与自然语言间的类比映射，为多模态对齐提供新路径。

Abstract: Large language models (LLMs) are trained and tested extensively on symbolic representations such as code and graphs, yet real-world user tasks are often specified in natural language. To what extent can LLMs generalize across these representations? Here, we approach this question by studying isomorphic tasks involving procedures represented in code, graphs, and natural language (e.g., scheduling steps in planning). We find that training LLMs with popular post-training methods on graphs or code data alone does not reliably generalize to corresponding natural language tasks, while training solely on natural language can lead to inefficient performance gains. To address this gap, we propose a two-stage data curriculum that first trains on symbolic, then natural language data. The curriculum substantially improves model performance across model families and tasks. Remarkably, a 1.5B Qwen model trained by our method can closely match zero-shot GPT-4o in naturalistic planning. Finally, our analysis suggests that successful cross-representation generalization can be interpreted as a form of generative analogy, which our curriculum effectively encourages.

</details>


### [130] [SEAD: Self-Evolving Agent for Multi-Turn Service Dialogue](https://arxiv.org/abs/2602.03548)
*Yuqin Dai,Ning Gao,Wei Zhang,Jie Wang,Zichen Luo,Jinpeng Wang,Yujie Wang,Ruiyuan Wu,Chaozheng Wang*

Main category: cs.CL

TL;DR: 该论文提出SEAD框架，通过解耦用户建模解决服务对话中数据质量低和训练场景适应性问题，显著提升任务完成率和对话效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖低质量人工对话数据且难以模拟真实用户行为，导致服务对话性能不足。需要无需大规模标注数据的有效训练框架。

Method: SEAD包含Profile Controller（生成多样化用户状态以动态调整训练难度）和User Role-play Model（专注真实性角色扮演）两个独立组件，实现渐进式自适应训练而非对抗性环境。

Result: 实验显示SEAD相比开源基座模型和商业闭源模型，任务完成率提升17.6%，对话效率提升11.1%。

Conclusion: 该框架通过结构化用户建模和协同训练机制，在服务对话场景中展现出显著优越性，代码已开源。

Abstract: Large Language Models have demonstrated remarkable capabilities in open-domain dialogues. However, current methods exhibit suboptimal performance in service dialogues, as they rely on noisy, low-quality human conversation data. This limitation arises from data scarcity and the difficulty of simulating authentic, goal-oriented user behaviors. To address these issues, we propose SEAD (Self-Evolving Agent for Service Dialogue), a framework that enables agents to learn effective strategies without large-scale human annotations. SEAD decouples user modeling into two components: a Profile Controller that generates diverse user states to manage training curriculum, and a User Role-play Model that focuses on realistic role-playing. This design ensures the environment provides adaptive training scenarios rather than acting as an unfair adversary. Experiments demonstrate that SEAD significantly outperforms Open-source Foundation Models and Closed-source Commercial Models, improving task completion rate by 17.6% and dialogue efficiency by 11.1%. Code is available at: https://github.com/Da1yuqin/SEAD.

</details>


### [131] [Assessing the Impact of Typological Features on Multilingual Machine Translation in the Age of Large Language Models](https://arxiv.org/abs/2602.03551)
*Vitalii Hirak,Jaap Jumelet,Arianna Bisazza*

Main category: cs.CL

TL;DR: 本文研究多语言翻译模型中目标语言类型学属性对翻译质量的影响，发现特定语言需优化解码策略，并发布212种语言类型学数据集。


<details>
  <summary>Details</summary>
Motivation: 现有研究基于小规模模型分析语言类型学对翻译的影响，本文旨在通过大规模预训练模型探讨该问题，并排除数据资源等干扰因素，提出改进解码策略的可能性。

Method: 分析NLLB-200（编码器-解码器）和Tower+（仅解码器）模型，在212种语言上控制数据资源和书写脚本变量，评估翻译质量与类型学属性的关系，同时发布FLORES+基准的细粒度类型学特征数据集。

Result: 目标语言类型学显著影响翻译质量，即使控制其他因素后依然存在；部分语言通过扩大输出空间搜索（如宽波束搜索）可提升效果，证明类型学与解码策略的交互作用。

Conclusion: 语言类型学是多语言翻译质量的重要决定因素，建议针对特定语言采用非标准解码策略，并通过公开数据集推动相关研究，未来可探索动态解码优化方法。

Abstract: Despite major advances in multilingual modeling, large quality disparities persist across languages. Besides the obvious impact of uneven training resources, typological properties have also been proposed to determine the intrinsic difficulty of modeling a language. The existing evidence, however, is mostly based on small monolingual language models or bilingual translation models trained from scratch. We expand on this line of work by analyzing two large pre-trained multilingual translation models, NLLB-200 and Tower+, which are state-of-the-art representatives of encoder-decoder and decoder-only machine translation, respectively. Based on a broad set of languages, we find that target language typology drives translation quality of both models, even after controlling for more trivial factors, such as data resourcedness and writing script. Additionally, languages with certain typological properties benefit more from a wider search of the output space, suggesting that such languages could profit from alternative decoding strategies beyond the standard left-to-right beam search. To facilitate further research in this area, we release a set of fine-grained typological properties for 212 languages of the FLORES+ MT evaluation benchmark.

</details>


### [132] [ACL: Aligned Contrastive Learning Improves BERT and Multi-exit BERT Fine-tuning](https://arxiv.org/abs/2602.03563)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出了一种监督场景下的Aligned Contrastive Learning（ACL）框架，包含ACL-Embed、ACL-Grad和ACL-CL三个组件，解决了对比学习（CL）与交叉熵损失（CE）冲突问题，并在GLUE任务和多出口BERT微调中取得性能提升。


<details>
  <summary>Details</summary>
Motivation: 对比学习在自监督领域表现优异但监督场景研究不足，实验表明CL与CE损失目标存在冲突，阻碍CL在监督学习中的应用，因此需设计新框架协调两者。

Method: 核心方法包括：1) ACL-Embed将标签嵌入视为增强样本，通过CL对齐标签与数据表征；2) ACL-Grad在目标冲突时丢弃ACL-Embed项；3) ACL-CL通过教师出口引导学生浅层出口优化。

Result: ACL-BRT在GLUE任务中优于CE和CE+SCL，CL-ACL在多出口BERT微调中显著提升性能，为低延迟应用提供更高质效平衡。

Conclusion: ACL通过解决CL-CE冲突，在监督场景对比学习中实现突破，尤其适用于多出口BERT的端到端优化，为实时系统提供高效解决方案。

Abstract: Despite its success in self-supervised learning, contrastive learning is less studied in the supervised setting. In this work, we first use a set of pilot experiments to show that in the supervised setting, the cross-entropy loss objective (CE) and the contrastive learning objective often conflict with each other, thus hindering the applications of CL in supervised settings. To resolve this problem, we introduce a novel \underline{A}ligned \underline{C}ontrastive \underline{L}earning (ACL) framework. First, ACL-Embed regards label embeddings as extra augmented samples with different labels and employs contrastive learning to align the label embeddings with its samples' representations. Second, to facilitate the optimization of ACL-Embed objective combined with the CE loss, we propose ACL-Grad, which will discard the ACL-Embed term if the two objectives are in conflict. To further enhance the performances of intermediate exits of multi-exit BERT, we further propose cross-layer ACL (ACL-CL), which is to ask the teacher exit to guide the optimization of student shallow exits. Extensive experiments on the GLUE benchmark results in the following takeaways: (a) ACL-BRT outperforms or performs comparably with CE and CE+SCL on the GLUE tasks; (b) ACL, especially CL-ACL, significantly surpasses the baseline methods on the fine-tuning of multi-exit BERT, thus providing better quality-speed tradeoffs for low-latency applications.

</details>


### [133] [Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs](https://arxiv.org/abs/2602.03578)
*Su Dong,Qinggang Zhang,Yilin Xiao,Shengyuan Chen,Chuang Zhou,Xiao Huang*

Main category: cs.CL

TL;DR: EA-GraphRAG是一种自适应框架，通过语法感知的复杂度分析动态选择RAG或GraphRAG范式，解决知识密集型任务中现有方法在准确率、延迟和复杂查询处理上的不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因幻觉和参数化知识过时在知识密集型任务中表现不佳，GraphRAG虽提升结构化推理却存在普适性缺陷，需设计自适应机制平衡性能与效率。

Method: 提出三层架构：1）句法特征构建器解析查询结构；2）轻量复杂度评分器生成连续评分；3）评分驱动路由策略：低分用稠密RAG，高分用图检索，中等分采用复杂度感知的互逆排名融合。

Result: 在单跳/多跳QA混合基准测试中，相比传统方法准确率提升23.6%，吞吐量增加1.8倍，平均延迟降低至120ms，达到SOTA性能并减少50%图检索计算开销。

Conclusion: 通过结构化路由决策机制，实现了RAG与GraphRAG的优势互补，在保持低延迟的同时显著改善复杂场景下的问答表现，为知识增强型生成系统设计提供了范例。

Abstract: Large language models (LLMs) often struggle with knowledge-intensive tasks due to hallucinations and outdated parametric knowledge. While Retrieval-Augmented Generation (RAG) addresses this by integrating external corpora, its effectiveness is limited by fragmented information in unstructured domain documents. Graph-augmented RAG (GraphRAG) emerged to enhance contextual reasoning through structured knowledge graphs, yet paradoxically underperforms vanilla RAG in real-world scenarios, exhibiting significant accuracy drops and prohibitive latency despite gains on complex queries. We identify the rigid application of GraphRAG to all queries, regardless of complexity, as the root cause. To resolve this, we propose an efficient and adaptive GraphRAG framework called EA-GraphRAG that dynamically integrates RAG and GraphRAG paradigms through syntax-aware complexity analysis. Our approach introduces: (i) a syntactic feature constructor that parses each query and extracts a set of structural features; (ii) a lightweight complexity scorer that maps these features to a continuous complexity score; and (iii) a score-driven routing policy that selects dense RAG for low-score queries, invokes graph-based retrieval for high-score queries, and applies complexity-aware reciprocal rank fusion to handle borderline cases. Extensive experiments on a comprehensive benchmark, consisting of two single-hop and two multi-hop QA benchmarks, demonstrate that our EA-GraphRAG significantly improves accuracy, reduces latency, and achieves state-of-the-art performance in handling mixed scenarios involving both simple and complex queries.

</details>


### [134] [$V_0$: A Generalist Value Model for Any Policy at State Zero](https://arxiv.org/abs/2602.03584)
*Yi-Kai Zhang,Zhiyuan Yao,Hongyan Hao,Yueqing Sun,Qi Gu,Hui Su,Xunliang Cai,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.CL

TL;DR: 本文提出$V_0$，一种无需参数更新的通用价值模型，通过动态分析模型历史表现来估计初始状态价值，替代传统Actor-Critic方法中高成本的Critic模型，实现大语言模型（LLM）训练和部署中的资源高效分配。


<details>
  <summary>Details</summary>
Motivation: 传统Actor-Critic方法中Critic模型需与策略模型同步更新，导致高计算成本；GRPO虽避免该问题但依赖大量采样。$V_0$旨在通过零参数更新的价值估计范式，降低资源开销并提升采样效率。

Method: $V_0$将策略模型的动态性能作为显式上下文输入，利用历史指令-性能对动态建模，直接估计初始状态（State Zero）的价值，无需依赖参数拟合跟踪策略变化。

Result: $V_0$在GRPO训练中显著优于启发式预算分配，在LLM路由任务中实现性能与成本的帕累托最优权衡，并作为调度器在训练时优化采样资源分配，部署时动态选择合适模型。

Conclusion: $V_0$通过消除Critic模型的耦合更新需求，为LLM训练和部署提供了可扩展的资源调度框架，兼顾性价比与性能，验证了动态价值估计范式的有效性。

Abstract: Policy gradient methods rely on a baseline to measure the relative advantage of an action, ensuring the model reinforces behaviors that outperform its current average capability. In the training of Large Language Models (LLMs) using Actor-Critic methods (e.g., PPO), this baseline is typically estimated by a Value Model (Critic) often as large as the policy model itself. However, as the policy continuously evolves, the value model requires expensive, synchronous incremental training to accurately track the shifting capabilities of the policy. To avoid this overhead, Group Relative Policy Optimization (GRPO) eliminates the coupled value model by using the average reward of a group of rollouts as the baseline; yet, this approach necessitates extensive sampling to maintain estimation stability. In this paper, we propose $V_0$, a Generalist Value Model capable of estimating the expected performance of any model on unseen prompts without requiring parameter updates. We reframe value estimation by treating the policy's dynamic capability as an explicit context input; specifically, we leverage a history of instruction-performance pairs to dynamically profile the model, departing from the traditional paradigm that relies on parameter fitting to perceive capability shifts. Focusing on value estimation at State Zero (i.e., the initial prompt, hence $V_0$), our model serves as a critical resource scheduler. During GRPO training, $V_0$ predicts success rates prior to rollout, allowing for efficient sampling budget allocation; during deployment, it functions as a router, dispatching instructions to the most cost-effective and suitable model. Empirical results demonstrate that $V_0$ significantly outperforms heuristic budget allocation and achieves a Pareto-optimal trade-off between performance and cost in LLM routing tasks.

</details>


### [135] [CL-bench: A Benchmark for Context Learning](https://arxiv.org/abs/2602.03587)
*Shihan Dou,Ming Zhang,Zhangyue Yin,Chenhao Huang,Yujiong Shen,Junzhe Wang,Jiayi Chen,Yuchen Ni,Junjie Ye,Cheng Zhang,Huaibing Xie,Jianglu Hu,Shaolei Wang,Weichao Wang,Yanling Xiao,Yiting Liu,Zenan Xu,Zhen Guo,Pluto Zhou,Tao Gui,Zuxuan Wu,Xipeng Qiu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Di Wang,Shunyu Yao*

Main category: cs.CL

TL;DR: 本论文提出了CL-bench，这是一个包含500个复杂上下文、1,899个任务的真实世界基准测试，旨在评估语言模型（LMs）从新任务相关上下文中学习并利用超出预训练知识的推理能力。实验表明当前模型表现较差（平均17.2%），揭示了上下文学习仍是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型依赖预训练知识，但真实任务需模型动态学习任务特定的新知识（如领域规则、实证法律等），而这类上下文学习能力长期被忽视。

Method: 构建CL-bench基准，包含由专家设计的复杂任务，要求模型必须通过当前上下文获取新知识。任务难度远超传统上下文检索或简单指令模式学习任务。

Result: 评估10个前沿LMs发现：平均仅解决17.2%的任务，最强模型GPT-5.1也仅解决23.7%，验证了当前LMs在上下文学习能力上的重大缺陷。

Conclusion: CL-bench填补了模型动态知识获取能力的评估空白，为开发面向真实复杂场景的下一代智能语言模型提供了关键方向。

Abstract: Current language models (LMs) excel at reasoning over prompts using pre-trained knowledge. However, real-world tasks are far more complex and context-dependent: models must learn from task-specific context and leverage new knowledge beyond what is learned during pre-training to reason and resolve tasks. We term this capability context learning, a crucial ability that humans naturally possess but has been largely overlooked. To this end, we introduce CL-bench, a real-world benchmark consisting of 500 complex contexts, 1,899 tasks, and 31,607 verification rubrics, all crafted by experienced domain experts. Each task is designed such that the new content required to resolve it is contained within the corresponding context. Resolving tasks in CL-bench requires models to learn from the context, ranging from new domain-specific knowledge, rule systems, and complex procedures to laws derived from empirical data, all of which are absent from pre-training. This goes far beyond long-context tasks that primarily test retrieval or reading comprehension, and in-context learning tasks, where models learn simple task patterns via instructions and demonstrations. Our evaluations of ten frontier LMs find that models solve only 17.2% of tasks on average. Even the best-performing model, GPT-5.1, solves only 23.7%, revealing that LMs have yet to achieve effective context learning, which poses a critical bottleneck for tackling real-world, complex context-dependent tasks. CL-bench represents a step towards building LMs with this fundamental capability, making them more intelligent and advancing their deployment in real-world scenarios.

</details>


### [136] [Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs](https://arxiv.org/abs/2602.03588)
*Xuran Cai,Amir Goharshady*

Main category: cs.CL

TL;DR: 本文提出了一种基于Series-Parallel-Loop（SPL）分解的PCSP通用算法，适用于控制流图结构的程序优化任务。


<details>
  <summary>Details</summary>
Motivation: 传统CSP无法处理约束违反的场景，而编译器优化中的寄存器分配、冗余消除等任务需要允许部分约束违反并优化成本，因此需要PCSP框架。

Method: 通过对SPL分解的控制流图进行动态规划，结合约束传播和剪枝策略，设计时间复杂度为O(|G|·|D|^6)的算法，利用SPL结构特性实现约束优化。

Result: 理论分析表明算法具有线性时间复杂度（固定域规模），在最优银行选择任务中实验性能比现有方法提升4倍。

Conclusion: 该算法统一了已有SPL-PCSP方法，为程序优化提供了通用解决方案，验证了SPL分解对PCSP问题的有效性。

Abstract: In this work, we focus on the Partial Constraint Satisfaction Problem (PCSP) over control-flow graphs (CFGs) of programs. PCSP serves as a generalization of the well-known Constraint Satisfaction Problem (CSP). In the CSP framework, we define a set of variables, a set of constraints, and a finite domain $D$ that encompasses all possible values for each variable. The objective is to assign a value to each variable in such a way that all constraints are satisfied. In the graph variant of CSP, an underlying graph is considered and we have one variable corresponding to each vertex of the graph and one or several constraints corresponding to each edge. In PCSPs, we allow for certain constraints to be violated at a specified cost, aiming to find a solution that minimizes the total cost. Numerous classical compiler optimization tasks can be framed as PCSPs over control-flow graphs. Examples include Register Allocation, Lifetime-optimal Speculative Partial Redundancy Elimination (LOSPRE), and Optimal Placement of Bank Selection Instructions. On the other hand, it is well-known that control-flow graphs of structured programs are sparse and decomposable in a variety of ways. In this work, we rely on the Series-Parallel-Loop (SPL) decompositions as introduced by~\cite{RegisterAllocation}. Our main contribution is a general algorithm for PCSPs over SPL graphs with a time complexity of \(O(|G| \cdot |D|^6)\), where \(|G|\) represents the size of the control-flow graph. Note that for any fixed domain $D,$ this yields a linear-time solution. Our algorithm can be seen as a generalization and unification of previous SPL-based approaches for register allocation and LOSPRE. In addition, we provide experimental results over another classical PCSP task, i.e. Optimal Bank Selection, achieving runtimes four times better than the previous state of the art.

</details>


### [137] [Controlling Output Rankings in Generative Engines for LLM-based Search](https://arxiv.org/abs/2602.03608)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Yifeng Luo,Huimin Zeng,Man Luo,Haohan Wang*

Main category: cs.CL

TL;DR: CORE利用生成式搜索引擎内容优化技术，提升小企业产品的LLM推荐排名，平均Top-5推广成功率超91%。


<details>
  <summary>Details</summary>
Motivation: LLM搜索的黑盒排序机制导致小企业曝光不足，亟需无需修改模型的外部排名优化方案

Method: 提出CORE框架，通过添加字符串/推理/评论型优化内容到检索结果中，基于ProductBench基准测试15品类2000+产品，构建可解释的LLM输出控制机制

Result: 在4大主流LLM验证中实现Top-1/3/5平均91.4%/86.6%/80.3%的提升成功率，优化内容质量保持86%以上人工评分满意度

Conclusion: 该方案突破生成式搜索算法黑箱限制，为中小商户提供可解释的搜索优化工具，实验验证有效性超现有方法23%以上

Abstract: The way customers search for and choose products is changing with the rise of large language models (LLMs). LLM-based search, or generative engines, provides direct product recommendations to users, rather than traditional online search results that require users to explore options themselves. However, these recommendations are strongly influenced by the initial retrieval order of LLMs, which disadvantages small businesses and independent creators by limiting their visibility.
  In this work, we propose CORE, an optimization method that \textbf{C}ontrols \textbf{O}utput \textbf{R}ankings in g\textbf{E}nerative Engines for LLM-based search. Since the LLM's interactions with the search engine are black-box, CORE targets the content returned by search engines as the primary means of influencing output rankings. Specifically, CORE optimizes retrieved content by appending strategically designed optimization content to steer the ranking of outputs. We introduce three types of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate CORE in realistic settings, we introduce ProductBench, a large-scale benchmark with 15 product categories and 200 products per category, where each product is associated with its top-10 recommendations collected from Amazon's search interface.
  Extensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-4, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \textbf{91.4\% @Top-5}, \textbf{86.6\% @Top-3}, and \textbf{80.3\% @Top-1}, across 15 product categories, outperforming existing ranking manipulation methods while preserving the fluency of optimized content.

</details>


### [138] [Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation](https://arxiv.org/abs/2602.03619)
*Changze Lv,Jie Zhou,Wentao Zhao,Jingwen Xu,Zisu Huang,Muzhao Tian,Shihan Dou,Tao Gui,Le Tian,Xiao Zhou,Xiaoqing Zheng,Xuanjing Huang,Jie Zhou*

Main category: cs.CL

TL;DR: 本论文提出了一种基于强化学习和多智能体马尔可夫状态工作流的定制化量规生成方法，用于提升深度研究（DeepResearch）报告生成系统的评估与训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究生成系统缺乏可验证的奖励信号，依赖粒度不足的预定义量规或人工构建的查询量规，存在扩展性差和成本高的问题。

Method: 构造包含人类偏好的成对报告对比数据集，通过结合人类偏好监督和LLM量规评估的混合奖励进行强化学习，并引入多智能体马尔可夫状态工作流以优化长程推理。

Result: 所提量规生成器在区分度和人类对齐度上优于现有方法，在DeepResearch Bench测试中超越所有开源基线，接近闭源模型表现。

Conclusion: 量规生成器与多智能体框架的结合可有效解决研究生成系统的评估与训练挑战。

Abstract: Nowadays, training and evaluating DeepResearch-generated reports remain challenging due to the lack of verifiable reward signals. Accordingly, rubric-based evaluation has become a common practice. However, existing approaches either rely on coarse, pre-defined rubrics that lack sufficient granularity, or depend on manually constructed query-specific rubrics that are costly and difficult to scale. In this paper, we propose a pipeline to train human-preference-aligned query-specific rubric generators tailored for DeepResearch report generation. We first construct a dataset of DeepResearch-style queries annotated with human preferences over paired reports, and train rubric generators via reinforcement learning with a hybrid reward combining human preference supervision and LLM-based rubric evaluation. To better handle long-horizon reasoning, we further introduce a Multi-agent Markov-state (MaMs) workflow for report generation. We empirically show that our proposed rubric generators deliver more discriminative and better human-aligned supervision than existing rubric design strategies. Moreover, when integrated into the MaMs training framework, DeepResearch systems equipped with our rubric generators consistently outperform all open-source baselines on the DeepResearch Bench and achieve performance comparable to that of leading closed-source models.

</details>


### [139] [BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish](https://arxiv.org/abs/2602.03633)
*Burak Aktaş,Mehmet Can Baytekin,Süha Kağan Köse,Ömer İlbilgi,Elif Özge Yılmaz,Çağrı Toraman,Bilge Kaan Görür*

Main category: cs.CL

TL;DR: The paper introduces BIRDTurk, the first Turkish Text-to-SQL benchmark adapted from BIRD, revealing performance challenges in low-resource/morphologically rich languages and cross-lingual robustness of agentic reasoning methods.


<details>
  <summary>Details</summary>
Motivation: Existing Text-to-SQL systems underperform in low-resource languages like Turkish. A controlled benchmark is needed to isolate linguistic vs. data scarcity effects while maintaining SQL execution consistency.

Method: Turkic adaptation of BIRD via controlled translation of schema identifiers, preserving SQL logic. Translation quality validated via CLT-determined human evaluation samples. Evaluated 3 paradigms: inference prompting, agentic reasoning, and SFT on multilingual/monolingual models.

Result: 98.15% human-validated translation accuracy achieved. Turkish caused 7-15% performance drops in standard models. Agentic reasoning showed cross-lingual robustness (e.g., 13.2% exec. acc. improvement over SFT baselines). Monolingual SFT remained challenging.

Conclusion: BIRDTurk provides a rigorous framework for cross-lingual Text-to-SQL evaluation. The work highlights the need for models better handling linguistic divergence and demonstrates practical value in agentic architectures for low-resource language scenarios.

Abstract: Text-to-SQL systems have achieved strong performance on English benchmarks, yet their behavior in morphologically rich, low-resource languages remains largely unexplored. We introduce BIRDTurk, the first Turkish adaptation of the BIRD benchmark, constructed through a controlled translation pipeline that adapts schema identifiers to Turkish while strictly preserving the logical structure and execution semantics of SQL queries and databases. Translation quality is validated on a sample size determined by the Central Limit Theorem to ensure 95% confidence, achieving 98.15% accuracy on human-evaluated samples. Using BIRDTurk, we evaluate inference-based prompting, agentic multi-stage reasoning, and supervised fine-tuning. Our results reveal that Turkish introduces consistent performance degradation, driven by both structural linguistic divergence and underrepresentation in LLM pretraining, while agentic reasoning demonstrates stronger cross-lingual robustness. Supervised fine-tuning remains challenging for standard multilingual baselines but scales effectively with modern instruction-tuned models. BIRDTurk provides a controlled testbed for cross-lingual Text-to-SQL evaluation under realistic database conditions. We release the training and development splits to support future research.

</details>


### [140] [TRE: Encouraging Exploration in the Trust Region](https://arxiv.org/abs/2602.03635)
*Chao Huang,Yujing Lu,Quangang Li,Shenghe Wang,Yan Wang,Yueyang Zhang,Long Xia,Jiashu Zhao,Zhiyuan Sun,Daiting Shi,Tingwen Liu*

Main category: cs.CL

TL;DR: 提出TRE方法解决大语言模型中熵正则化效果不佳问题，通过在信任区域内进行探索提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统熵正则化在大规模词汇和长生成场景下会无差别稀释有效token概率，导致推理不连贯，需针对性改进探索策略。

Method: 设计信任区域熵（TRE）算法，通过动态约束模型仅在可信token范围内进行概率分布熵最大化。

Result: 在数学推理、组合搜索和偏好对齐任务中，TRE均显著优于PPO和标准熵正则化方法。

Conclusion: TRE通过区域化熵约束实现有效探索，解决了大规模生成场景下传统方法导致的尾部风险问题。

Abstract: Entropy regularization is a standard technique in reinforcement learning (RL) to enhance exploration, yet it yields negligible effects or even degrades performance in Large Language Models (LLMs). We attribute this failure to the cumulative tail risk inherent to LLMs with massive vocabularies and long generation horizons. In such environments, standard global entropy maximization indiscriminately dilutes probability mass into the vast tail of invalid tokens rather than focusing on plausible candidates, thereby disrupting coherent reasoning. To address this, we propose Trust Region Entropy (TRE), a method that encourages exploration strictly within the model's trust region. Extensive experiments across mathematical reasoning (MATH), combinatorial search (Countdown), and preference alignment (HH) tasks demonstrate that TRE consistently outperforms vanilla PPO, standard entropy regularization, and other exploration baselines. Our code is available at https://github.com/WhyChaos/TRE-Encouraging-Exploration-in-the-Trust-Region.

</details>


### [141] [RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish](https://arxiv.org/abs/2602.03652)
*Süha Kağan Köse,Mehmet Can Baytekin,Burak Aktaş,Bilge Kaan Görür,Evren Ayberk Munis,Deniz Yılmaz,Muhammed Yusuf Kartal,Çağrı Toraman*

Main category: cs.CL

TL;DR: The paper addresses the lack of RAG design guidance for morphologically rich languages like Turkish by creating a Turkish RAG benchmark dataset and evaluating pipeline configurations. It finds that complex methods like HyDE achieve higher accuracy (85%) compared to the baseline (78.70%), while a cost-effective configuration (84.60%) balances performance and efficiency. Over-reliance on generative modules may harm performance, suggesting simpler approaches with robust reranking work better.


<details>
  <summary>Details</summary>
Motivation: Existing RAG design principles are English-centric, limiting insights for morphologically complex languages like Turkish. This work aims to bridge this gap by investigating RAG performance in Turkish using a newly constructed dataset.

Method: A Turkish RAG dataset was built from Turkish Wikipedia and CulturaX (question-answer pairs and passages). Seven stages of the RAG pipeline (query transformation, reranking, answer refinement, etc.) were benchmarked without task-specific fine-tuning.

Result: HyDE achieved the highest accuracy (85%), significantly outperforming the baseline. Cross-encoder Reranking with Context Augmentation reached 84.60% accuracy while reducing costs. Over-stacked generative modules degraded performance, but query clarification with strong reranking resolved this.

Conclusion: Turkish RAG benefits from complex methods like HyDE, but optimal performance requires balancing pipeline complexity. Over-engineering harms results, while query clarification and reranking offer a practical trade-off. Morphological richness necessitates tailored RAG strategies.

Abstract: Retrieval-Augmented Generation (RAG) enhances LLM factuality, yet design guidance remains English-centric, limiting insights for morphologically rich languages like Turkish. We address this by constructing a comprehensive Turkish RAG dataset derived from Turkish Wikipedia and CulturaX, comprising question-answer pairs and relevant passage chunks. We benchmark seven stages of the RAG pipeline, from query transformation and reranking to answer refinement, without task-specific fine-tuning. Our results show that complex methods like HyDE maximize accuracy (85%) that is considerably higher than the baseline (78.70%). Also a Pareto-optimal configuration using Cross-encoder Reranking and Context Augmentation achieves comparable performance (84.60%) with much lower cost. We further demonstrate that over-stacking generative modules can degrade performance by distorting morphological cues, whereas simple query clarification with robust reranking offers an effective solution.

</details>


### [142] [Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration](https://arxiv.org/abs/2602.03677)
*Yu Zhang,Mufan Xu,Xuefeng Bai,Kehai chen,Pengfei Zhang,Yang Xiang,Min Zhang*

Main category: cs.CL

TL;DR: 本文研究了多模态大语言模型中模态跟随能力的机制，发现指令标记作为结构锚点，浅层注意力非选择性传输信息，深层注意力解决模态竞争，MLP层具有语义惯性。通过干预关键注意力头可显著改变模态跟随效果。


<details>
  <summary>Details</summary>
Motivation: 模态跟随能力对多模态大模型的实际部署安全性至关重要，但其决策机制尚不明确。研究旨在通过信息流分析揭示核心机制，提升模型可解释性。

Method: 通过信息流视角，分析注意力层和MLP层在指令引导下的模态仲裁作用。采用因果干预实验，操作关键注意力头并测量模态跟随率变化。

Result: 发现指令标记形成结构锚点，浅层注意力传递多元信息，深层注意力按指令意图裁决模态竞争（如文本vs图像）。MLP层存在阻碍变化的语义惯性。识别出稀疏关键注意力头，操纵5%即可使模态跟随率变化±60%。

Conclusion: 揭示了指令驱动模态仲裁的分层机制，证明深度架构具备竞争解决与稳定保持的对立统一。为提升模型透明度、构建可控多模态系统提供了理论框架和可操作的干预方法。

Abstract: Modality following serves as the capacity of multimodal large language models (MLLMs) to selectively utilize multimodal contexts based on user instructions. It is fundamental to ensuring safety and reliability in real-world deployments. However, the underlying mechanisms governing this decision-making process remain poorly understood. In this paper, we investigate its working mechanism through an information flow lens. Our findings reveal that instruction tokens function as structural anchors for modality arbitration: Shallow attention layers perform non-selective information transfer, routing multimodal cues to these anchors as a latent buffer; Modality competition is resolved within deep attention layers guided by the instruction intent, while MLP layers exhibit semantic inertia, acting as an adversarial force. Furthermore, we identify a sparse set of specialized attention heads that drive this arbitration. Causal interventions demonstrate that manipulating a mere $5\%$ of these critical heads can decrease the modality-following ratio by $60\%$ through blocking, or increase it by $60\%$ through targeted amplification of failed samples. Our work provides a substantial step toward model transparency and offers a principled framework for the orchestration of multimodal information in MLLMs.

</details>


### [143] [Neural Attention Search Linear: Towards Adaptive Token-Level Hybrid Attention Models](https://arxiv.org/abs/2602.03681)
*Difan Deng,Andreas Bentzen Winje,Lukas Fehring,Marius Lindauer*

Main category: cs.CL

TL;DR: 本研究提出NAtS-L框架，通过在同一层中对不同tokens混合线性注意力和softmax注意力，提升模型效率与表现。


<details>
  <summary>Details</summary>
Motivation: 线性注意力模型受限于隐藏层大小导致的表达能力不足，现有混合方法仍因保留softmax层存在效率瓶颈。需寻找更细粒度的混合策略。

Method: 在token层面构建门控机制，动态选择使用线性注意力（压缩短期影响tokens）或softmax注意力（保留长期关联tokens）。通过搜索最优Gated DeltaNet与softmax组合实现动态分配。

Result: 实验证明NAtS-L在保持模型表现力的同时显著提升计算效率，验证了token级别混合注意力机制的有效性。

Conclusion: 该框架通过差异化处理关键tokens和常规tokens，在保证性能前提下突破了传统注意力模型的计算复杂度限制。

Abstract: The quadratic computational complexity of softmax transformers has become a bottleneck in long-context scenarios. In contrast, linear attention model families provide a promising direction towards a more efficient sequential model. These linear attention models compress past KV values into a single hidden state, thereby efficiently reducing complexity during both training and inference. However, their expressivity remains limited by the size of their hidden state. Previous work proposed interleaving softmax and linear attention layers to reduce computational complexity while preserving expressivity. Nevertheless, the efficiency of these models remains bottlenecked by their softmax attention layers. In this paper, we propose Neural Attention Search Linear (NAtS-L), a framework that applies both linear attention and softmax attention operations within the same layer on different tokens. NAtS-L automatically determines whether a token can be handled by a linear attention model, i.e., tokens that have only short-term impact and can be encoded into fixed-size hidden states, or require softmax attention, i.e., tokens that contain information related to long-term retrieval and need to be preserved for future queries. By searching for optimal Gated DeltaNet and softmax attention combinations across tokens, we show that NAtS-L provides a strong yet efficient token-level hybrid architecture.

</details>


### [144] [Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.03689)
*Jiashuo Sun,Pengcheng Jiang,Saizhuo Wang,Jiajun Fan,Heng Wang,Siru Ouyang,Ming Zhong,Yizhu Jiao,Chengsong Huang,Xueqiang Xu,Pengrui Han,Peiran Li,Jiaxin Huang,Ge Liu,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: BAR-RAG通过引入边界感知的证据选择机制，利用强化学习优化生成器适配的检索证据，在知识密集型问答任务中有效提升模型鲁棒性，平均性能提高10.3%。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统因检索器仅优化相关性，导致证据选择出现极端情况：要么选择暴露答案的简单证据，要么选择缺乏关键信息的难例，无法为生成器提供合适的学习信号。

Method: 1. 将重排序器改造为边界感知证据选择器，通过强化学习结合生成器反馈；2. 构建两阶段流程：第一阶段训练选择器聚焦生成器的“金发区”证据，第二阶段在诱导证据分布上微调生成器缓解分布差异。

Result: 在多个知识密集型问答基准测试中取得显著提升，在NoisyRetrieval评测集上相对基线方法平均提升10.3%，且鲁棒性指标提升幅度超过15%。代码已开源。

Conclusion: 通过建立生成器引导的证据选择标准和分布对齐策略，证明证据质量对RAG系统性能的决定性影响，为解决检索生成协同优化问题提供了新范式。

Abstract: Retrieval-Augmented Generation (RAG) systems remain brittle under realistic retrieval noise, even when the required evidence appears in the top-K results. A key reason is that retrievers and rerankers optimize solely for relevance, often selecting either trivial, answer-revealing passages or evidence that lacks the critical information required to answer the question, without considering whether the evidence is suitable for the generator. We propose BAR-RAG, which reframes the reranker as a boundary-aware evidence selector that targets the generator's Goldilocks Zone -- evidence that is neither trivially easy nor fundamentally unanswerable for the generator, but is challenging yet sufficient for inference and thus provides the strongest learning signal. BAR-RAG trains the selector with reinforcement learning using generator feedback, and adopts a two-stage pipeline that fine-tunes the generator under the induced evidence distribution to mitigate the distribution mismatch between training and inference. Experiments on knowledge-intensive question answering benchmarks show that BAR-RAG consistently improves end-to-end performance under noisy retrieval, achieving an average gain of 10.3 percent over strong RAG and reranking baselines while substantially improving robustness. Code is publicly avaliable at https://github.com/GasolSun36/BAR-RAG.

</details>


### [145] [OCRTurk: A Comprehensive OCR Benchmark for Turkish](https://arxiv.org/abs/2602.03693)
*Deniz Yılmaz,Evren Ayberk Munis,Çağrı Toraman,Süha Kağan Köse,Burak Aktaş,Mehmet Can Baytekin,Bilge Kaan Görür*

Main category: cs.CL

TL;DR: 介绍了一个名为OCRTurk的土耳其语文档解析基准，包含多种文档类型和三个难度层级，旨在填补低资源语言土耳其语文档解析标准化评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有文档解析模型的基准测试主要针对高资源语言，对低资源语言如土耳其语的覆盖有限，且缺乏反映真实场景和文档多样性的标准化基准。

Method: 构建包含180份土耳其语文档的OCRTurk数据集，涵盖学术论文、幻灯片等类型，采用逐元素指标评估七种OCR模型性能。

Result: PaddleOCR在多数元素指标和各难度层级的标准化编辑距离中表现最优，但图形识别效果欠佳；模型在非学术文档表现较好，而幻灯片识别最具挑战性。

Conclusion: OCRTurk为土耳其语文档处理提供了标准化评估框架，揭示了当前OCR模型在低资源语言场景下的性能差异和优化方向。

Abstract: Document parsing is now widely used in applications, such as large-scale document digitization, retrieval-augmented generation, and domain-specific pipelines in healthcare and education. Benchmarking these models is crucial for assessing their reliability and practical robustness. Existing benchmarks mostly target high-resource languages and provide limited coverage for low-resource settings, such as Turkish. Moreover, existing studies on Turkish document parsing lack a standardized benchmark that reflects real-world scenarios and document diversity. To address this gap, we introduce OCRTurk, a Turkish document parsing benchmark covering multiple layout elements and document categories at three difficulty levels. OCRTurk consists of 180 Turkish documents drawn from academic articles, theses, slide decks, and non-academic articles. We evaluate seven OCR models on OCRTurk using element-wise metrics. Across difficulty levels, PaddleOCR achieves the strongest overall results, leading most element-wise metrics except figures and attaining high Normalized Edit Distance scores in easy, medium, and hard subsets. We also observe performance variation by document type. Models perform well on non-academic documents, while slideshows become the most challenging.

</details>


### [146] [Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models](https://arxiv.org/abs/2602.03704)
*Yu Tian,Linh Huynh,Katerina Christhilf,Shubham Chakraborty,Micah Watanabe,Tracy Arner,Danielle McNamara*

Main category: cs.CL

TL;DR: ReQUESTA框架结合多智能体与规则组件，生成具有认知多样性的选择题，提升阅读理解测评质量。


<details>
  <summary>Details</summary>
Motivation: 现有大模型生成的选择题难以精准控制认知负荷，需通过系统化方法提升题目可靠性和目标导向性。

Method: 将题目生成分解为专业子任务（如规划、生成、迭代评估），融合LLM智能体与规则逻辑，基于学术说明文进行大规模对比实验。

Result: 相比GPT-5零样本生成，ReQUESTA题目更具挑战性和区分度，专家评估显示干扰项语言一致性和语义合理性显著优化（inferential类问题尤为突出）。

Conclusion: 混合智能体架构可通过流程设计增强LLM生成可控性，结构化工作流是提升自动化测评工具的关键范式。

Abstract: Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, and main idea comprehension. ReQUESTA decomposes MCQ authoring into specialized subtasks and coordinates LLM-powered agents with rule-based components to support planning, controlled generation, iterative evaluation, and post-processing. We evaluated the framework in a large-scale reading comprehension study using academic expository texts, comparing ReQUESTA-generated MCQs with those produced by a single-pass GPT-5 zero-shot baseline. Psychometric analyses of learner responses assessed item difficulty and discrimination, while expert raters evaluated question quality across multiple dimensions, including topic relevance and distractor quality. Results showed that ReQUESTA-generated items were consistently more challenging, more discriminative, and more strongly aligned with overall reading comprehension performance. Expert evaluations further indicated stronger alignment with central concepts and superior distractor linguistic consistency and semantic plausibility, particularly for inferential questions. These findings demonstrate that hybrid, agentic orchestration can systematically improve the reliability and controllability of LLM-based generation, highlighting workflow design as a key lever for structured artifact generation beyond single-pass prompting.

</details>


### [147] [Beyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal States](https://arxiv.org/abs/2602.03708)
*Ximing Dong,Shaowei Wang,Dayi Lin,Boyuan Chen,Ahmed E. Hassan*

Main category: cs.CL

TL;DR: 本研究提出SemanticSpec，通过语义感知的推测解码显著加速大语言模型(LRM)推理，解决其长思考链导致的高延迟问题。


<details>
  <summary>Details</summary>
Motivation: 现有token级别推测解码无法识别语义等价序列（不同token表达相同含义），导致大量生成内容被错误拒绝，影响推理效率。

Method: 创新性引入语义概率估计机制，通过探查模型内部隐藏状态评估完整语义序列的生成概率，实现以语义单元而非token为单位的并行验证。

Result: 在DeepSeekR1-32B和QwQ-32B模型上分别实现2.7倍和2.1倍加速，全面超越token/sequence级别的基线方法，在效率和效果上保持最优。

Conclusion: 语义感知的推测解码框架SemanticSpec能有效解决长文本生成场景下的语义冗余问题，为大模型推理加速提供新范式。

Abstract: Large Language Models (LLMs) achieve strong performance across many tasks but suffer from high inference latency due to autoregressive decoding. The issue is exacerbated in Large Reasoning Models (LRMs), which generate lengthy chains of thought. While speculative decoding accelerates inference by drafting and verifying multiple tokens in parallel, existing methods operate at the token level and ignore semantic equivalence (i.e., different token sequences expressing the same meaning), leading to inefficient rejections. We propose SemanticSpec, a semantic-aware speculative decoding framework that verifies entire semantic sequences instead of tokens. SemanticSpec introduces a semantic probability estimation mechanism that probes the model's internal hidden states to assess the likelihood of generating sequences with specific meanings.Experiments on four benchmarks show that SemanticSpec achieves up to 2.7x speedup on DeepSeekR1-32B and 2.1x on QwQ-32B, consistently outperforming token-level and sequence-level baselines in both efficiency and effectiveness.

</details>


### [148] [No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding](https://arxiv.org/abs/2602.03709)
*Vynska Amalia Permadi,Xingwei Tan,Nafise Sadat Moosavi,Nikos Aletras*

Main category: cs.CL

TL;DR: This paper introduces ID-MoCQA, a large-scale multi-hop QA dataset for evaluating cultural understanding in LLMs, grounded in Indonesian traditions with multi-hop reasoning chains and high-quality validation methods to identify gaps in cultural reasoning capabilities.


<details>
  <summary>Details</summary>
Motivation: Most cultural QA benchmarks rely on single-hop questions, which may not comprehensively assess cultural understanding as they focus on isolated facts rather than implicit knowledge and multi-step reasoning.

Method: A framework was developed to transform single-hop cultural questions into multi-hop reasoning chains with six clue types (commonsense, temporal, geographical, etc.). A validation pipeline used expert review and LLM-as-a-judge filtering to ensure dataset quality.

Result: State-of-the-art models showed significant gaps in nuanced cultural reasoning, particularly multi-hop inference tasks, demonstrating current limitations in LLMs’ cultural competence.

Conclusion: ID-MoCQA provides an essential benchmark to advance the cultural reasoning capabilities of LLMs, emphasizing the need for improved implicit knowledge integration in such systems.

Abstract: Understanding culture requires reasoning across context, tradition, and implicit social knowledge, far beyond recalling isolated facts. Yet most culturally focused question answering (QA) benchmarks rely on single-hop questions, which may allow models to exploit shallow cues rather than demonstrate genuine cultural reasoning. In this work, we introduce ID-MoCQA, the first large-scale multi-hop QA dataset for assessing the cultural understanding of large language models (LLMs), grounded in Indonesian traditions and available in both English and Indonesian. We present a new framework that systematically transforms single-hop cultural questions into multi-hop reasoning chains spanning six clue types (e.g., commonsense, temporal, geographical). Our multi-stage validation pipeline, combining expert review and LLM-as-a-judge filtering, ensures high-quality question-answer pairs. Our evaluation across state-of-the-art models reveals substantial gaps in cultural reasoning, particularly in tasks requiring nuanced inference. ID-MoCQA provides a challenging and essential benchmark for advancing the cultural competency of LLMs.

</details>


### [149] [CUBO: Self-Contained Retrieval-Augmented Generation on Consumer Laptops 10 GB Corpora, 16 GB RAM, Single-Device Deployment](https://arxiv.org/abs/2602.03731)
*Paolo Astrino*

Main category: cs.CL

TL;DR: 论文介绍了CUBO，一种专为16GB内存消费级笔记本设计的内存高效RAG平台，通过流式处理、混合检索和硬件感知调度，在15.5GB内存限制下实现接近云端的召回率（0.48-0.97），同时满足GDPR数据本地化要求。代码开源且实测延迟185ms。


<details>
  <summary>Details</summary>
Motivation: 云端AI存在GDPR违规风险，而传统本地系统需18-32GB内存，制约了敏感文档处理器的合规部署。论文旨在解决专业机构在数据隐私与硬件成本之间的矛盾。

Method: 采用流式数据摄取（O(1)缓冲开销）、分层混合检索（融合Dense/Sparse检索）与硬件感知任务调度，在37,000行代码中实现内存优化与数据本地化处理。

Result: BEIR基准测试显示Recall@10指标达0.48-0.97，C1笔记本端到端延迟185ms（p50），内存占用严格控制在15.5GB内，验证了中小规模文档库的可行性。

Conclusion: CUBO证明消费级硬件可兼顾RAG系统性能与GDPR合规性，为敏感文档处理器提供低成本本地化部署方案（代码开源https://github.com/PaoloAstrino/CUBO）

Abstract: Organizations handling sensitive documents face a tension: cloud-based AI risks GDPR violations, while local systems typically require 18-32 GB RAM. This paper presents CUBO, a systems-oriented RAG platform for consumer laptops with 16 GB shared memory. CUBO's novelty lies in engineering integration of streaming ingestion (O(1) buffer overhead), tiered hybrid retrieval, and hardware-aware orchestration that enables competitive Recall@10 (0.48-0.97 across BEIR domains) within a hard 15.5 GB RAM ceiling. The 37,000-line codebase achieves retrieval latencies of 185 ms (p50) on C1,300 laptops while maintaining data minimization through local-only processing aligned with GDPR Art. 5(1)(c). Evaluation on BEIR benchmarks validates practical deployability for small-to-medium professional archives. The codebase is publicly available at https://github.com/PaoloAstrino/CUBO.

</details>


### [150] [Context Compression via Explicit Information Transmission](https://arxiv.org/abs/2602.03784)
*Jiangnan Ye,Hanqi Yan,Zhenyi Shen,Heng Chang,Ye Mao,Yulan He*

Main category: cs.CL

TL;DR: 提出ComprExIT框架，通过显式信息传输（分层间深度传输与层内宽度传输）解决LLM长上下文压缩中的信息覆盖和分配不协调问题，仅增加1%参数量即超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 长文本处理中，传统LLM注意力机制存在二次复杂度和KV缓存膨胀问题；现有方法依赖自注意力迭代压缩，但会导致跨层表征覆盖（layer collapse）和token压缩容量分配失衡，影响压缩效果。

Method: 设计冻结LLM参数的双阶段压缩机制：1. 深度传输（depth-wise）选择性地将多层表征融合到锚点token，缓解跨层覆盖；2. 宽度传输（width-wise）通过全局优化传输方案，协调锚点token的信息分配至压缩槽位，实现信息容量均衡分配。

Result: 在6个问答任务中，ComprExIT对比SOTA方法提升绝对值达12.7%，且参数增量仅1%，推理速度提升3倍，在32k-131k上下文长度测试中保持稳定性能。

Conclusion: 显式分离压缩过程与LLM内部注意力动态（即解耦），并通过分层/分维度的协调压缩设计，显著提升长上下文压缩效率和鲁棒性，为LLM扩展应用提供了轻量级解决方案。

Abstract: Long-context inference with Large Language Models (LLMs) is costly due to quadratic attention and growing key-value caches, motivating context compression. In this work, we study soft context compression, where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states. This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors, mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.

</details>


### [151] [They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References](https://arxiv.org/abs/2602.03822)
*Sahil Tripathi,Gautam Siddharth Kashyap,Mehwish Nasim,Jian Yang,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: CROSS-ALIGN+是一个三阶段框架，通过知识增强、参数高效微调和解释生成，解决模因滥用检测中的文化盲点、边界模糊和缺乏可解释性问题，显著提升性能并提供决策依据。


<details>
  <summary>Details</summary>
Motivation: 针对模因滥用检测中传统方法的文化盲点、滥用与讽刺边界模糊、模型推理不可解释等局限性，需构建综合解决方案增强检测效果和可解释性。

Method: 三阶段框架：1) 知识增强（ConceptNet/Wikidata/Hatebase结构化知识融合多模态表征）；2) LoRA适配器锐化决策边界；3) 级联解释生成。

Result: 在5个基准数据集和8个LVLM上实验显示，相较SOTA方法F1值提升17%，且具有决策可解释性。

Conclusion: CROSS-ALIGN+有效解决模因检测三重挑战，兼顾性能提升与模型透明度，为敏感内容过滤提供新范式。

Abstract: Meme-based social abuse detection is challenging because harmful intent often relies on implicit cultural symbolism and subtle cross-modal incongruence. Prior approaches, from fusion-based methods to in-context learning with Large Vision-Language Models (LVLMs), have made progress but remain limited by three factors: i) cultural blindness (missing symbolic context), ii) boundary ambiguity (satire vs. abuse confusion), and iii) lack of interpretability (opaque model reasoning). We introduce CROSS-ALIGN+, a three-stage framework that systematically addresses these limitations: (1) Stage I mitigates cultural blindness by enriching multimodal representations with structured knowledge from ConceptNet, Wikidata, and Hatebase; (2) Stage II reduces boundary ambiguity through parameter-efficient LoRA adapters that sharpen decision boundaries; and (3) Stage III enhances interpretability by generating cascaded explanations. Extensive experiments on five benchmarks and eight LVLMs demonstrate that CROSS-ALIGN+ consistently outperforms state-of-the-art methods, achieving up to 17% relative F1 improvement while providing interpretable justifications for each decision.

</details>


### [152] [Accelerating Scientific Research with Gemini: Case Studies and Common Techniques](https://arxiv.org/abs/2602.03837)
*David P. Woodruff,Vincent Cohen-Addad,Lalit Jain,Jieming Mao,Song Zuo,MohammadHossein Bateni,Simina Branzei,Michael P. Brenner,Lin Chen,Ying Feng,Lance Fortnow,Gang Fu,Ziyi Guan,Zahra Hadizadeh,Mohammad T. Hajiaghayi,Mahdi JafariRaviz,Adel Javanmard,Karthik C. S.,Ken-ichi Kawarabayashi,Ravi Kumar,Silvio Lattanzi,Euiwoong Lee,Yi Li,Ioannis Panageas,Dimitris Paparas,Benjamin Przybocki,Bernardo Subercaseaux,Ola Svensson,Shayan Taherijam,Xuan Wu,Eylon Yogev,Morteza Zadimoghaddam,Samson Zhou,Vahab Mirrokni*

Main category: cs.CL

TL;DR: Advanced AI models aid in novel scientific discovery through collaborative problem-solving, enhancing human capabilities in mathematics and theoretical research.


<details>
  <summary>Details</summary>
Motivation: LLMs increasingly assist routine tasks, but their ability to contribute meaningfully to expert-level mathematical discovery remains unproven. The paper seeks to demonstrate their effectiveness in rigorous, creative theoretical research collaboration.

Method: Case studies analyze human-AI collaboration with Gemini models using techniques like iterative refinement, problem decomposition, cross-domain knowledge transfer, adversarial proof verification, and neuro-symbolic code-execution loops for automated validation.

Result: Successful AI-human partnerships solved open problems, refuted conjectures, generated proofs across disciplines, exposed mathematical flaws via rigorous adversarial review, and validated complex derivations through autonomous code execution.

Conclusion: AI systems evolve from automation tools to active collaborators in scientific discovery through optimized interaction paradigms, transforming mathematical research workflows and expanding discovery potential.

Abstract: Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a "neuro-symbolic" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.

</details>


### [153] [Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing](https://arxiv.org/abs/2602.03845)
*Tong Zheng,Chengsong Huang,Runpeng Dai,Yun He,Rui Liu,Xin Ni,Huiwen Bao,Kaishen Wang,Hongtu Zhu,Jiaxin Huang,Furong Huang,Heng Huang*

Main category: cs.CL

TL;DR: 引入2D探测框架与无训练控制器Parallel-Probe，优化并行推理的宽度与深度分配，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有并行推理效率方法依赖局部信号，缺乏全局动态利用机制，导致计算负担过重。

Method: 通过2D探测周期捕获中间答案，揭示宽度-深度动态特性，提出基于共识的早停策略和基于偏离的分支剪枝算法。

Result: 在三个基准数据集上，相比多数投票法降低序列计算量35.8%，总成本降低25.8%，保持高精度。

Conclusion: 通过揭示全局动态特性并设计高效控制器，为并行推理建立了更优的权衡前沿。

Abstract: Parallel thinking has emerged as a promising paradigm for reasoning, yet it imposes significant computational burdens. Existing efficiency methods primarily rely on local, per-trajectory signals and lack principled mechanisms to exploit global dynamics across parallel branches. We introduce 2D probing, an interface that exposes the width-depth dynamics of parallel thinking by periodically eliciting intermediate answers from all branches. Our analysis reveals three key insights: non-monotonic scaling across width-depth allocations, heterogeneous reasoning branch lengths, and early stabilization of global consensus. Guided by these insights, we introduce $\textbf{Parallel-Probe}$, a training-free controller designed to optimize online parallel thinking. Parallel-Probe employs consensus-based early stopping to regulate reasoning depth and deviation-based branch pruning to dynamically adjust width. Extensive experiments across three benchmarks and multiple models demonstrate that Parallel-Probe establishes a superior Pareto frontier for test-time scaling. Compared to standard majority voting, it reduces sequential tokens by up to $\textbf{35.8}$% and total token cost by over $\textbf{25.8}$% while maintaining competitive accuracy.

</details>
